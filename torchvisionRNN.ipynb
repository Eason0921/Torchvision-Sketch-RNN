{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7348c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch.autograd import Variable  # 导入torch中Variable模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dabd6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b399d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HParams超参数类\n",
    "class HParams():\n",
    "    def __init__(self):\n",
    "        self.data_location = './cat.npz'\n",
    "        self.enc_hidden_size = 256#encoder\n",
    "        self.dec_hidden_size = 512#decoder\n",
    "        \n",
    "        self.Nz = 128#latent vector size\n",
    "        self.input_size = 5#输入数据的特征维数[sqe_length,batch_size,input_size],h0,c0        \n",
    "        self.M = 20#高斯混合数\n",
    "        self.dropout = 0.1\n",
    "        self.batch_size = 128\n",
    "        self.eta_min = 0.01#最小学习率\n",
    "        self.R = 0.99995 # KL annealing decay rate per minibatch\n",
    "        self.KL_min = 0.2# Level of KL loss at which to stop optimizing for KL\n",
    "        self.wKL = 1# KL weight of loss equation. Recommend 0.5 or 1.0.\n",
    "        #0.5\n",
    "        self.lr = 0.001\n",
    "        self.lr_decay = 0.9999# Learning rate decay per minibatch.\n",
    "        self.min_lr = 0.00001\n",
    "        \n",
    "        self.grad_clip = 1.0 # Gradient clipping. Recommend leaving at 1.0.\n",
    "        self.temperature = 0.4\n",
    "        self.max_seq_length = 200\n",
    "hp = HParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18329d",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb7711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(strokes):\n",
    "    \"\"\"Return the maximum length of an array of strokes.\"\"\"\n",
    "    max_len = 0\n",
    "    max_len = 0\n",
    "    for stroke in strokes:\n",
    "        ml = len(stroke)\n",
    "        if ml > max_len:\n",
    "            max_len = ml\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30509843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normalizing_scale_factor(strokes):\n",
    "    \"\"\"Calculate the normalizing factor explained in appendix of sketch-rnn.\"\"\"\n",
    "    data = []\n",
    "    for i in range(len(strokes)):\n",
    "        for j in range(len(strokes[i])):\n",
    "            data.append(strokes[i][j, 0])\n",
    "            data.append(strokes[i][j, 1])\n",
    "    data = np.array(data)\n",
    "    return np.std(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c250137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#预处理：确定范围，以最大seq长度筛选，除以scale factor\n",
    "def preprocess(strokes):\n",
    "    \"\"\"Remove entries from strokes having > max_seq_length points.\"\"\"\n",
    "    data = []\n",
    "    scale_factor = calculate_normalizing_scale_factor(strokes)\n",
    "    for seq in strokes:\n",
    "        if seq.shape[0] <= hp.max_seq_length :\n",
    "            seq = np.minimum(seq, 1000)#limit=1000\n",
    "            seq = np.maximum(seq, -1000)\n",
    "            seq = np.array(seq, dtype=np.float32)\n",
    "            seq[:,0:2]/=scale_factor\n",
    "            data.append(seq)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08d0563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(strokes):\n",
    "    \"\"\"Normalize entire dataset (delta_x, delta_y) by the scaling factor.\"\"\"\n",
    "    data = []\n",
    "    scale_factor = calculate_normalizing_scale_factor(strokes)\n",
    "    for seq in strokes:\n",
    "        seq[:, 0:2] /= scale_factor\n",
    "        data.append(seq)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "054bf86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.load(hp.data_location, encoding='latin1',allow_pickle=True)\n",
    "data = dataset['train']\n",
    "data = preprocess(data)\n",
    "Nmax = get_max_len(data)\n",
    "Nmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94f83c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a batch:\n",
    "#随机抽取data的index，组成batchsize个为一组的batch，并由 x y 0/1转化为x y\n",
    "#0 0 1\n",
    "#返回batch和每个batch的点位数量序列\n",
    "#batch_size为100，在dim=1堆叠, size(200,100,5)\n",
    "def make_batch(batch_size):\n",
    "    batch_idx = np.random.choice(len(data),batch_size)\n",
    "    batch_sequences = [data[idx] for idx in batch_idx]#batch序列 大小为batch_size\n",
    "    strokes = []\n",
    "    lengths = []\n",
    "    indice = 0\n",
    "    for seq in batch_sequences:\n",
    "        len_seq = len(seq[:,0])\n",
    "        new_seq = np.zeros((Nmax,5))#返回batch和每个batch的点位数量序列.zeros((Nmax,5))\n",
    "        new_seq[:len_seq,:2] = seq[:,:2]\n",
    "        new_seq[:len_seq-1,2] = 1-seq[:-1,2]#0->1 0 0 1->0 1 0\n",
    "        new_seq[:len_seq,3] = seq[:,2]\n",
    "        new_seq[(len_seq-1):,4] = 1\n",
    "        new_seq[len_seq-1,2:4] = 0\n",
    "        lengths.append(len(seq[:,0]))#总长度\n",
    "        strokes.append(new_seq)#笔画数据集\n",
    "        indice += 1\n",
    "    #转化为tensor\n",
    "    batch = Variable(torch.from_numpy(np.stack(strokes,1)).cuda().float())\n",
    "    return batch, lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ccc3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ adaptive lr\n",
    "def lr_decay(optimizer):\n",
    "    \"\"\"Decay learning rate by a factor of lr_decay\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if param_group['lr']>hp.min_lr:\n",
    "            param_group['lr'] *= hp.lr_decay\n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc986391",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c71521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sketchRNN_encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sketchRNN_encoder,self).__init__()\n",
    "        self.lstm = nn.LSTM(5,hp.enc_hidden_size,bidirectional=True)\n",
    "        self.dropout = nn.Dropout(hp.dropout)\n",
    "        #使用全连接层从最后输出h获取向量μ和σ，大小为Nz\n",
    "        self.mu_function = nn.Linear(2*hp.enc_hidden_size,hp.Nz)\n",
    "        self.sigma_function= nn.Linear(2*hp.enc_hidden_size,hp.Nz)\n",
    "        \n",
    "        self.train()\n",
    "    def forward(self,inputs,batch_size):\n",
    "        #零初始化\n",
    "        h_0 = torch.zeros(2,batch_size,hp.enc_hidden_size).cuda()#bi-LSTM隐含状态\n",
    "        cell_0 = torch.zeros(2,batch_size,hp.enc_hidden_size).cuda()#bi-SLTM单元状态\n",
    "        h_cell_0 = (h_0,cell_0)\n",
    "        _,(h,cell) = self.lstm(inputs.float(),h_cell_0)\n",
    "        h_forward,h_backward = torch.split(self.dropout(h),1,0)#h_forward,h_backward[2,batchsize,hiddensize]->h[batchsize,2*hidden_size]\n",
    "        h_final = torch.cat([h_forward.squeeze(0),h_backward.squeeze(0)],1)\n",
    "        \n",
    "        #计算μ和σ\n",
    "        mu = self.mu_function(h_final)\n",
    "        sigma_hat = self.sigma_function(h_final)\n",
    "        sigma = torch.exp(sigma_hat/2.)\n",
    "        #计算z\n",
    "        z_size = mu.size()\n",
    "        N = torch.normal(torch.zeros(z_size),torch.ones(z_size)).cuda()#N~N(0,1)\n",
    "        z = mu + sigma*N#z=μ+σN\n",
    "        \n",
    "        return z,mu,sigma_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6354191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sketchRNN_decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sketchRNN_decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(hp.Nz+5, hp.dec_hidden_size)\n",
    "        self.dropout = nn.Dropout(hp.dropout)\n",
    "        # 从z初始化h&cell\n",
    "        self.h_cell_function = nn.Linear(hp.Nz, 2*hp.dec_hidden_size)\n",
    "        #初始化隐藏状态yi,yi=Wy hi + by,R^(6M+3)\n",
    "        self.yi_params_function = nn.Linear(hp.dec_hidden_size,6*hp.M+3)\n",
    "    def forward(self,inputs,z,h_cell_0=None):\n",
    "        \n",
    "        if h_cell_0 is None:\n",
    "            h_0,cell_0 = torch.split(torch.tanh(self.h_cell_function(z)),hp.dec_hidden_size,1)\n",
    "            h_cell_0 = (h_0.unsqueeze(0).contiguous(), cell_0.unsqueeze(0).contiguous())\n",
    "        outputs,(h,cell) = self.lstm(inputs, h_cell_0)\n",
    "        \n",
    "        #判断是train还是eval\n",
    "        #训练时使用最后一层输出特征outputs，验证使用最后一层隐藏层h\n",
    "        if self.training:\n",
    "            y = self.yi_params_function(outputs.view(-1,hp.dec_hidden_size))\n",
    "        else:\n",
    "            #eval()\n",
    "            y = self.yi_params_function(self.dropout(h).view(-1,hp.dec_hidden_size))\n",
    "        \n",
    "        params = torch.split(y,6,1)\n",
    "        params_mixture = torch.stack(params[:-1]) # trajectory\n",
    "        params_pen = params[-1]\n",
    "        # 获取各结果\n",
    "        pi,mu_x,mu_y,sigma_x,sigma_y,rho_xy = torch.split(params_mixture,1,2)\n",
    "        # preprocess params::\n",
    "        if self.training:\n",
    "            len_out = Nmax+1\n",
    "        else:\n",
    "            len_out = 1\n",
    "        pi = F.softmax(pi.transpose(0,1),dim=1).view(len_out,-1,hp.M)#[len_out,？，M]\n",
    "        mu_x = mu_x.transpose(0,1).squeeze().contiguous().view(len_out,-1,hp.M)\n",
    "        mu_y = mu_y.transpose(0,1).squeeze().contiguous().view(len_out,-1,hp.M)\n",
    "        sigma_x = torch.exp(sigma_x.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        sigma_y = torch.exp(sigma_y.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        rho_xy = torch.tanh(rho_xy.transpose(0,1).squeeze()).view(len_out,-1,hp.M)\n",
    "        q = F.softmax(params_pen,dim=1).view(len_out,-1,3)#k={1,2,3}\n",
    "        return pi,mu_x,mu_y,sigma_x,sigma_y,rho_xy,q,h,cell\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66707339",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sketchRNN_model():\n",
    "    def __init__(self):\n",
    "        self.encoder = sketchRNN_encoder().cuda()\n",
    "        self.decoder = sketchRNN_decoder().cuda()\n",
    "        \n",
    "        self.encoder_optimizer = optim.Adam(self.encoder.parameters(),hp.lr)\n",
    "        self.decoder_optimizer = optim.Adam(self.decoder.parameters(),hp.lr)\n",
    "        self.eta_step = hp.eta_min#最小学习率\n",
    "        \n",
    "    def make_target(self,batch,lengths):\n",
    "        #初始化Si为【0,0,0,0,1】，增加一个维度\n",
    "        eos = torch.stack([torch.Tensor([0,0,0,0,1])]*batch.size()[1]).cuda().unsqueeze(0)\n",
    "        #eos（1,100,5）\n",
    "        batch = torch.cat([batch,eos],0)\n",
    "        #batch (201,100,5)\n",
    "        mask = torch.zeros(Nmax+1, batch.size()[1])\n",
    "        #mask（201，100）\n",
    "        \n",
    "        for indice,length in enumerate(lengths):\n",
    "            #点位数序列\n",
    "            #解决RNN中输入有多种长度的问题，\n",
    "            #将所有有数值的地方填1，RNN跳过所有mask为0的输入\n",
    "            mask[:length,indice] = 1\n",
    "        mask = mask.cuda()\n",
    "        \n",
    "        dx = torch.stack([batch.data[:,:,0]]*hp.M,2)\n",
    "        dy = torch.stack([batch.data[:,:,1]]*hp.M,2)\n",
    "        p1 = batch.data[:,:,2]\n",
    "        p2 = batch.data[:,:,3]\n",
    "        p3 = batch.data[:,:,4]\n",
    "        p = torch.stack([p1,p2,p3],2)\n",
    "        return mask,dx,dy,p\n",
    "    \n",
    "    def train(self, epoch):\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "        batch, lengths = make_batch(hp.batch_size)\n",
    "        ##返回batch和每个batch的点位数量序列\n",
    "        #(200,100,5)\n",
    "        \n",
    "        # encode\n",
    "        z, self.mu, self.sigma = self.encoder(batch, hp.batch_size)\n",
    "        \n",
    "        # create start of sequence（sos）:拓展一维(1,100,5)\n",
    "        sos = torch.stack([torch.Tensor([0,0,1,0,0])]*hp.batch_size).cuda().unsqueeze(0)\n",
    "        \n",
    "        # had sos at the begining of the batch:\n",
    "        #按行拼接(201,100,5)\n",
    "        batch_init = torch.cat([sos, batch],0)\n",
    "        # expend z to be ready to concatenate with inputs:\n",
    "        z_stack = torch.stack([z]*(Nmax+1))#(201,[z])\n",
    "        # inputs is concatenation of z and batch_inputs\n",
    "        #加在dim=2\n",
    "        inputs = torch.cat([batch_init, z_stack],2)\n",
    "        ##########################################\n",
    "        \n",
    "        # decode:\n",
    "        self.pi, self.mu_x, self.mu_y, self.sigma_x, self.sigma_y, \\\n",
    "            self.rho_xy, self.q, _, _ = self.decoder(inputs, z)\n",
    "        # prepare targets:\n",
    "        \n",
    "        mask,dx,dy,p = self.make_target(batch, lengths)\n",
    "        \n",
    "        # prepare optimizers:\n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_optimizer.zero_grad()\n",
    "        \n",
    "        # update eta for LKL:\n",
    "        self.eta_step = 1-(1-hp.eta_min)*hp.R\n",
    "        # compute losses:\n",
    "        LKL = self.kullback_leibler_loss()\n",
    "        LR = self.reconstruction_loss(mask,dx,dy,p,epoch)\n",
    "        loss = LR + LKL\n",
    "        \n",
    "        # gradient step\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient cliping\n",
    "        nn.utils.clip_grad_norm_(self.encoder.parameters(), hp.grad_clip)\n",
    "        nn.utils.clip_grad_norm_(self.decoder.parameters(), hp.grad_clip)\n",
    "        \n",
    "        # optim step\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()\n",
    "        # some print and save:\n",
    "        if epoch%1==0:\n",
    "            print('epoch',epoch,'loss',format(loss.item(),'.4f'),'LR',format(LR.item(),'.4f'),'LKL',format(LKL.item(),'.4f'))\n",
    "            self.encoder_optimizer = lr_decay(self.encoder_optimizer)\n",
    "            self.decoder_optimizer = lr_decay(self.decoder_optimizer)\n",
    "        if epoch%100==0:\n",
    "            #self.save(epoch)\n",
    "            self.conditional_generation(epoch)\n",
    "\n",
    "    def bivariate_normal_pdf(self, dx, dy):\n",
    "        #求出双变量归一化pdf\n",
    "        #tf_2d_normal\n",
    "        z_x = ((dx-self.mu_x)/self.sigma_x)**2\n",
    "        z_y = ((dy-self.mu_y)/self.sigma_y)**2\n",
    "        z_xy = (dx-self.mu_x)*(dy-self.mu_y)/(self.sigma_x*self.sigma_y)\n",
    "        z = z_x + z_y -2*self.rho_xy*z_xy\n",
    "        exp = torch.exp(-z/(2*(1-self.rho_xy**2)))\n",
    "        norm = 2*np.pi*self.sigma_x*self.sigma_y*torch.sqrt(1-self.rho_xy**2)\n",
    "        return exp/norm\n",
    "\n",
    "    def reconstruction_loss(self, mask, dx, dy, p, epoch):\n",
    "        pdf = self.bivariate_normal_pdf(dx, dy)\n",
    "        #equation9 epsilon=1e5\n",
    "#         result1 = torch.sum(self.pi*pdf,2)\n",
    "#         result1 = torch.mul(self.pi,pdf)\n",
    "#         result1 = torch.sum(result1,1,keepdim=True)\n",
    "# #         result2 = torch.sum(result)\n",
    "#         result1 = -torch.log(1e-6+result1)\n",
    "#         mask = torch.reshape(mask,[-1,1])\n",
    "#         LS = torch.mul(mask,result1)/float(Nmax*hp.batch_size)\n",
    "#         LS = torch.sum(mask*result1)/float(Nmax*hp.batch_size)\n",
    "#         LS = -torch.sum(mask*torch.log(1e-5+torch.mul(self.pi * pdf))/float(Nmax*hp.batch_size)\n",
    "        LS = -torch.sum(mask*torch.log(1e-6+torch.sum(self.pi * pdf, 2)))\\\n",
    "            /float(Nmax*hp.batch_size)\n",
    "        #sum(self.pi * pdf, 2)：对应dim=2维度相加，相当于每行跨列相加求和\n",
    "        LP = -torch.sum(p*torch.log(self.q))/float(Nmax*hp.batch_size)\n",
    "        LR = LS+LP\n",
    "        LR = torch.mean(LR)\n",
    "#         print(\"LS:\",LS,\" LP:\",LP)\n",
    "        return LR\n",
    "\n",
    "    def kullback_leibler_loss(self):\n",
    "        LKL = -0.5*torch.sum(1+self.sigma-self.mu**2-torch.exp(self.sigma))\\\n",
    "            /float(hp.Nz*hp.batch_size)\n",
    "        KL_min = Variable(torch.Tensor([hp.KL_min]).cuda()).detach()\n",
    "        return hp.wKL*self.eta_step * torch.max(LKL,KL_min)\n",
    "    #self.kl_cost = tf.maximum(self.kl_cost, self.hps.kl_tolerance)\n",
    "\n",
    "    def save(self, epoch):\n",
    "        sel = np.random.rand()\n",
    "        torch.save(self.encoder.state_dict(), \\\n",
    "            'encoderRNN_sel_%3f_epoch_%d.pth' % (sel,epoch))\n",
    "        torch.save(self.decoder.state_dict(), \\\n",
    "            'decoderRNN_sel_%3f_epoch_%d.pth' % (sel,epoch))\n",
    "\n",
    "    def load(self, encoder_name, decoder_name):\n",
    "        saved_encoder = torch.load(encoder_name)\n",
    "        saved_decoder = torch.load(decoder_name)\n",
    "        self.encoder.load_state_dict(saved_encoder)\n",
    "        self.decoder.load_state_dict(saved_decoder)\n",
    "\n",
    "    def conditional_generation(self, epoch):\n",
    "        batch,lengths = make_batch(1)\n",
    "        # batchsize = 1\n",
    "        # should remove dropouts:\n",
    "        self.encoder.train(False)\n",
    "        self.decoder.train(False)\n",
    "        # encode:\n",
    "        z, _, _ = self.encoder(batch, 1)\n",
    "        # batchsize = 1\n",
    "\n",
    "        sos = Variable(torch.Tensor([0,0,1,0,0]).view(1,1,-1).cuda())\n",
    "        s = sos\n",
    "        seq_x = []\n",
    "        seq_y = []\n",
    "        seq_z = []\n",
    "        hidden_cell = None\n",
    "        for i in range(Nmax):\n",
    "            input = torch.cat([s,z.unsqueeze(0)],2)\n",
    "            # decode:\n",
    "            self.pi, self.mu_x, self.mu_y, self.sigma_x, self.sigma_y, \\\n",
    "                self.rho_xy, self.q, hidden, cell = self.decoder(input, z, hidden_cell)\n",
    "            hidden_cell = (hidden, cell)\n",
    "            # sample from parameters:\n",
    "            s, dx, dy, pen_down, eos = self.sample_next_state()\n",
    "            #------\n",
    "            seq_x.append(dx)\n",
    "            seq_y.append(dy)\n",
    "            seq_z.append(pen_down)\n",
    "            if eos:\n",
    "                print(i)\n",
    "                break\n",
    "        # visualize result:\n",
    "        x_sample = np.cumsum(seq_x, 0)\n",
    "        y_sample = np.cumsum(seq_y, 0)\n",
    "        z_sample = np.array(seq_z)\n",
    "        sequence = np.stack([x_sample,y_sample,z_sample]).T\n",
    "        make_image(sequence, epoch)\n",
    "\n",
    "    def sample_next_state(self):\n",
    "\n",
    "        def adjust_temp(pi_pdf):\n",
    "            pi_pdf = np.log(pi_pdf)/hp.temperature\n",
    "            pi_pdf -= pi_pdf.max()\n",
    "            pi_pdf = np.exp(pi_pdf)\n",
    "            pi_pdf /= pi_pdf.sum()\n",
    "            return pi_pdf\n",
    "\n",
    "        # get mixture indice:\n",
    "        pi = self.pi.data[0,0,:].cpu().numpy()\n",
    "        pi = adjust_temp(pi)\n",
    "        pi_idx = np.random.choice(hp.M, p=pi)\n",
    "        # get pen state:\n",
    "        q = self.q.data[0,0,:].cpu().numpy()\n",
    "        q = adjust_temp(q)\n",
    "        q_idx = np.random.choice(3, p=q)\n",
    "        # get mixture params:\n",
    "        mu_x = self.mu_x.data[0,0,pi_idx]\n",
    "        mu_y = self.mu_y.data[0,0,pi_idx]\n",
    "        sigma_x = self.sigma_x.data[0,0,pi_idx]\n",
    "        sigma_y = self.sigma_y.data[0,0,pi_idx]\n",
    "        rho_xy = self.rho_xy.data[0,0,pi_idx]\n",
    "        x,y = sample_bivariate_normal(mu_x,mu_y,sigma_x,sigma_y,rho_xy,greedy=False)\n",
    "        next_state = torch.zeros(5)\n",
    "        next_state[0] = x\n",
    "        next_state[1] = y\n",
    "        next_state[q_idx+2] = 1\n",
    "        if use_cuda:\n",
    "            return Variable(next_state.cuda()).view(1,1,-1),x,y,q_idx==1,q_idx==2\n",
    "        else:\n",
    "            return Variable(next_state).view(1,1,-1),x,y,q_idx==1,q_idx==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "031fbcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_bivariate_normal(mu_x,mu_y,sigma_x,sigma_y,rho_xy, greedy=False):\n",
    "    # inputs must be floats\n",
    "    if greedy:\n",
    "      return mu_x,mu_y\n",
    "    mean = [mu_x, mu_y]\n",
    "    sigma_x *= np.sqrt(hp.temperature)\n",
    "    sigma_y *= np.sqrt(hp.temperature)\n",
    "    cov = [[sigma_x * sigma_x, rho_xy * sigma_x * sigma_y],\\\n",
    "        [rho_xy * sigma_x * sigma_y, sigma_y * sigma_y]]\n",
    "    x = np.random.multivariate_normal(mean, cov, 1)\n",
    "    return x[0][0], x[0][1]\n",
    "\n",
    "def make_image(sequence, epoch, name='_output_'):\n",
    "    \"\"\"plot drawing with separated strokes\"\"\"\n",
    "    strokes = np.split(sequence, np.where(sequence[:,2]>0)[0]+1)\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    for s in strokes:\n",
    "        plt.plot(s[:,0],-s[:,1])\n",
    "    canvas = plt.get_current_fig_manager().canvas\n",
    "    canvas.draw()\n",
    "    pil_image = PIL.Image.frombytes('RGB', canvas.get_width_height(),\n",
    "                 canvas.tostring_rgb())\n",
    "    name = str(epoch)+name+'.jpg'\n",
    "    pil_image.save(name,\"JPEG\")\n",
    "    plt.close(\"all\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "156f4df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 2.5350 LR 2.5329 LKL 0.0020\n",
      "4\n",
      "epoch 1 loss 2.4254 LR 2.4234 LKL 0.0020\n",
      "epoch 2 loss 2.3512 LR 2.3492 LKL 0.0020\n",
      "epoch 3 loss 2.3851 LR 2.3830 LKL 0.0020\n",
      "epoch 4 loss 2.3245 LR 2.3224 LKL 0.0020\n",
      "epoch 5 loss 2.1063 LR 2.1043 LKL 0.0020\n",
      "epoch 6 loss 2.0701 LR 2.0681 LKL 0.0020\n",
      "epoch 7 loss 2.1095 LR 2.1075 LKL 0.0020\n",
      "epoch 8 loss 2.2341 LR 2.2321 LKL 0.0020\n",
      "epoch 9 loss 2.0296 LR 2.0276 LKL 0.0020\n",
      "epoch 10 loss 1.8773 LR 1.8753 LKL 0.0020\n",
      "epoch 11 loss 1.8531 LR 1.8511 LKL 0.0020\n",
      "epoch 12 loss 1.8231 LR 1.8211 LKL 0.0020\n",
      "epoch 13 loss 1.8801 LR 1.8781 LKL 0.0020\n",
      "epoch 14 loss 1.6428 LR 1.6408 LKL 0.0020\n",
      "epoch 15 loss 1.6390 LR 1.6370 LKL 0.0020\n",
      "epoch 16 loss 1.7140 LR 1.7120 LKL 0.0020\n",
      "epoch 17 loss 1.5738 LR 1.5718 LKL 0.0020\n",
      "epoch 18 loss 1.6121 LR 1.6101 LKL 0.0020\n",
      "epoch 19 loss 1.5828 LR 1.5808 LKL 0.0020\n",
      "epoch 20 loss 1.6875 LR 1.6855 LKL 0.0020\n",
      "epoch 21 loss 1.5661 LR 1.5641 LKL 0.0020\n",
      "epoch 22 loss 1.5928 LR 1.5908 LKL 0.0020\n",
      "epoch 23 loss 1.5965 LR 1.5944 LKL 0.0020\n",
      "epoch 24 loss 1.5596 LR 1.5576 LKL 0.0020\n",
      "epoch 25 loss 1.5869 LR 1.5849 LKL 0.0020\n",
      "epoch 26 loss 1.6352 LR 1.6332 LKL 0.0020\n",
      "epoch 27 loss 1.5208 LR 1.5188 LKL 0.0020\n",
      "epoch 28 loss 1.4624 LR 1.4604 LKL 0.0020\n",
      "epoch 29 loss 1.4630 LR 1.4609 LKL 0.0020\n",
      "epoch 30 loss 1.4651 LR 1.4631 LKL 0.0020\n",
      "epoch 31 loss 1.3142 LR 1.3122 LKL 0.0020\n",
      "epoch 32 loss 1.4359 LR 1.4338 LKL 0.0020\n",
      "epoch 33 loss 1.3335 LR 1.3315 LKL 0.0020\n",
      "epoch 34 loss 1.4023 LR 1.4003 LKL 0.0020\n",
      "epoch 35 loss 1.4878 LR 1.4858 LKL 0.0020\n",
      "epoch 36 loss 1.4030 LR 1.4010 LKL 0.0020\n",
      "epoch 37 loss 1.3877 LR 1.3857 LKL 0.0020\n",
      "epoch 38 loss 1.4590 LR 1.4570 LKL 0.0020\n",
      "epoch 39 loss 1.4301 LR 1.4281 LKL 0.0020\n",
      "epoch 40 loss 1.3795 LR 1.3775 LKL 0.0020\n",
      "epoch 41 loss 1.3691 LR 1.3671 LKL 0.0020\n",
      "epoch 42 loss 1.3719 LR 1.3699 LKL 0.0020\n",
      "epoch 43 loss 1.4109 LR 1.4089 LKL 0.0020\n",
      "epoch 44 loss 1.3390 LR 1.3370 LKL 0.0020\n",
      "epoch 45 loss 1.3166 LR 1.3146 LKL 0.0020\n",
      "epoch 46 loss 1.3672 LR 1.3652 LKL 0.0020\n",
      "epoch 47 loss 1.4372 LR 1.4352 LKL 0.0020\n",
      "epoch 48 loss 1.2982 LR 1.2962 LKL 0.0020\n",
      "epoch 49 loss 1.2729 LR 1.2709 LKL 0.0020\n",
      "epoch 50 loss 1.2996 LR 1.2976 LKL 0.0020\n",
      "epoch 51 loss 1.3139 LR 1.3119 LKL 0.0020\n",
      "epoch 52 loss 1.3419 LR 1.3397 LKL 0.0022\n",
      "epoch 53 loss 1.2849 LR 1.2818 LKL 0.0030\n",
      "epoch 54 loss 1.3772 LR 1.3735 LKL 0.0037\n",
      "epoch 55 loss 1.2759 LR 1.2714 LKL 0.0045\n",
      "epoch 56 loss 1.2933 LR 1.2874 LKL 0.0059\n",
      "epoch 57 loss 1.3341 LR 1.3283 LKL 0.0058\n",
      "epoch 58 loss 1.2204 LR 1.2139 LKL 0.0065\n",
      "epoch 59 loss 1.1877 LR 1.1824 LKL 0.0053\n",
      "epoch 60 loss 1.1697 LR 1.1652 LKL 0.0045\n",
      "epoch 61 loss 1.2151 LR 1.2110 LKL 0.0041\n",
      "epoch 62 loss 1.2442 LR 1.2404 LKL 0.0037\n",
      "epoch 63 loss 1.2795 LR 1.2759 LKL 0.0036\n",
      "epoch 64 loss 1.1997 LR 1.1960 LKL 0.0036\n",
      "epoch 65 loss 1.1867 LR 1.1829 LKL 0.0038\n",
      "epoch 66 loss 1.2088 LR 1.2047 LKL 0.0041\n",
      "epoch 67 loss 1.2821 LR 1.2776 LKL 0.0045\n",
      "epoch 68 loss 1.1935 LR 1.1888 LKL 0.0047\n",
      "epoch 69 loss 1.2437 LR 1.2384 LKL 0.0053\n",
      "epoch 70 loss 1.1692 LR 1.1645 LKL 0.0047\n",
      "epoch 71 loss 1.1540 LR 1.1498 LKL 0.0043\n",
      "epoch 72 loss 1.2050 LR 1.2009 LKL 0.0041\n",
      "epoch 73 loss 1.2610 LR 1.2570 LKL 0.0039\n",
      "epoch 74 loss 1.1798 LR 1.1759 LKL 0.0039\n",
      "epoch 75 loss 1.1221 LR 1.1181 LKL 0.0040\n",
      "epoch 76 loss 1.1988 LR 1.1947 LKL 0.0041\n",
      "epoch 77 loss 1.2191 LR 1.2150 LKL 0.0042\n",
      "epoch 78 loss 1.2056 LR 1.2014 LKL 0.0042\n",
      "epoch 79 loss 1.0946 LR 1.0903 LKL 0.0043\n",
      "epoch 80 loss 1.1345 LR 1.1300 LKL 0.0045\n",
      "epoch 81 loss 1.0766 LR 1.0720 LKL 0.0047\n",
      "epoch 82 loss 1.1632 LR 1.1584 LKL 0.0048\n",
      "epoch 83 loss 1.1488 LR 1.1437 LKL 0.0051\n",
      "epoch 84 loss 1.1489 LR 1.1434 LKL 0.0055\n",
      "epoch 85 loss 1.0988 LR 1.0930 LKL 0.0058\n",
      "epoch 86 loss 1.1134 LR 1.1071 LKL 0.0063\n",
      "epoch 87 loss 1.0904 LR 1.0836 LKL 0.0068\n",
      "epoch 88 loss 1.1173 LR 1.1100 LKL 0.0073\n",
      "epoch 89 loss 1.0342 LR 1.0265 LKL 0.0078\n",
      "epoch 90 loss 1.0924 LR 1.0846 LKL 0.0078\n",
      "epoch 91 loss 1.0961 LR 1.0884 LKL 0.0077\n",
      "epoch 92 loss 1.0996 LR 1.0925 LKL 0.0070\n",
      "epoch 93 loss 1.0473 LR 1.0408 LKL 0.0065\n",
      "epoch 94 loss 1.1322 LR 1.1262 LKL 0.0060\n",
      "epoch 95 loss 1.0907 LR 1.0850 LKL 0.0057\n",
      "epoch 96 loss 1.0317 LR 1.0261 LKL 0.0056\n",
      "epoch 97 loss 1.0702 LR 1.0648 LKL 0.0054\n",
      "epoch 98 loss 1.0485 LR 1.0433 LKL 0.0052\n",
      "epoch 99 loss 1.0696 LR 1.0645 LKL 0.0051\n",
      "epoch 100 loss 1.0770 LR 1.0720 LKL 0.0050\n",
      "epoch 101 loss 1.0352 LR 1.0301 LKL 0.0052\n",
      "epoch 102 loss 1.0342 LR 1.0288 LKL 0.0054\n",
      "epoch 103 loss 1.0521 LR 1.0464 LKL 0.0057\n",
      "epoch 104 loss 1.0163 LR 1.0103 LKL 0.0060\n",
      "epoch 105 loss 1.0449 LR 1.0385 LKL 0.0064\n",
      "epoch 106 loss 1.0551 LR 1.0483 LKL 0.0067\n",
      "epoch 107 loss 0.9385 LR 0.9315 LKL 0.0070\n",
      "epoch 108 loss 0.9839 LR 0.9768 LKL 0.0071\n",
      "epoch 109 loss 0.9434 LR 0.9362 LKL 0.0072\n",
      "epoch 110 loss 1.0620 LR 1.0547 LKL 0.0073\n",
      "epoch 111 loss 1.0100 LR 1.0027 LKL 0.0073\n",
      "epoch 112 loss 1.0131 LR 1.0058 LKL 0.0073\n",
      "epoch 113 loss 0.9890 LR 0.9817 LKL 0.0073\n",
      "epoch 114 loss 0.9402 LR 0.9329 LKL 0.0073\n",
      "epoch 115 loss 0.9967 LR 0.9894 LKL 0.0073\n",
      "epoch 116 loss 0.8996 LR 0.8922 LKL 0.0075\n",
      "epoch 117 loss 0.9639 LR 0.9562 LKL 0.0077\n",
      "epoch 118 loss 0.9700 LR 0.9621 LKL 0.0079\n",
      "epoch 119 loss 0.8876 LR 0.8794 LKL 0.0082\n",
      "epoch 120 loss 0.9020 LR 0.8936 LKL 0.0083\n",
      "epoch 121 loss 0.9975 LR 0.9890 LKL 0.0085\n",
      "epoch 122 loss 0.9120 LR 0.9031 LKL 0.0089\n",
      "epoch 123 loss 0.9564 LR 0.9471 LKL 0.0092\n",
      "epoch 124 loss 0.9856 LR 0.9762 LKL 0.0094\n",
      "epoch 125 loss 0.9060 LR 0.8965 LKL 0.0094\n",
      "epoch 126 loss 0.9099 LR 0.9005 LKL 0.0094\n",
      "epoch 127 loss 0.8781 LR 0.8687 LKL 0.0095\n",
      "epoch 128 loss 0.9169 LR 0.9071 LKL 0.0098\n",
      "epoch 129 loss 0.8977 LR 0.8877 LKL 0.0100\n",
      "epoch 130 loss 0.9277 LR 0.9174 LKL 0.0103\n",
      "epoch 131 loss 0.8790 LR 0.8686 LKL 0.0104\n",
      "epoch 132 loss 0.9087 LR 0.8985 LKL 0.0102\n",
      "epoch 133 loss 0.8830 LR 0.8730 LKL 0.0101\n",
      "epoch 134 loss 0.9265 LR 0.9166 LKL 0.0099\n",
      "epoch 135 loss 0.9034 LR 0.8936 LKL 0.0098\n",
      "epoch 136 loss 0.9233 LR 0.9136 LKL 0.0096\n",
      "epoch 137 loss 0.8538 LR 0.8445 LKL 0.0093\n",
      "epoch 138 loss 0.8879 LR 0.8788 LKL 0.0092\n",
      "epoch 139 loss 0.9760 LR 0.9670 LKL 0.0089\n",
      "epoch 140 loss 0.8931 LR 0.8841 LKL 0.0090\n",
      "epoch 141 loss 0.9181 LR 0.9093 LKL 0.0088\n",
      "epoch 142 loss 0.8587 LR 0.8497 LKL 0.0089\n",
      "epoch 143 loss 0.8344 LR 0.8254 LKL 0.0090\n",
      "epoch 144 loss 0.8331 LR 0.8241 LKL 0.0090\n",
      "epoch 145 loss 0.8884 LR 0.8796 LKL 0.0088\n",
      "epoch 146 loss 0.8805 LR 0.8716 LKL 0.0088\n",
      "epoch 147 loss 0.9044 LR 0.8955 LKL 0.0089\n",
      "epoch 148 loss 0.8197 LR 0.8107 LKL 0.0090\n",
      "epoch 149 loss 0.8318 LR 0.8227 LKL 0.0091\n",
      "epoch 150 loss 0.8864 LR 0.8770 LKL 0.0094\n",
      "epoch 151 loss 0.8035 LR 0.7940 LKL 0.0095\n",
      "epoch 152 loss 0.8433 LR 0.8339 LKL 0.0094\n",
      "epoch 153 loss 0.7890 LR 0.7799 LKL 0.0091\n",
      "epoch 154 loss 0.8091 LR 0.7999 LKL 0.0092\n",
      "epoch 155 loss 0.8342 LR 0.8250 LKL 0.0093\n",
      "epoch 156 loss 0.8450 LR 0.8355 LKL 0.0095\n",
      "epoch 157 loss 0.8303 LR 0.8206 LKL 0.0098\n",
      "epoch 158 loss 0.7690 LR 0.7590 LKL 0.0100\n",
      "epoch 159 loss 0.7686 LR 0.7583 LKL 0.0103\n",
      "epoch 160 loss 0.7948 LR 0.7847 LKL 0.0101\n",
      "epoch 161 loss 0.7683 LR 0.7582 LKL 0.0102\n",
      "epoch 162 loss 0.8677 LR 0.8574 LKL 0.0103\n",
      "epoch 163 loss 0.7916 LR 0.7812 LKL 0.0105\n",
      "epoch 164 loss 0.8154 LR 0.8050 LKL 0.0104\n",
      "epoch 165 loss 0.8088 LR 0.7984 LKL 0.0104\n",
      "epoch 166 loss 0.7440 LR 0.7332 LKL 0.0107\n",
      "epoch 167 loss 0.8497 LR 0.8389 LKL 0.0108\n",
      "epoch 168 loss 0.7913 LR 0.7805 LKL 0.0108\n",
      "epoch 169 loss 0.7860 LR 0.7755 LKL 0.0106\n",
      "epoch 170 loss 0.8292 LR 0.8187 LKL 0.0105\n",
      "epoch 171 loss 0.6959 LR 0.6855 LKL 0.0104\n",
      "epoch 172 loss 0.7116 LR 0.7012 LKL 0.0104\n",
      "epoch 173 loss 0.7659 LR 0.7556 LKL 0.0104\n",
      "epoch 174 loss 0.8241 LR 0.8138 LKL 0.0103\n",
      "epoch 175 loss 0.7079 LR 0.6976 LKL 0.0103\n",
      "epoch 176 loss 0.7906 LR 0.7805 LKL 0.0101\n",
      "epoch 177 loss 0.7434 LR 0.7334 LKL 0.0100\n",
      "epoch 178 loss 0.7821 LR 0.7719 LKL 0.0102\n",
      "epoch 179 loss 0.7806 LR 0.7704 LKL 0.0103\n",
      "epoch 180 loss 0.7878 LR 0.7774 LKL 0.0104\n",
      "epoch 181 loss 0.7779 LR 0.7673 LKL 0.0105\n",
      "epoch 182 loss 0.8012 LR 0.7906 LKL 0.0106\n",
      "epoch 183 loss 0.7078 LR 0.6971 LKL 0.0107\n",
      "epoch 184 loss 0.7429 LR 0.7321 LKL 0.0107\n",
      "epoch 185 loss 0.7042 LR 0.6935 LKL 0.0107\n",
      "epoch 186 loss 0.8189 LR 0.8081 LKL 0.0108\n",
      "epoch 187 loss 0.7455 LR 0.7349 LKL 0.0106\n",
      "epoch 188 loss 0.7415 LR 0.7310 LKL 0.0105\n",
      "epoch 189 loss 0.7510 LR 0.7405 LKL 0.0105\n",
      "epoch 190 loss 0.7375 LR 0.7269 LKL 0.0106\n",
      "epoch 191 loss 0.7251 LR 0.7143 LKL 0.0108\n",
      "epoch 192 loss 0.7392 LR 0.7289 LKL 0.0104\n",
      "epoch 193 loss 0.6686 LR 0.6586 LKL 0.0100\n",
      "epoch 194 loss 0.7597 LR 0.7499 LKL 0.0098\n",
      "epoch 195 loss 0.7174 LR 0.7076 LKL 0.0099\n",
      "epoch 196 loss 0.7172 LR 0.7072 LKL 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197 loss 0.6995 LR 0.6894 LKL 0.0101\n",
      "epoch 198 loss 0.7312 LR 0.7212 LKL 0.0101\n",
      "epoch 199 loss 0.7322 LR 0.7220 LKL 0.0102\n",
      "epoch 200 loss 0.6975 LR 0.6871 LKL 0.0104\n",
      "epoch 201 loss 0.7011 LR 0.6908 LKL 0.0103\n",
      "epoch 202 loss 0.6780 LR 0.6678 LKL 0.0102\n",
      "epoch 203 loss 0.7687 LR 0.7583 LKL 0.0104\n",
      "epoch 204 loss 0.7157 LR 0.7050 LKL 0.0107\n",
      "epoch 205 loss 0.7329 LR 0.7219 LKL 0.0110\n",
      "epoch 206 loss 0.7601 LR 0.7492 LKL 0.0109\n",
      "epoch 207 loss 0.6550 LR 0.6442 LKL 0.0107\n",
      "epoch 208 loss 0.6800 LR 0.6692 LKL 0.0108\n",
      "epoch 209 loss 0.6970 LR 0.6864 LKL 0.0106\n",
      "epoch 210 loss 0.6837 LR 0.6734 LKL 0.0103\n",
      "epoch 211 loss 0.6609 LR 0.6509 LKL 0.0100\n",
      "epoch 212 loss 0.7082 LR 0.6980 LKL 0.0102\n",
      "epoch 213 loss 0.6683 LR 0.6583 LKL 0.0101\n",
      "epoch 214 loss 0.6803 LR 0.6701 LKL 0.0103\n",
      "epoch 215 loss 0.6934 LR 0.6831 LKL 0.0102\n",
      "epoch 216 loss 0.7266 LR 0.7164 LKL 0.0101\n",
      "epoch 217 loss 0.6410 LR 0.6309 LKL 0.0100\n",
      "epoch 218 loss 0.7145 LR 0.7045 LKL 0.0100\n",
      "epoch 219 loss 0.6821 LR 0.6721 LKL 0.0100\n",
      "epoch 220 loss 0.6930 LR 0.6825 LKL 0.0105\n",
      "epoch 221 loss 0.7001 LR 0.6900 LKL 0.0101\n",
      "epoch 222 loss 0.6581 LR 0.6481 LKL 0.0100\n",
      "epoch 223 loss 0.7078 LR 0.6978 LKL 0.0100\n",
      "epoch 224 loss 0.6495 LR 0.6395 LKL 0.0100\n",
      "epoch 225 loss 0.7035 LR 0.6933 LKL 0.0102\n",
      "epoch 226 loss 0.6511 LR 0.6408 LKL 0.0103\n",
      "epoch 227 loss 0.6570 LR 0.6466 LKL 0.0104\n",
      "epoch 228 loss 0.6388 LR 0.6281 LKL 0.0107\n",
      "epoch 229 loss 0.7046 LR 0.6939 LKL 0.0107\n",
      "epoch 230 loss 0.6267 LR 0.6159 LKL 0.0108\n",
      "epoch 231 loss 0.6831 LR 0.6721 LKL 0.0110\n",
      "epoch 232 loss 0.6379 LR 0.6266 LKL 0.0113\n",
      "epoch 233 loss 0.7216 LR 0.7104 LKL 0.0112\n",
      "epoch 234 loss 0.6455 LR 0.6344 LKL 0.0111\n",
      "epoch 235 loss 0.6286 LR 0.6174 LKL 0.0112\n",
      "epoch 236 loss 0.6470 LR 0.6359 LKL 0.0111\n",
      "epoch 237 loss 0.6951 LR 0.6842 LKL 0.0109\n",
      "epoch 238 loss 0.7031 LR 0.6923 LKL 0.0108\n",
      "epoch 239 loss 0.6676 LR 0.6567 LKL 0.0109\n",
      "epoch 240 loss 0.6592 LR 0.6483 LKL 0.0108\n",
      "epoch 241 loss 0.6532 LR 0.6421 LKL 0.0110\n",
      "epoch 242 loss 0.6610 LR 0.6498 LKL 0.0112\n",
      "epoch 243 loss 0.6676 LR 0.6562 LKL 0.0114\n",
      "epoch 244 loss 0.6821 LR 0.6708 LKL 0.0113\n",
      "epoch 245 loss 0.7069 LR 0.6955 LKL 0.0113\n",
      "epoch 246 loss 0.6907 LR 0.6793 LKL 0.0113\n",
      "epoch 247 loss 0.6509 LR 0.6395 LKL 0.0114\n",
      "epoch 248 loss 0.6454 LR 0.6342 LKL 0.0112\n",
      "epoch 249 loss 0.6601 LR 0.6489 LKL 0.0112\n",
      "epoch 250 loss 0.6236 LR 0.6123 LKL 0.0113\n",
      "epoch 251 loss 0.6300 LR 0.6188 LKL 0.0112\n",
      "epoch 252 loss 0.6217 LR 0.6103 LKL 0.0113\n",
      "epoch 253 loss 0.6235 LR 0.6122 LKL 0.0113\n",
      "epoch 254 loss 0.6068 LR 0.5954 LKL 0.0114\n",
      "epoch 255 loss 0.6485 LR 0.6370 LKL 0.0114\n",
      "epoch 256 loss 0.6348 LR 0.6230 LKL 0.0118\n",
      "epoch 257 loss 0.6367 LR 0.6250 LKL 0.0117\n",
      "epoch 258 loss 0.6679 LR 0.6563 LKL 0.0116\n",
      "epoch 259 loss 0.6864 LR 0.6747 LKL 0.0117\n",
      "epoch 260 loss 0.6732 LR 0.6615 LKL 0.0117\n",
      "epoch 261 loss 0.6786 LR 0.6671 LKL 0.0115\n",
      "epoch 262 loss 0.6223 LR 0.6107 LKL 0.0116\n",
      "epoch 263 loss 0.6505 LR 0.6389 LKL 0.0116\n",
      "epoch 264 loss 0.6631 LR 0.6515 LKL 0.0116\n",
      "epoch 265 loss 0.7111 LR 0.6993 LKL 0.0119\n",
      "epoch 266 loss 0.6298 LR 0.6177 LKL 0.0121\n",
      "epoch 267 loss 0.6180 LR 0.6059 LKL 0.0121\n",
      "epoch 268 loss 0.6202 LR 0.6083 LKL 0.0119\n",
      "epoch 269 loss 0.6113 LR 0.5999 LKL 0.0114\n",
      "epoch 270 loss 0.6419 LR 0.6307 LKL 0.0113\n",
      "epoch 271 loss 0.5937 LR 0.5827 LKL 0.0111\n",
      "epoch 272 loss 0.5996 LR 0.5885 LKL 0.0111\n",
      "epoch 273 loss 0.6119 LR 0.6006 LKL 0.0114\n",
      "epoch 274 loss 0.6260 LR 0.6145 LKL 0.0115\n",
      "epoch 275 loss 0.6509 LR 0.6394 LKL 0.0115\n",
      "epoch 276 loss 0.6124 LR 0.6010 LKL 0.0114\n",
      "epoch 277 loss 0.6073 LR 0.5959 LKL 0.0115\n",
      "epoch 278 loss 0.6481 LR 0.6364 LKL 0.0118\n",
      "epoch 279 loss 0.5563 LR 0.5444 LKL 0.0119\n",
      "epoch 280 loss 0.6322 LR 0.6201 LKL 0.0121\n",
      "epoch 281 loss 0.6422 LR 0.6298 LKL 0.0123\n",
      "epoch 282 loss 0.5835 LR 0.5710 LKL 0.0125\n",
      "epoch 283 loss 0.6199 LR 0.6075 LKL 0.0124\n",
      "epoch 284 loss 0.5996 LR 0.5869 LKL 0.0127\n",
      "epoch 285 loss 0.5819 LR 0.5695 LKL 0.0124\n",
      "epoch 286 loss 0.6023 LR 0.5898 LKL 0.0125\n",
      "epoch 287 loss 0.6146 LR 0.6021 LKL 0.0125\n",
      "epoch 288 loss 0.6070 LR 0.5948 LKL 0.0122\n",
      "epoch 289 loss 0.6401 LR 0.6277 LKL 0.0124\n",
      "epoch 290 loss 0.6505 LR 0.6381 LKL 0.0124\n",
      "epoch 291 loss 0.5778 LR 0.5654 LKL 0.0124\n",
      "epoch 292 loss 0.5486 LR 0.5359 LKL 0.0127\n",
      "epoch 293 loss 0.5844 LR 0.5717 LKL 0.0127\n",
      "epoch 294 loss 0.5405 LR 0.5279 LKL 0.0126\n",
      "epoch 295 loss 0.5945 LR 0.5819 LKL 0.0126\n",
      "epoch 296 loss 0.6232 LR 0.6107 LKL 0.0125\n",
      "epoch 297 loss 0.5359 LR 0.5232 LKL 0.0127\n",
      "epoch 298 loss 0.6202 LR 0.6075 LKL 0.0127\n",
      "epoch 299 loss 0.5820 LR 0.5693 LKL 0.0127\n",
      "epoch 300 loss 0.5517 LR 0.5389 LKL 0.0127\n",
      "epoch 301 loss 0.5490 LR 0.5362 LKL 0.0128\n",
      "epoch 302 loss 0.5995 LR 0.5866 LKL 0.0129\n",
      "epoch 303 loss 0.5310 LR 0.5175 LKL 0.0134\n",
      "epoch 304 loss 0.5760 LR 0.5627 LKL 0.0133\n",
      "epoch 305 loss 0.5987 LR 0.5854 LKL 0.0133\n",
      "epoch 306 loss 0.5644 LR 0.5513 LKL 0.0131\n",
      "epoch 307 loss 0.5431 LR 0.5300 LKL 0.0132\n",
      "epoch 308 loss 0.5405 LR 0.5275 LKL 0.0130\n",
      "epoch 309 loss 0.5434 LR 0.5304 LKL 0.0130\n",
      "epoch 310 loss 0.5867 LR 0.5739 LKL 0.0128\n",
      "epoch 311 loss 0.5750 LR 0.5626 LKL 0.0124\n",
      "epoch 312 loss 0.5342 LR 0.5218 LKL 0.0124\n",
      "epoch 313 loss 0.5655 LR 0.5530 LKL 0.0125\n",
      "epoch 314 loss 0.6501 LR 0.6375 LKL 0.0125\n",
      "epoch 315 loss 0.5986 LR 0.5859 LKL 0.0127\n",
      "epoch 316 loss 0.5711 LR 0.5584 LKL 0.0127\n",
      "epoch 317 loss 0.6229 LR 0.6103 LKL 0.0125\n",
      "epoch 318 loss 0.5999 LR 0.5871 LKL 0.0128\n",
      "epoch 319 loss 0.5676 LR 0.5547 LKL 0.0130\n",
      "epoch 320 loss 0.5468 LR 0.5338 LKL 0.0130\n",
      "epoch 321 loss 0.5800 LR 0.5669 LKL 0.0131\n",
      "epoch 322 loss 0.5527 LR 0.5394 LKL 0.0133\n",
      "epoch 323 loss 0.5423 LR 0.5289 LKL 0.0134\n",
      "epoch 324 loss 0.5900 LR 0.5765 LKL 0.0135\n",
      "epoch 325 loss 0.5667 LR 0.5530 LKL 0.0137\n",
      "epoch 326 loss 0.5224 LR 0.5086 LKL 0.0138\n",
      "epoch 327 loss 0.5764 LR 0.5625 LKL 0.0139\n",
      "epoch 328 loss 0.5794 LR 0.5656 LKL 0.0138\n",
      "epoch 329 loss 0.5218 LR 0.5080 LKL 0.0138\n",
      "epoch 330 loss 0.5591 LR 0.5452 LKL 0.0139\n",
      "epoch 331 loss 0.6001 LR 0.5864 LKL 0.0137\n",
      "epoch 332 loss 0.5594 LR 0.5457 LKL 0.0138\n",
      "epoch 333 loss 0.5629 LR 0.5492 LKL 0.0137\n",
      "epoch 334 loss 0.4805 LR 0.4670 LKL 0.0135\n",
      "epoch 335 loss 0.5747 LR 0.5614 LKL 0.0133\n",
      "epoch 336 loss 0.5365 LR 0.5233 LKL 0.0133\n",
      "epoch 337 loss 0.5254 LR 0.5123 LKL 0.0131\n",
      "epoch 338 loss 0.5514 LR 0.5385 LKL 0.0130\n",
      "epoch 339 loss 0.5832 LR 0.5702 LKL 0.0130\n",
      "epoch 340 loss 0.5763 LR 0.5633 LKL 0.0130\n",
      "epoch 341 loss 0.5651 LR 0.5521 LKL 0.0130\n",
      "epoch 342 loss 0.5754 LR 0.5625 LKL 0.0129\n",
      "epoch 343 loss 0.5757 LR 0.5629 LKL 0.0128\n",
      "epoch 344 loss 0.5153 LR 0.5023 LKL 0.0130\n",
      "epoch 345 loss 0.6010 LR 0.5881 LKL 0.0129\n",
      "epoch 346 loss 0.4975 LR 0.4846 LKL 0.0129\n",
      "epoch 347 loss 0.5473 LR 0.5340 LKL 0.0133\n",
      "epoch 348 loss 0.4815 LR 0.4683 LKL 0.0133\n",
      "epoch 349 loss 0.5632 LR 0.5499 LKL 0.0132\n",
      "epoch 350 loss 0.5290 LR 0.5157 LKL 0.0133\n",
      "epoch 351 loss 0.5514 LR 0.5385 LKL 0.0129\n",
      "epoch 352 loss 0.5492 LR 0.5360 LKL 0.0132\n",
      "epoch 353 loss 0.5696 LR 0.5565 LKL 0.0131\n",
      "epoch 354 loss 0.5452 LR 0.5318 LKL 0.0134\n",
      "epoch 355 loss 0.5304 LR 0.5171 LKL 0.0133\n",
      "epoch 356 loss 0.5440 LR 0.5305 LKL 0.0135\n",
      "epoch 357 loss 0.5697 LR 0.5562 LKL 0.0135\n",
      "epoch 358 loss 0.5588 LR 0.5453 LKL 0.0136\n",
      "epoch 359 loss 0.5602 LR 0.5468 LKL 0.0134\n",
      "epoch 360 loss 0.5931 LR 0.5799 LKL 0.0132\n",
      "epoch 361 loss 0.5039 LR 0.4905 LKL 0.0134\n",
      "epoch 362 loss 0.5116 LR 0.4982 LKL 0.0134\n",
      "epoch 363 loss 0.5216 LR 0.5080 LKL 0.0136\n",
      "epoch 364 loss 0.5529 LR 0.5391 LKL 0.0138\n",
      "epoch 365 loss 0.6010 LR 0.5874 LKL 0.0136\n",
      "epoch 366 loss 0.5996 LR 0.5857 LKL 0.0138\n",
      "epoch 367 loss 0.5156 LR 0.5019 LKL 0.0136\n",
      "epoch 368 loss 0.5420 LR 0.5279 LKL 0.0141\n",
      "epoch 369 loss 0.5423 LR 0.5283 LKL 0.0140\n",
      "epoch 370 loss 0.5312 LR 0.5171 LKL 0.0141\n",
      "epoch 371 loss 0.5942 LR 0.5802 LKL 0.0140\n",
      "epoch 372 loss 0.4952 LR 0.4809 LKL 0.0144\n",
      "epoch 373 loss 0.5271 LR 0.5129 LKL 0.0142\n",
      "epoch 374 loss 0.4907 LR 0.4766 LKL 0.0141\n",
      "epoch 375 loss 0.5603 LR 0.5465 LKL 0.0138\n",
      "epoch 376 loss 0.4974 LR 0.4836 LKL 0.0138\n",
      "epoch 377 loss 0.5056 LR 0.4918 LKL 0.0138\n",
      "epoch 378 loss 0.5495 LR 0.5357 LKL 0.0138\n",
      "epoch 379 loss 0.5149 LR 0.5009 LKL 0.0140\n",
      "epoch 380 loss 0.5060 LR 0.4920 LKL 0.0140\n",
      "epoch 381 loss 0.5589 LR 0.5449 LKL 0.0140\n",
      "epoch 382 loss 0.5051 LR 0.4910 LKL 0.0141\n",
      "epoch 383 loss 0.5254 LR 0.5111 LKL 0.0144\n",
      "epoch 384 loss 0.5185 LR 0.5040 LKL 0.0145\n",
      "epoch 385 loss 0.5293 LR 0.5151 LKL 0.0142\n",
      "epoch 386 loss 0.5547 LR 0.5406 LKL 0.0141\n",
      "epoch 387 loss 0.5610 LR 0.5471 LKL 0.0139\n",
      "epoch 388 loss 0.4675 LR 0.4537 LKL 0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 389 loss 0.5513 LR 0.5378 LKL 0.0135\n",
      "epoch 390 loss 0.5236 LR 0.5100 LKL 0.0136\n",
      "epoch 391 loss 0.5478 LR 0.5343 LKL 0.0135\n",
      "epoch 392 loss 0.4817 LR 0.4682 LKL 0.0135\n",
      "epoch 393 loss 0.5117 LR 0.4980 LKL 0.0137\n",
      "epoch 394 loss 0.5672 LR 0.5535 LKL 0.0138\n",
      "epoch 395 loss 0.4484 LR 0.4343 LKL 0.0141\n",
      "epoch 396 loss 0.5261 LR 0.5121 LKL 0.0139\n",
      "epoch 397 loss 0.5014 LR 0.4872 LKL 0.0142\n",
      "epoch 398 loss 0.5175 LR 0.5035 LKL 0.0140\n",
      "epoch 399 loss 0.4978 LR 0.4838 LKL 0.0139\n",
      "epoch 400 loss 0.5149 LR 0.5009 LKL 0.0141\n",
      "epoch 401 loss 0.5804 LR 0.5662 LKL 0.0142\n",
      "epoch 402 loss 0.5095 LR 0.4952 LKL 0.0143\n",
      "epoch 403 loss 0.4982 LR 0.4838 LKL 0.0144\n",
      "epoch 404 loss 0.5386 LR 0.5245 LKL 0.0141\n",
      "epoch 405 loss 0.4861 LR 0.4721 LKL 0.0140\n",
      "epoch 406 loss 0.5091 LR 0.4950 LKL 0.0141\n",
      "epoch 407 loss 0.4999 LR 0.4857 LKL 0.0142\n",
      "epoch 408 loss 0.5280 LR 0.5139 LKL 0.0142\n",
      "epoch 409 loss 0.5748 LR 0.5605 LKL 0.0144\n",
      "epoch 410 loss 0.5212 LR 0.5070 LKL 0.0142\n",
      "epoch 411 loss 0.4850 LR 0.4707 LKL 0.0143\n",
      "epoch 412 loss 0.5050 LR 0.4908 LKL 0.0142\n",
      "epoch 413 loss 0.4832 LR 0.4690 LKL 0.0142\n",
      "epoch 414 loss 0.5023 LR 0.4879 LKL 0.0144\n",
      "epoch 415 loss 0.4857 LR 0.4713 LKL 0.0144\n",
      "epoch 416 loss 0.5332 LR 0.5187 LKL 0.0145\n",
      "epoch 417 loss 0.5078 LR 0.4932 LKL 0.0146\n",
      "epoch 418 loss 0.4753 LR 0.4604 LKL 0.0149\n",
      "epoch 419 loss 0.4428 LR 0.4279 LKL 0.0149\n",
      "epoch 420 loss 0.5107 LR 0.4956 LKL 0.0151\n",
      "epoch 421 loss 0.5467 LR 0.5316 LKL 0.0151\n",
      "epoch 422 loss 0.4953 LR 0.4805 LKL 0.0148\n",
      "epoch 423 loss 0.5251 LR 0.5102 LKL 0.0148\n",
      "epoch 424 loss 0.5489 LR 0.5345 LKL 0.0144\n",
      "epoch 425 loss 0.4980 LR 0.4833 LKL 0.0147\n",
      "epoch 426 loss 0.4813 LR 0.4666 LKL 0.0146\n",
      "epoch 427 loss 0.5086 LR 0.4938 LKL 0.0149\n",
      "epoch 428 loss 0.5307 LR 0.5157 LKL 0.0150\n",
      "epoch 429 loss 0.4998 LR 0.4846 LKL 0.0152\n",
      "epoch 430 loss 0.4957 LR 0.4805 LKL 0.0152\n",
      "epoch 431 loss 0.5296 LR 0.5145 LKL 0.0151\n",
      "epoch 432 loss 0.5310 LR 0.5158 LKL 0.0151\n",
      "epoch 433 loss 0.5060 LR 0.4910 LKL 0.0150\n",
      "epoch 434 loss 0.5056 LR 0.4906 LKL 0.0150\n",
      "epoch 435 loss 0.5140 LR 0.4988 LKL 0.0151\n",
      "epoch 436 loss 0.5072 LR 0.4920 LKL 0.0152\n",
      "epoch 437 loss 0.4849 LR 0.4700 LKL 0.0149\n",
      "epoch 438 loss 0.5162 LR 0.5012 LKL 0.0150\n",
      "epoch 439 loss 0.5868 LR 0.5720 LKL 0.0149\n",
      "epoch 440 loss 0.4966 LR 0.4816 LKL 0.0150\n",
      "epoch 441 loss 0.5060 LR 0.4914 LKL 0.0146\n",
      "epoch 442 loss 0.4728 LR 0.4583 LKL 0.0144\n",
      "epoch 443 loss 0.4639 LR 0.4494 LKL 0.0145\n",
      "epoch 444 loss 0.4834 LR 0.4686 LKL 0.0148\n",
      "epoch 445 loss 0.5352 LR 0.5204 LKL 0.0148\n",
      "epoch 446 loss 0.5170 LR 0.5020 LKL 0.0150\n",
      "epoch 447 loss 0.5132 LR 0.4981 LKL 0.0151\n",
      "epoch 448 loss 0.5128 LR 0.4978 LKL 0.0150\n",
      "epoch 449 loss 0.4675 LR 0.4525 LKL 0.0150\n",
      "epoch 450 loss 0.4589 LR 0.4438 LKL 0.0151\n",
      "epoch 451 loss 0.5119 LR 0.4968 LKL 0.0151\n",
      "epoch 452 loss 0.5314 LR 0.5166 LKL 0.0149\n",
      "epoch 453 loss 0.5004 LR 0.4855 LKL 0.0148\n",
      "epoch 454 loss 0.4617 LR 0.4469 LKL 0.0148\n",
      "epoch 455 loss 0.5274 LR 0.5126 LKL 0.0148\n",
      "epoch 456 loss 0.4615 LR 0.4467 LKL 0.0148\n",
      "epoch 457 loss 0.4142 LR 0.3993 LKL 0.0149\n",
      "epoch 458 loss 0.5131 LR 0.4982 LKL 0.0149\n",
      "epoch 459 loss 0.5222 LR 0.5071 LKL 0.0151\n",
      "epoch 460 loss 0.5406 LR 0.5251 LKL 0.0155\n",
      "epoch 461 loss 0.4827 LR 0.4672 LKL 0.0155\n",
      "epoch 462 loss 0.4586 LR 0.4434 LKL 0.0152\n",
      "epoch 463 loss 0.4667 LR 0.4514 LKL 0.0153\n",
      "epoch 464 loss 0.5074 LR 0.4920 LKL 0.0153\n",
      "epoch 465 loss 0.4946 LR 0.4793 LKL 0.0153\n",
      "epoch 466 loss 0.4845 LR 0.4690 LKL 0.0155\n",
      "epoch 467 loss 0.5382 LR 0.5230 LKL 0.0152\n",
      "epoch 468 loss 0.5052 LR 0.4896 LKL 0.0157\n",
      "epoch 469 loss 0.5194 LR 0.5038 LKL 0.0155\n",
      "epoch 470 loss 0.5106 LR 0.4953 LKL 0.0154\n",
      "epoch 471 loss 0.4756 LR 0.4603 LKL 0.0153\n",
      "epoch 472 loss 0.4592 LR 0.4439 LKL 0.0153\n",
      "epoch 473 loss 0.4649 LR 0.4497 LKL 0.0152\n",
      "epoch 474 loss 0.4746 LR 0.4592 LKL 0.0154\n",
      "epoch 475 loss 0.4785 LR 0.4629 LKL 0.0156\n",
      "epoch 476 loss 0.5086 LR 0.4932 LKL 0.0153\n",
      "epoch 477 loss 0.4327 LR 0.4177 LKL 0.0151\n",
      "epoch 478 loss 0.4522 LR 0.4371 LKL 0.0151\n",
      "epoch 479 loss 0.4552 LR 0.4401 LKL 0.0150\n",
      "epoch 480 loss 0.4843 LR 0.4691 LKL 0.0152\n",
      "epoch 481 loss 0.4852 LR 0.4699 LKL 0.0152\n",
      "epoch 482 loss 0.4659 LR 0.4506 LKL 0.0153\n",
      "epoch 483 loss 0.4498 LR 0.4346 LKL 0.0152\n",
      "epoch 484 loss 0.4610 LR 0.4457 LKL 0.0153\n",
      "epoch 485 loss 0.4583 LR 0.4430 LKL 0.0153\n",
      "epoch 486 loss 0.5176 LR 0.5022 LKL 0.0154\n",
      "epoch 487 loss 0.4884 LR 0.4728 LKL 0.0156\n",
      "epoch 488 loss 0.4794 LR 0.4636 LKL 0.0158\n",
      "epoch 489 loss 0.4992 LR 0.4835 LKL 0.0157\n",
      "epoch 490 loss 0.4416 LR 0.4257 LKL 0.0160\n",
      "epoch 491 loss 0.4394 LR 0.4232 LKL 0.0162\n",
      "epoch 492 loss 0.5118 LR 0.4957 LKL 0.0161\n",
      "epoch 493 loss 0.4772 LR 0.4611 LKL 0.0161\n",
      "epoch 494 loss 0.4626 LR 0.4465 LKL 0.0161\n",
      "epoch 495 loss 0.4667 LR 0.4505 LKL 0.0162\n",
      "epoch 496 loss 0.4545 LR 0.4384 LKL 0.0161\n",
      "epoch 497 loss 0.4172 LR 0.4010 LKL 0.0163\n",
      "epoch 498 loss 0.5052 LR 0.4890 LKL 0.0163\n",
      "epoch 499 loss 0.4696 LR 0.4534 LKL 0.0161\n",
      "epoch 500 loss 0.4184 LR 0.4023 LKL 0.0161\n",
      "99\n",
      "epoch 501 loss 0.4734 LR 0.4571 LKL 0.0163\n",
      "epoch 502 loss 0.4396 LR 0.4234 LKL 0.0163\n",
      "epoch 503 loss 0.4947 LR 0.4785 LKL 0.0162\n",
      "epoch 504 loss 0.4084 LR 0.3921 LKL 0.0163\n",
      "epoch 505 loss 0.4972 LR 0.4809 LKL 0.0163\n",
      "epoch 506 loss 0.4565 LR 0.4404 LKL 0.0162\n",
      "epoch 507 loss 0.4772 LR 0.4611 LKL 0.0161\n",
      "epoch 508 loss 0.4801 LR 0.4640 LKL 0.0161\n",
      "epoch 509 loss 0.4400 LR 0.4242 LKL 0.0158\n",
      "epoch 510 loss 0.4088 LR 0.3931 LKL 0.0156\n",
      "epoch 511 loss 0.4553 LR 0.4397 LKL 0.0156\n",
      "epoch 512 loss 0.4364 LR 0.4209 LKL 0.0155\n",
      "epoch 513 loss 0.3872 LR 0.3716 LKL 0.0156\n",
      "epoch 514 loss 0.4293 LR 0.4139 LKL 0.0153\n",
      "epoch 515 loss 0.4142 LR 0.3989 LKL 0.0153\n",
      "epoch 516 loss 0.4565 LR 0.4412 LKL 0.0154\n",
      "epoch 517 loss 0.4684 LR 0.4533 LKL 0.0151\n",
      "epoch 518 loss 0.4746 LR 0.4596 LKL 0.0150\n",
      "epoch 519 loss 0.4452 LR 0.4303 LKL 0.0149\n",
      "epoch 520 loss 0.4005 LR 0.3858 LKL 0.0146\n",
      "epoch 521 loss 0.5540 LR 0.5392 LKL 0.0148\n",
      "epoch 522 loss 0.4907 LR 0.4760 LKL 0.0147\n",
      "epoch 523 loss 0.4690 LR 0.4542 LKL 0.0148\n",
      "epoch 524 loss 0.4414 LR 0.4265 LKL 0.0149\n",
      "epoch 525 loss 0.4549 LR 0.4399 LKL 0.0150\n",
      "epoch 526 loss 0.4596 LR 0.4445 LKL 0.0151\n",
      "epoch 527 loss 0.4600 LR 0.4448 LKL 0.0153\n",
      "epoch 528 loss 0.4586 LR 0.4435 LKL 0.0152\n",
      "epoch 529 loss 0.4264 LR 0.4111 LKL 0.0153\n",
      "epoch 530 loss 0.5166 LR 0.5014 LKL 0.0152\n",
      "epoch 531 loss 0.4820 LR 0.4667 LKL 0.0154\n",
      "epoch 532 loss 0.4752 LR 0.4598 LKL 0.0154\n",
      "epoch 533 loss 0.4387 LR 0.4234 LKL 0.0153\n",
      "epoch 534 loss 0.5379 LR 0.5227 LKL 0.0152\n",
      "epoch 535 loss 0.4707 LR 0.4554 LKL 0.0152\n",
      "epoch 536 loss 0.4491 LR 0.4338 LKL 0.0153\n",
      "epoch 537 loss 0.4517 LR 0.4364 LKL 0.0153\n",
      "epoch 538 loss 0.4187 LR 0.4034 LKL 0.0153\n",
      "epoch 539 loss 0.4173 LR 0.4023 LKL 0.0150\n",
      "epoch 540 loss 0.3936 LR 0.3785 LKL 0.0151\n",
      "epoch 541 loss 0.4640 LR 0.4488 LKL 0.0153\n",
      "epoch 542 loss 0.4257 LR 0.4103 LKL 0.0154\n",
      "epoch 543 loss 0.4555 LR 0.4401 LKL 0.0154\n",
      "epoch 544 loss 0.4365 LR 0.4212 LKL 0.0153\n",
      "epoch 545 loss 0.4491 LR 0.4339 LKL 0.0153\n",
      "epoch 546 loss 0.4507 LR 0.4353 LKL 0.0155\n",
      "epoch 547 loss 0.4262 LR 0.4104 LKL 0.0158\n",
      "epoch 548 loss 0.4039 LR 0.3882 LKL 0.0157\n",
      "epoch 549 loss 0.4541 LR 0.4387 LKL 0.0154\n",
      "epoch 550 loss 0.4511 LR 0.4357 LKL 0.0154\n",
      "epoch 551 loss 0.4206 LR 0.4052 LKL 0.0154\n",
      "epoch 552 loss 0.3816 LR 0.3661 LKL 0.0155\n",
      "epoch 553 loss 0.4428 LR 0.4270 LKL 0.0157\n",
      "epoch 554 loss 0.4983 LR 0.4827 LKL 0.0156\n",
      "epoch 555 loss 0.4253 LR 0.4097 LKL 0.0155\n",
      "epoch 556 loss 0.4201 LR 0.4045 LKL 0.0156\n",
      "epoch 557 loss 0.4495 LR 0.4337 LKL 0.0158\n",
      "epoch 558 loss 0.4910 LR 0.4752 LKL 0.0158\n",
      "epoch 559 loss 0.4602 LR 0.4443 LKL 0.0158\n",
      "epoch 560 loss 0.4246 LR 0.4089 LKL 0.0158\n",
      "epoch 561 loss 0.4371 LR 0.4213 LKL 0.0158\n",
      "epoch 562 loss 0.4506 LR 0.4349 LKL 0.0157\n",
      "epoch 563 loss 0.4449 LR 0.4289 LKL 0.0160\n",
      "epoch 564 loss 0.4297 LR 0.4137 LKL 0.0160\n",
      "epoch 565 loss 0.4395 LR 0.4233 LKL 0.0163\n",
      "epoch 566 loss 0.4906 LR 0.4745 LKL 0.0161\n",
      "epoch 567 loss 0.4552 LR 0.4389 LKL 0.0163\n",
      "epoch 568 loss 0.3783 LR 0.3621 LKL 0.0161\n",
      "epoch 569 loss 0.4265 LR 0.4104 LKL 0.0162\n",
      "epoch 570 loss 0.3963 LR 0.3800 LKL 0.0163\n",
      "epoch 571 loss 0.4391 LR 0.4228 LKL 0.0163\n",
      "epoch 572 loss 0.4018 LR 0.3854 LKL 0.0163\n",
      "epoch 573 loss 0.4873 LR 0.4708 LKL 0.0165\n",
      "epoch 574 loss 0.3848 LR 0.3679 LKL 0.0169\n",
      "epoch 575 loss 0.3971 LR 0.3803 LKL 0.0168\n",
      "epoch 576 loss 0.3942 LR 0.3773 LKL 0.0169\n",
      "epoch 577 loss 0.5128 LR 0.4960 LKL 0.0168\n",
      "epoch 578 loss 0.4408 LR 0.4242 LKL 0.0166\n",
      "epoch 579 loss 0.4399 LR 0.4233 LKL 0.0167\n",
      "epoch 580 loss 0.4426 LR 0.4260 LKL 0.0166\n",
      "epoch 581 loss 0.4197 LR 0.4032 LKL 0.0165\n",
      "epoch 582 loss 0.3734 LR 0.3572 LKL 0.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 583 loss 0.4286 LR 0.4125 LKL 0.0162\n",
      "epoch 584 loss 0.4411 LR 0.4247 LKL 0.0164\n",
      "epoch 585 loss 0.3906 LR 0.3745 LKL 0.0161\n",
      "epoch 586 loss 0.4174 LR 0.4013 LKL 0.0161\n",
      "epoch 587 loss 0.4089 LR 0.3930 LKL 0.0160\n",
      "epoch 588 loss 0.4163 LR 0.4003 LKL 0.0160\n",
      "epoch 589 loss 0.4446 LR 0.4288 LKL 0.0158\n",
      "epoch 590 loss 0.3950 LR 0.3794 LKL 0.0156\n",
      "epoch 591 loss 0.4741 LR 0.4584 LKL 0.0156\n",
      "epoch 592 loss 0.4697 LR 0.4542 LKL 0.0155\n",
      "epoch 593 loss 0.3848 LR 0.3692 LKL 0.0156\n",
      "epoch 594 loss 0.4462 LR 0.4308 LKL 0.0154\n",
      "epoch 595 loss 0.4237 LR 0.4081 LKL 0.0157\n",
      "epoch 596 loss 0.3787 LR 0.3630 LKL 0.0157\n",
      "epoch 597 loss 0.4456 LR 0.4298 LKL 0.0158\n",
      "epoch 598 loss 0.4173 LR 0.4014 LKL 0.0159\n",
      "epoch 599 loss 0.4453 LR 0.4292 LKL 0.0161\n",
      "epoch 600 loss 0.4486 LR 0.4323 LKL 0.0164\n",
      "epoch 601 loss 0.4141 LR 0.3976 LKL 0.0165\n",
      "epoch 602 loss 0.4260 LR 0.4098 LKL 0.0162\n",
      "epoch 603 loss 0.4842 LR 0.4679 LKL 0.0163\n",
      "epoch 604 loss 0.4277 LR 0.4113 LKL 0.0164\n",
      "epoch 605 loss 0.4320 LR 0.4155 LKL 0.0164\n",
      "epoch 606 loss 0.4302 LR 0.4140 LKL 0.0163\n",
      "epoch 607 loss 0.3735 LR 0.3571 LKL 0.0164\n",
      "epoch 608 loss 0.4333 LR 0.4166 LKL 0.0167\n",
      "epoch 609 loss 0.3883 LR 0.3716 LKL 0.0166\n",
      "epoch 610 loss 0.4306 LR 0.4137 LKL 0.0169\n",
      "epoch 611 loss 0.4674 LR 0.4506 LKL 0.0168\n",
      "epoch 612 loss 0.4501 LR 0.4335 LKL 0.0165\n",
      "epoch 613 loss 0.4238 LR 0.4071 LKL 0.0167\n",
      "epoch 614 loss 0.4441 LR 0.4277 LKL 0.0164\n",
      "epoch 615 loss 0.5066 LR 0.4901 LKL 0.0166\n",
      "epoch 616 loss 0.4511 LR 0.4346 LKL 0.0165\n",
      "epoch 617 loss 0.5061 LR 0.4895 LKL 0.0167\n",
      "epoch 618 loss 0.3525 LR 0.3356 LKL 0.0169\n",
      "epoch 619 loss 0.4459 LR 0.4292 LKL 0.0167\n",
      "epoch 620 loss 0.3728 LR 0.3560 LKL 0.0168\n",
      "epoch 621 loss 0.4376 LR 0.4208 LKL 0.0168\n",
      "epoch 622 loss 0.4028 LR 0.3862 LKL 0.0167\n",
      "epoch 623 loss 0.3759 LR 0.3593 LKL 0.0166\n",
      "epoch 624 loss 0.4635 LR 0.4470 LKL 0.0165\n",
      "epoch 625 loss 0.4702 LR 0.4538 LKL 0.0164\n",
      "epoch 626 loss 0.4044 LR 0.3878 LKL 0.0166\n",
      "epoch 627 loss 0.3890 LR 0.3724 LKL 0.0167\n",
      "epoch 628 loss 0.4026 LR 0.3858 LKL 0.0167\n",
      "epoch 629 loss 0.3687 LR 0.3519 LKL 0.0169\n",
      "epoch 630 loss 0.4455 LR 0.4289 LKL 0.0166\n",
      "epoch 631 loss 0.3955 LR 0.3787 LKL 0.0167\n",
      "epoch 632 loss 0.3552 LR 0.3386 LKL 0.0166\n",
      "epoch 633 loss 0.4366 LR 0.4200 LKL 0.0166\n",
      "epoch 634 loss 0.3898 LR 0.3730 LKL 0.0169\n",
      "epoch 635 loss 0.3834 LR 0.3668 LKL 0.0165\n",
      "epoch 636 loss 0.4232 LR 0.4065 LKL 0.0166\n",
      "epoch 637 loss 0.4500 LR 0.4332 LKL 0.0168\n",
      "epoch 638 loss 0.4835 LR 0.4668 LKL 0.0167\n",
      "epoch 639 loss 0.4178 LR 0.4011 LKL 0.0168\n",
      "epoch 640 loss 0.4183 LR 0.4017 LKL 0.0166\n",
      "epoch 641 loss 0.3676 LR 0.3507 LKL 0.0169\n",
      "epoch 642 loss 0.4354 LR 0.4186 LKL 0.0167\n",
      "epoch 643 loss 0.3859 LR 0.3692 LKL 0.0167\n",
      "epoch 644 loss 0.4631 LR 0.4464 LKL 0.0167\n",
      "epoch 645 loss 0.4161 LR 0.3993 LKL 0.0168\n",
      "epoch 646 loss 0.4124 LR 0.3955 LKL 0.0169\n",
      "epoch 647 loss 0.4040 LR 0.3871 LKL 0.0170\n",
      "epoch 648 loss 0.3683 LR 0.3516 LKL 0.0167\n",
      "epoch 649 loss 0.3944 LR 0.3777 LKL 0.0167\n",
      "epoch 650 loss 0.4213 LR 0.4046 LKL 0.0167\n",
      "epoch 651 loss 0.4661 LR 0.4492 LKL 0.0169\n",
      "epoch 652 loss 0.4675 LR 0.4507 LKL 0.0168\n",
      "epoch 653 loss 0.3888 LR 0.3719 LKL 0.0169\n",
      "epoch 654 loss 0.3936 LR 0.3766 LKL 0.0170\n",
      "epoch 655 loss 0.3372 LR 0.3201 LKL 0.0171\n",
      "epoch 656 loss 0.4359 LR 0.4187 LKL 0.0171\n",
      "epoch 657 loss 0.3678 LR 0.3506 LKL 0.0172\n",
      "epoch 658 loss 0.4034 LR 0.3861 LKL 0.0173\n",
      "epoch 659 loss 0.3480 LR 0.3305 LKL 0.0175\n",
      "epoch 660 loss 0.4213 LR 0.4040 LKL 0.0173\n",
      "epoch 661 loss 0.4206 LR 0.4031 LKL 0.0175\n",
      "epoch 662 loss 0.4005 LR 0.3829 LKL 0.0177\n",
      "epoch 663 loss 0.3898 LR 0.3724 LKL 0.0174\n",
      "epoch 664 loss 0.4353 LR 0.4177 LKL 0.0176\n",
      "epoch 665 loss 0.4332 LR 0.4156 LKL 0.0175\n",
      "epoch 666 loss 0.3127 LR 0.2952 LKL 0.0176\n",
      "epoch 667 loss 0.3850 LR 0.3675 LKL 0.0175\n",
      "epoch 668 loss 0.3557 LR 0.3383 LKL 0.0174\n",
      "epoch 669 loss 0.4126 LR 0.3952 LKL 0.0174\n",
      "epoch 670 loss 0.3747 LR 0.3573 LKL 0.0174\n",
      "epoch 671 loss 0.4033 LR 0.3860 LKL 0.0173\n",
      "epoch 672 loss 0.3891 LR 0.3720 LKL 0.0171\n",
      "epoch 673 loss 0.4040 LR 0.3869 LKL 0.0171\n",
      "epoch 674 loss 0.3799 LR 0.3630 LKL 0.0170\n",
      "epoch 675 loss 0.3952 LR 0.3782 LKL 0.0170\n",
      "epoch 676 loss 0.4209 LR 0.4042 LKL 0.0167\n",
      "epoch 677 loss 0.4248 LR 0.4079 LKL 0.0169\n",
      "epoch 678 loss 0.4073 LR 0.3903 LKL 0.0170\n",
      "epoch 679 loss 0.3639 LR 0.3471 LKL 0.0168\n",
      "epoch 680 loss 0.4118 LR 0.3950 LKL 0.0167\n",
      "epoch 681 loss 0.4203 LR 0.4037 LKL 0.0167\n",
      "epoch 682 loss 0.3995 LR 0.3829 LKL 0.0167\n",
      "epoch 683 loss 0.3770 LR 0.3604 LKL 0.0166\n",
      "epoch 684 loss 0.4183 LR 0.4014 LKL 0.0169\n",
      "epoch 685 loss 0.3980 LR 0.3810 LKL 0.0170\n",
      "epoch 686 loss 0.4288 LR 0.4119 LKL 0.0169\n",
      "epoch 687 loss 0.3898 LR 0.3726 LKL 0.0172\n",
      "epoch 688 loss 0.3647 LR 0.3474 LKL 0.0174\n",
      "epoch 689 loss 0.3936 LR 0.3765 LKL 0.0171\n",
      "epoch 690 loss 0.3918 LR 0.3746 LKL 0.0172\n",
      "epoch 691 loss 0.3849 LR 0.3677 LKL 0.0172\n",
      "epoch 692 loss 0.3871 LR 0.3697 LKL 0.0174\n",
      "epoch 693 loss 0.4163 LR 0.3991 LKL 0.0173\n",
      "epoch 694 loss 0.4445 LR 0.4270 LKL 0.0175\n",
      "epoch 695 loss 0.3876 LR 0.3702 LKL 0.0173\n",
      "epoch 696 loss 0.4074 LR 0.3900 LKL 0.0174\n",
      "epoch 697 loss 0.3873 LR 0.3700 LKL 0.0173\n",
      "epoch 698 loss 0.3499 LR 0.3322 LKL 0.0177\n",
      "epoch 699 loss 0.4679 LR 0.4504 LKL 0.0175\n",
      "epoch 700 loss 0.4304 LR 0.4131 LKL 0.0173\n",
      "epoch 701 loss 0.4018 LR 0.3845 LKL 0.0173\n",
      "epoch 702 loss 0.3534 LR 0.3362 LKL 0.0173\n",
      "epoch 703 loss 0.4049 LR 0.3877 LKL 0.0172\n",
      "epoch 704 loss 0.3487 LR 0.3314 LKL 0.0173\n",
      "epoch 705 loss 0.4200 LR 0.4026 LKL 0.0174\n",
      "epoch 706 loss 0.4073 LR 0.3900 LKL 0.0173\n",
      "epoch 707 loss 0.3562 LR 0.3389 LKL 0.0174\n",
      "epoch 708 loss 0.3392 LR 0.3218 LKL 0.0174\n",
      "epoch 709 loss 0.4144 LR 0.3972 LKL 0.0172\n",
      "epoch 710 loss 0.4039 LR 0.3865 LKL 0.0174\n",
      "epoch 711 loss 0.4178 LR 0.4004 LKL 0.0174\n",
      "epoch 712 loss 0.3572 LR 0.3398 LKL 0.0174\n",
      "epoch 713 loss 0.3737 LR 0.3563 LKL 0.0174\n",
      "epoch 714 loss 0.3739 LR 0.3564 LKL 0.0175\n",
      "epoch 715 loss 0.4138 LR 0.3963 LKL 0.0175\n",
      "epoch 716 loss 0.3543 LR 0.3368 LKL 0.0174\n",
      "epoch 717 loss 0.3559 LR 0.3384 LKL 0.0175\n",
      "epoch 718 loss 0.3444 LR 0.3271 LKL 0.0173\n",
      "epoch 719 loss 0.3865 LR 0.3691 LKL 0.0174\n",
      "epoch 720 loss 0.3586 LR 0.3412 LKL 0.0175\n",
      "epoch 721 loss 0.3417 LR 0.3244 LKL 0.0172\n",
      "epoch 722 loss 0.3922 LR 0.3749 LKL 0.0174\n",
      "epoch 723 loss 0.3854 LR 0.3680 LKL 0.0174\n",
      "epoch 724 loss 0.3697 LR 0.3522 LKL 0.0176\n",
      "epoch 725 loss 0.5053 LR 0.4878 LKL 0.0175\n",
      "epoch 726 loss 0.4430 LR 0.4256 LKL 0.0174\n",
      "epoch 727 loss 0.4078 LR 0.3904 LKL 0.0174\n",
      "epoch 728 loss 0.3681 LR 0.3505 LKL 0.0175\n",
      "epoch 729 loss 0.4088 LR 0.3912 LKL 0.0176\n",
      "epoch 730 loss 0.3571 LR 0.3396 LKL 0.0175\n",
      "epoch 731 loss 0.4137 LR 0.3961 LKL 0.0176\n",
      "epoch 732 loss 0.4500 LR 0.4325 LKL 0.0175\n",
      "epoch 733 loss 0.4055 LR 0.3880 LKL 0.0175\n",
      "epoch 734 loss 0.3571 LR 0.3397 LKL 0.0174\n",
      "epoch 735 loss 0.3709 LR 0.3532 LKL 0.0177\n",
      "epoch 736 loss 0.3909 LR 0.3732 LKL 0.0177\n",
      "epoch 737 loss 0.3843 LR 0.3667 LKL 0.0175\n",
      "epoch 738 loss 0.3827 LR 0.3654 LKL 0.0173\n",
      "epoch 739 loss 0.4248 LR 0.4073 LKL 0.0175\n",
      "epoch 740 loss 0.3917 LR 0.3743 LKL 0.0174\n",
      "epoch 741 loss 0.3785 LR 0.3613 LKL 0.0172\n",
      "epoch 742 loss 0.3754 LR 0.3585 LKL 0.0169\n",
      "epoch 743 loss 0.3923 LR 0.3754 LKL 0.0168\n",
      "epoch 744 loss 0.3943 LR 0.3777 LKL 0.0167\n",
      "epoch 745 loss 0.4159 LR 0.3992 LKL 0.0167\n",
      "epoch 746 loss 0.3884 LR 0.3717 LKL 0.0168\n",
      "epoch 747 loss 0.4593 LR 0.4428 LKL 0.0165\n",
      "epoch 748 loss 0.3867 LR 0.3702 LKL 0.0165\n",
      "epoch 749 loss 0.3567 LR 0.3399 LKL 0.0168\n",
      "epoch 750 loss 0.4654 LR 0.4487 LKL 0.0167\n",
      "epoch 751 loss 0.3830 LR 0.3662 LKL 0.0168\n",
      "epoch 752 loss 0.3735 LR 0.3567 LKL 0.0168\n",
      "epoch 753 loss 0.3793 LR 0.3626 LKL 0.0167\n",
      "epoch 754 loss 0.3678 LR 0.3510 LKL 0.0168\n",
      "epoch 755 loss 0.3652 LR 0.3483 LKL 0.0169\n",
      "epoch 756 loss 0.3575 LR 0.3405 LKL 0.0170\n",
      "epoch 757 loss 0.3922 LR 0.3752 LKL 0.0170\n",
      "epoch 758 loss 0.3728 LR 0.3558 LKL 0.0169\n",
      "epoch 759 loss 0.4002 LR 0.3832 LKL 0.0170\n",
      "epoch 760 loss 0.3722 LR 0.3553 LKL 0.0169\n",
      "epoch 761 loss 0.3607 LR 0.3440 LKL 0.0166\n",
      "epoch 762 loss 0.3635 LR 0.3467 LKL 0.0168\n",
      "epoch 763 loss 0.3949 LR 0.3782 LKL 0.0167\n",
      "epoch 764 loss 0.3837 LR 0.3668 LKL 0.0169\n",
      "epoch 765 loss 0.3739 LR 0.3570 LKL 0.0169\n",
      "epoch 766 loss 0.3549 LR 0.3379 LKL 0.0170\n",
      "epoch 767 loss 0.3425 LR 0.3255 LKL 0.0171\n",
      "epoch 768 loss 0.3914 LR 0.3742 LKL 0.0171\n",
      "epoch 769 loss 0.4118 LR 0.3945 LKL 0.0173\n",
      "epoch 770 loss 0.3608 LR 0.3434 LKL 0.0174\n",
      "epoch 771 loss 0.3342 LR 0.3166 LKL 0.0176\n",
      "epoch 772 loss 0.3920 LR 0.3743 LKL 0.0177\n",
      "epoch 773 loss 0.3890 LR 0.3714 LKL 0.0176\n",
      "epoch 774 loss 0.3643 LR 0.3469 LKL 0.0173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 775 loss 0.3385 LR 0.3211 LKL 0.0174\n",
      "epoch 776 loss 0.3929 LR 0.3753 LKL 0.0175\n",
      "epoch 777 loss 0.3728 LR 0.3552 LKL 0.0176\n",
      "epoch 778 loss 0.3457 LR 0.3285 LKL 0.0172\n",
      "epoch 779 loss 0.3880 LR 0.3706 LKL 0.0174\n",
      "epoch 780 loss 0.3533 LR 0.3361 LKL 0.0173\n",
      "epoch 781 loss 0.3247 LR 0.3073 LKL 0.0174\n",
      "epoch 782 loss 0.3794 LR 0.3620 LKL 0.0174\n",
      "epoch 783 loss 0.4013 LR 0.3840 LKL 0.0173\n",
      "epoch 784 loss 0.3534 LR 0.3360 LKL 0.0174\n",
      "epoch 785 loss 0.3876 LR 0.3700 LKL 0.0176\n",
      "epoch 786 loss 0.3344 LR 0.3169 LKL 0.0175\n",
      "epoch 787 loss 0.3156 LR 0.2981 LKL 0.0175\n",
      "epoch 788 loss 0.3290 LR 0.3114 LKL 0.0175\n",
      "epoch 789 loss 0.3445 LR 0.3272 LKL 0.0173\n",
      "epoch 790 loss 0.3626 LR 0.3453 LKL 0.0173\n",
      "epoch 791 loss 0.3358 LR 0.3185 LKL 0.0174\n",
      "epoch 792 loss 0.4098 LR 0.3924 LKL 0.0174\n",
      "epoch 793 loss 0.3832 LR 0.3656 LKL 0.0176\n",
      "epoch 794 loss 0.3670 LR 0.3496 LKL 0.0173\n",
      "epoch 795 loss 0.3558 LR 0.3382 LKL 0.0175\n",
      "epoch 796 loss 0.3691 LR 0.3515 LKL 0.0176\n",
      "epoch 797 loss 0.3833 LR 0.3656 LKL 0.0178\n",
      "epoch 798 loss 0.3357 LR 0.3182 LKL 0.0175\n",
      "epoch 799 loss 0.4089 LR 0.3912 LKL 0.0176\n",
      "epoch 800 loss 0.4327 LR 0.4147 LKL 0.0180\n",
      "epoch 801 loss 0.3896 LR 0.3717 LKL 0.0179\n",
      "epoch 802 loss 0.3692 LR 0.3510 LKL 0.0181\n",
      "epoch 803 loss 0.4184 LR 0.4004 LKL 0.0180\n",
      "epoch 804 loss 0.4283 LR 0.4102 LKL 0.0182\n",
      "epoch 805 loss 0.4211 LR 0.4028 LKL 0.0183\n",
      "epoch 806 loss 0.3552 LR 0.3371 LKL 0.0181\n",
      "epoch 807 loss 0.3514 LR 0.3335 LKL 0.0179\n",
      "epoch 808 loss 0.4147 LR 0.3968 LKL 0.0179\n",
      "epoch 809 loss 0.3814 LR 0.3636 LKL 0.0178\n",
      "epoch 810 loss 0.4197 LR 0.4018 LKL 0.0179\n",
      "epoch 811 loss 0.3651 LR 0.3471 LKL 0.0180\n",
      "epoch 812 loss 0.3003 LR 0.2823 LKL 0.0180\n",
      "epoch 813 loss 0.3650 LR 0.3472 LKL 0.0178\n",
      "epoch 814 loss 0.4036 LR 0.3858 LKL 0.0178\n",
      "epoch 815 loss 0.3411 LR 0.3233 LKL 0.0178\n",
      "epoch 816 loss 0.3775 LR 0.3599 LKL 0.0176\n",
      "epoch 817 loss 0.3769 LR 0.3591 LKL 0.0177\n",
      "epoch 818 loss 0.3334 LR 0.3155 LKL 0.0178\n",
      "epoch 819 loss 0.3606 LR 0.3430 LKL 0.0176\n",
      "epoch 820 loss 0.3229 LR 0.3051 LKL 0.0178\n",
      "epoch 821 loss 0.3979 LR 0.3800 LKL 0.0180\n",
      "epoch 822 loss 0.4365 LR 0.4187 LKL 0.0178\n",
      "epoch 823 loss 0.3683 LR 0.3507 LKL 0.0176\n",
      "epoch 824 loss 0.3697 LR 0.3520 LKL 0.0177\n",
      "epoch 825 loss 0.3029 LR 0.2852 LKL 0.0177\n",
      "epoch 826 loss 0.3574 LR 0.3395 LKL 0.0179\n",
      "epoch 827 loss 0.3473 LR 0.3296 LKL 0.0177\n",
      "epoch 828 loss 0.3230 LR 0.3050 LKL 0.0180\n",
      "epoch 829 loss 0.3700 LR 0.3519 LKL 0.0181\n",
      "epoch 830 loss 0.3427 LR 0.3245 LKL 0.0181\n",
      "epoch 831 loss 0.3680 LR 0.3500 LKL 0.0180\n",
      "epoch 832 loss 0.3121 LR 0.2940 LKL 0.0181\n",
      "epoch 833 loss 0.3588 LR 0.3407 LKL 0.0181\n",
      "epoch 834 loss 0.3301 LR 0.3120 LKL 0.0181\n",
      "epoch 835 loss 0.3677 LR 0.3498 LKL 0.0178\n",
      "epoch 836 loss 0.3676 LR 0.3498 LKL 0.0178\n",
      "epoch 837 loss 0.3083 LR 0.2904 LKL 0.0179\n",
      "epoch 838 loss 0.3722 LR 0.3542 LKL 0.0180\n",
      "epoch 839 loss 0.3702 LR 0.3523 LKL 0.0179\n",
      "epoch 840 loss 0.3392 LR 0.3214 LKL 0.0178\n",
      "epoch 841 loss 0.4064 LR 0.3885 LKL 0.0179\n",
      "epoch 842 loss 0.4159 LR 0.3981 LKL 0.0177\n",
      "epoch 843 loss 0.3069 LR 0.2892 LKL 0.0177\n",
      "epoch 844 loss 0.2863 LR 0.2686 LKL 0.0177\n",
      "epoch 845 loss 0.3155 LR 0.2979 LKL 0.0177\n",
      "epoch 846 loss 0.4050 LR 0.3874 LKL 0.0176\n",
      "epoch 847 loss 0.3519 LR 0.3343 LKL 0.0177\n",
      "epoch 848 loss 0.4268 LR 0.4091 LKL 0.0176\n",
      "epoch 849 loss 0.3387 LR 0.3213 LKL 0.0174\n",
      "epoch 850 loss 0.3719 LR 0.3543 LKL 0.0176\n",
      "epoch 851 loss 0.3446 LR 0.3270 LKL 0.0176\n",
      "epoch 852 loss 0.3754 LR 0.3578 LKL 0.0176\n",
      "epoch 853 loss 0.3251 LR 0.3072 LKL 0.0179\n",
      "epoch 854 loss 0.4027 LR 0.3852 LKL 0.0175\n",
      "epoch 855 loss 0.3213 LR 0.3036 LKL 0.0177\n",
      "epoch 856 loss 0.3110 LR 0.2933 LKL 0.0177\n",
      "epoch 857 loss 0.3384 LR 0.3205 LKL 0.0178\n",
      "epoch 858 loss 0.3533 LR 0.3354 LKL 0.0179\n",
      "epoch 859 loss 0.3482 LR 0.3303 LKL 0.0179\n",
      "epoch 860 loss 0.3142 LR 0.2963 LKL 0.0179\n",
      "epoch 861 loss 0.3579 LR 0.3397 LKL 0.0182\n",
      "epoch 862 loss 0.2974 LR 0.2792 LKL 0.0181\n",
      "epoch 863 loss 0.3327 LR 0.3144 LKL 0.0183\n",
      "epoch 864 loss 0.3484 LR 0.3304 LKL 0.0180\n",
      "epoch 865 loss 0.3359 LR 0.3178 LKL 0.0181\n",
      "epoch 866 loss 0.3900 LR 0.3719 LKL 0.0181\n",
      "epoch 867 loss 0.3543 LR 0.3363 LKL 0.0180\n",
      "epoch 868 loss 0.4054 LR 0.3872 LKL 0.0182\n",
      "epoch 869 loss 0.3676 LR 0.3494 LKL 0.0182\n",
      "epoch 870 loss 0.3402 LR 0.3219 LKL 0.0183\n",
      "epoch 871 loss 0.3591 LR 0.3410 LKL 0.0181\n",
      "epoch 872 loss 0.3604 LR 0.3422 LKL 0.0182\n",
      "epoch 873 loss 0.3371 LR 0.3189 LKL 0.0182\n",
      "epoch 874 loss 0.3500 LR 0.3317 LKL 0.0182\n",
      "epoch 875 loss 0.3643 LR 0.3461 LKL 0.0181\n",
      "epoch 876 loss 0.3530 LR 0.3347 LKL 0.0183\n",
      "epoch 877 loss 0.2763 LR 0.2579 LKL 0.0184\n",
      "epoch 878 loss 0.3639 LR 0.3456 LKL 0.0183\n",
      "epoch 879 loss 0.3466 LR 0.3284 LKL 0.0182\n",
      "epoch 880 loss 0.3099 LR 0.2918 LKL 0.0181\n",
      "epoch 881 loss 0.3504 LR 0.3324 LKL 0.0180\n",
      "epoch 882 loss 0.3574 LR 0.3396 LKL 0.0178\n",
      "epoch 883 loss 0.3732 LR 0.3554 LKL 0.0178\n",
      "epoch 884 loss 0.3327 LR 0.3148 LKL 0.0179\n",
      "epoch 885 loss 0.3668 LR 0.3491 LKL 0.0176\n",
      "epoch 886 loss 0.3482 LR 0.3305 LKL 0.0177\n",
      "epoch 887 loss 0.3615 LR 0.3438 LKL 0.0177\n",
      "epoch 888 loss 0.3655 LR 0.3478 LKL 0.0177\n",
      "epoch 889 loss 0.3303 LR 0.3124 LKL 0.0180\n",
      "epoch 890 loss 0.4035 LR 0.3854 LKL 0.0181\n",
      "epoch 891 loss 0.3408 LR 0.3229 LKL 0.0179\n",
      "epoch 892 loss 0.2808 LR 0.2629 LKL 0.0179\n",
      "epoch 893 loss 0.3410 LR 0.3229 LKL 0.0181\n",
      "epoch 894 loss 0.3384 LR 0.3204 LKL 0.0180\n",
      "epoch 895 loss 0.3609 LR 0.3430 LKL 0.0179\n",
      "epoch 896 loss 0.3725 LR 0.3542 LKL 0.0183\n",
      "epoch 897 loss 0.3313 LR 0.3131 LKL 0.0182\n",
      "epoch 898 loss 0.3420 LR 0.3241 LKL 0.0179\n",
      "epoch 899 loss 0.3684 LR 0.3505 LKL 0.0179\n",
      "epoch 900 loss 0.3612 LR 0.3432 LKL 0.0180\n",
      "epoch 901 loss 0.3207 LR 0.3027 LKL 0.0180\n",
      "epoch 902 loss 0.3700 LR 0.3521 LKL 0.0179\n",
      "epoch 903 loss 0.3867 LR 0.3691 LKL 0.0176\n",
      "epoch 904 loss 0.3250 LR 0.3074 LKL 0.0176\n",
      "epoch 905 loss 0.3453 LR 0.3278 LKL 0.0175\n",
      "epoch 906 loss 0.3382 LR 0.3207 LKL 0.0175\n",
      "epoch 907 loss 0.3629 LR 0.3452 LKL 0.0178\n",
      "epoch 908 loss 0.3005 LR 0.2828 LKL 0.0178\n",
      "epoch 909 loss 0.3613 LR 0.3438 LKL 0.0175\n",
      "epoch 910 loss 0.3600 LR 0.3423 LKL 0.0176\n",
      "epoch 911 loss 0.3518 LR 0.3345 LKL 0.0173\n",
      "epoch 912 loss 0.3283 LR 0.3107 LKL 0.0176\n",
      "epoch 913 loss 0.3357 LR 0.3181 LKL 0.0176\n",
      "epoch 914 loss 0.2833 LR 0.2657 LKL 0.0176\n",
      "epoch 915 loss 0.3491 LR 0.3312 LKL 0.0179\n",
      "epoch 916 loss 0.3903 LR 0.3725 LKL 0.0178\n",
      "epoch 917 loss 0.3142 LR 0.2961 LKL 0.0180\n",
      "epoch 918 loss 0.3343 LR 0.3160 LKL 0.0183\n",
      "epoch 919 loss 0.3261 LR 0.3078 LKL 0.0183\n",
      "epoch 920 loss 0.2971 LR 0.2785 LKL 0.0186\n",
      "epoch 921 loss 0.3568 LR 0.3383 LKL 0.0185\n",
      "epoch 922 loss 0.3447 LR 0.3262 LKL 0.0185\n",
      "epoch 923 loss 0.3038 LR 0.2854 LKL 0.0184\n",
      "epoch 924 loss 0.3137 LR 0.2951 LKL 0.0186\n",
      "epoch 925 loss 0.3236 LR 0.3052 LKL 0.0184\n",
      "epoch 926 loss 0.2889 LR 0.2705 LKL 0.0184\n",
      "epoch 927 loss 0.3308 LR 0.3125 LKL 0.0183\n",
      "epoch 928 loss 0.3058 LR 0.2876 LKL 0.0182\n",
      "epoch 929 loss 0.3706 LR 0.3527 LKL 0.0180\n",
      "epoch 930 loss 0.2806 LR 0.2625 LKL 0.0181\n",
      "epoch 931 loss 0.2745 LR 0.2563 LKL 0.0182\n",
      "epoch 932 loss 0.3268 LR 0.3085 LKL 0.0182\n",
      "epoch 933 loss 0.2757 LR 0.2576 LKL 0.0181\n",
      "epoch 934 loss 0.3389 LR 0.3207 LKL 0.0182\n",
      "epoch 935 loss 0.2889 LR 0.2708 LKL 0.0181\n",
      "epoch 936 loss 0.4129 LR 0.3948 LKL 0.0181\n",
      "epoch 937 loss 0.4062 LR 0.3880 LKL 0.0182\n",
      "epoch 938 loss 0.3518 LR 0.3339 LKL 0.0179\n",
      "epoch 939 loss 0.3711 LR 0.3528 LKL 0.0183\n",
      "epoch 940 loss 0.3377 LR 0.3195 LKL 0.0182\n",
      "epoch 941 loss 0.3389 LR 0.3205 LKL 0.0184\n",
      "epoch 942 loss 0.3218 LR 0.3032 LKL 0.0185\n",
      "epoch 943 loss 0.3057 LR 0.2871 LKL 0.0186\n",
      "epoch 944 loss 0.4021 LR 0.3835 LKL 0.0186\n",
      "epoch 945 loss 0.3247 LR 0.3059 LKL 0.0188\n",
      "epoch 946 loss 0.3502 LR 0.3314 LKL 0.0188\n",
      "epoch 947 loss 0.3289 LR 0.3102 LKL 0.0187\n",
      "epoch 948 loss 0.3475 LR 0.3288 LKL 0.0187\n",
      "epoch 949 loss 0.3442 LR 0.3257 LKL 0.0185\n",
      "epoch 950 loss 0.3816 LR 0.3635 LKL 0.0181\n",
      "epoch 951 loss 0.3204 LR 0.3020 LKL 0.0184\n",
      "epoch 952 loss 0.2892 LR 0.2707 LKL 0.0185\n",
      "epoch 953 loss 0.3709 LR 0.3525 LKL 0.0184\n",
      "epoch 954 loss 0.4000 LR 0.3818 LKL 0.0182\n",
      "epoch 955 loss 0.3570 LR 0.3386 LKL 0.0184\n",
      "epoch 956 loss 0.3733 LR 0.3550 LKL 0.0183\n",
      "epoch 957 loss 0.2976 LR 0.2792 LKL 0.0184\n",
      "epoch 958 loss 0.2622 LR 0.2438 LKL 0.0183\n",
      "epoch 959 loss 0.2843 LR 0.2660 LKL 0.0182\n",
      "epoch 960 loss 0.3425 LR 0.3243 LKL 0.0182\n",
      "epoch 961 loss 0.3396 LR 0.3215 LKL 0.0181\n",
      "epoch 962 loss 0.3685 LR 0.3505 LKL 0.0180\n",
      "epoch 963 loss 0.3378 LR 0.3197 LKL 0.0180\n",
      "epoch 964 loss 0.3084 LR 0.2904 LKL 0.0180\n",
      "epoch 965 loss 0.3251 LR 0.3073 LKL 0.0178\n",
      "epoch 966 loss 0.3018 LR 0.2840 LKL 0.0179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 967 loss 0.2851 LR 0.2671 LKL 0.0180\n",
      "epoch 968 loss 0.3726 LR 0.3545 LKL 0.0181\n",
      "epoch 969 loss 0.3466 LR 0.3284 LKL 0.0182\n",
      "epoch 970 loss 0.2375 LR 0.2191 LKL 0.0184\n",
      "epoch 971 loss 0.3001 LR 0.2816 LKL 0.0185\n",
      "epoch 972 loss 0.3446 LR 0.3262 LKL 0.0184\n",
      "epoch 973 loss 0.3909 LR 0.3724 LKL 0.0185\n",
      "epoch 974 loss 0.3567 LR 0.3382 LKL 0.0185\n",
      "epoch 975 loss 0.3241 LR 0.3055 LKL 0.0186\n",
      "epoch 976 loss 0.3132 LR 0.2948 LKL 0.0184\n",
      "epoch 977 loss 0.2877 LR 0.2693 LKL 0.0184\n",
      "epoch 978 loss 0.2795 LR 0.2609 LKL 0.0186\n",
      "epoch 979 loss 0.2915 LR 0.2727 LKL 0.0188\n",
      "epoch 980 loss 0.3012 LR 0.2826 LKL 0.0186\n",
      "epoch 981 loss 0.3911 LR 0.3724 LKL 0.0187\n",
      "epoch 982 loss 0.3569 LR 0.3384 LKL 0.0185\n",
      "epoch 983 loss 0.3458 LR 0.3273 LKL 0.0185\n",
      "epoch 984 loss 0.2619 LR 0.2435 LKL 0.0184\n",
      "epoch 985 loss 0.3417 LR 0.3231 LKL 0.0185\n",
      "epoch 986 loss 0.3270 LR 0.3083 LKL 0.0187\n",
      "epoch 987 loss 0.3308 LR 0.3123 LKL 0.0185\n",
      "epoch 988 loss 0.3450 LR 0.3266 LKL 0.0183\n",
      "epoch 989 loss 0.3475 LR 0.3292 LKL 0.0184\n",
      "epoch 990 loss 0.3310 LR 0.3123 LKL 0.0187\n",
      "epoch 991 loss 0.2909 LR 0.2723 LKL 0.0185\n",
      "epoch 992 loss 0.2995 LR 0.2812 LKL 0.0183\n",
      "epoch 993 loss 0.3824 LR 0.3640 LKL 0.0184\n",
      "epoch 994 loss 0.3020 LR 0.2835 LKL 0.0184\n",
      "epoch 995 loss 0.2947 LR 0.2762 LKL 0.0185\n",
      "epoch 996 loss 0.3209 LR 0.3026 LKL 0.0184\n",
      "epoch 997 loss 0.2934 LR 0.2747 LKL 0.0186\n",
      "epoch 998 loss 0.3991 LR 0.3804 LKL 0.0186\n",
      "epoch 999 loss 0.2920 LR 0.2736 LKL 0.0184\n",
      "epoch 1000 loss 0.3166 LR 0.2980 LKL 0.0186\n",
      "epoch 1001 loss 0.3177 LR 0.2993 LKL 0.0184\n",
      "epoch 1002 loss 0.3495 LR 0.3312 LKL 0.0183\n",
      "epoch 1003 loss 0.3219 LR 0.3037 LKL 0.0182\n",
      "epoch 1004 loss 0.2826 LR 0.2644 LKL 0.0182\n",
      "epoch 1005 loss 0.3273 LR 0.3091 LKL 0.0182\n",
      "epoch 1006 loss 0.3006 LR 0.2826 LKL 0.0180\n",
      "epoch 1007 loss 0.3278 LR 0.3099 LKL 0.0179\n",
      "epoch 1008 loss 0.3218 LR 0.3036 LKL 0.0182\n",
      "epoch 1009 loss 0.3183 LR 0.2999 LKL 0.0183\n",
      "epoch 1010 loss 0.2945 LR 0.2761 LKL 0.0184\n",
      "epoch 1011 loss 0.2898 LR 0.2715 LKL 0.0183\n",
      "epoch 1012 loss 0.2983 LR 0.2798 LKL 0.0185\n",
      "epoch 1013 loss 0.2478 LR 0.2290 LKL 0.0188\n",
      "epoch 1014 loss 0.3071 LR 0.2884 LKL 0.0187\n",
      "epoch 1015 loss 0.3281 LR 0.3093 LKL 0.0188\n",
      "epoch 1016 loss 0.3000 LR 0.2813 LKL 0.0187\n",
      "epoch 1017 loss 0.3382 LR 0.3192 LKL 0.0190\n",
      "epoch 1018 loss 0.2966 LR 0.2775 LKL 0.0191\n",
      "epoch 1019 loss 0.3052 LR 0.2863 LKL 0.0189\n",
      "epoch 1020 loss 0.2982 LR 0.2794 LKL 0.0188\n",
      "epoch 1021 loss 0.3053 LR 0.2862 LKL 0.0191\n",
      "epoch 1022 loss 0.3733 LR 0.3543 LKL 0.0190\n",
      "epoch 1023 loss 0.2765 LR 0.2579 LKL 0.0186\n",
      "epoch 1024 loss 0.3098 LR 0.2910 LKL 0.0189\n",
      "epoch 1025 loss 0.2854 LR 0.2665 LKL 0.0189\n",
      "epoch 1026 loss 0.3485 LR 0.3295 LKL 0.0190\n",
      "epoch 1027 loss 0.3038 LR 0.2850 LKL 0.0188\n",
      "epoch 1028 loss 0.2867 LR 0.2679 LKL 0.0188\n",
      "epoch 1029 loss 0.2889 LR 0.2701 LKL 0.0188\n",
      "epoch 1030 loss 0.3078 LR 0.2890 LKL 0.0188\n",
      "epoch 1031 loss 0.3256 LR 0.3069 LKL 0.0186\n",
      "epoch 1032 loss 0.3535 LR 0.3350 LKL 0.0186\n",
      "epoch 1033 loss 0.2701 LR 0.2515 LKL 0.0186\n",
      "epoch 1034 loss 0.3311 LR 0.3124 LKL 0.0187\n",
      "epoch 1035 loss 0.2774 LR 0.2586 LKL 0.0188\n",
      "epoch 1036 loss 0.3362 LR 0.3176 LKL 0.0186\n",
      "epoch 1037 loss 0.3346 LR 0.3157 LKL 0.0189\n",
      "epoch 1038 loss 0.3459 LR 0.3272 LKL 0.0187\n",
      "epoch 1039 loss 0.3237 LR 0.3051 LKL 0.0187\n",
      "epoch 1040 loss 0.3463 LR 0.3277 LKL 0.0186\n",
      "epoch 1041 loss 0.3151 LR 0.2962 LKL 0.0189\n",
      "epoch 1042 loss 0.3015 LR 0.2827 LKL 0.0189\n",
      "epoch 1043 loss 0.3635 LR 0.3445 LKL 0.0190\n",
      "epoch 1044 loss 0.3071 LR 0.2882 LKL 0.0188\n",
      "epoch 1045 loss 0.3158 LR 0.2969 LKL 0.0189\n",
      "epoch 1046 loss 0.3273 LR 0.3082 LKL 0.0191\n",
      "epoch 1047 loss 0.3183 LR 0.2995 LKL 0.0189\n",
      "epoch 1048 loss 0.3053 LR 0.2866 LKL 0.0187\n",
      "epoch 1049 loss 0.2860 LR 0.2672 LKL 0.0188\n",
      "epoch 1050 loss 0.3161 LR 0.2974 LKL 0.0187\n",
      "epoch 1051 loss 0.3166 LR 0.2979 LKL 0.0187\n",
      "epoch 1052 loss 0.3774 LR 0.3590 LKL 0.0185\n",
      "epoch 1053 loss 0.2663 LR 0.2477 LKL 0.0186\n",
      "epoch 1054 loss 0.3084 LR 0.2899 LKL 0.0185\n",
      "epoch 1055 loss 0.3220 LR 0.3036 LKL 0.0185\n",
      "epoch 1056 loss 0.2724 LR 0.2539 LKL 0.0185\n",
      "epoch 1057 loss 0.3085 LR 0.2901 LKL 0.0184\n",
      "epoch 1058 loss 0.2737 LR 0.2554 LKL 0.0183\n",
      "epoch 1059 loss 0.3129 LR 0.2948 LKL 0.0182\n",
      "epoch 1060 loss 0.2961 LR 0.2779 LKL 0.0182\n",
      "epoch 1061 loss 0.3116 LR 0.2934 LKL 0.0182\n",
      "epoch 1062 loss 0.3927 LR 0.3745 LKL 0.0182\n",
      "epoch 1063 loss 0.3322 LR 0.3138 LKL 0.0184\n",
      "epoch 1064 loss 0.3267 LR 0.3082 LKL 0.0186\n",
      "epoch 1065 loss 0.3467 LR 0.3278 LKL 0.0189\n",
      "epoch 1066 loss 0.3069 LR 0.2882 LKL 0.0187\n",
      "epoch 1067 loss 0.3350 LR 0.3161 LKL 0.0189\n",
      "epoch 1068 loss 0.2607 LR 0.2417 LKL 0.0189\n",
      "epoch 1069 loss 0.3421 LR 0.3229 LKL 0.0192\n",
      "epoch 1070 loss 0.3428 LR 0.3238 LKL 0.0190\n",
      "epoch 1071 loss 0.3102 LR 0.2910 LKL 0.0193\n",
      "epoch 1072 loss 0.2800 LR 0.2611 LKL 0.0189\n",
      "epoch 1073 loss 0.2900 LR 0.2710 LKL 0.0190\n",
      "epoch 1074 loss 0.2858 LR 0.2668 LKL 0.0190\n",
      "epoch 1075 loss 0.3054 LR 0.2866 LKL 0.0189\n",
      "epoch 1076 loss 0.2615 LR 0.2425 LKL 0.0191\n",
      "epoch 1077 loss 0.2954 LR 0.2763 LKL 0.0191\n",
      "epoch 1078 loss 0.3775 LR 0.3586 LKL 0.0190\n",
      "epoch 1079 loss 0.3241 LR 0.3052 LKL 0.0189\n",
      "epoch 1080 loss 0.3340 LR 0.3152 LKL 0.0188\n",
      "epoch 1081 loss 0.3626 LR 0.3440 LKL 0.0187\n",
      "epoch 1082 loss 0.3239 LR 0.3053 LKL 0.0186\n",
      "epoch 1083 loss 0.3138 LR 0.2949 LKL 0.0189\n",
      "epoch 1084 loss 0.2892 LR 0.2706 LKL 0.0186\n",
      "epoch 1085 loss 0.3202 LR 0.3017 LKL 0.0186\n",
      "epoch 1086 loss 0.3057 LR 0.2869 LKL 0.0188\n",
      "epoch 1087 loss 0.3007 LR 0.2818 LKL 0.0188\n",
      "epoch 1088 loss 0.2807 LR 0.2617 LKL 0.0190\n",
      "epoch 1089 loss 0.2846 LR 0.2657 LKL 0.0189\n",
      "epoch 1090 loss 0.2547 LR 0.2357 LKL 0.0191\n",
      "epoch 1091 loss 0.2947 LR 0.2758 LKL 0.0190\n",
      "epoch 1092 loss 0.3618 LR 0.3430 LKL 0.0188\n",
      "epoch 1093 loss 0.3333 LR 0.3144 LKL 0.0189\n",
      "epoch 1094 loss 0.3166 LR 0.2978 LKL 0.0189\n",
      "epoch 1095 loss 0.2559 LR 0.2371 LKL 0.0188\n",
      "epoch 1096 loss 0.3605 LR 0.3418 LKL 0.0187\n",
      "epoch 1097 loss 0.3477 LR 0.3289 LKL 0.0188\n",
      "epoch 1098 loss 0.2675 LR 0.2486 LKL 0.0189\n",
      "epoch 1099 loss 0.3175 LR 0.2987 LKL 0.0188\n",
      "epoch 1100 loss 0.2779 LR 0.2591 LKL 0.0189\n",
      "110\n",
      "epoch 1101 loss 0.2901 LR 0.2712 LKL 0.0189\n",
      "epoch 1102 loss 0.3338 LR 0.3149 LKL 0.0189\n",
      "epoch 1103 loss 0.2841 LR 0.2654 LKL 0.0187\n",
      "epoch 1104 loss 0.2942 LR 0.2755 LKL 0.0187\n",
      "epoch 1105 loss 0.3030 LR 0.2843 LKL 0.0186\n",
      "epoch 1106 loss 0.2673 LR 0.2485 LKL 0.0189\n",
      "epoch 1107 loss 0.2978 LR 0.2791 LKL 0.0187\n",
      "epoch 1108 loss 0.3225 LR 0.3037 LKL 0.0188\n",
      "epoch 1109 loss 0.3293 LR 0.3102 LKL 0.0190\n",
      "epoch 1110 loss 0.2760 LR 0.2569 LKL 0.0191\n",
      "epoch 1111 loss 0.3130 LR 0.2940 LKL 0.0190\n",
      "epoch 1112 loss 0.3401 LR 0.3210 LKL 0.0191\n",
      "epoch 1113 loss 0.3192 LR 0.3001 LKL 0.0191\n",
      "epoch 1114 loss 0.3204 LR 0.3015 LKL 0.0189\n",
      "epoch 1115 loss 0.3566 LR 0.3378 LKL 0.0189\n",
      "epoch 1116 loss 0.3234 LR 0.3045 LKL 0.0190\n",
      "epoch 1117 loss 0.2980 LR 0.2789 LKL 0.0191\n",
      "epoch 1118 loss 0.2895 LR 0.2706 LKL 0.0189\n",
      "epoch 1119 loss 0.3083 LR 0.2896 LKL 0.0188\n",
      "epoch 1120 loss 0.3638 LR 0.3451 LKL 0.0187\n",
      "epoch 1121 loss 0.2441 LR 0.2253 LKL 0.0189\n",
      "epoch 1122 loss 0.3068 LR 0.2878 LKL 0.0190\n",
      "epoch 1123 loss 0.2781 LR 0.2591 LKL 0.0190\n",
      "epoch 1124 loss 0.2453 LR 0.2263 LKL 0.0190\n",
      "epoch 1125 loss 0.2772 LR 0.2579 LKL 0.0192\n",
      "epoch 1126 loss 0.3167 LR 0.2973 LKL 0.0194\n",
      "epoch 1127 loss 0.3409 LR 0.3214 LKL 0.0195\n",
      "epoch 1128 loss 0.2932 LR 0.2738 LKL 0.0194\n",
      "epoch 1129 loss 0.3122 LR 0.2928 LKL 0.0194\n",
      "epoch 1130 loss 0.2795 LR 0.2601 LKL 0.0193\n",
      "epoch 1131 loss 0.2987 LR 0.2795 LKL 0.0192\n",
      "epoch 1132 loss 0.2883 LR 0.2692 LKL 0.0191\n",
      "epoch 1133 loss 0.2772 LR 0.2583 LKL 0.0189\n",
      "epoch 1134 loss 0.3346 LR 0.3155 LKL 0.0191\n",
      "epoch 1135 loss 0.2575 LR 0.2387 LKL 0.0188\n",
      "epoch 1136 loss 0.2704 LR 0.2515 LKL 0.0190\n",
      "epoch 1137 loss 0.3305 LR 0.3117 LKL 0.0189\n",
      "epoch 1138 loss 0.3375 LR 0.3186 LKL 0.0189\n",
      "epoch 1139 loss 0.3101 LR 0.2910 LKL 0.0191\n",
      "epoch 1140 loss 0.2214 LR 0.2026 LKL 0.0188\n",
      "epoch 1141 loss 0.2786 LR 0.2598 LKL 0.0188\n",
      "epoch 1142 loss 0.3036 LR 0.2846 LKL 0.0190\n",
      "epoch 1143 loss 0.2988 LR 0.2798 LKL 0.0189\n",
      "epoch 1144 loss 0.3326 LR 0.3140 LKL 0.0187\n",
      "epoch 1145 loss 0.3023 LR 0.2836 LKL 0.0187\n",
      "epoch 1146 loss 0.2518 LR 0.2331 LKL 0.0188\n",
      "epoch 1147 loss 0.3291 LR 0.3103 LKL 0.0188\n",
      "epoch 1148 loss 0.2998 LR 0.2808 LKL 0.0191\n",
      "epoch 1149 loss 0.2673 LR 0.2482 LKL 0.0191\n",
      "epoch 1150 loss 0.2510 LR 0.2321 LKL 0.0190\n",
      "epoch 1151 loss 0.2694 LR 0.2505 LKL 0.0189\n",
      "epoch 1152 loss 0.2998 LR 0.2806 LKL 0.0192\n",
      "epoch 1153 loss 0.2936 LR 0.2746 LKL 0.0190\n",
      "epoch 1154 loss 0.3341 LR 0.3153 LKL 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1155 loss 0.2669 LR 0.2481 LKL 0.0188\n",
      "epoch 1156 loss 0.3131 LR 0.2942 LKL 0.0189\n",
      "epoch 1157 loss 0.2553 LR 0.2363 LKL 0.0190\n",
      "epoch 1158 loss 0.2520 LR 0.2332 LKL 0.0188\n",
      "epoch 1159 loss 0.3024 LR 0.2834 LKL 0.0191\n",
      "epoch 1160 loss 0.3069 LR 0.2879 LKL 0.0189\n",
      "epoch 1161 loss 0.3477 LR 0.3289 LKL 0.0188\n",
      "epoch 1162 loss 0.2842 LR 0.2654 LKL 0.0188\n",
      "epoch 1163 loss 0.3025 LR 0.2834 LKL 0.0192\n",
      "epoch 1164 loss 0.3393 LR 0.3205 LKL 0.0188\n",
      "epoch 1165 loss 0.3273 LR 0.3082 LKL 0.0191\n",
      "epoch 1166 loss 0.3000 LR 0.2810 LKL 0.0190\n",
      "epoch 1167 loss 0.3286 LR 0.3095 LKL 0.0190\n",
      "epoch 1168 loss 0.2350 LR 0.2158 LKL 0.0192\n",
      "epoch 1169 loss 0.2948 LR 0.2755 LKL 0.0193\n",
      "epoch 1170 loss 0.3356 LR 0.3162 LKL 0.0194\n",
      "epoch 1171 loss 0.2938 LR 0.2746 LKL 0.0192\n",
      "epoch 1172 loss 0.2620 LR 0.2430 LKL 0.0190\n",
      "epoch 1173 loss 0.2658 LR 0.2467 LKL 0.0192\n",
      "epoch 1174 loss 0.3092 LR 0.2899 LKL 0.0193\n",
      "epoch 1175 loss 0.2799 LR 0.2604 LKL 0.0194\n",
      "epoch 1176 loss 0.3623 LR 0.3430 LKL 0.0193\n",
      "epoch 1177 loss 0.2949 LR 0.2759 LKL 0.0190\n",
      "epoch 1178 loss 0.3358 LR 0.3166 LKL 0.0192\n",
      "epoch 1179 loss 0.2632 LR 0.2440 LKL 0.0192\n",
      "epoch 1180 loss 0.2819 LR 0.2623 LKL 0.0196\n",
      "epoch 1181 loss 0.3140 LR 0.2944 LKL 0.0197\n",
      "epoch 1182 loss 0.2583 LR 0.2386 LKL 0.0197\n",
      "epoch 1183 loss 0.3134 LR 0.2936 LKL 0.0198\n",
      "epoch 1184 loss 0.3044 LR 0.2846 LKL 0.0197\n",
      "epoch 1185 loss 0.2410 LR 0.2216 LKL 0.0194\n",
      "epoch 1186 loss 0.2963 LR 0.2768 LKL 0.0195\n",
      "epoch 1187 loss 0.2619 LR 0.2422 LKL 0.0196\n",
      "epoch 1188 loss 0.3156 LR 0.2963 LKL 0.0194\n",
      "epoch 1189 loss 0.3109 LR 0.2913 LKL 0.0196\n",
      "epoch 1190 loss 0.2628 LR 0.2433 LKL 0.0195\n",
      "epoch 1191 loss 0.2848 LR 0.2653 LKL 0.0194\n",
      "epoch 1192 loss 0.2236 LR 0.2038 LKL 0.0198\n",
      "epoch 1193 loss 0.2878 LR 0.2679 LKL 0.0199\n",
      "epoch 1194 loss 0.3043 LR 0.2846 LKL 0.0197\n",
      "epoch 1195 loss 0.2582 LR 0.2388 LKL 0.0195\n",
      "epoch 1196 loss 0.3059 LR 0.2864 LKL 0.0195\n",
      "epoch 1197 loss 0.2573 LR 0.2379 LKL 0.0195\n",
      "epoch 1198 loss 0.2651 LR 0.2455 LKL 0.0196\n",
      "epoch 1199 loss 0.2873 LR 0.2679 LKL 0.0194\n",
      "epoch 1200 loss 0.2915 LR 0.2723 LKL 0.0192\n",
      "epoch 1201 loss 0.2696 LR 0.2506 LKL 0.0191\n",
      "epoch 1202 loss 0.2826 LR 0.2636 LKL 0.0190\n",
      "epoch 1203 loss 0.3152 LR 0.2964 LKL 0.0189\n",
      "epoch 1204 loss 0.2995 LR 0.2806 LKL 0.0189\n",
      "epoch 1205 loss 0.2227 LR 0.2037 LKL 0.0190\n",
      "epoch 1206 loss 0.3729 LR 0.3540 LKL 0.0189\n",
      "epoch 1207 loss 0.3109 LR 0.2920 LKL 0.0190\n",
      "epoch 1208 loss 0.3281 LR 0.3092 LKL 0.0189\n",
      "epoch 1209 loss 0.2802 LR 0.2613 LKL 0.0189\n",
      "epoch 1210 loss 0.3028 LR 0.2837 LKL 0.0191\n",
      "epoch 1211 loss 0.2874 LR 0.2684 LKL 0.0191\n",
      "epoch 1212 loss 0.2397 LR 0.2205 LKL 0.0192\n",
      "epoch 1213 loss 0.2958 LR 0.2766 LKL 0.0192\n",
      "epoch 1214 loss 0.3157 LR 0.2963 LKL 0.0195\n",
      "epoch 1215 loss 0.2328 LR 0.2135 LKL 0.0193\n",
      "epoch 1216 loss 0.2916 LR 0.2722 LKL 0.0194\n",
      "epoch 1217 loss 0.3026 LR 0.2832 LKL 0.0194\n",
      "epoch 1218 loss 0.3230 LR 0.3036 LKL 0.0194\n",
      "epoch 1219 loss 0.2386 LR 0.2191 LKL 0.0195\n",
      "epoch 1220 loss 0.3062 LR 0.2868 LKL 0.0194\n",
      "epoch 1221 loss 0.3258 LR 0.3064 LKL 0.0194\n",
      "epoch 1222 loss 0.2714 LR 0.2519 LKL 0.0196\n",
      "epoch 1223 loss 0.2940 LR 0.2743 LKL 0.0197\n",
      "epoch 1224 loss 0.3388 LR 0.3193 LKL 0.0195\n",
      "epoch 1225 loss 0.2495 LR 0.2299 LKL 0.0196\n",
      "epoch 1226 loss 0.2587 LR 0.2392 LKL 0.0195\n",
      "epoch 1227 loss 0.3408 LR 0.3212 LKL 0.0196\n",
      "epoch 1228 loss 0.3168 LR 0.2973 LKL 0.0195\n",
      "epoch 1229 loss 0.3048 LR 0.2854 LKL 0.0194\n",
      "epoch 1230 loss 0.2769 LR 0.2577 LKL 0.0191\n",
      "epoch 1231 loss 0.2400 LR 0.2208 LKL 0.0192\n",
      "epoch 1232 loss 0.2509 LR 0.2318 LKL 0.0191\n",
      "epoch 1233 loss 0.2785 LR 0.2592 LKL 0.0193\n",
      "epoch 1234 loss 0.3219 LR 0.3029 LKL 0.0190\n",
      "epoch 1235 loss 0.2523 LR 0.2333 LKL 0.0190\n",
      "epoch 1236 loss 0.2815 LR 0.2623 LKL 0.0192\n",
      "epoch 1237 loss 0.2416 LR 0.2224 LKL 0.0192\n",
      "epoch 1238 loss 0.3101 LR 0.2909 LKL 0.0192\n",
      "epoch 1239 loss 0.2050 LR 0.1859 LKL 0.0192\n",
      "epoch 1240 loss 0.2741 LR 0.2550 LKL 0.0192\n",
      "epoch 1241 loss 0.3007 LR 0.2816 LKL 0.0191\n",
      "epoch 1242 loss 0.3071 LR 0.2875 LKL 0.0196\n",
      "epoch 1243 loss 0.2460 LR 0.2265 LKL 0.0195\n",
      "epoch 1244 loss 0.2640 LR 0.2445 LKL 0.0194\n",
      "epoch 1245 loss 0.2502 LR 0.2306 LKL 0.0196\n",
      "epoch 1246 loss 0.2602 LR 0.2407 LKL 0.0195\n",
      "epoch 1247 loss 0.2480 LR 0.2280 LKL 0.0200\n",
      "epoch 1248 loss 0.2898 LR 0.2699 LKL 0.0199\n",
      "epoch 1249 loss 0.2649 LR 0.2450 LKL 0.0198\n",
      "epoch 1250 loss 0.2818 LR 0.2616 LKL 0.0201\n",
      "epoch 1251 loss 0.3178 LR 0.2976 LKL 0.0201\n",
      "epoch 1252 loss 0.2958 LR 0.2758 LKL 0.0200\n",
      "epoch 1253 loss 0.3298 LR 0.3099 LKL 0.0199\n",
      "epoch 1254 loss 0.2726 LR 0.2527 LKL 0.0200\n",
      "epoch 1255 loss 0.2417 LR 0.2218 LKL 0.0198\n",
      "epoch 1256 loss 0.2662 LR 0.2465 LKL 0.0197\n",
      "epoch 1257 loss 0.2944 LR 0.2748 LKL 0.0196\n",
      "epoch 1258 loss 0.3063 LR 0.2867 LKL 0.0196\n",
      "epoch 1259 loss 0.2451 LR 0.2256 LKL 0.0195\n",
      "epoch 1260 loss 0.2829 LR 0.2635 LKL 0.0194\n",
      "epoch 1261 loss 0.3084 LR 0.2890 LKL 0.0194\n",
      "epoch 1262 loss 0.3074 LR 0.2881 LKL 0.0194\n",
      "epoch 1263 loss 0.3090 LR 0.2899 LKL 0.0191\n",
      "epoch 1264 loss 0.2371 LR 0.2181 LKL 0.0190\n",
      "epoch 1265 loss 0.2756 LR 0.2566 LKL 0.0190\n",
      "epoch 1266 loss 0.2382 LR 0.2190 LKL 0.0192\n",
      "epoch 1267 loss 0.3145 LR 0.2954 LKL 0.0191\n",
      "epoch 1268 loss 0.3588 LR 0.3402 LKL 0.0186\n",
      "epoch 1269 loss 0.3055 LR 0.2865 LKL 0.0190\n",
      "epoch 1270 loss 0.2712 LR 0.2522 LKL 0.0190\n",
      "epoch 1271 loss 0.3010 LR 0.2821 LKL 0.0190\n",
      "epoch 1272 loss 0.3175 LR 0.2983 LKL 0.0193\n",
      "epoch 1273 loss 0.2729 LR 0.2536 LKL 0.0192\n",
      "epoch 1274 loss 0.2660 LR 0.2468 LKL 0.0192\n",
      "epoch 1275 loss 0.2511 LR 0.2319 LKL 0.0193\n",
      "epoch 1276 loss 0.2677 LR 0.2484 LKL 0.0193\n",
      "epoch 1277 loss 0.2485 LR 0.2292 LKL 0.0193\n",
      "epoch 1278 loss 0.2180 LR 0.1983 LKL 0.0197\n",
      "epoch 1279 loss 0.3167 LR 0.2970 LKL 0.0197\n",
      "epoch 1280 loss 0.2626 LR 0.2426 LKL 0.0200\n",
      "epoch 1281 loss 0.2608 LR 0.2407 LKL 0.0201\n",
      "epoch 1282 loss 0.2567 LR 0.2366 LKL 0.0201\n",
      "epoch 1283 loss 0.2219 LR 0.2017 LKL 0.0201\n",
      "epoch 1284 loss 0.2664 LR 0.2460 LKL 0.0203\n",
      "epoch 1285 loss 0.2370 LR 0.2166 LKL 0.0204\n",
      "epoch 1286 loss 0.3059 LR 0.2854 LKL 0.0205\n",
      "epoch 1287 loss 0.2592 LR 0.2388 LKL 0.0204\n",
      "epoch 1288 loss 0.2965 LR 0.2761 LKL 0.0204\n",
      "epoch 1289 loss 0.2728 LR 0.2524 LKL 0.0204\n",
      "epoch 1290 loss 0.2435 LR 0.2232 LKL 0.0202\n",
      "epoch 1291 loss 0.2945 LR 0.2748 LKL 0.0198\n",
      "epoch 1292 loss 0.2789 LR 0.2592 LKL 0.0196\n",
      "epoch 1293 loss 0.2936 LR 0.2739 LKL 0.0197\n",
      "epoch 1294 loss 0.2680 LR 0.2485 LKL 0.0195\n",
      "epoch 1295 loss 0.2718 LR 0.2523 LKL 0.0195\n",
      "epoch 1296 loss 0.3478 LR 0.3286 LKL 0.0192\n",
      "epoch 1297 loss 0.2871 LR 0.2679 LKL 0.0193\n",
      "epoch 1298 loss 0.2401 LR 0.2208 LKL 0.0193\n",
      "epoch 1299 loss 0.3023 LR 0.2830 LKL 0.0193\n",
      "epoch 1300 loss 0.2400 LR 0.2207 LKL 0.0193\n",
      "epoch 1301 loss 0.3097 LR 0.2905 LKL 0.0192\n",
      "epoch 1302 loss 0.2590 LR 0.2399 LKL 0.0191\n",
      "epoch 1303 loss 0.2604 LR 0.2414 LKL 0.0190\n",
      "epoch 1304 loss 0.2380 LR 0.2188 LKL 0.0193\n",
      "epoch 1305 loss 0.2346 LR 0.2152 LKL 0.0194\n",
      "epoch 1306 loss 0.2271 LR 0.2077 LKL 0.0193\n",
      "epoch 1307 loss 0.2399 LR 0.2202 LKL 0.0197\n",
      "epoch 1308 loss 0.2225 LR 0.2027 LKL 0.0198\n",
      "epoch 1309 loss 0.2650 LR 0.2453 LKL 0.0197\n",
      "epoch 1310 loss 0.2975 LR 0.2775 LKL 0.0200\n",
      "epoch 1311 loss 0.2155 LR 0.1953 LKL 0.0202\n",
      "epoch 1312 loss 0.2353 LR 0.2150 LKL 0.0202\n",
      "epoch 1313 loss 0.2702 LR 0.2501 LKL 0.0201\n",
      "epoch 1314 loss 0.2428 LR 0.2226 LKL 0.0201\n",
      "epoch 1315 loss 0.2434 LR 0.2230 LKL 0.0204\n",
      "epoch 1316 loss 0.2759 LR 0.2556 LKL 0.0204\n",
      "epoch 1317 loss 0.2808 LR 0.2605 LKL 0.0203\n",
      "epoch 1318 loss 0.1976 LR 0.1772 LKL 0.0204\n",
      "epoch 1319 loss 0.2183 LR 0.1981 LKL 0.0202\n",
      "epoch 1320 loss 0.2477 LR 0.2273 LKL 0.0204\n",
      "epoch 1321 loss 0.2820 LR 0.2616 LKL 0.0204\n",
      "epoch 1322 loss 0.2249 LR 0.2047 LKL 0.0203\n",
      "epoch 1323 loss 0.2832 LR 0.2628 LKL 0.0204\n",
      "epoch 1324 loss 0.2717 LR 0.2516 LKL 0.0201\n",
      "epoch 1325 loss 0.2683 LR 0.2482 LKL 0.0201\n",
      "epoch 1326 loss 0.2986 LR 0.2785 LKL 0.0201\n",
      "epoch 1327 loss 0.2628 LR 0.2427 LKL 0.0201\n",
      "epoch 1328 loss 0.2586 LR 0.2385 LKL 0.0201\n",
      "epoch 1329 loss 0.2758 LR 0.2556 LKL 0.0202\n",
      "epoch 1330 loss 0.2557 LR 0.2357 LKL 0.0201\n",
      "epoch 1331 loss 0.2294 LR 0.2093 LKL 0.0201\n",
      "epoch 1332 loss 0.1987 LR 0.1783 LKL 0.0204\n",
      "epoch 1333 loss 0.2449 LR 0.2248 LKL 0.0201\n",
      "epoch 1334 loss 0.2745 LR 0.2544 LKL 0.0201\n",
      "epoch 1335 loss 0.2421 LR 0.2220 LKL 0.0201\n",
      "epoch 1336 loss 0.2576 LR 0.2376 LKL 0.0201\n",
      "epoch 1337 loss 0.2320 LR 0.2121 LKL 0.0199\n",
      "epoch 1338 loss 0.2594 LR 0.2395 LKL 0.0198\n",
      "epoch 1339 loss 0.2527 LR 0.2329 LKL 0.0198\n",
      "epoch 1340 loss 0.2734 LR 0.2540 LKL 0.0194\n",
      "epoch 1341 loss 0.2575 LR 0.2379 LKL 0.0195\n",
      "epoch 1342 loss 0.2780 LR 0.2584 LKL 0.0196\n",
      "epoch 1343 loss 0.2731 LR 0.2535 LKL 0.0196\n",
      "epoch 1344 loss 0.2904 LR 0.2709 LKL 0.0195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1345 loss 0.2617 LR 0.2422 LKL 0.0195\n",
      "epoch 1346 loss 0.3083 LR 0.2891 LKL 0.0193\n",
      "epoch 1347 loss 0.3038 LR 0.2844 LKL 0.0195\n",
      "epoch 1348 loss 0.2826 LR 0.2631 LKL 0.0195\n",
      "epoch 1349 loss 0.2672 LR 0.2476 LKL 0.0196\n",
      "epoch 1350 loss 0.2918 LR 0.2720 LKL 0.0197\n",
      "epoch 1351 loss 0.2992 LR 0.2793 LKL 0.0199\n",
      "epoch 1352 loss 0.2434 LR 0.2234 LKL 0.0200\n",
      "epoch 1353 loss 0.2454 LR 0.2253 LKL 0.0201\n",
      "epoch 1354 loss 0.2947 LR 0.2743 LKL 0.0204\n",
      "epoch 1355 loss 0.2648 LR 0.2444 LKL 0.0204\n",
      "epoch 1356 loss 0.2977 LR 0.2774 LKL 0.0204\n",
      "epoch 1357 loss 0.2629 LR 0.2426 LKL 0.0203\n",
      "epoch 1358 loss 0.2678 LR 0.2474 LKL 0.0203\n",
      "epoch 1359 loss 0.3165 LR 0.2962 LKL 0.0204\n",
      "epoch 1360 loss 0.2997 LR 0.2795 LKL 0.0201\n",
      "epoch 1361 loss 0.2265 LR 0.2064 LKL 0.0201\n",
      "epoch 1362 loss 0.2491 LR 0.2290 LKL 0.0202\n",
      "epoch 1363 loss 0.2253 LR 0.2053 LKL 0.0200\n",
      "epoch 1364 loss 0.2744 LR 0.2544 LKL 0.0201\n",
      "epoch 1365 loss 0.2270 LR 0.2072 LKL 0.0199\n",
      "epoch 1366 loss 0.2211 LR 0.2010 LKL 0.0201\n",
      "epoch 1367 loss 0.2567 LR 0.2367 LKL 0.0200\n",
      "epoch 1368 loss 0.2852 LR 0.2651 LKL 0.0201\n",
      "epoch 1369 loss 0.3231 LR 0.3028 LKL 0.0203\n",
      "epoch 1370 loss 0.3025 LR 0.2826 LKL 0.0199\n",
      "epoch 1371 loss 0.2709 LR 0.2510 LKL 0.0199\n",
      "epoch 1372 loss 0.2145 LR 0.1945 LKL 0.0200\n",
      "epoch 1373 loss 0.2550 LR 0.2351 LKL 0.0199\n",
      "epoch 1374 loss 0.2572 LR 0.2374 LKL 0.0198\n",
      "epoch 1375 loss 0.2301 LR 0.2102 LKL 0.0200\n",
      "epoch 1376 loss 0.2618 LR 0.2419 LKL 0.0199\n",
      "epoch 1377 loss 0.3047 LR 0.2850 LKL 0.0197\n",
      "epoch 1378 loss 0.2927 LR 0.2727 LKL 0.0199\n",
      "epoch 1379 loss 0.2435 LR 0.2234 LKL 0.0201\n",
      "epoch 1380 loss 0.2204 LR 0.2005 LKL 0.0200\n",
      "epoch 1381 loss 0.2824 LR 0.2624 LKL 0.0200\n",
      "epoch 1382 loss 0.2438 LR 0.2240 LKL 0.0198\n",
      "epoch 1383 loss 0.2609 LR 0.2409 LKL 0.0200\n",
      "epoch 1384 loss 0.2364 LR 0.2162 LKL 0.0201\n",
      "epoch 1385 loss 0.2643 LR 0.2443 LKL 0.0200\n",
      "epoch 1386 loss 0.2365 LR 0.2164 LKL 0.0201\n",
      "epoch 1387 loss 0.2368 LR 0.2166 LKL 0.0202\n",
      "epoch 1388 loss 0.2341 LR 0.2140 LKL 0.0201\n",
      "epoch 1389 loss 0.2254 LR 0.2053 LKL 0.0201\n",
      "epoch 1390 loss 0.3065 LR 0.2866 LKL 0.0199\n",
      "epoch 1391 loss 0.2908 LR 0.2706 LKL 0.0202\n",
      "epoch 1392 loss 0.2614 LR 0.2413 LKL 0.0201\n",
      "epoch 1393 loss 0.2908 LR 0.2706 LKL 0.0202\n",
      "epoch 1394 loss 0.2037 LR 0.1834 LKL 0.0204\n",
      "epoch 1395 loss 0.2391 LR 0.2190 LKL 0.0201\n",
      "epoch 1396 loss 0.2389 LR 0.2186 LKL 0.0203\n",
      "epoch 1397 loss 0.2349 LR 0.2147 LKL 0.0202\n",
      "epoch 1398 loss 0.2433 LR 0.2231 LKL 0.0201\n",
      "epoch 1399 loss 0.2354 LR 0.2152 LKL 0.0202\n",
      "epoch 1400 loss 0.2438 LR 0.2236 LKL 0.0202\n",
      "88\n",
      "epoch 1401 loss 0.2540 LR 0.2338 LKL 0.0202\n",
      "epoch 1402 loss 0.2598 LR 0.2396 LKL 0.0202\n",
      "epoch 1403 loss 0.2679 LR 0.2477 LKL 0.0202\n",
      "epoch 1404 loss 0.2106 LR 0.1903 LKL 0.0203\n",
      "epoch 1405 loss 0.2509 LR 0.2304 LKL 0.0205\n",
      "epoch 1406 loss 0.2439 LR 0.2234 LKL 0.0205\n",
      "epoch 1407 loss 0.3195 LR 0.2991 LKL 0.0204\n",
      "epoch 1408 loss 0.2538 LR 0.2335 LKL 0.0204\n",
      "epoch 1409 loss 0.2500 LR 0.2296 LKL 0.0204\n",
      "epoch 1410 loss 0.2125 LR 0.1921 LKL 0.0204\n",
      "epoch 1411 loss 0.2558 LR 0.2353 LKL 0.0205\n",
      "epoch 1412 loss 0.2879 LR 0.2677 LKL 0.0202\n",
      "epoch 1413 loss 0.2849 LR 0.2646 LKL 0.0203\n",
      "epoch 1414 loss 0.2555 LR 0.2355 LKL 0.0201\n",
      "epoch 1415 loss 0.2341 LR 0.2140 LKL 0.0201\n",
      "epoch 1416 loss 0.2452 LR 0.2252 LKL 0.0200\n",
      "epoch 1417 loss 0.2496 LR 0.2298 LKL 0.0198\n",
      "epoch 1418 loss 0.2474 LR 0.2274 LKL 0.0200\n",
      "epoch 1419 loss 0.2318 LR 0.2118 LKL 0.0200\n",
      "epoch 1420 loss 0.2959 LR 0.2758 LKL 0.0200\n",
      "epoch 1421 loss 0.2047 LR 0.1848 LKL 0.0199\n",
      "epoch 1422 loss 0.2623 LR 0.2424 LKL 0.0199\n",
      "epoch 1423 loss 0.2724 LR 0.2524 LKL 0.0200\n",
      "epoch 1424 loss 0.2556 LR 0.2357 LKL 0.0199\n",
      "epoch 1425 loss 0.2824 LR 0.2623 LKL 0.0201\n",
      "epoch 1426 loss 0.2394 LR 0.2195 LKL 0.0199\n",
      "epoch 1427 loss 0.2678 LR 0.2478 LKL 0.0200\n",
      "epoch 1428 loss 0.2489 LR 0.2289 LKL 0.0200\n",
      "epoch 1429 loss 0.3052 LR 0.2853 LKL 0.0199\n",
      "epoch 1430 loss 0.2475 LR 0.2277 LKL 0.0199\n",
      "epoch 1431 loss 0.2896 LR 0.2695 LKL 0.0201\n",
      "epoch 1432 loss 0.2796 LR 0.2594 LKL 0.0201\n",
      "epoch 1433 loss 0.2501 LR 0.2300 LKL 0.0201\n",
      "epoch 1434 loss 0.2777 LR 0.2576 LKL 0.0201\n",
      "epoch 1435 loss 0.2309 LR 0.2110 LKL 0.0199\n",
      "epoch 1436 loss 0.2636 LR 0.2437 LKL 0.0198\n",
      "epoch 1437 loss 0.2572 LR 0.2370 LKL 0.0202\n",
      "epoch 1438 loss 0.2438 LR 0.2234 LKL 0.0204\n",
      "epoch 1439 loss 0.2398 LR 0.2195 LKL 0.0204\n",
      "epoch 1440 loss 0.2851 LR 0.2645 LKL 0.0205\n",
      "epoch 1441 loss 0.2901 LR 0.2695 LKL 0.0205\n",
      "epoch 1442 loss 0.2251 LR 0.2045 LKL 0.0206\n",
      "epoch 1443 loss 0.2302 LR 0.2095 LKL 0.0207\n",
      "epoch 1444 loss 0.2452 LR 0.2245 LKL 0.0207\n",
      "epoch 1445 loss 0.1913 LR 0.1706 LKL 0.0207\n",
      "epoch 1446 loss 0.2351 LR 0.2146 LKL 0.0205\n",
      "epoch 1447 loss 0.2297 LR 0.2094 LKL 0.0203\n",
      "epoch 1448 loss 0.2822 LR 0.2616 LKL 0.0206\n",
      "epoch 1449 loss 0.3088 LR 0.2881 LKL 0.0208\n",
      "epoch 1450 loss 0.1907 LR 0.1701 LKL 0.0206\n",
      "epoch 1451 loss 0.2502 LR 0.2294 LKL 0.0208\n",
      "epoch 1452 loss 0.1958 LR 0.1752 LKL 0.0206\n",
      "epoch 1453 loss 0.1970 LR 0.1764 LKL 0.0206\n",
      "epoch 1454 loss 0.3297 LR 0.3090 LKL 0.0207\n",
      "epoch 1455 loss 0.2951 LR 0.2744 LKL 0.0207\n",
      "epoch 1456 loss 0.3027 LR 0.2822 LKL 0.0205\n",
      "epoch 1457 loss 0.2115 LR 0.1912 LKL 0.0203\n",
      "epoch 1458 loss 0.2786 LR 0.2581 LKL 0.0204\n",
      "epoch 1459 loss 0.2328 LR 0.2122 LKL 0.0206\n",
      "epoch 1460 loss 0.2338 LR 0.2130 LKL 0.0208\n",
      "epoch 1461 loss 0.2148 LR 0.1939 LKL 0.0209\n",
      "epoch 1462 loss 0.3042 LR 0.2836 LKL 0.0206\n",
      "epoch 1463 loss 0.2450 LR 0.2243 LKL 0.0207\n",
      "epoch 1464 loss 0.2369 LR 0.2163 LKL 0.0206\n",
      "epoch 1465 loss 0.2397 LR 0.2193 LKL 0.0204\n",
      "epoch 1466 loss 0.2427 LR 0.2222 LKL 0.0205\n",
      "epoch 1467 loss 0.2404 LR 0.2200 LKL 0.0204\n",
      "epoch 1468 loss 0.2493 LR 0.2290 LKL 0.0203\n",
      "epoch 1469 loss 0.2289 LR 0.2084 LKL 0.0205\n",
      "epoch 1470 loss 0.2293 LR 0.2091 LKL 0.0203\n",
      "epoch 1471 loss 0.2563 LR 0.2359 LKL 0.0204\n",
      "epoch 1472 loss 0.2191 LR 0.1987 LKL 0.0204\n",
      "epoch 1473 loss 0.2592 LR 0.2389 LKL 0.0203\n",
      "epoch 1474 loss 0.2250 LR 0.2046 LKL 0.0205\n",
      "epoch 1475 loss 0.2565 LR 0.2362 LKL 0.0203\n",
      "epoch 1476 loss 0.2577 LR 0.2372 LKL 0.0205\n",
      "epoch 1477 loss 0.2946 LR 0.2740 LKL 0.0206\n",
      "epoch 1478 loss 0.2386 LR 0.2181 LKL 0.0205\n",
      "epoch 1479 loss 0.2394 LR 0.2189 LKL 0.0205\n",
      "epoch 1480 loss 0.2287 LR 0.2082 LKL 0.0205\n",
      "epoch 1481 loss 0.2809 LR 0.2604 LKL 0.0205\n",
      "epoch 1482 loss 0.2092 LR 0.1887 LKL 0.0205\n",
      "epoch 1483 loss 0.2630 LR 0.2427 LKL 0.0204\n",
      "epoch 1484 loss 0.1991 LR 0.1787 LKL 0.0204\n",
      "epoch 1485 loss 0.3266 LR 0.3062 LKL 0.0204\n",
      "epoch 1486 loss 0.2398 LR 0.2192 LKL 0.0206\n",
      "epoch 1487 loss 0.2924 LR 0.2718 LKL 0.0206\n",
      "epoch 1488 loss 0.2693 LR 0.2488 LKL 0.0205\n",
      "epoch 1489 loss 0.2242 LR 0.2035 LKL 0.0206\n",
      "epoch 1490 loss 0.2227 LR 0.2020 LKL 0.0208\n",
      "epoch 1491 loss 0.2079 LR 0.1870 LKL 0.0209\n",
      "epoch 1492 loss 0.2798 LR 0.2592 LKL 0.0207\n",
      "epoch 1493 loss 0.2787 LR 0.2582 LKL 0.0205\n",
      "epoch 1494 loss 0.2200 LR 0.1994 LKL 0.0206\n",
      "epoch 1495 loss 0.2427 LR 0.2223 LKL 0.0204\n",
      "epoch 1496 loss 0.1895 LR 0.1689 LKL 0.0206\n",
      "epoch 1497 loss 0.2308 LR 0.2103 LKL 0.0204\n",
      "epoch 1498 loss 0.2437 LR 0.2236 LKL 0.0201\n",
      "epoch 1499 loss 0.2352 LR 0.2149 LKL 0.0202\n",
      "epoch 1500 loss 0.2718 LR 0.2516 LKL 0.0201\n",
      "102\n",
      "epoch 1501 loss 0.1648 LR 0.1443 LKL 0.0206\n",
      "epoch 1502 loss 0.2482 LR 0.2278 LKL 0.0204\n",
      "epoch 1503 loss 0.2409 LR 0.2205 LKL 0.0204\n",
      "epoch 1504 loss 0.2684 LR 0.2477 LKL 0.0208\n",
      "epoch 1505 loss 0.2694 LR 0.2487 LKL 0.0207\n",
      "epoch 1506 loss 0.2140 LR 0.1932 LKL 0.0208\n",
      "epoch 1507 loss 0.1942 LR 0.1733 LKL 0.0209\n",
      "epoch 1508 loss 0.2586 LR 0.2377 LKL 0.0210\n",
      "epoch 1509 loss 0.2196 LR 0.1988 LKL 0.0209\n",
      "epoch 1510 loss 0.2487 LR 0.2280 LKL 0.0207\n",
      "epoch 1511 loss 0.2169 LR 0.1963 LKL 0.0206\n",
      "epoch 1512 loss 0.2158 LR 0.1953 LKL 0.0205\n",
      "epoch 1513 loss 0.1798 LR 0.1594 LKL 0.0204\n",
      "epoch 1514 loss 0.2182 LR 0.1981 LKL 0.0201\n",
      "epoch 1515 loss 0.2653 LR 0.2453 LKL 0.0200\n",
      "epoch 1516 loss 0.2403 LR 0.2204 LKL 0.0199\n",
      "epoch 1517 loss 0.2176 LR 0.1977 LKL 0.0198\n",
      "epoch 1518 loss 0.1725 LR 0.1524 LKL 0.0201\n",
      "epoch 1519 loss 0.2600 LR 0.2399 LKL 0.0200\n",
      "epoch 1520 loss 0.2600 LR 0.2399 LKL 0.0201\n",
      "epoch 1521 loss 0.2811 LR 0.2610 LKL 0.0201\n",
      "epoch 1522 loss 0.2454 LR 0.2253 LKL 0.0201\n",
      "epoch 1523 loss 0.2751 LR 0.2547 LKL 0.0204\n",
      "epoch 1524 loss 0.2471 LR 0.2266 LKL 0.0206\n",
      "epoch 1525 loss 0.2545 LR 0.2336 LKL 0.0209\n",
      "epoch 1526 loss 0.2452 LR 0.2242 LKL 0.0210\n",
      "epoch 1527 loss 0.2834 LR 0.2626 LKL 0.0208\n",
      "epoch 1528 loss 0.1979 LR 0.1771 LKL 0.0208\n",
      "epoch 1529 loss 0.2063 LR 0.1853 LKL 0.0210\n",
      "epoch 1530 loss 0.2662 LR 0.2452 LKL 0.0210\n",
      "epoch 1531 loss 0.2047 LR 0.1836 LKL 0.0211\n",
      "epoch 1532 loss 0.2244 LR 0.2035 LKL 0.0208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1533 loss 0.2540 LR 0.2331 LKL 0.0209\n",
      "epoch 1534 loss 0.1874 LR 0.1666 LKL 0.0208\n",
      "epoch 1535 loss 0.2474 LR 0.2266 LKL 0.0207\n",
      "epoch 1536 loss 0.2520 LR 0.2313 LKL 0.0206\n",
      "epoch 1537 loss 0.2282 LR 0.2074 LKL 0.0209\n",
      "epoch 1538 loss 0.2362 LR 0.2156 LKL 0.0206\n",
      "epoch 1539 loss 0.2716 LR 0.2511 LKL 0.0205\n",
      "epoch 1540 loss 0.2341 LR 0.2136 LKL 0.0205\n",
      "epoch 1541 loss 0.1987 LR 0.1783 LKL 0.0203\n",
      "epoch 1542 loss 0.2784 LR 0.2582 LKL 0.0202\n",
      "epoch 1543 loss 0.2569 LR 0.2366 LKL 0.0203\n",
      "epoch 1544 loss 0.2576 LR 0.2373 LKL 0.0203\n",
      "epoch 1545 loss 0.2272 LR 0.2069 LKL 0.0203\n",
      "epoch 1546 loss 0.2310 LR 0.2107 LKL 0.0203\n",
      "epoch 1547 loss 0.2190 LR 0.1987 LKL 0.0203\n",
      "epoch 1548 loss 0.2106 LR 0.1901 LKL 0.0205\n",
      "epoch 1549 loss 0.2653 LR 0.2449 LKL 0.0204\n",
      "epoch 1550 loss 0.1970 LR 0.1766 LKL 0.0204\n",
      "epoch 1551 loss 0.2386 LR 0.2178 LKL 0.0208\n",
      "epoch 1552 loss 0.2523 LR 0.2317 LKL 0.0206\n",
      "epoch 1553 loss 0.2592 LR 0.2388 LKL 0.0204\n",
      "epoch 1554 loss 0.2247 LR 0.2042 LKL 0.0205\n",
      "epoch 1555 loss 0.2351 LR 0.2145 LKL 0.0207\n",
      "epoch 1556 loss 0.2141 LR 0.1935 LKL 0.0207\n",
      "epoch 1557 loss 0.2324 LR 0.2119 LKL 0.0205\n",
      "epoch 1558 loss 0.2248 LR 0.2042 LKL 0.0205\n",
      "epoch 1559 loss 0.2384 LR 0.2180 LKL 0.0204\n",
      "epoch 1560 loss 0.2027 LR 0.1824 LKL 0.0203\n",
      "epoch 1561 loss 0.2780 LR 0.2577 LKL 0.0203\n",
      "epoch 1562 loss 0.2551 LR 0.2349 LKL 0.0203\n",
      "epoch 1563 loss 0.2219 LR 0.2018 LKL 0.0201\n",
      "epoch 1564 loss 0.2446 LR 0.2243 LKL 0.0203\n",
      "epoch 1565 loss 0.1851 LR 0.1646 LKL 0.0205\n",
      "epoch 1566 loss 0.2397 LR 0.2192 LKL 0.0205\n",
      "epoch 1567 loss 0.2303 LR 0.2096 LKL 0.0207\n",
      "epoch 1568 loss 0.2642 LR 0.2436 LKL 0.0207\n",
      "epoch 1569 loss 0.2301 LR 0.2095 LKL 0.0206\n",
      "epoch 1570 loss 0.2519 LR 0.2313 LKL 0.0206\n",
      "epoch 1571 loss 0.2854 LR 0.2648 LKL 0.0206\n",
      "epoch 1572 loss 0.2842 LR 0.2634 LKL 0.0208\n",
      "epoch 1573 loss 0.2328 LR 0.2122 LKL 0.0206\n",
      "epoch 1574 loss 0.2083 LR 0.1877 LKL 0.0206\n",
      "epoch 1575 loss 0.2072 LR 0.1867 LKL 0.0205\n",
      "epoch 1576 loss 0.1986 LR 0.1780 LKL 0.0207\n",
      "epoch 1577 loss 0.2384 LR 0.2178 LKL 0.0205\n",
      "epoch 1578 loss 0.2912 LR 0.2709 LKL 0.0204\n",
      "epoch 1579 loss 0.3043 LR 0.2841 LKL 0.0202\n",
      "epoch 1580 loss 0.2467 LR 0.2264 LKL 0.0203\n",
      "epoch 1581 loss 0.2066 LR 0.1864 LKL 0.0202\n",
      "epoch 1582 loss 0.2192 LR 0.1989 LKL 0.0203\n",
      "epoch 1583 loss 0.2141 LR 0.1944 LKL 0.0198\n",
      "epoch 1584 loss 0.2351 LR 0.2152 LKL 0.0199\n",
      "epoch 1585 loss 0.2437 LR 0.2237 LKL 0.0199\n",
      "epoch 1586 loss 0.2257 LR 0.2057 LKL 0.0200\n",
      "epoch 1587 loss 0.3150 LR 0.2952 LKL 0.0199\n",
      "epoch 1588 loss 0.2101 LR 0.1900 LKL 0.0201\n",
      "epoch 1589 loss 0.2432 LR 0.2233 LKL 0.0199\n",
      "epoch 1590 loss 0.1929 LR 0.1729 LKL 0.0200\n",
      "epoch 1591 loss 0.2334 LR 0.2134 LKL 0.0200\n",
      "epoch 1592 loss 0.2181 LR 0.1980 LKL 0.0201\n",
      "epoch 1593 loss 0.2640 LR 0.2442 LKL 0.0198\n",
      "epoch 1594 loss 0.2566 LR 0.2366 LKL 0.0200\n",
      "epoch 1595 loss 0.1687 LR 0.1487 LKL 0.0200\n",
      "epoch 1596 loss 0.2238 LR 0.2036 LKL 0.0202\n",
      "epoch 1597 loss 0.2552 LR 0.2350 LKL 0.0202\n",
      "epoch 1598 loss 0.2425 LR 0.2223 LKL 0.0202\n",
      "epoch 1599 loss 0.2389 LR 0.2188 LKL 0.0201\n",
      "epoch 1600 loss 0.2655 LR 0.2452 LKL 0.0203\n",
      "105\n",
      "epoch 1601 loss 0.2237 LR 0.2034 LKL 0.0203\n",
      "epoch 1602 loss 0.2480 LR 0.2275 LKL 0.0205\n",
      "epoch 1603 loss 0.2103 LR 0.1898 LKL 0.0205\n",
      "epoch 1604 loss 0.2020 LR 0.1812 LKL 0.0208\n",
      "epoch 1605 loss 0.2712 LR 0.2505 LKL 0.0207\n",
      "epoch 1606 loss 0.2643 LR 0.2435 LKL 0.0207\n",
      "epoch 1607 loss 0.2107 LR 0.1900 LKL 0.0207\n",
      "epoch 1608 loss 0.2780 LR 0.2572 LKL 0.0208\n",
      "epoch 1609 loss 0.2326 LR 0.2119 LKL 0.0207\n",
      "epoch 1610 loss 0.2117 LR 0.1911 LKL 0.0206\n",
      "epoch 1611 loss 0.2833 LR 0.2626 LKL 0.0207\n",
      "epoch 1612 loss 0.2253 LR 0.2043 LKL 0.0209\n",
      "epoch 1613 loss 0.1642 LR 0.1432 LKL 0.0209\n",
      "epoch 1614 loss 0.2238 LR 0.2029 LKL 0.0209\n",
      "epoch 1615 loss 0.2076 LR 0.1868 LKL 0.0208\n",
      "epoch 1616 loss 0.2319 LR 0.2110 LKL 0.0209\n",
      "epoch 1617 loss 0.2077 LR 0.1869 LKL 0.0208\n",
      "epoch 1618 loss 0.2578 LR 0.2372 LKL 0.0206\n",
      "epoch 1619 loss 0.2080 LR 0.1876 LKL 0.0204\n",
      "epoch 1620 loss 0.2004 LR 0.1798 LKL 0.0206\n",
      "epoch 1621 loss 0.2150 LR 0.1947 LKL 0.0203\n",
      "epoch 1622 loss 0.1921 LR 0.1716 LKL 0.0205\n",
      "epoch 1623 loss 0.2036 LR 0.1830 LKL 0.0206\n",
      "epoch 1624 loss 0.2062 LR 0.1855 LKL 0.0207\n",
      "epoch 1625 loss 0.2473 LR 0.2268 LKL 0.0205\n",
      "epoch 1626 loss 0.2348 LR 0.2142 LKL 0.0206\n",
      "epoch 1627 loss 0.2140 LR 0.1934 LKL 0.0205\n",
      "epoch 1628 loss 0.2771 LR 0.2567 LKL 0.0204\n",
      "epoch 1629 loss 0.2294 LR 0.2090 LKL 0.0204\n",
      "epoch 1630 loss 0.2135 LR 0.1930 LKL 0.0204\n",
      "epoch 1631 loss 0.2504 LR 0.2301 LKL 0.0203\n",
      "epoch 1632 loss 0.2061 LR 0.1857 LKL 0.0204\n",
      "epoch 1633 loss 0.2278 LR 0.2075 LKL 0.0202\n",
      "epoch 1634 loss 0.2557 LR 0.2353 LKL 0.0204\n",
      "epoch 1635 loss 0.2403 LR 0.2199 LKL 0.0204\n",
      "epoch 1636 loss 0.1738 LR 0.1537 LKL 0.0201\n",
      "epoch 1637 loss 0.2232 LR 0.2031 LKL 0.0201\n",
      "epoch 1638 loss 0.2204 LR 0.2004 LKL 0.0200\n",
      "epoch 1639 loss 0.1835 LR 0.1636 LKL 0.0200\n",
      "epoch 1640 loss 0.2893 LR 0.2690 LKL 0.0203\n",
      "epoch 1641 loss 0.2493 LR 0.2291 LKL 0.0202\n",
      "epoch 1642 loss 0.2125 LR 0.1919 LKL 0.0206\n",
      "epoch 1643 loss 0.2387 LR 0.2180 LKL 0.0207\n",
      "epoch 1644 loss 0.2439 LR 0.2233 LKL 0.0207\n",
      "epoch 1645 loss 0.2276 LR 0.2067 LKL 0.0209\n",
      "epoch 1646 loss 0.2327 LR 0.2121 LKL 0.0206\n",
      "epoch 1647 loss 0.2086 LR 0.1879 LKL 0.0207\n",
      "epoch 1648 loss 0.2270 LR 0.2062 LKL 0.0208\n",
      "epoch 1649 loss 0.2272 LR 0.2065 LKL 0.0208\n",
      "epoch 1650 loss 0.1663 LR 0.1456 LKL 0.0208\n",
      "epoch 1651 loss 0.2452 LR 0.2243 LKL 0.0209\n",
      "epoch 1652 loss 0.2750 LR 0.2540 LKL 0.0210\n",
      "epoch 1653 loss 0.2194 LR 0.1982 LKL 0.0212\n",
      "epoch 1654 loss 0.2043 LR 0.1829 LKL 0.0214\n",
      "epoch 1655 loss 0.1820 LR 0.1607 LKL 0.0213\n",
      "epoch 1656 loss 0.2002 LR 0.1789 LKL 0.0212\n",
      "epoch 1657 loss 0.1948 LR 0.1738 LKL 0.0210\n",
      "epoch 1658 loss 0.2697 LR 0.2488 LKL 0.0209\n",
      "epoch 1659 loss 0.2640 LR 0.2430 LKL 0.0210\n",
      "epoch 1660 loss 0.2547 LR 0.2337 LKL 0.0210\n",
      "epoch 1661 loss 0.2233 LR 0.2024 LKL 0.0210\n",
      "epoch 1662 loss 0.2054 LR 0.1846 LKL 0.0207\n",
      "epoch 1663 loss 0.1809 LR 0.1602 LKL 0.0207\n",
      "epoch 1664 loss 0.2323 LR 0.2117 LKL 0.0207\n",
      "epoch 1665 loss 0.2361 LR 0.2152 LKL 0.0209\n",
      "epoch 1666 loss 0.2529 LR 0.2322 LKL 0.0207\n",
      "epoch 1667 loss 0.2397 LR 0.2190 LKL 0.0207\n",
      "epoch 1668 loss 0.2486 LR 0.2280 LKL 0.0206\n",
      "epoch 1669 loss 0.2822 LR 0.2618 LKL 0.0204\n",
      "epoch 1670 loss 0.1775 LR 0.1570 LKL 0.0205\n",
      "epoch 1671 loss 0.2921 LR 0.2717 LKL 0.0204\n",
      "epoch 1672 loss 0.2674 LR 0.2470 LKL 0.0204\n",
      "epoch 1673 loss 0.1921 LR 0.1717 LKL 0.0204\n",
      "epoch 1674 loss 0.2204 LR 0.2001 LKL 0.0204\n",
      "epoch 1675 loss 0.2295 LR 0.2091 LKL 0.0204\n",
      "epoch 1676 loss 0.2202 LR 0.1999 LKL 0.0202\n",
      "epoch 1677 loss 0.2847 LR 0.2643 LKL 0.0204\n",
      "epoch 1678 loss 0.2086 LR 0.1882 LKL 0.0204\n",
      "epoch 1679 loss 0.1961 LR 0.1755 LKL 0.0206\n",
      "epoch 1680 loss 0.2343 LR 0.2137 LKL 0.0206\n",
      "epoch 1681 loss 0.1524 LR 0.1319 LKL 0.0205\n",
      "epoch 1682 loss 0.2135 LR 0.1932 LKL 0.0203\n",
      "epoch 1683 loss 0.2743 LR 0.2537 LKL 0.0206\n",
      "epoch 1684 loss 0.2317 LR 0.2114 LKL 0.0204\n",
      "epoch 1685 loss 0.1886 LR 0.1683 LKL 0.0204\n",
      "epoch 1686 loss 0.2278 LR 0.2072 LKL 0.0205\n",
      "epoch 1687 loss 0.2191 LR 0.1987 LKL 0.0205\n",
      "epoch 1688 loss 0.2136 LR 0.1929 LKL 0.0206\n",
      "epoch 1689 loss 0.2632 LR 0.2423 LKL 0.0209\n",
      "epoch 1690 loss 0.2097 LR 0.1885 LKL 0.0211\n",
      "epoch 1691 loss 0.1941 LR 0.1730 LKL 0.0210\n",
      "epoch 1692 loss 0.2120 LR 0.1913 LKL 0.0207\n",
      "epoch 1693 loss 0.2462 LR 0.2251 LKL 0.0211\n",
      "epoch 1694 loss 0.2467 LR 0.2260 LKL 0.0208\n",
      "epoch 1695 loss 0.2860 LR 0.2652 LKL 0.0208\n",
      "epoch 1696 loss 0.2223 LR 0.2014 LKL 0.0209\n",
      "epoch 1697 loss 0.2214 LR 0.2006 LKL 0.0208\n",
      "epoch 1698 loss 0.2640 LR 0.2429 LKL 0.0210\n",
      "epoch 1699 loss 0.2047 LR 0.1839 LKL 0.0208\n",
      "epoch 1700 loss 0.2506 LR 0.2295 LKL 0.0211\n",
      "epoch 1701 loss 0.1776 LR 0.1569 LKL 0.0208\n",
      "epoch 1702 loss 0.1769 LR 0.1560 LKL 0.0209\n",
      "epoch 1703 loss 0.2443 LR 0.2232 LKL 0.0211\n",
      "epoch 1704 loss 0.2310 LR 0.2102 LKL 0.0209\n",
      "epoch 1705 loss 0.2080 LR 0.1871 LKL 0.0209\n",
      "epoch 1706 loss 0.1842 LR 0.1631 LKL 0.0212\n",
      "epoch 1707 loss 0.2258 LR 0.2047 LKL 0.0211\n",
      "epoch 1708 loss 0.2073 LR 0.1863 LKL 0.0210\n",
      "epoch 1709 loss 0.1914 LR 0.1705 LKL 0.0209\n",
      "epoch 1710 loss 0.2445 LR 0.2236 LKL 0.0209\n",
      "epoch 1711 loss 0.1766 LR 0.1556 LKL 0.0210\n",
      "epoch 1712 loss 0.1801 LR 0.1589 LKL 0.0212\n",
      "epoch 1713 loss 0.2300 LR 0.2092 LKL 0.0207\n",
      "epoch 1714 loss 0.1558 LR 0.1349 LKL 0.0208\n",
      "epoch 1715 loss 0.2748 LR 0.2544 LKL 0.0205\n",
      "epoch 1716 loss 0.2098 LR 0.1889 LKL 0.0208\n",
      "epoch 1717 loss 0.2042 LR 0.1833 LKL 0.0209\n",
      "epoch 1718 loss 0.2780 LR 0.2571 LKL 0.0209\n",
      "epoch 1719 loss 0.2437 LR 0.2230 LKL 0.0207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1720 loss 0.2457 LR 0.2250 LKL 0.0207\n",
      "epoch 1721 loss 0.2113 LR 0.1908 LKL 0.0205\n",
      "epoch 1722 loss 0.1992 LR 0.1789 LKL 0.0203\n",
      "epoch 1723 loss 0.2063 LR 0.1860 LKL 0.0204\n",
      "epoch 1724 loss 0.2170 LR 0.1967 LKL 0.0203\n",
      "epoch 1725 loss 0.2176 LR 0.1974 LKL 0.0202\n",
      "epoch 1726 loss 0.1980 LR 0.1775 LKL 0.0204\n",
      "epoch 1727 loss 0.2337 LR 0.2136 LKL 0.0201\n",
      "epoch 1728 loss 0.2499 LR 0.2294 LKL 0.0205\n",
      "epoch 1729 loss 0.2277 LR 0.2072 LKL 0.0205\n",
      "epoch 1730 loss 0.2355 LR 0.2150 LKL 0.0205\n",
      "epoch 1731 loss 0.2577 LR 0.2371 LKL 0.0205\n",
      "epoch 1732 loss 0.1920 LR 0.1715 LKL 0.0205\n",
      "epoch 1733 loss 0.1926 LR 0.1720 LKL 0.0206\n",
      "epoch 1734 loss 0.2074 LR 0.1867 LKL 0.0207\n",
      "epoch 1735 loss 0.2254 LR 0.2047 LKL 0.0207\n",
      "epoch 1736 loss 0.1708 LR 0.1501 LKL 0.0207\n",
      "epoch 1737 loss 0.2251 LR 0.2044 LKL 0.0206\n",
      "epoch 1738 loss 0.2198 LR 0.1993 LKL 0.0205\n",
      "epoch 1739 loss 0.2011 LR 0.1806 LKL 0.0205\n",
      "epoch 1740 loss 0.2666 LR 0.2458 LKL 0.0208\n",
      "epoch 1741 loss 0.1789 LR 0.1581 LKL 0.0208\n",
      "epoch 1742 loss 0.2284 LR 0.2076 LKL 0.0208\n",
      "epoch 1743 loss 0.2602 LR 0.2393 LKL 0.0209\n",
      "epoch 1744 loss 0.1897 LR 0.1687 LKL 0.0210\n",
      "epoch 1745 loss 0.1711 LR 0.1501 LKL 0.0210\n",
      "epoch 1746 loss 0.2396 LR 0.2188 LKL 0.0208\n",
      "epoch 1747 loss 0.2203 LR 0.1996 LKL 0.0207\n",
      "epoch 1748 loss 0.2256 LR 0.2047 LKL 0.0209\n",
      "epoch 1749 loss 0.2714 LR 0.2506 LKL 0.0208\n",
      "epoch 1750 loss 0.2078 LR 0.1867 LKL 0.0211\n",
      "epoch 1751 loss 0.2063 LR 0.1853 LKL 0.0210\n",
      "epoch 1752 loss 0.2366 LR 0.2158 LKL 0.0209\n",
      "epoch 1753 loss 0.1858 LR 0.1651 LKL 0.0207\n",
      "epoch 1754 loss 0.2161 LR 0.1952 LKL 0.0209\n",
      "epoch 1755 loss 0.1969 LR 0.1756 LKL 0.0213\n",
      "epoch 1756 loss 0.2074 LR 0.1865 LKL 0.0210\n",
      "epoch 1757 loss 0.2158 LR 0.1947 LKL 0.0210\n",
      "epoch 1758 loss 0.1813 LR 0.1603 LKL 0.0210\n",
      "epoch 1759 loss 0.2185 LR 0.1972 LKL 0.0212\n",
      "epoch 1760 loss 0.2022 LR 0.1812 LKL 0.0210\n",
      "epoch 1761 loss 0.2101 LR 0.1890 LKL 0.0211\n",
      "epoch 1762 loss 0.2622 LR 0.2411 LKL 0.0210\n",
      "epoch 1763 loss 0.2030 LR 0.1820 LKL 0.0210\n",
      "epoch 1764 loss 0.2066 LR 0.1857 LKL 0.0209\n",
      "epoch 1765 loss 0.2097 LR 0.1890 LKL 0.0207\n",
      "epoch 1766 loss 0.2013 LR 0.1804 LKL 0.0209\n",
      "epoch 1767 loss 0.1937 LR 0.1728 LKL 0.0209\n",
      "epoch 1768 loss 0.2130 LR 0.1922 LKL 0.0208\n",
      "epoch 1769 loss 0.1504 LR 0.1295 LKL 0.0208\n",
      "epoch 1770 loss 0.2407 LR 0.2200 LKL 0.0208\n",
      "epoch 1771 loss 0.2134 LR 0.1928 LKL 0.0207\n",
      "epoch 1772 loss 0.2119 LR 0.1912 LKL 0.0207\n",
      "epoch 1773 loss 0.2365 LR 0.2156 LKL 0.0208\n",
      "epoch 1774 loss 0.2160 LR 0.1954 LKL 0.0206\n",
      "epoch 1775 loss 0.2475 LR 0.2269 LKL 0.0207\n",
      "epoch 1776 loss 0.1903 LR 0.1696 LKL 0.0206\n",
      "epoch 1777 loss 0.2171 LR 0.1965 LKL 0.0205\n",
      "epoch 1778 loss 0.2558 LR 0.2354 LKL 0.0204\n",
      "epoch 1779 loss 0.2103 LR 0.1895 LKL 0.0208\n",
      "epoch 1780 loss 0.1868 LR 0.1658 LKL 0.0210\n",
      "epoch 1781 loss 0.2013 LR 0.1803 LKL 0.0210\n",
      "epoch 1782 loss 0.1934 LR 0.1721 LKL 0.0213\n",
      "epoch 1783 loss 0.1759 LR 0.1550 LKL 0.0210\n",
      "epoch 1784 loss 0.1994 LR 0.1785 LKL 0.0209\n",
      "epoch 1785 loss 0.1938 LR 0.1725 LKL 0.0213\n",
      "epoch 1786 loss 0.2240 LR 0.2031 LKL 0.0209\n",
      "epoch 1787 loss 0.1660 LR 0.1449 LKL 0.0211\n",
      "epoch 1788 loss 0.2177 LR 0.1965 LKL 0.0212\n",
      "epoch 1789 loss 0.1639 LR 0.1427 LKL 0.0213\n",
      "epoch 1790 loss 0.2271 LR 0.2058 LKL 0.0213\n",
      "epoch 1791 loss 0.2295 LR 0.2083 LKL 0.0213\n",
      "epoch 1792 loss 0.2293 LR 0.2081 LKL 0.0211\n",
      "epoch 1793 loss 0.2096 LR 0.1885 LKL 0.0211\n",
      "epoch 1794 loss 0.1887 LR 0.1676 LKL 0.0211\n",
      "epoch 1795 loss 0.1916 LR 0.1704 LKL 0.0212\n",
      "epoch 1796 loss 0.2079 LR 0.1870 LKL 0.0209\n",
      "epoch 1797 loss 0.1783 LR 0.1571 LKL 0.0212\n",
      "epoch 1798 loss 0.2246 LR 0.2034 LKL 0.0212\n",
      "epoch 1799 loss 0.1762 LR 0.1549 LKL 0.0213\n",
      "epoch 1800 loss 0.1909 LR 0.1697 LKL 0.0212\n",
      "epoch 1801 loss 0.2305 LR 0.2095 LKL 0.0210\n",
      "epoch 1802 loss 0.1955 LR 0.1745 LKL 0.0210\n",
      "epoch 1803 loss 0.1530 LR 0.1321 LKL 0.0209\n",
      "epoch 1804 loss 0.2133 LR 0.1926 LKL 0.0207\n",
      "epoch 1805 loss 0.2454 LR 0.2243 LKL 0.0211\n",
      "epoch 1806 loss 0.1829 LR 0.1621 LKL 0.0208\n",
      "epoch 1807 loss 0.1796 LR 0.1589 LKL 0.0207\n",
      "epoch 1808 loss 0.2441 LR 0.2236 LKL 0.0205\n",
      "epoch 1809 loss 0.2293 LR 0.2089 LKL 0.0204\n",
      "epoch 1810 loss 0.2117 LR 0.1912 LKL 0.0205\n",
      "epoch 1811 loss 0.1823 LR 0.1617 LKL 0.0205\n",
      "epoch 1812 loss 0.2093 LR 0.1891 LKL 0.0202\n",
      "epoch 1813 loss 0.2412 LR 0.2208 LKL 0.0203\n",
      "epoch 1814 loss 0.1790 LR 0.1585 LKL 0.0204\n",
      "epoch 1815 loss 0.2065 LR 0.1862 LKL 0.0204\n",
      "epoch 1816 loss 0.2224 LR 0.2018 LKL 0.0206\n",
      "epoch 1817 loss 0.2205 LR 0.2000 LKL 0.0205\n",
      "epoch 1818 loss 0.1690 LR 0.1485 LKL 0.0205\n",
      "epoch 1819 loss 0.1991 LR 0.1785 LKL 0.0206\n",
      "epoch 1820 loss 0.2097 LR 0.1890 LKL 0.0207\n",
      "epoch 1821 loss 0.1864 LR 0.1655 LKL 0.0209\n",
      "epoch 1822 loss 0.2241 LR 0.2033 LKL 0.0208\n",
      "epoch 1823 loss 0.2478 LR 0.2272 LKL 0.0206\n",
      "epoch 1824 loss 0.1801 LR 0.1594 LKL 0.0206\n",
      "epoch 1825 loss 0.2090 LR 0.1885 LKL 0.0205\n",
      "epoch 1826 loss 0.2222 LR 0.2015 LKL 0.0207\n",
      "epoch 1827 loss 0.2140 LR 0.1931 LKL 0.0209\n",
      "epoch 1828 loss 0.2559 LR 0.2352 LKL 0.0206\n",
      "epoch 1829 loss 0.2053 LR 0.1845 LKL 0.0209\n",
      "epoch 1830 loss 0.2038 LR 0.1829 LKL 0.0209\n",
      "epoch 1831 loss 0.2355 LR 0.2148 LKL 0.0207\n",
      "epoch 1832 loss 0.1857 LR 0.1649 LKL 0.0208\n",
      "epoch 1833 loss 0.2404 LR 0.2196 LKL 0.0208\n",
      "epoch 1834 loss 0.2143 LR 0.1937 LKL 0.0206\n",
      "epoch 1835 loss 0.1665 LR 0.1457 LKL 0.0208\n",
      "epoch 1836 loss 0.2131 LR 0.1923 LKL 0.0208\n",
      "epoch 1837 loss 0.2057 LR 0.1846 LKL 0.0211\n",
      "epoch 1838 loss 0.2640 LR 0.2430 LKL 0.0210\n",
      "epoch 1839 loss 0.2111 LR 0.1902 LKL 0.0209\n",
      "epoch 1840 loss 0.2380 LR 0.2171 LKL 0.0209\n",
      "epoch 1841 loss 0.1929 LR 0.1720 LKL 0.0209\n",
      "epoch 1842 loss 0.2341 LR 0.2131 LKL 0.0209\n",
      "epoch 1843 loss 0.2587 LR 0.2377 LKL 0.0210\n",
      "epoch 1844 loss 0.1874 LR 0.1664 LKL 0.0210\n",
      "epoch 1845 loss 0.2194 LR 0.1987 LKL 0.0207\n",
      "epoch 1846 loss 0.1980 LR 0.1771 LKL 0.0209\n",
      "epoch 1847 loss 0.1849 LR 0.1640 LKL 0.0209\n",
      "epoch 1848 loss 0.2047 LR 0.1838 LKL 0.0210\n",
      "epoch 1849 loss 0.2198 LR 0.1992 LKL 0.0205\n",
      "epoch 1850 loss 0.2179 LR 0.1973 LKL 0.0207\n",
      "epoch 1851 loss 0.2389 LR 0.2178 LKL 0.0211\n",
      "epoch 1852 loss 0.2275 LR 0.2065 LKL 0.0210\n",
      "epoch 1853 loss 0.1899 LR 0.1689 LKL 0.0210\n",
      "epoch 1854 loss 0.2096 LR 0.1884 LKL 0.0212\n",
      "epoch 1855 loss 0.1638 LR 0.1427 LKL 0.0211\n",
      "epoch 1856 loss 0.2213 LR 0.2000 LKL 0.0213\n",
      "epoch 1857 loss 0.1970 LR 0.1756 LKL 0.0214\n",
      "epoch 1858 loss 0.2484 LR 0.2274 LKL 0.0210\n",
      "epoch 1859 loss 0.2259 LR 0.2047 LKL 0.0212\n",
      "epoch 1860 loss 0.2351 LR 0.2142 LKL 0.0209\n",
      "epoch 1861 loss 0.1693 LR 0.1481 LKL 0.0212\n",
      "epoch 1862 loss 0.2067 LR 0.1855 LKL 0.0211\n",
      "epoch 1863 loss 0.2539 LR 0.2332 LKL 0.0207\n",
      "epoch 1864 loss 0.2207 LR 0.2001 LKL 0.0206\n",
      "epoch 1865 loss 0.2002 LR 0.1795 LKL 0.0208\n",
      "epoch 1866 loss 0.1954 LR 0.1747 LKL 0.0207\n",
      "epoch 1867 loss 0.1936 LR 0.1728 LKL 0.0208\n",
      "epoch 1868 loss 0.2236 LR 0.2029 LKL 0.0207\n",
      "epoch 1869 loss 0.2280 LR 0.2073 LKL 0.0207\n",
      "epoch 1870 loss 0.1520 LR 0.1313 LKL 0.0207\n",
      "epoch 1871 loss 0.2127 LR 0.1917 LKL 0.0211\n",
      "epoch 1872 loss 0.2284 LR 0.2074 LKL 0.0210\n",
      "epoch 1873 loss 0.2314 LR 0.2105 LKL 0.0209\n",
      "epoch 1874 loss 0.1938 LR 0.1729 LKL 0.0209\n",
      "epoch 1875 loss 0.1695 LR 0.1486 LKL 0.0210\n",
      "epoch 1876 loss 0.1672 LR 0.1461 LKL 0.0211\n",
      "epoch 1877 loss 0.1802 LR 0.1594 LKL 0.0208\n",
      "epoch 1878 loss 0.1796 LR 0.1588 LKL 0.0209\n",
      "epoch 1879 loss 0.2289 LR 0.2080 LKL 0.0209\n",
      "epoch 1880 loss 0.2043 LR 0.1834 LKL 0.0210\n",
      "epoch 1881 loss 0.2729 LR 0.2521 LKL 0.0208\n",
      "epoch 1882 loss 0.2152 LR 0.1943 LKL 0.0209\n",
      "epoch 1883 loss 0.2096 LR 0.1891 LKL 0.0204\n",
      "epoch 1884 loss 0.1974 LR 0.1768 LKL 0.0206\n",
      "epoch 1885 loss 0.2140 LR 0.1934 LKL 0.0206\n",
      "epoch 1886 loss 0.1840 LR 0.1634 LKL 0.0206\n",
      "epoch 1887 loss 0.1785 LR 0.1583 LKL 0.0203\n",
      "epoch 1888 loss 0.2177 LR 0.1973 LKL 0.0204\n",
      "epoch 1889 loss 0.2819 LR 0.2616 LKL 0.0204\n",
      "epoch 1890 loss 0.1759 LR 0.1552 LKL 0.0207\n",
      "epoch 1891 loss 0.2218 LR 0.2010 LKL 0.0208\n",
      "epoch 1892 loss 0.1685 LR 0.1476 LKL 0.0209\n",
      "epoch 1893 loss 0.1893 LR 0.1684 LKL 0.0209\n",
      "epoch 1894 loss 0.1958 LR 0.1748 LKL 0.0210\n",
      "epoch 1895 loss 0.2047 LR 0.1834 LKL 0.0213\n",
      "epoch 1896 loss 0.2360 LR 0.2147 LKL 0.0212\n",
      "epoch 1897 loss 0.2072 LR 0.1857 LKL 0.0215\n",
      "epoch 1898 loss 0.1444 LR 0.1231 LKL 0.0213\n",
      "epoch 1899 loss 0.2173 LR 0.1957 LKL 0.0216\n",
      "epoch 1900 loss 0.1770 LR 0.1557 LKL 0.0214\n",
      "epoch 1901 loss 0.2313 LR 0.2101 LKL 0.0212\n",
      "epoch 1902 loss 0.1884 LR 0.1671 LKL 0.0213\n",
      "epoch 1903 loss 0.2759 LR 0.2547 LKL 0.0212\n",
      "epoch 1904 loss 0.1666 LR 0.1454 LKL 0.0212\n",
      "epoch 1905 loss 0.2240 LR 0.2028 LKL 0.0212\n",
      "epoch 1906 loss 0.2034 LR 0.1821 LKL 0.0213\n",
      "epoch 1907 loss 0.1520 LR 0.1308 LKL 0.0213\n",
      "epoch 1908 loss 0.2007 LR 0.1793 LKL 0.0213\n",
      "epoch 1909 loss 0.2618 LR 0.2407 LKL 0.0211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1910 loss 0.2624 LR 0.2413 LKL 0.0211\n",
      "epoch 1911 loss 0.1700 LR 0.1486 LKL 0.0214\n",
      "epoch 1912 loss 0.2174 LR 0.1959 LKL 0.0214\n",
      "epoch 1913 loss 0.2654 LR 0.2441 LKL 0.0213\n",
      "epoch 1914 loss 0.2382 LR 0.2168 LKL 0.0214\n",
      "epoch 1915 loss 0.2374 LR 0.2161 LKL 0.0213\n",
      "epoch 1916 loss 0.2088 LR 0.1875 LKL 0.0213\n",
      "epoch 1917 loss 0.2139 LR 0.1926 LKL 0.0213\n",
      "epoch 1918 loss 0.1629 LR 0.1417 LKL 0.0212\n",
      "epoch 1919 loss 0.1464 LR 0.1252 LKL 0.0212\n",
      "epoch 1920 loss 0.2295 LR 0.2087 LKL 0.0208\n",
      "epoch 1921 loss 0.2063 LR 0.1852 LKL 0.0211\n",
      "epoch 1922 loss 0.1634 LR 0.1422 LKL 0.0212\n",
      "epoch 1923 loss 0.1964 LR 0.1753 LKL 0.0211\n",
      "epoch 1924 loss 0.1728 LR 0.1514 LKL 0.0214\n",
      "epoch 1925 loss 0.2203 LR 0.1990 LKL 0.0212\n",
      "epoch 1926 loss 0.1777 LR 0.1565 LKL 0.0212\n",
      "epoch 1927 loss 0.1678 LR 0.1468 LKL 0.0211\n",
      "epoch 1928 loss 0.2595 LR 0.2389 LKL 0.0207\n",
      "epoch 1929 loss 0.1973 LR 0.1764 LKL 0.0209\n",
      "epoch 1930 loss 0.1697 LR 0.1488 LKL 0.0209\n",
      "epoch 1931 loss 0.2228 LR 0.2019 LKL 0.0208\n",
      "epoch 1932 loss 0.2004 LR 0.1795 LKL 0.0209\n",
      "epoch 1933 loss 0.1884 LR 0.1676 LKL 0.0208\n",
      "epoch 1934 loss 0.2305 LR 0.2099 LKL 0.0206\n",
      "epoch 1935 loss 0.2586 LR 0.2379 LKL 0.0207\n",
      "epoch 1936 loss 0.1929 LR 0.1723 LKL 0.0206\n",
      "epoch 1937 loss 0.2050 LR 0.1842 LKL 0.0208\n",
      "epoch 1938 loss 0.2271 LR 0.2062 LKL 0.0209\n",
      "epoch 1939 loss 0.1493 LR 0.1286 LKL 0.0207\n",
      "epoch 1940 loss 0.2475 LR 0.2265 LKL 0.0211\n",
      "epoch 1941 loss 0.1684 LR 0.1471 LKL 0.0213\n",
      "epoch 1942 loss 0.1842 LR 0.1629 LKL 0.0213\n",
      "epoch 1943 loss 0.1570 LR 0.1355 LKL 0.0215\n",
      "epoch 1944 loss 0.2060 LR 0.1848 LKL 0.0212\n",
      "epoch 1945 loss 0.2059 LR 0.1845 LKL 0.0214\n",
      "epoch 1946 loss 0.2055 LR 0.1838 LKL 0.0216\n",
      "epoch 1947 loss 0.2336 LR 0.2122 LKL 0.0214\n",
      "epoch 1948 loss 0.1730 LR 0.1513 LKL 0.0217\n",
      "epoch 1949 loss 0.2346 LR 0.2129 LKL 0.0216\n",
      "epoch 1950 loss 0.1599 LR 0.1379 LKL 0.0220\n",
      "epoch 1951 loss 0.1926 LR 0.1709 LKL 0.0218\n",
      "epoch 1952 loss 0.2653 LR 0.2437 LKL 0.0217\n",
      "epoch 1953 loss 0.1906 LR 0.1689 LKL 0.0216\n",
      "epoch 1954 loss 0.2493 LR 0.2276 LKL 0.0216\n",
      "epoch 1955 loss 0.2014 LR 0.1799 LKL 0.0215\n",
      "epoch 1956 loss 0.2859 LR 0.2645 LKL 0.0214\n",
      "epoch 1957 loss 0.1131 LR 0.0918 LKL 0.0213\n",
      "epoch 1958 loss 0.2626 LR 0.2412 LKL 0.0214\n",
      "epoch 1959 loss 0.1959 LR 0.1745 LKL 0.0214\n",
      "epoch 1960 loss 0.2748 LR 0.2534 LKL 0.0214\n",
      "epoch 1961 loss 0.1677 LR 0.1464 LKL 0.0214\n",
      "epoch 1962 loss 0.2294 LR 0.2083 LKL 0.0211\n",
      "epoch 1963 loss 0.2109 LR 0.1898 LKL 0.0211\n",
      "epoch 1964 loss 0.2123 LR 0.1912 LKL 0.0211\n",
      "epoch 1965 loss 0.2584 LR 0.2375 LKL 0.0209\n",
      "epoch 1966 loss 0.1826 LR 0.1616 LKL 0.0209\n",
      "epoch 1967 loss 0.1381 LR 0.1170 LKL 0.0210\n",
      "epoch 1968 loss 0.1898 LR 0.1688 LKL 0.0210\n",
      "epoch 1969 loss 0.1999 LR 0.1786 LKL 0.0213\n",
      "epoch 1970 loss 0.1941 LR 0.1729 LKL 0.0213\n",
      "epoch 1971 loss 0.1716 LR 0.1500 LKL 0.0216\n",
      "epoch 1972 loss 0.1863 LR 0.1648 LKL 0.0216\n",
      "epoch 1973 loss 0.1749 LR 0.1532 LKL 0.0217\n",
      "epoch 1974 loss 0.2046 LR 0.1828 LKL 0.0218\n",
      "epoch 1975 loss 0.1995 LR 0.1779 LKL 0.0216\n",
      "epoch 1976 loss 0.1817 LR 0.1597 LKL 0.0220\n",
      "epoch 1977 loss 0.2239 LR 0.2020 LKL 0.0219\n",
      "epoch 1978 loss 0.2058 LR 0.1836 LKL 0.0222\n",
      "epoch 1979 loss 0.1981 LR 0.1758 LKL 0.0223\n",
      "epoch 1980 loss 0.1644 LR 0.1424 LKL 0.0220\n",
      "epoch 1981 loss 0.1762 LR 0.1539 LKL 0.0222\n",
      "epoch 1982 loss 0.1862 LR 0.1643 LKL 0.0219\n",
      "epoch 1983 loss 0.2046 LR 0.1828 LKL 0.0218\n",
      "epoch 1984 loss 0.1788 LR 0.1571 LKL 0.0217\n",
      "epoch 1985 loss 0.1925 LR 0.1708 LKL 0.0217\n",
      "epoch 1986 loss 0.1775 LR 0.1561 LKL 0.0215\n",
      "epoch 1987 loss 0.1893 LR 0.1679 LKL 0.0214\n",
      "epoch 1988 loss 0.1741 LR 0.1528 LKL 0.0213\n",
      "epoch 1989 loss 0.1955 LR 0.1741 LKL 0.0214\n",
      "epoch 1990 loss 0.1661 LR 0.1450 LKL 0.0211\n",
      "epoch 1991 loss 0.1617 LR 0.1406 LKL 0.0210\n",
      "epoch 1992 loss 0.1288 LR 0.1078 LKL 0.0210\n",
      "epoch 1993 loss 0.1346 LR 0.1134 LKL 0.0212\n",
      "epoch 1994 loss 0.1655 LR 0.1444 LKL 0.0211\n",
      "epoch 1995 loss 0.2112 LR 0.1901 LKL 0.0210\n",
      "epoch 1996 loss 0.1745 LR 0.1535 LKL 0.0210\n",
      "epoch 1997 loss 0.2629 LR 0.2418 LKL 0.0211\n",
      "epoch 1998 loss 0.2151 LR 0.1939 LKL 0.0212\n",
      "epoch 1999 loss 0.1979 LR 0.1766 LKL 0.0214\n",
      "epoch 2000 loss 0.1949 LR 0.1736 LKL 0.0213\n",
      "epoch 2001 loss 0.1286 LR 0.1072 LKL 0.0213\n",
      "epoch 2002 loss 0.1729 LR 0.1514 LKL 0.0215\n",
      "epoch 2003 loss 0.1505 LR 0.1287 LKL 0.0218\n",
      "epoch 2004 loss 0.2015 LR 0.1797 LKL 0.0218\n",
      "epoch 2005 loss 0.2337 LR 0.2122 LKL 0.0216\n",
      "epoch 2006 loss 0.2592 LR 0.2377 LKL 0.0215\n",
      "epoch 2007 loss 0.2100 LR 0.1884 LKL 0.0216\n",
      "epoch 2008 loss 0.1508 LR 0.1293 LKL 0.0215\n",
      "epoch 2009 loss 0.2370 LR 0.2155 LKL 0.0215\n",
      "epoch 2010 loss 0.1523 LR 0.1308 LKL 0.0214\n",
      "epoch 2011 loss 0.1576 LR 0.1359 LKL 0.0216\n",
      "epoch 2012 loss 0.1990 LR 0.1773 LKL 0.0217\n",
      "epoch 2013 loss 0.1659 LR 0.1442 LKL 0.0217\n",
      "epoch 2014 loss 0.2547 LR 0.2334 LKL 0.0213\n",
      "epoch 2015 loss 0.1706 LR 0.1489 LKL 0.0217\n",
      "epoch 2016 loss 0.1722 LR 0.1504 LKL 0.0219\n",
      "epoch 2017 loss 0.1929 LR 0.1714 LKL 0.0215\n",
      "epoch 2018 loss 0.1949 LR 0.1733 LKL 0.0216\n",
      "epoch 2019 loss 0.1932 LR 0.1717 LKL 0.0215\n",
      "epoch 2020 loss 0.1812 LR 0.1595 LKL 0.0217\n",
      "epoch 2021 loss 0.1600 LR 0.1385 LKL 0.0215\n",
      "epoch 2022 loss 0.1861 LR 0.1649 LKL 0.0213\n",
      "epoch 2023 loss 0.1971 LR 0.1759 LKL 0.0212\n",
      "epoch 2024 loss 0.2379 LR 0.2168 LKL 0.0211\n",
      "epoch 2025 loss 0.1530 LR 0.1317 LKL 0.0213\n",
      "epoch 2026 loss 0.1237 LR 0.1023 LKL 0.0214\n",
      "epoch 2027 loss 0.2079 LR 0.1869 LKL 0.0209\n",
      "epoch 2028 loss 0.1611 LR 0.1400 LKL 0.0211\n",
      "epoch 2029 loss 0.2007 LR 0.1796 LKL 0.0211\n",
      "epoch 2030 loss 0.1890 LR 0.1682 LKL 0.0208\n",
      "epoch 2031 loss 0.1183 LR 0.0972 LKL 0.0211\n",
      "epoch 2032 loss 0.1859 LR 0.1649 LKL 0.0210\n",
      "epoch 2033 loss 0.2175 LR 0.1965 LKL 0.0210\n",
      "epoch 2034 loss 0.1515 LR 0.1304 LKL 0.0211\n",
      "epoch 2035 loss 0.2320 LR 0.2107 LKL 0.0213\n",
      "epoch 2036 loss 0.1957 LR 0.1743 LKL 0.0214\n",
      "epoch 2037 loss 0.2604 LR 0.2391 LKL 0.0212\n",
      "epoch 2038 loss 0.1757 LR 0.1543 LKL 0.0215\n",
      "epoch 2039 loss 0.1537 LR 0.1322 LKL 0.0215\n",
      "epoch 2040 loss 0.1851 LR 0.1637 LKL 0.0214\n",
      "epoch 2041 loss 0.1738 LR 0.1526 LKL 0.0212\n",
      "epoch 2042 loss 0.2371 LR 0.2159 LKL 0.0212\n",
      "epoch 2043 loss 0.1106 LR 0.0892 LKL 0.0213\n",
      "epoch 2044 loss 0.1925 LR 0.1710 LKL 0.0214\n",
      "epoch 2045 loss 0.1736 LR 0.1521 LKL 0.0215\n",
      "epoch 2046 loss 0.1201 LR 0.0987 LKL 0.0215\n",
      "epoch 2047 loss 0.1495 LR 0.1278 LKL 0.0216\n",
      "epoch 2048 loss 0.1495 LR 0.1279 LKL 0.0216\n",
      "epoch 2049 loss 0.1663 LR 0.1449 LKL 0.0215\n",
      "epoch 2050 loss 0.1744 LR 0.1529 LKL 0.0215\n",
      "epoch 2051 loss 0.1740 LR 0.1526 LKL 0.0214\n",
      "epoch 2052 loss 0.1500 LR 0.1283 LKL 0.0217\n",
      "epoch 2053 loss 0.1611 LR 0.1400 LKL 0.0212\n",
      "epoch 2054 loss 0.2035 LR 0.1822 LKL 0.0213\n",
      "epoch 2055 loss 0.1832 LR 0.1616 LKL 0.0216\n",
      "epoch 2056 loss 0.2270 LR 0.2058 LKL 0.0212\n",
      "epoch 2057 loss 0.1957 LR 0.1744 LKL 0.0213\n",
      "epoch 2058 loss 0.2145 LR 0.1933 LKL 0.0212\n",
      "epoch 2059 loss 0.2082 LR 0.1869 LKL 0.0213\n",
      "epoch 2060 loss 0.2097 LR 0.1886 LKL 0.0211\n",
      "epoch 2061 loss 0.1666 LR 0.1454 LKL 0.0212\n",
      "epoch 2062 loss 0.1794 LR 0.1583 LKL 0.0212\n",
      "epoch 2063 loss 0.1706 LR 0.1494 LKL 0.0212\n",
      "epoch 2064 loss 0.2040 LR 0.1827 LKL 0.0213\n",
      "epoch 2065 loss 0.2400 LR 0.2186 LKL 0.0214\n",
      "epoch 2066 loss 0.2000 LR 0.1786 LKL 0.0213\n",
      "epoch 2067 loss 0.1534 LR 0.1321 LKL 0.0213\n",
      "epoch 2068 loss 0.1366 LR 0.1150 LKL 0.0216\n",
      "epoch 2069 loss 0.1933 LR 0.1720 LKL 0.0212\n",
      "epoch 2070 loss 0.1822 LR 0.1612 LKL 0.0210\n",
      "epoch 2071 loss 0.2261 LR 0.2054 LKL 0.0207\n",
      "epoch 2072 loss 0.1940 LR 0.1731 LKL 0.0209\n",
      "epoch 2073 loss 0.2161 LR 0.1955 LKL 0.0207\n",
      "epoch 2074 loss 0.1533 LR 0.1325 LKL 0.0207\n",
      "epoch 2075 loss 0.1620 LR 0.1414 LKL 0.0206\n",
      "epoch 2076 loss 0.1654 LR 0.1445 LKL 0.0208\n",
      "epoch 2077 loss 0.1598 LR 0.1392 LKL 0.0206\n",
      "epoch 2078 loss 0.1609 LR 0.1402 LKL 0.0207\n",
      "epoch 2079 loss 0.1852 LR 0.1645 LKL 0.0206\n",
      "epoch 2080 loss 0.1703 LR 0.1495 LKL 0.0208\n",
      "epoch 2081 loss 0.1791 LR 0.1582 LKL 0.0209\n",
      "epoch 2082 loss 0.2254 LR 0.2042 LKL 0.0212\n",
      "epoch 2083 loss 0.1889 LR 0.1677 LKL 0.0213\n",
      "epoch 2084 loss 0.1611 LR 0.1399 LKL 0.0213\n",
      "epoch 2085 loss 0.1557 LR 0.1344 LKL 0.0213\n",
      "epoch 2086 loss 0.1696 LR 0.1480 LKL 0.0216\n",
      "epoch 2087 loss 0.2603 LR 0.2387 LKL 0.0216\n",
      "epoch 2088 loss 0.1255 LR 0.1036 LKL 0.0219\n",
      "epoch 2089 loss 0.1830 LR 0.1610 LKL 0.0220\n",
      "epoch 2090 loss 0.1763 LR 0.1543 LKL 0.0220\n",
      "epoch 2091 loss 0.2025 LR 0.1806 LKL 0.0220\n",
      "epoch 2092 loss 0.1530 LR 0.1311 LKL 0.0219\n",
      "epoch 2093 loss 0.1416 LR 0.1196 LKL 0.0220\n",
      "epoch 2094 loss 0.1410 LR 0.1191 LKL 0.0219\n",
      "epoch 2095 loss 0.2106 LR 0.1890 LKL 0.0217\n",
      "epoch 2096 loss 0.2366 LR 0.2147 LKL 0.0219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2097 loss 0.1612 LR 0.1395 LKL 0.0217\n",
      "epoch 2098 loss 0.1889 LR 0.1671 LKL 0.0218\n",
      "epoch 2099 loss 0.2223 LR 0.2008 LKL 0.0215\n",
      "epoch 2100 loss 0.1680 LR 0.1462 LKL 0.0218\n",
      "53\n",
      "epoch 2101 loss 0.1746 LR 0.1527 LKL 0.0219\n",
      "epoch 2102 loss 0.1889 LR 0.1668 LKL 0.0221\n",
      "epoch 2103 loss 0.2117 LR 0.1896 LKL 0.0221\n",
      "epoch 2104 loss 0.1749 LR 0.1528 LKL 0.0221\n",
      "epoch 2105 loss 0.1628 LR 0.1408 LKL 0.0220\n",
      "epoch 2106 loss 0.1844 LR 0.1628 LKL 0.0216\n",
      "epoch 2107 loss 0.1826 LR 0.1611 LKL 0.0215\n",
      "epoch 2108 loss 0.1917 LR 0.1700 LKL 0.0217\n",
      "epoch 2109 loss 0.1326 LR 0.1109 LKL 0.0217\n",
      "epoch 2110 loss 0.1757 LR 0.1541 LKL 0.0216\n",
      "epoch 2111 loss 0.1703 LR 0.1490 LKL 0.0213\n",
      "epoch 2112 loss 0.2064 LR 0.1849 LKL 0.0215\n",
      "epoch 2113 loss 0.2086 LR 0.1872 LKL 0.0214\n",
      "epoch 2114 loss 0.2112 LR 0.1900 LKL 0.0212\n",
      "epoch 2115 loss 0.2159 LR 0.1948 LKL 0.0210\n",
      "epoch 2116 loss 0.1656 LR 0.1444 LKL 0.0213\n",
      "epoch 2117 loss 0.1090 LR 0.0875 LKL 0.0214\n",
      "epoch 2118 loss 0.1483 LR 0.1268 LKL 0.0215\n",
      "epoch 2119 loss 0.2020 LR 0.1805 LKL 0.0215\n",
      "epoch 2120 loss 0.1634 LR 0.1419 LKL 0.0215\n",
      "epoch 2121 loss 0.1482 LR 0.1266 LKL 0.0217\n",
      "epoch 2122 loss 0.2179 LR 0.1964 LKL 0.0215\n",
      "epoch 2123 loss 0.1350 LR 0.1135 LKL 0.0215\n",
      "epoch 2124 loss 0.2163 LR 0.1947 LKL 0.0216\n",
      "epoch 2125 loss 0.2409 LR 0.2193 LKL 0.0217\n",
      "epoch 2126 loss 0.0829 LR 0.0610 LKL 0.0219\n",
      "epoch 2127 loss 0.2047 LR 0.1829 LKL 0.0218\n",
      "epoch 2128 loss 0.1939 LR 0.1721 LKL 0.0218\n",
      "epoch 2129 loss 0.1111 LR 0.0894 LKL 0.0217\n",
      "epoch 2130 loss 0.1563 LR 0.1344 LKL 0.0219\n",
      "epoch 2131 loss 0.1506 LR 0.1287 LKL 0.0219\n",
      "epoch 2132 loss 0.2472 LR 0.2257 LKL 0.0215\n",
      "epoch 2133 loss 0.1527 LR 0.1309 LKL 0.0218\n",
      "epoch 2134 loss 0.1868 LR 0.1653 LKL 0.0215\n",
      "epoch 2135 loss 0.2236 LR 0.2021 LKL 0.0215\n",
      "epoch 2136 loss 0.2266 LR 0.2051 LKL 0.0215\n",
      "epoch 2137 loss 0.2351 LR 0.2137 LKL 0.0215\n",
      "epoch 2138 loss 0.1680 LR 0.1466 LKL 0.0214\n",
      "epoch 2139 loss 0.1958 LR 0.1743 LKL 0.0214\n",
      "epoch 2140 loss 0.1936 LR 0.1721 LKL 0.0215\n",
      "epoch 2141 loss 0.1863 LR 0.1648 LKL 0.0215\n",
      "epoch 2142 loss 0.1919 LR 0.1703 LKL 0.0215\n",
      "epoch 2143 loss 0.1704 LR 0.1488 LKL 0.0216\n",
      "epoch 2144 loss 0.1228 LR 0.1015 LKL 0.0213\n",
      "epoch 2145 loss 0.1647 LR 0.1435 LKL 0.0212\n",
      "epoch 2146 loss 0.1655 LR 0.1443 LKL 0.0211\n",
      "epoch 2147 loss 0.1964 LR 0.1750 LKL 0.0214\n",
      "epoch 2148 loss 0.1670 LR 0.1458 LKL 0.0212\n",
      "epoch 2149 loss 0.2142 LR 0.1931 LKL 0.0211\n",
      "epoch 2150 loss 0.1698 LR 0.1487 LKL 0.0211\n",
      "epoch 2151 loss 0.1692 LR 0.1480 LKL 0.0212\n",
      "epoch 2152 loss 0.1183 LR 0.0968 LKL 0.0214\n",
      "epoch 2153 loss 0.1837 LR 0.1623 LKL 0.0215\n",
      "epoch 2154 loss 0.1910 LR 0.1694 LKL 0.0216\n",
      "epoch 2155 loss 0.2232 LR 0.2019 LKL 0.0213\n",
      "epoch 2156 loss 0.1788 LR 0.1572 LKL 0.0216\n",
      "epoch 2157 loss 0.1920 LR 0.1706 LKL 0.0214\n",
      "epoch 2158 loss 0.1906 LR 0.1690 LKL 0.0216\n",
      "epoch 2159 loss 0.1719 LR 0.1505 LKL 0.0214\n",
      "epoch 2160 loss 0.1539 LR 0.1323 LKL 0.0216\n",
      "epoch 2161 loss 0.1069 LR 0.0853 LKL 0.0216\n",
      "epoch 2162 loss 0.1934 LR 0.1719 LKL 0.0214\n",
      "epoch 2163 loss 0.2270 LR 0.2057 LKL 0.0214\n",
      "epoch 2164 loss 0.1634 LR 0.1420 LKL 0.0214\n",
      "epoch 2165 loss 0.1995 LR 0.1783 LKL 0.0212\n",
      "epoch 2166 loss 0.1712 LR 0.1496 LKL 0.0215\n",
      "epoch 2167 loss 0.1570 LR 0.1356 LKL 0.0215\n",
      "epoch 2168 loss 0.2116 LR 0.1901 LKL 0.0215\n",
      "epoch 2169 loss 0.1365 LR 0.1149 LKL 0.0217\n",
      "epoch 2170 loss 0.1192 LR 0.0976 LKL 0.0215\n",
      "epoch 2171 loss 0.1771 LR 0.1557 LKL 0.0214\n",
      "epoch 2172 loss 0.2103 LR 0.1890 LKL 0.0213\n",
      "epoch 2173 loss 0.1602 LR 0.1387 LKL 0.0214\n",
      "epoch 2174 loss 0.1774 LR 0.1560 LKL 0.0213\n",
      "epoch 2175 loss 0.1721 LR 0.1506 LKL 0.0215\n",
      "epoch 2176 loss 0.1619 LR 0.1404 LKL 0.0215\n",
      "epoch 2177 loss 0.1800 LR 0.1585 LKL 0.0215\n",
      "epoch 2178 loss 0.1928 LR 0.1714 LKL 0.0214\n",
      "epoch 2179 loss 0.1871 LR 0.1654 LKL 0.0217\n",
      "epoch 2180 loss 0.1706 LR 0.1486 LKL 0.0220\n",
      "epoch 2181 loss 0.1983 LR 0.1765 LKL 0.0217\n",
      "epoch 2182 loss 0.2166 LR 0.1947 LKL 0.0219\n",
      "epoch 2183 loss 0.1782 LR 0.1562 LKL 0.0220\n",
      "epoch 2184 loss 0.2260 LR 0.2041 LKL 0.0220\n",
      "epoch 2185 loss 0.1696 LR 0.1475 LKL 0.0221\n",
      "epoch 2186 loss 0.1749 LR 0.1530 LKL 0.0218\n",
      "epoch 2187 loss 0.1584 LR 0.1365 LKL 0.0219\n",
      "epoch 2188 loss 0.1538 LR 0.1315 LKL 0.0223\n",
      "epoch 2189 loss 0.1898 LR 0.1680 LKL 0.0218\n",
      "epoch 2190 loss 0.1486 LR 0.1269 LKL 0.0216\n",
      "epoch 2191 loss 0.1714 LR 0.1496 LKL 0.0217\n",
      "epoch 2192 loss 0.1410 LR 0.1194 LKL 0.0217\n",
      "epoch 2193 loss 0.1694 LR 0.1476 LKL 0.0218\n",
      "epoch 2194 loss 0.1388 LR 0.1170 LKL 0.0218\n",
      "epoch 2195 loss 0.1494 LR 0.1274 LKL 0.0220\n",
      "epoch 2196 loss 0.1632 LR 0.1410 LKL 0.0222\n",
      "epoch 2197 loss 0.1442 LR 0.1222 LKL 0.0220\n",
      "epoch 2198 loss 0.2062 LR 0.1845 LKL 0.0218\n",
      "epoch 2199 loss 0.1747 LR 0.1528 LKL 0.0220\n",
      "epoch 2200 loss 0.2005 LR 0.1786 LKL 0.0219\n",
      "76\n",
      "epoch 2201 loss 0.1201 LR 0.0981 LKL 0.0220\n",
      "epoch 2202 loss 0.2067 LR 0.1847 LKL 0.0220\n",
      "epoch 2203 loss 0.1535 LR 0.1314 LKL 0.0220\n",
      "epoch 2204 loss 0.1827 LR 0.1608 LKL 0.0219\n",
      "epoch 2205 loss 0.1344 LR 0.1124 LKL 0.0220\n",
      "epoch 2206 loss 0.1141 LR 0.0921 LKL 0.0220\n",
      "epoch 2207 loss 0.1802 LR 0.1581 LKL 0.0221\n",
      "epoch 2208 loss 0.1649 LR 0.1427 LKL 0.0222\n",
      "epoch 2209 loss 0.1924 LR 0.1706 LKL 0.0217\n",
      "epoch 2210 loss 0.1399 LR 0.1180 LKL 0.0219\n",
      "epoch 2211 loss 0.1810 LR 0.1592 LKL 0.0218\n",
      "epoch 2212 loss 0.1708 LR 0.1491 LKL 0.0217\n",
      "epoch 2213 loss 0.1821 LR 0.1603 LKL 0.0217\n",
      "epoch 2214 loss 0.1422 LR 0.1206 LKL 0.0217\n",
      "epoch 2215 loss 0.1386 LR 0.1171 LKL 0.0215\n",
      "epoch 2216 loss 0.1851 LR 0.1636 LKL 0.0215\n",
      "epoch 2217 loss 0.1556 LR 0.1342 LKL 0.0214\n",
      "epoch 2218 loss 0.1946 LR 0.1730 LKL 0.0216\n",
      "epoch 2219 loss 0.1771 LR 0.1553 LKL 0.0217\n",
      "epoch 2220 loss 0.2294 LR 0.2078 LKL 0.0217\n",
      "epoch 2221 loss 0.1662 LR 0.1445 LKL 0.0217\n",
      "epoch 2222 loss 0.1593 LR 0.1375 LKL 0.0217\n",
      "epoch 2223 loss 0.1699 LR 0.1481 LKL 0.0218\n",
      "epoch 2224 loss 0.1320 LR 0.1102 LKL 0.0218\n",
      "epoch 2225 loss 0.1343 LR 0.1124 LKL 0.0218\n",
      "epoch 2226 loss 0.1446 LR 0.1230 LKL 0.0217\n",
      "epoch 2227 loss 0.1480 LR 0.1263 LKL 0.0217\n",
      "epoch 2228 loss 0.1475 LR 0.1259 LKL 0.0216\n",
      "epoch 2229 loss 0.1383 LR 0.1167 LKL 0.0216\n",
      "epoch 2230 loss 0.1601 LR 0.1387 LKL 0.0214\n",
      "epoch 2231 loss 0.2077 LR 0.1861 LKL 0.0216\n",
      "epoch 2232 loss 0.2146 LR 0.1930 LKL 0.0216\n",
      "epoch 2233 loss 0.1387 LR 0.1168 LKL 0.0219\n",
      "epoch 2234 loss 0.1519 LR 0.1302 LKL 0.0217\n",
      "epoch 2235 loss 0.2011 LR 0.1792 LKL 0.0220\n",
      "epoch 2236 loss 0.2110 LR 0.1890 LKL 0.0221\n",
      "epoch 2237 loss 0.2017 LR 0.1796 LKL 0.0220\n",
      "epoch 2238 loss 0.1475 LR 0.1251 LKL 0.0224\n",
      "epoch 2239 loss 0.1546 LR 0.1322 LKL 0.0224\n",
      "epoch 2240 loss 0.2152 LR 0.1928 LKL 0.0224\n",
      "epoch 2241 loss 0.2051 LR 0.1827 LKL 0.0223\n",
      "epoch 2242 loss 0.1686 LR 0.1461 LKL 0.0224\n",
      "epoch 2243 loss 0.1804 LR 0.1582 LKL 0.0221\n",
      "epoch 2244 loss 0.2426 LR 0.2205 LKL 0.0221\n",
      "epoch 2245 loss 0.1839 LR 0.1619 LKL 0.0219\n",
      "epoch 2246 loss 0.2218 LR 0.2001 LKL 0.0218\n",
      "epoch 2247 loss 0.1924 LR 0.1705 LKL 0.0219\n",
      "epoch 2248 loss 0.1450 LR 0.1232 LKL 0.0218\n",
      "epoch 2249 loss 0.1565 LR 0.1346 LKL 0.0220\n",
      "epoch 2250 loss 0.2208 LR 0.1989 LKL 0.0219\n",
      "epoch 2251 loss 0.1658 LR 0.1441 LKL 0.0217\n",
      "epoch 2252 loss 0.1716 LR 0.1500 LKL 0.0216\n",
      "epoch 2253 loss 0.1539 LR 0.1325 LKL 0.0214\n",
      "epoch 2254 loss 0.1786 LR 0.1572 LKL 0.0214\n",
      "epoch 2255 loss 0.1724 LR 0.1509 LKL 0.0215\n",
      "epoch 2256 loss 0.1463 LR 0.1248 LKL 0.0215\n",
      "epoch 2257 loss 0.1719 LR 0.1506 LKL 0.0214\n",
      "epoch 2258 loss 0.1591 LR 0.1378 LKL 0.0213\n",
      "epoch 2259 loss 0.1494 LR 0.1282 LKL 0.0211\n",
      "epoch 2260 loss 0.1748 LR 0.1536 LKL 0.0213\n",
      "epoch 2261 loss 0.1633 LR 0.1420 LKL 0.0213\n",
      "epoch 2262 loss 0.1550 LR 0.1336 LKL 0.0213\n",
      "epoch 2263 loss 0.2288 LR 0.2073 LKL 0.0214\n",
      "epoch 2264 loss 0.1649 LR 0.1432 LKL 0.0216\n",
      "epoch 2265 loss 0.2165 LR 0.1949 LKL 0.0216\n",
      "epoch 2266 loss 0.1347 LR 0.1132 LKL 0.0215\n",
      "epoch 2267 loss 0.1967 LR 0.1751 LKL 0.0216\n",
      "epoch 2268 loss 0.1253 LR 0.1036 LKL 0.0217\n",
      "epoch 2269 loss 0.1892 LR 0.1675 LKL 0.0217\n",
      "epoch 2270 loss 0.1571 LR 0.1354 LKL 0.0217\n",
      "epoch 2271 loss 0.2143 LR 0.1928 LKL 0.0215\n",
      "epoch 2272 loss 0.1760 LR 0.1544 LKL 0.0217\n",
      "epoch 2273 loss 0.1760 LR 0.1543 LKL 0.0217\n",
      "epoch 2274 loss 0.1728 LR 0.1509 LKL 0.0219\n",
      "epoch 2275 loss 0.1380 LR 0.1160 LKL 0.0219\n",
      "epoch 2276 loss 0.1888 LR 0.1669 LKL 0.0219\n",
      "epoch 2277 loss 0.1483 LR 0.1265 LKL 0.0218\n",
      "epoch 2278 loss 0.2019 LR 0.1798 LKL 0.0221\n",
      "epoch 2279 loss 0.1308 LR 0.1088 LKL 0.0220\n",
      "epoch 2280 loss 0.2137 LR 0.1920 LKL 0.0217\n",
      "epoch 2281 loss 0.1761 LR 0.1541 LKL 0.0220\n",
      "epoch 2282 loss 0.1685 LR 0.1466 LKL 0.0220\n",
      "epoch 2283 loss 0.2142 LR 0.1926 LKL 0.0216\n",
      "epoch 2284 loss 0.1741 LR 0.1524 LKL 0.0217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2285 loss 0.1254 LR 0.1035 LKL 0.0219\n",
      "epoch 2286 loss 0.2121 LR 0.1904 LKL 0.0217\n",
      "epoch 2287 loss 0.1643 LR 0.1428 LKL 0.0215\n",
      "epoch 2288 loss 0.1768 LR 0.1553 LKL 0.0215\n",
      "epoch 2289 loss 0.1232 LR 0.1018 LKL 0.0214\n",
      "epoch 2290 loss 0.1853 LR 0.1639 LKL 0.0214\n",
      "epoch 2291 loss 0.1997 LR 0.1785 LKL 0.0212\n",
      "epoch 2292 loss 0.1701 LR 0.1488 LKL 0.0213\n",
      "epoch 2293 loss 0.1947 LR 0.1736 LKL 0.0211\n",
      "epoch 2294 loss 0.1484 LR 0.1269 LKL 0.0216\n",
      "epoch 2295 loss 0.1955 LR 0.1742 LKL 0.0213\n",
      "epoch 2296 loss 0.1504 LR 0.1288 LKL 0.0215\n",
      "epoch 2297 loss 0.1844 LR 0.1628 LKL 0.0216\n",
      "epoch 2298 loss 0.2116 LR 0.1899 LKL 0.0217\n",
      "epoch 2299 loss 0.1149 LR 0.0930 LKL 0.0219\n",
      "epoch 2300 loss 0.1446 LR 0.1227 LKL 0.0219\n",
      "epoch 2301 loss 0.1833 LR 0.1614 LKL 0.0219\n",
      "epoch 2302 loss 0.1590 LR 0.1371 LKL 0.0219\n",
      "epoch 2303 loss 0.1739 LR 0.1519 LKL 0.0219\n",
      "epoch 2304 loss 0.1851 LR 0.1631 LKL 0.0220\n",
      "epoch 2305 loss 0.1193 LR 0.0974 LKL 0.0219\n",
      "epoch 2306 loss 0.1411 LR 0.1191 LKL 0.0220\n",
      "epoch 2307 loss 0.1936 LR 0.1715 LKL 0.0222\n",
      "epoch 2308 loss 0.1312 LR 0.1092 LKL 0.0220\n",
      "epoch 2309 loss 0.2166 LR 0.1946 LKL 0.0220\n",
      "epoch 2310 loss 0.1361 LR 0.1142 LKL 0.0220\n",
      "epoch 2311 loss 0.1982 LR 0.1764 LKL 0.0218\n",
      "epoch 2312 loss 0.2231 LR 0.2014 LKL 0.0218\n",
      "epoch 2313 loss 0.1867 LR 0.1649 LKL 0.0218\n",
      "epoch 2314 loss 0.1620 LR 0.1402 LKL 0.0218\n",
      "epoch 2315 loss 0.1964 LR 0.1749 LKL 0.0215\n",
      "epoch 2316 loss 0.1861 LR 0.1647 LKL 0.0214\n",
      "epoch 2317 loss 0.1572 LR 0.1357 LKL 0.0215\n",
      "epoch 2318 loss 0.2083 LR 0.1869 LKL 0.0214\n",
      "epoch 2319 loss 0.1643 LR 0.1434 LKL 0.0209\n",
      "epoch 2320 loss 0.1466 LR 0.1253 LKL 0.0213\n",
      "epoch 2321 loss 0.2044 LR 0.1832 LKL 0.0212\n",
      "epoch 2322 loss 0.1828 LR 0.1615 LKL 0.0212\n",
      "epoch 2323 loss 0.1663 LR 0.1449 LKL 0.0214\n",
      "epoch 2324 loss 0.1882 LR 0.1665 LKL 0.0217\n",
      "epoch 2325 loss 0.1872 LR 0.1657 LKL 0.0214\n",
      "epoch 2326 loss 0.2026 LR 0.1809 LKL 0.0217\n",
      "epoch 2327 loss 0.2010 LR 0.1794 LKL 0.0216\n",
      "epoch 2328 loss 0.1294 LR 0.1076 LKL 0.0218\n",
      "epoch 2329 loss 0.1369 LR 0.1150 LKL 0.0219\n",
      "epoch 2330 loss 0.1882 LR 0.1665 LKL 0.0217\n",
      "epoch 2331 loss 0.1900 LR 0.1682 LKL 0.0219\n",
      "epoch 2332 loss 0.1506 LR 0.1290 LKL 0.0217\n",
      "epoch 2333 loss 0.1696 LR 0.1482 LKL 0.0215\n",
      "epoch 2334 loss 0.1207 LR 0.0992 LKL 0.0216\n",
      "epoch 2335 loss 0.1651 LR 0.1434 LKL 0.0216\n",
      "epoch 2336 loss 0.1318 LR 0.1103 LKL 0.0215\n",
      "epoch 2337 loss 0.1960 LR 0.1749 LKL 0.0212\n",
      "epoch 2338 loss 0.1696 LR 0.1484 LKL 0.0212\n",
      "epoch 2339 loss 0.1891 LR 0.1677 LKL 0.0213\n",
      "epoch 2340 loss 0.1479 LR 0.1268 LKL 0.0211\n",
      "epoch 2341 loss 0.1909 LR 0.1696 LKL 0.0214\n",
      "epoch 2342 loss 0.1346 LR 0.1133 LKL 0.0212\n",
      "epoch 2343 loss 0.1314 LR 0.1098 LKL 0.0217\n",
      "epoch 2344 loss 0.2182 LR 0.1965 LKL 0.0217\n",
      "epoch 2345 loss 0.1495 LR 0.1278 LKL 0.0217\n",
      "epoch 2346 loss 0.1625 LR 0.1409 LKL 0.0216\n",
      "epoch 2347 loss 0.2092 LR 0.1874 LKL 0.0218\n",
      "epoch 2348 loss 0.1638 LR 0.1421 LKL 0.0217\n",
      "epoch 2349 loss 0.1693 LR 0.1472 LKL 0.0221\n",
      "epoch 2350 loss 0.1355 LR 0.1134 LKL 0.0221\n",
      "epoch 2351 loss 0.1122 LR 0.0900 LKL 0.0222\n",
      "epoch 2352 loss 0.1494 LR 0.1272 LKL 0.0222\n",
      "epoch 2353 loss 0.1377 LR 0.1157 LKL 0.0220\n",
      "epoch 2354 loss 0.1575 LR 0.1356 LKL 0.0219\n",
      "epoch 2355 loss 0.1910 LR 0.1688 LKL 0.0222\n",
      "epoch 2356 loss 0.1536 LR 0.1315 LKL 0.0221\n",
      "epoch 2357 loss 0.2048 LR 0.1828 LKL 0.0221\n",
      "epoch 2358 loss 0.2058 LR 0.1838 LKL 0.0220\n",
      "epoch 2359 loss 0.1700 LR 0.1483 LKL 0.0217\n",
      "epoch 2360 loss 0.1416 LR 0.1199 LKL 0.0217\n",
      "epoch 2361 loss 0.1676 LR 0.1458 LKL 0.0218\n",
      "epoch 2362 loss 0.1613 LR 0.1396 LKL 0.0218\n",
      "epoch 2363 loss 0.1693 LR 0.1478 LKL 0.0215\n",
      "epoch 2364 loss 0.1669 LR 0.1453 LKL 0.0216\n",
      "epoch 2365 loss 0.1472 LR 0.1258 LKL 0.0214\n",
      "epoch 2366 loss 0.1710 LR 0.1496 LKL 0.0214\n",
      "epoch 2367 loss 0.1417 LR 0.1204 LKL 0.0213\n",
      "epoch 2368 loss 0.2002 LR 0.1790 LKL 0.0213\n",
      "epoch 2369 loss 0.1656 LR 0.1445 LKL 0.0211\n",
      "epoch 2370 loss 0.1451 LR 0.1239 LKL 0.0212\n",
      "epoch 2371 loss 0.1793 LR 0.1580 LKL 0.0213\n",
      "epoch 2372 loss 0.1666 LR 0.1452 LKL 0.0213\n",
      "epoch 2373 loss 0.1777 LR 0.1562 LKL 0.0215\n",
      "epoch 2374 loss 0.1852 LR 0.1635 LKL 0.0217\n",
      "epoch 2375 loss 0.1871 LR 0.1653 LKL 0.0218\n",
      "epoch 2376 loss 0.2226 LR 0.2009 LKL 0.0216\n",
      "epoch 2377 loss 0.1870 LR 0.1651 LKL 0.0220\n",
      "epoch 2378 loss 0.2449 LR 0.2233 LKL 0.0217\n",
      "epoch 2379 loss 0.1783 LR 0.1566 LKL 0.0216\n",
      "epoch 2380 loss 0.1746 LR 0.1528 LKL 0.0218\n",
      "epoch 2381 loss 0.1189 LR 0.0971 LKL 0.0218\n",
      "epoch 2382 loss 0.1770 LR 0.1552 LKL 0.0219\n",
      "epoch 2383 loss 0.1372 LR 0.1156 LKL 0.0217\n",
      "epoch 2384 loss 0.1547 LR 0.1328 LKL 0.0218\n",
      "epoch 2385 loss 0.1677 LR 0.1454 LKL 0.0223\n",
      "epoch 2386 loss 0.1775 LR 0.1553 LKL 0.0222\n",
      "epoch 2387 loss 0.2109 LR 0.1890 LKL 0.0219\n",
      "epoch 2388 loss 0.1314 LR 0.1094 LKL 0.0220\n",
      "epoch 2389 loss 0.1874 LR 0.1654 LKL 0.0221\n",
      "epoch 2390 loss 0.2294 LR 0.2075 LKL 0.0218\n",
      "epoch 2391 loss 0.1799 LR 0.1582 LKL 0.0217\n",
      "epoch 2392 loss 0.1506 LR 0.1290 LKL 0.0217\n",
      "epoch 2393 loss 0.1256 LR 0.1037 LKL 0.0219\n",
      "epoch 2394 loss 0.1376 LR 0.1155 LKL 0.0220\n",
      "epoch 2395 loss 0.1045 LR 0.0827 LKL 0.0217\n",
      "epoch 2396 loss 0.1818 LR 0.1601 LKL 0.0217\n",
      "epoch 2397 loss 0.1771 LR 0.1553 LKL 0.0218\n",
      "epoch 2398 loss 0.1526 LR 0.1312 LKL 0.0215\n",
      "epoch 2399 loss 0.1929 LR 0.1715 LKL 0.0214\n",
      "epoch 2400 loss 0.1612 LR 0.1395 LKL 0.0217\n",
      "66\n",
      "epoch 2401 loss 0.1931 LR 0.1716 LKL 0.0215\n",
      "epoch 2402 loss 0.1777 LR 0.1563 LKL 0.0214\n",
      "epoch 2403 loss 0.1480 LR 0.1263 LKL 0.0217\n",
      "epoch 2404 loss 0.1670 LR 0.1452 LKL 0.0217\n",
      "epoch 2405 loss 0.2130 LR 0.1915 LKL 0.0215\n",
      "epoch 2406 loss 0.1321 LR 0.1105 LKL 0.0216\n",
      "epoch 2407 loss 0.1520 LR 0.1301 LKL 0.0219\n",
      "epoch 2408 loss 0.2268 LR 0.2050 LKL 0.0218\n",
      "epoch 2409 loss 0.0974 LR 0.0752 LKL 0.0222\n",
      "epoch 2410 loss 0.2145 LR 0.1924 LKL 0.0221\n",
      "epoch 2411 loss 0.1447 LR 0.1224 LKL 0.0223\n",
      "epoch 2412 loss 0.2005 LR 0.1785 LKL 0.0220\n",
      "epoch 2413 loss 0.1325 LR 0.1104 LKL 0.0221\n",
      "epoch 2414 loss 0.1485 LR 0.1264 LKL 0.0222\n",
      "epoch 2415 loss 0.1906 LR 0.1686 LKL 0.0220\n",
      "epoch 2416 loss 0.1253 LR 0.1032 LKL 0.0221\n",
      "epoch 2417 loss 0.2080 LR 0.1862 LKL 0.0218\n",
      "epoch 2418 loss 0.1727 LR 0.1508 LKL 0.0218\n",
      "epoch 2419 loss 0.1534 LR 0.1314 LKL 0.0220\n",
      "epoch 2420 loss 0.1908 LR 0.1690 LKL 0.0219\n",
      "epoch 2421 loss 0.2143 LR 0.1928 LKL 0.0216\n",
      "epoch 2422 loss 0.1480 LR 0.1262 LKL 0.0218\n",
      "epoch 2423 loss 0.1704 LR 0.1487 LKL 0.0217\n",
      "epoch 2424 loss 0.2016 LR 0.1800 LKL 0.0216\n",
      "epoch 2425 loss 0.1328 LR 0.1110 LKL 0.0217\n",
      "epoch 2426 loss 0.2018 LR 0.1798 LKL 0.0220\n",
      "epoch 2427 loss 0.1392 LR 0.1172 LKL 0.0220\n",
      "epoch 2428 loss 0.1617 LR 0.1394 LKL 0.0223\n",
      "epoch 2429 loss 0.2029 LR 0.1808 LKL 0.0221\n",
      "epoch 2430 loss 0.1295 LR 0.1074 LKL 0.0221\n",
      "epoch 2431 loss 0.1951 LR 0.1731 LKL 0.0220\n",
      "epoch 2432 loss 0.1331 LR 0.1106 LKL 0.0225\n",
      "epoch 2433 loss 0.1124 LR 0.0899 LKL 0.0225\n",
      "epoch 2434 loss 0.1708 LR 0.1486 LKL 0.0222\n",
      "epoch 2435 loss 0.1932 LR 0.1709 LKL 0.0223\n",
      "epoch 2436 loss 0.2021 LR 0.1801 LKL 0.0220\n",
      "epoch 2437 loss 0.1493 LR 0.1270 LKL 0.0222\n",
      "epoch 2438 loss 0.1416 LR 0.1196 LKL 0.0219\n",
      "epoch 2439 loss 0.1381 LR 0.1160 LKL 0.0221\n",
      "epoch 2440 loss 0.1993 LR 0.1776 LKL 0.0218\n",
      "epoch 2441 loss 0.0832 LR 0.0613 LKL 0.0219\n",
      "epoch 2442 loss 0.1847 LR 0.1631 LKL 0.0216\n",
      "epoch 2443 loss 0.1480 LR 0.1262 LKL 0.0218\n",
      "epoch 2444 loss 0.0955 LR 0.0734 LKL 0.0220\n",
      "epoch 2445 loss 0.2036 LR 0.1817 LKL 0.0219\n",
      "epoch 2446 loss 0.1975 LR 0.1755 LKL 0.0219\n",
      "epoch 2447 loss 0.1707 LR 0.1485 LKL 0.0222\n",
      "epoch 2448 loss 0.1751 LR 0.1530 LKL 0.0221\n",
      "epoch 2449 loss 0.1553 LR 0.1336 LKL 0.0217\n",
      "epoch 2450 loss 0.1896 LR 0.1677 LKL 0.0220\n",
      "epoch 2451 loss 0.2298 LR 0.2079 LKL 0.0220\n",
      "epoch 2452 loss 0.1402 LR 0.1184 LKL 0.0218\n",
      "epoch 2453 loss 0.1343 LR 0.1122 LKL 0.0221\n",
      "epoch 2454 loss 0.1483 LR 0.1264 LKL 0.0219\n",
      "epoch 2455 loss 0.1715 LR 0.1495 LKL 0.0219\n",
      "epoch 2456 loss 0.1690 LR 0.1473 LKL 0.0216\n",
      "epoch 2457 loss 0.1592 LR 0.1372 LKL 0.0219\n",
      "epoch 2458 loss 0.1634 LR 0.1415 LKL 0.0219\n",
      "epoch 2459 loss 0.1777 LR 0.1556 LKL 0.0221\n",
      "epoch 2460 loss 0.1877 LR 0.1658 LKL 0.0219\n",
      "epoch 2461 loss 0.1685 LR 0.1466 LKL 0.0219\n",
      "epoch 2462 loss 0.1296 LR 0.1076 LKL 0.0220\n",
      "epoch 2463 loss 0.1824 LR 0.1605 LKL 0.0219\n",
      "epoch 2464 loss 0.1505 LR 0.1283 LKL 0.0222\n",
      "epoch 2465 loss 0.1665 LR 0.1443 LKL 0.0222\n",
      "epoch 2466 loss 0.1415 LR 0.1194 LKL 0.0221\n",
      "epoch 2467 loss 0.1304 LR 0.1081 LKL 0.0223\n",
      "epoch 2468 loss 0.1413 LR 0.1189 LKL 0.0224\n",
      "epoch 2469 loss 0.1703 LR 0.1480 LKL 0.0223\n",
      "epoch 2470 loss 0.1230 LR 0.1005 LKL 0.0224\n",
      "epoch 2471 loss 0.1883 LR 0.1660 LKL 0.0223\n",
      "epoch 2472 loss 0.0805 LR 0.0578 LKL 0.0227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2473 loss 0.1257 LR 0.1032 LKL 0.0225\n",
      "epoch 2474 loss 0.1782 LR 0.1554 LKL 0.0228\n",
      "epoch 2475 loss 0.1530 LR 0.1304 LKL 0.0226\n",
      "epoch 2476 loss 0.1644 LR 0.1419 LKL 0.0225\n",
      "epoch 2477 loss 0.1446 LR 0.1221 LKL 0.0225\n",
      "epoch 2478 loss 0.1766 LR 0.1541 LKL 0.0225\n",
      "epoch 2479 loss 0.1985 LR 0.1761 LKL 0.0224\n",
      "epoch 2480 loss 0.1562 LR 0.1338 LKL 0.0224\n",
      "epoch 2481 loss 0.1222 LR 0.0998 LKL 0.0223\n",
      "epoch 2482 loss 0.1684 LR 0.1459 LKL 0.0225\n",
      "epoch 2483 loss 0.1413 LR 0.1188 LKL 0.0226\n",
      "epoch 2484 loss 0.1462 LR 0.1236 LKL 0.0225\n",
      "epoch 2485 loss 0.1610 LR 0.1386 LKL 0.0224\n",
      "epoch 2486 loss 0.1518 LR 0.1293 LKL 0.0225\n",
      "epoch 2487 loss 0.2174 LR 0.1949 LKL 0.0225\n",
      "epoch 2488 loss 0.2093 LR 0.1868 LKL 0.0225\n",
      "epoch 2489 loss 0.1164 LR 0.0939 LKL 0.0225\n",
      "epoch 2490 loss 0.1819 LR 0.1598 LKL 0.0222\n",
      "epoch 2491 loss 0.1145 LR 0.0924 LKL 0.0221\n",
      "epoch 2492 loss 0.2211 LR 0.1992 LKL 0.0219\n",
      "epoch 2493 loss 0.1776 LR 0.1557 LKL 0.0219\n",
      "epoch 2494 loss 0.1652 LR 0.1432 LKL 0.0220\n",
      "epoch 2495 loss 0.1330 LR 0.1111 LKL 0.0219\n",
      "epoch 2496 loss 0.1209 LR 0.0993 LKL 0.0216\n",
      "epoch 2497 loss 0.1664 LR 0.1446 LKL 0.0218\n",
      "epoch 2498 loss 0.1805 LR 0.1587 LKL 0.0218\n",
      "epoch 2499 loss 0.1198 LR 0.0976 LKL 0.0222\n",
      "epoch 2500 loss 0.1474 LR 0.1255 LKL 0.0218\n",
      "105\n",
      "epoch 2501 loss 0.1254 LR 0.1034 LKL 0.0221\n",
      "epoch 2502 loss 0.1667 LR 0.1449 LKL 0.0218\n",
      "epoch 2503 loss 0.1484 LR 0.1265 LKL 0.0219\n",
      "epoch 2504 loss 0.1857 LR 0.1638 LKL 0.0219\n",
      "epoch 2505 loss 0.1669 LR 0.1450 LKL 0.0219\n",
      "epoch 2506 loss 0.1223 LR 0.1005 LKL 0.0218\n",
      "epoch 2507 loss 0.1079 LR 0.0858 LKL 0.0221\n",
      "epoch 2508 loss 0.1085 LR 0.0865 LKL 0.0220\n",
      "epoch 2509 loss 0.1411 LR 0.1192 LKL 0.0218\n",
      "epoch 2510 loss 0.1437 LR 0.1218 LKL 0.0220\n",
      "epoch 2511 loss 0.1963 LR 0.1742 LKL 0.0221\n",
      "epoch 2512 loss 0.1553 LR 0.1332 LKL 0.0221\n",
      "epoch 2513 loss 0.1147 LR 0.0927 LKL 0.0221\n",
      "epoch 2514 loss 0.1324 LR 0.1101 LKL 0.0222\n",
      "epoch 2515 loss 0.1572 LR 0.1352 LKL 0.0220\n",
      "epoch 2516 loss 0.1264 LR 0.1041 LKL 0.0223\n",
      "epoch 2517 loss 0.1471 LR 0.1247 LKL 0.0224\n",
      "epoch 2518 loss 0.2371 LR 0.2149 LKL 0.0222\n",
      "epoch 2519 loss 0.1556 LR 0.1334 LKL 0.0223\n",
      "epoch 2520 loss 0.1279 LR 0.1058 LKL 0.0221\n",
      "epoch 2521 loss 0.1047 LR 0.0824 LKL 0.0223\n",
      "epoch 2522 loss 0.1655 LR 0.1432 LKL 0.0223\n",
      "epoch 2523 loss 0.1490 LR 0.1269 LKL 0.0222\n",
      "epoch 2524 loss 0.1572 LR 0.1349 LKL 0.0223\n",
      "epoch 2525 loss 0.1627 LR 0.1405 LKL 0.0222\n",
      "epoch 2526 loss 0.1776 LR 0.1551 LKL 0.0225\n",
      "epoch 2527 loss 0.1584 LR 0.1359 LKL 0.0224\n",
      "epoch 2528 loss 0.1264 LR 0.1041 LKL 0.0222\n",
      "epoch 2529 loss 0.1513 LR 0.1292 LKL 0.0222\n",
      "epoch 2530 loss 0.1515 LR 0.1295 LKL 0.0220\n",
      "epoch 2531 loss 0.1591 LR 0.1374 LKL 0.0217\n",
      "epoch 2532 loss 0.1971 LR 0.1753 LKL 0.0219\n",
      "epoch 2533 loss 0.1672 LR 0.1456 LKL 0.0216\n",
      "epoch 2534 loss 0.1401 LR 0.1185 LKL 0.0216\n",
      "epoch 2535 loss 0.0933 LR 0.0715 LKL 0.0218\n",
      "epoch 2536 loss 0.1626 LR 0.1408 LKL 0.0218\n",
      "epoch 2537 loss 0.1859 LR 0.1643 LKL 0.0215\n",
      "epoch 2538 loss 0.1326 LR 0.1108 LKL 0.0218\n",
      "epoch 2539 loss 0.1460 LR 0.1246 LKL 0.0215\n",
      "epoch 2540 loss 0.1576 LR 0.1361 LKL 0.0215\n",
      "epoch 2541 loss 0.1947 LR 0.1733 LKL 0.0215\n",
      "epoch 2542 loss 0.1034 LR 0.0818 LKL 0.0216\n",
      "epoch 2543 loss 0.1402 LR 0.1184 LKL 0.0219\n",
      "epoch 2544 loss 0.1093 LR 0.0874 LKL 0.0219\n",
      "epoch 2545 loss 0.1211 LR 0.0990 LKL 0.0221\n",
      "epoch 2546 loss 0.1530 LR 0.1311 LKL 0.0219\n",
      "epoch 2547 loss 0.1604 LR 0.1384 LKL 0.0221\n",
      "epoch 2548 loss 0.1910 LR 0.1690 LKL 0.0220\n",
      "epoch 2549 loss 0.1351 LR 0.1132 LKL 0.0219\n",
      "epoch 2550 loss 0.1607 LR 0.1388 LKL 0.0219\n",
      "epoch 2551 loss 0.1641 LR 0.1423 LKL 0.0219\n",
      "epoch 2552 loss 0.1417 LR 0.1199 LKL 0.0218\n",
      "epoch 2553 loss 0.1548 LR 0.1330 LKL 0.0218\n",
      "epoch 2554 loss 0.1587 LR 0.1369 LKL 0.0218\n",
      "epoch 2555 loss 0.1441 LR 0.1223 LKL 0.0218\n",
      "epoch 2556 loss 0.0929 LR 0.0712 LKL 0.0217\n",
      "epoch 2557 loss 0.1449 LR 0.1233 LKL 0.0216\n",
      "epoch 2558 loss 0.1618 LR 0.1402 LKL 0.0216\n",
      "epoch 2559 loss 0.1897 LR 0.1679 LKL 0.0218\n",
      "epoch 2560 loss 0.1365 LR 0.1148 LKL 0.0217\n",
      "epoch 2561 loss 0.1464 LR 0.1247 LKL 0.0217\n",
      "epoch 2562 loss 0.1174 LR 0.0953 LKL 0.0221\n",
      "epoch 2563 loss 0.2371 LR 0.2154 LKL 0.0218\n",
      "epoch 2564 loss 0.2069 LR 0.1851 LKL 0.0218\n",
      "epoch 2565 loss 0.1441 LR 0.1220 LKL 0.0221\n",
      "epoch 2566 loss 0.1362 LR 0.1143 LKL 0.0218\n",
      "epoch 2567 loss 0.1416 LR 0.1195 LKL 0.0221\n",
      "epoch 2568 loss 0.1015 LR 0.0794 LKL 0.0221\n",
      "epoch 2569 loss 0.1454 LR 0.1235 LKL 0.0219\n",
      "epoch 2570 loss 0.2241 LR 0.2024 LKL 0.0217\n",
      "epoch 2571 loss 0.1935 LR 0.1718 LKL 0.0217\n",
      "epoch 2572 loss 0.1920 LR 0.1701 LKL 0.0219\n",
      "epoch 2573 loss 0.1779 LR 0.1560 LKL 0.0219\n",
      "epoch 2574 loss 0.1382 LR 0.1160 LKL 0.0222\n",
      "epoch 2575 loss 0.1175 LR 0.0954 LKL 0.0220\n",
      "epoch 2576 loss 0.1448 LR 0.1231 LKL 0.0217\n",
      "epoch 2577 loss 0.1676 LR 0.1460 LKL 0.0216\n",
      "epoch 2578 loss 0.0945 LR 0.0724 LKL 0.0221\n",
      "epoch 2579 loss 0.1610 LR 0.1389 LKL 0.0221\n",
      "epoch 2580 loss 0.1883 LR 0.1663 LKL 0.0220\n",
      "epoch 2581 loss 0.2026 LR 0.1805 LKL 0.0221\n",
      "epoch 2582 loss 0.1489 LR 0.1268 LKL 0.0221\n",
      "epoch 2583 loss 0.1804 LR 0.1583 LKL 0.0220\n",
      "epoch 2584 loss 0.1503 LR 0.1283 LKL 0.0221\n",
      "epoch 2585 loss 0.1696 LR 0.1474 LKL 0.0222\n",
      "epoch 2586 loss 0.1100 LR 0.0878 LKL 0.0222\n",
      "epoch 2587 loss 0.1824 LR 0.1605 LKL 0.0219\n",
      "epoch 2588 loss 0.1746 LR 0.1528 LKL 0.0219\n",
      "epoch 2589 loss 0.1556 LR 0.1337 LKL 0.0219\n",
      "epoch 2590 loss 0.1107 LR 0.0889 LKL 0.0218\n",
      "epoch 2591 loss 0.1871 LR 0.1656 LKL 0.0215\n",
      "epoch 2592 loss 0.1789 LR 0.1571 LKL 0.0219\n",
      "epoch 2593 loss 0.1568 LR 0.1350 LKL 0.0219\n",
      "epoch 2594 loss 0.0730 LR 0.0511 LKL 0.0219\n",
      "epoch 2595 loss 0.1984 LR 0.1768 LKL 0.0216\n",
      "epoch 2596 loss 0.1460 LR 0.1239 LKL 0.0221\n",
      "epoch 2597 loss 0.1285 LR 0.1066 LKL 0.0219\n",
      "epoch 2598 loss 0.1264 LR 0.1043 LKL 0.0221\n",
      "epoch 2599 loss 0.1278 LR 0.1058 LKL 0.0220\n",
      "epoch 2600 loss 0.1619 LR 0.1399 LKL 0.0221\n",
      "62\n",
      "epoch 2601 loss 0.1111 LR 0.0891 LKL 0.0220\n",
      "epoch 2602 loss 0.1517 LR 0.1298 LKL 0.0220\n",
      "epoch 2603 loss 0.1776 LR 0.1557 LKL 0.0219\n",
      "epoch 2604 loss 0.1611 LR 0.1389 LKL 0.0222\n",
      "epoch 2605 loss 0.1404 LR 0.1183 LKL 0.0220\n",
      "epoch 2606 loss 0.1738 LR 0.1514 LKL 0.0224\n",
      "epoch 2607 loss 0.1700 LR 0.1478 LKL 0.0222\n",
      "epoch 2608 loss 0.1362 LR 0.1138 LKL 0.0224\n",
      "epoch 2609 loss 0.1376 LR 0.1152 LKL 0.0224\n",
      "epoch 2610 loss 0.1685 LR 0.1461 LKL 0.0223\n",
      "epoch 2611 loss 0.0922 LR 0.0700 LKL 0.0222\n",
      "epoch 2612 loss 0.1603 LR 0.1381 LKL 0.0222\n",
      "epoch 2613 loss 0.1520 LR 0.1297 LKL 0.0222\n",
      "epoch 2614 loss 0.1635 LR 0.1413 LKL 0.0222\n",
      "epoch 2615 loss 0.1260 LR 0.1039 LKL 0.0221\n",
      "epoch 2616 loss 0.1408 LR 0.1184 LKL 0.0224\n",
      "epoch 2617 loss 0.1089 LR 0.0867 LKL 0.0222\n",
      "epoch 2618 loss 0.1882 LR 0.1661 LKL 0.0221\n",
      "epoch 2619 loss 0.1034 LR 0.0813 LKL 0.0221\n",
      "epoch 2620 loss 0.1277 LR 0.1056 LKL 0.0221\n",
      "epoch 2621 loss 0.1723 LR 0.1504 LKL 0.0219\n",
      "epoch 2622 loss 0.1178 LR 0.0958 LKL 0.0220\n",
      "epoch 2623 loss 0.1495 LR 0.1271 LKL 0.0224\n",
      "epoch 2624 loss 0.1212 LR 0.0991 LKL 0.0222\n",
      "epoch 2625 loss 0.1678 LR 0.1456 LKL 0.0222\n",
      "epoch 2626 loss 0.1601 LR 0.1379 LKL 0.0222\n",
      "epoch 2627 loss 0.0942 LR 0.0723 LKL 0.0219\n",
      "epoch 2628 loss 0.1540 LR 0.1319 LKL 0.0221\n",
      "epoch 2629 loss 0.1439 LR 0.1221 LKL 0.0219\n",
      "epoch 2630 loss 0.1592 LR 0.1371 LKL 0.0221\n",
      "epoch 2631 loss 0.1694 LR 0.1472 LKL 0.0222\n",
      "epoch 2632 loss 0.0829 LR 0.0607 LKL 0.0223\n",
      "epoch 2633 loss 0.1061 LR 0.0838 LKL 0.0223\n",
      "epoch 2634 loss 0.1792 LR 0.1570 LKL 0.0223\n",
      "epoch 2635 loss 0.1507 LR 0.1282 LKL 0.0224\n",
      "epoch 2636 loss 0.1549 LR 0.1327 LKL 0.0222\n",
      "epoch 2637 loss 0.1082 LR 0.0857 LKL 0.0225\n",
      "epoch 2638 loss 0.1126 LR 0.0902 LKL 0.0224\n",
      "epoch 2639 loss 0.1654 LR 0.1430 LKL 0.0224\n",
      "epoch 2640 loss 0.1367 LR 0.1142 LKL 0.0225\n",
      "epoch 2641 loss 0.1638 LR 0.1414 LKL 0.0225\n",
      "epoch 2642 loss 0.1736 LR 0.1511 LKL 0.0225\n",
      "epoch 2643 loss 0.1903 LR 0.1682 LKL 0.0221\n",
      "epoch 2644 loss 0.1707 LR 0.1483 LKL 0.0223\n",
      "epoch 2645 loss 0.1069 LR 0.0846 LKL 0.0223\n",
      "epoch 2646 loss 0.2025 LR 0.1806 LKL 0.0219\n",
      "epoch 2647 loss 0.1501 LR 0.1280 LKL 0.0222\n",
      "epoch 2648 loss 0.1618 LR 0.1398 LKL 0.0219\n",
      "epoch 2649 loss 0.2154 LR 0.1936 LKL 0.0218\n",
      "epoch 2650 loss 0.1366 LR 0.1147 LKL 0.0219\n",
      "epoch 2651 loss 0.1213 LR 0.0996 LKL 0.0217\n",
      "epoch 2652 loss 0.1418 LR 0.1203 LKL 0.0215\n",
      "epoch 2653 loss 0.1743 LR 0.1529 LKL 0.0215\n",
      "epoch 2654 loss 0.1319 LR 0.1100 LKL 0.0219\n",
      "epoch 2655 loss 0.1954 LR 0.1735 LKL 0.0219\n",
      "epoch 2656 loss 0.1611 LR 0.1391 LKL 0.0220\n",
      "epoch 2657 loss 0.1719 LR 0.1498 LKL 0.0221\n",
      "epoch 2658 loss 0.1200 LR 0.0979 LKL 0.0221\n",
      "epoch 2659 loss 0.2052 LR 0.1833 LKL 0.0218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2660 loss 0.1522 LR 0.1301 LKL 0.0221\n",
      "epoch 2661 loss 0.1605 LR 0.1385 LKL 0.0220\n",
      "epoch 2662 loss 0.1582 LR 0.1363 LKL 0.0220\n",
      "epoch 2663 loss 0.1333 LR 0.1117 LKL 0.0216\n",
      "epoch 2664 loss 0.1146 LR 0.0928 LKL 0.0218\n",
      "epoch 2665 loss 0.1868 LR 0.1650 LKL 0.0218\n",
      "epoch 2666 loss 0.1342 LR 0.1122 LKL 0.0221\n",
      "epoch 2667 loss 0.1301 LR 0.1079 LKL 0.0222\n",
      "epoch 2668 loss 0.0981 LR 0.0761 LKL 0.0220\n",
      "epoch 2669 loss 0.1812 LR 0.1592 LKL 0.0220\n",
      "epoch 2670 loss 0.1791 LR 0.1573 LKL 0.0218\n",
      "epoch 2671 loss 0.1351 LR 0.1130 LKL 0.0221\n",
      "epoch 2672 loss 0.1218 LR 0.0997 LKL 0.0221\n",
      "epoch 2673 loss 0.1766 LR 0.1546 LKL 0.0221\n",
      "epoch 2674 loss 0.1354 LR 0.1134 LKL 0.0221\n",
      "epoch 2675 loss 0.1637 LR 0.1419 LKL 0.0218\n",
      "epoch 2676 loss 0.1787 LR 0.1567 LKL 0.0220\n",
      "epoch 2677 loss 0.1468 LR 0.1248 LKL 0.0220\n",
      "epoch 2678 loss 0.1437 LR 0.1217 LKL 0.0220\n",
      "epoch 2679 loss 0.1529 LR 0.1308 LKL 0.0222\n",
      "epoch 2680 loss 0.1501 LR 0.1278 LKL 0.0223\n",
      "epoch 2681 loss 0.1158 LR 0.0937 LKL 0.0221\n",
      "epoch 2682 loss 0.1168 LR 0.0945 LKL 0.0223\n",
      "epoch 2683 loss 0.1168 LR 0.0949 LKL 0.0219\n",
      "epoch 2684 loss 0.1433 LR 0.1216 LKL 0.0217\n",
      "epoch 2685 loss 0.1399 LR 0.1179 LKL 0.0220\n",
      "epoch 2686 loss 0.0868 LR 0.0651 LKL 0.0218\n",
      "epoch 2687 loss 0.1280 LR 0.1061 LKL 0.0219\n",
      "epoch 2688 loss 0.1728 LR 0.1509 LKL 0.0219\n",
      "epoch 2689 loss 0.1797 LR 0.1579 LKL 0.0218\n",
      "epoch 2690 loss 0.1353 LR 0.1133 LKL 0.0220\n",
      "epoch 2691 loss 0.1419 LR 0.1201 LKL 0.0219\n",
      "epoch 2692 loss 0.1352 LR 0.1135 LKL 0.0216\n",
      "epoch 2693 loss 0.1295 LR 0.1079 LKL 0.0216\n",
      "epoch 2694 loss 0.1970 LR 0.1755 LKL 0.0215\n",
      "epoch 2695 loss 0.1761 LR 0.1544 LKL 0.0218\n",
      "epoch 2696 loss 0.1112 LR 0.0894 LKL 0.0218\n",
      "epoch 2697 loss 0.1478 LR 0.1262 LKL 0.0216\n",
      "epoch 2698 loss 0.1572 LR 0.1353 LKL 0.0219\n",
      "epoch 2699 loss 0.1659 LR 0.1439 LKL 0.0219\n",
      "epoch 2700 loss 0.1388 LR 0.1165 LKL 0.0223\n",
      "epoch 2701 loss 0.0782 LR 0.0556 LKL 0.0226\n",
      "epoch 2702 loss 0.0989 LR 0.0764 LKL 0.0225\n",
      "epoch 2703 loss 0.1244 LR 0.1020 LKL 0.0224\n",
      "epoch 2704 loss 0.1349 LR 0.1123 LKL 0.0226\n",
      "epoch 2705 loss 0.1477 LR 0.1251 LKL 0.0226\n",
      "epoch 2706 loss 0.1272 LR 0.1043 LKL 0.0229\n",
      "epoch 2707 loss 0.1794 LR 0.1567 LKL 0.0227\n",
      "epoch 2708 loss 0.1334 LR 0.1106 LKL 0.0228\n",
      "epoch 2709 loss 0.1353 LR 0.1125 LKL 0.0228\n",
      "epoch 2710 loss 0.1619 LR 0.1394 LKL 0.0225\n",
      "epoch 2711 loss 0.0870 LR 0.0643 LKL 0.0227\n",
      "epoch 2712 loss 0.1073 LR 0.0845 LKL 0.0228\n",
      "epoch 2713 loss 0.1143 LR 0.0917 LKL 0.0225\n",
      "epoch 2714 loss 0.1169 LR 0.0947 LKL 0.0222\n",
      "epoch 2715 loss 0.1378 LR 0.1155 LKL 0.0223\n",
      "epoch 2716 loss 0.1514 LR 0.1294 LKL 0.0220\n",
      "epoch 2717 loss 0.1470 LR 0.1248 LKL 0.0222\n",
      "epoch 2718 loss 0.1399 LR 0.1180 LKL 0.0219\n",
      "epoch 2719 loss 0.0927 LR 0.0704 LKL 0.0223\n",
      "epoch 2720 loss 0.1546 LR 0.1327 LKL 0.0219\n",
      "epoch 2721 loss 0.0936 LR 0.0716 LKL 0.0220\n",
      "epoch 2722 loss 0.1093 LR 0.0871 LKL 0.0222\n",
      "epoch 2723 loss 0.1034 LR 0.0813 LKL 0.0222\n",
      "epoch 2724 loss 0.0878 LR 0.0655 LKL 0.0223\n",
      "epoch 2725 loss 0.1503 LR 0.1282 LKL 0.0221\n",
      "epoch 2726 loss 0.1472 LR 0.1253 LKL 0.0219\n",
      "epoch 2727 loss 0.1024 LR 0.0804 LKL 0.0221\n",
      "epoch 2728 loss 0.1062 LR 0.0840 LKL 0.0222\n",
      "epoch 2729 loss 0.1632 LR 0.1409 LKL 0.0224\n",
      "epoch 2730 loss 0.1492 LR 0.1267 LKL 0.0225\n",
      "epoch 2731 loss 0.1287 LR 0.1062 LKL 0.0225\n",
      "epoch 2732 loss 0.2458 LR 0.2236 LKL 0.0223\n",
      "epoch 2733 loss 0.1793 LR 0.1571 LKL 0.0221\n",
      "epoch 2734 loss 0.1465 LR 0.1241 LKL 0.0224\n",
      "epoch 2735 loss 0.0972 LR 0.0749 LKL 0.0223\n",
      "epoch 2736 loss 0.1403 LR 0.1182 LKL 0.0221\n",
      "epoch 2737 loss 0.0968 LR 0.0743 LKL 0.0224\n",
      "epoch 2738 loss 0.1733 LR 0.1510 LKL 0.0223\n",
      "epoch 2739 loss 0.1168 LR 0.0948 LKL 0.0220\n",
      "epoch 2740 loss 0.1578 LR 0.1359 LKL 0.0219\n",
      "epoch 2741 loss 0.1293 LR 0.1072 LKL 0.0221\n",
      "epoch 2742 loss 0.1120 LR 0.0899 LKL 0.0221\n",
      "epoch 2743 loss 0.0989 LR 0.0769 LKL 0.0220\n",
      "epoch 2744 loss 0.1313 LR 0.1096 LKL 0.0216\n",
      "epoch 2745 loss 0.1354 LR 0.1137 LKL 0.0217\n",
      "epoch 2746 loss 0.1119 LR 0.0898 LKL 0.0221\n",
      "epoch 2747 loss 0.1479 LR 0.1261 LKL 0.0217\n",
      "epoch 2748 loss 0.1160 LR 0.0940 LKL 0.0220\n",
      "epoch 2749 loss 0.1263 LR 0.1043 LKL 0.0220\n",
      "epoch 2750 loss 0.0983 LR 0.0762 LKL 0.0222\n",
      "epoch 2751 loss 0.1736 LR 0.1516 LKL 0.0220\n",
      "epoch 2752 loss 0.1616 LR 0.1394 LKL 0.0222\n",
      "epoch 2753 loss 0.1831 LR 0.1607 LKL 0.0224\n",
      "epoch 2754 loss 0.1431 LR 0.1209 LKL 0.0222\n",
      "epoch 2755 loss 0.1004 LR 0.0785 LKL 0.0220\n",
      "epoch 2756 loss 0.1682 LR 0.1461 LKL 0.0221\n",
      "epoch 2757 loss 0.1526 LR 0.1304 LKL 0.0222\n",
      "epoch 2758 loss 0.1038 LR 0.0817 LKL 0.0222\n",
      "epoch 2759 loss 0.1414 LR 0.1191 LKL 0.0222\n",
      "epoch 2760 loss 0.1087 LR 0.0865 LKL 0.0222\n",
      "epoch 2761 loss 0.1000 LR 0.0780 LKL 0.0220\n",
      "epoch 2762 loss 0.1594 LR 0.1376 LKL 0.0218\n",
      "epoch 2763 loss 0.1014 LR 0.0793 LKL 0.0221\n",
      "epoch 2764 loss 0.1381 LR 0.1162 LKL 0.0219\n",
      "epoch 2765 loss 0.0950 LR 0.0732 LKL 0.0218\n",
      "epoch 2766 loss 0.1346 LR 0.1127 LKL 0.0219\n",
      "epoch 2767 loss 0.1482 LR 0.1264 LKL 0.0218\n",
      "epoch 2768 loss 0.1445 LR 0.1225 LKL 0.0220\n",
      "epoch 2769 loss 0.1206 LR 0.0987 LKL 0.0219\n",
      "epoch 2770 loss 0.1314 LR 0.1094 LKL 0.0221\n",
      "epoch 2771 loss 0.1210 LR 0.0991 LKL 0.0219\n",
      "epoch 2772 loss 0.0592 LR 0.0369 LKL 0.0223\n",
      "epoch 2773 loss 0.1571 LR 0.1349 LKL 0.0222\n",
      "epoch 2774 loss 0.1079 LR 0.0856 LKL 0.0224\n",
      "epoch 2775 loss 0.0883 LR 0.0659 LKL 0.0224\n",
      "epoch 2776 loss 0.1657 LR 0.1433 LKL 0.0224\n",
      "epoch 2777 loss 0.1683 LR 0.1459 LKL 0.0224\n",
      "epoch 2778 loss 0.1850 LR 0.1628 LKL 0.0222\n",
      "epoch 2779 loss 0.1291 LR 0.1065 LKL 0.0225\n",
      "epoch 2780 loss 0.1009 LR 0.0787 LKL 0.0222\n",
      "epoch 2781 loss 0.0775 LR 0.0550 LKL 0.0225\n",
      "epoch 2782 loss 0.1442 LR 0.1219 LKL 0.0223\n",
      "epoch 2783 loss 0.0956 LR 0.0732 LKL 0.0223\n",
      "epoch 2784 loss 0.0808 LR 0.0584 LKL 0.0225\n",
      "epoch 2785 loss 0.1519 LR 0.1294 LKL 0.0225\n",
      "epoch 2786 loss 0.1467 LR 0.1243 LKL 0.0224\n",
      "epoch 2787 loss 0.0989 LR 0.0764 LKL 0.0225\n",
      "epoch 2788 loss 0.1208 LR 0.0983 LKL 0.0225\n",
      "epoch 2789 loss 0.1241 LR 0.1018 LKL 0.0223\n",
      "epoch 2790 loss 0.1591 LR 0.1367 LKL 0.0223\n",
      "epoch 2791 loss 0.0505 LR 0.0278 LKL 0.0226\n",
      "epoch 2792 loss 0.1169 LR 0.0944 LKL 0.0225\n",
      "epoch 2793 loss 0.1485 LR 0.1259 LKL 0.0226\n",
      "epoch 2794 loss 0.1266 LR 0.1039 LKL 0.0227\n",
      "epoch 2795 loss 0.1016 LR 0.0789 LKL 0.0227\n",
      "epoch 2796 loss 0.1268 LR 0.1040 LKL 0.0228\n",
      "epoch 2797 loss 0.0987 LR 0.0758 LKL 0.0229\n",
      "epoch 2798 loss 0.1463 LR 0.1237 LKL 0.0226\n",
      "epoch 2799 loss 0.0972 LR 0.0746 LKL 0.0225\n",
      "epoch 2800 loss 0.1864 LR 0.1636 LKL 0.0228\n",
      "74\n",
      "epoch 2801 loss 0.1543 LR 0.1315 LKL 0.0228\n",
      "epoch 2802 loss 0.1823 LR 0.1598 LKL 0.0226\n",
      "epoch 2803 loss 0.1600 LR 0.1375 LKL 0.0225\n",
      "epoch 2804 loss 0.1112 LR 0.0885 LKL 0.0226\n",
      "epoch 2805 loss 0.1309 LR 0.1084 LKL 0.0225\n",
      "epoch 2806 loss 0.1282 LR 0.1057 LKL 0.0225\n",
      "epoch 2807 loss 0.1228 LR 0.1003 LKL 0.0224\n",
      "epoch 2808 loss 0.1562 LR 0.1338 LKL 0.0225\n",
      "epoch 2809 loss 0.1403 LR 0.1180 LKL 0.0222\n",
      "epoch 2810 loss 0.1025 LR 0.0803 LKL 0.0222\n",
      "epoch 2811 loss 0.1533 LR 0.1311 LKL 0.0222\n",
      "epoch 2812 loss 0.1449 LR 0.1226 LKL 0.0223\n",
      "epoch 2813 loss 0.0973 LR 0.0751 LKL 0.0222\n",
      "epoch 2814 loss 0.0870 LR 0.0646 LKL 0.0225\n",
      "epoch 2815 loss 0.1038 LR 0.0813 LKL 0.0225\n",
      "epoch 2816 loss 0.1358 LR 0.1137 LKL 0.0221\n",
      "epoch 2817 loss 0.1756 LR 0.1534 LKL 0.0222\n",
      "epoch 2818 loss 0.0894 LR 0.0671 LKL 0.0223\n",
      "epoch 2819 loss 0.1436 LR 0.1215 LKL 0.0221\n",
      "epoch 2820 loss 0.1654 LR 0.1433 LKL 0.0221\n",
      "epoch 2821 loss 0.1531 LR 0.1308 LKL 0.0223\n",
      "epoch 2822 loss 0.1464 LR 0.1241 LKL 0.0223\n",
      "epoch 2823 loss 0.1215 LR 0.0990 LKL 0.0225\n",
      "epoch 2824 loss 0.1572 LR 0.1352 LKL 0.0220\n",
      "epoch 2825 loss 0.1539 LR 0.1316 LKL 0.0222\n",
      "epoch 2826 loss 0.1146 LR 0.0923 LKL 0.0223\n",
      "epoch 2827 loss 0.1362 LR 0.1141 LKL 0.0221\n",
      "epoch 2828 loss 0.0814 LR 0.0590 LKL 0.0224\n",
      "epoch 2829 loss 0.1146 LR 0.0922 LKL 0.0224\n",
      "epoch 2830 loss 0.1853 LR 0.1631 LKL 0.0222\n",
      "epoch 2831 loss 0.1163 LR 0.0938 LKL 0.0225\n",
      "epoch 2832 loss 0.1225 LR 0.0999 LKL 0.0226\n",
      "epoch 2833 loss 0.1018 LR 0.0791 LKL 0.0226\n",
      "epoch 2834 loss 0.1546 LR 0.1322 LKL 0.0224\n",
      "epoch 2835 loss 0.1004 LR 0.0777 LKL 0.0227\n",
      "epoch 2836 loss 0.1112 LR 0.0885 LKL 0.0226\n",
      "epoch 2837 loss 0.1418 LR 0.1191 LKL 0.0226\n",
      "epoch 2838 loss 0.1289 LR 0.1061 LKL 0.0228\n",
      "epoch 2839 loss 0.0980 LR 0.0754 LKL 0.0226\n",
      "epoch 2840 loss 0.1204 LR 0.0976 LKL 0.0228\n",
      "epoch 2841 loss 0.1853 LR 0.1625 LKL 0.0228\n",
      "epoch 2842 loss 0.1131 LR 0.0903 LKL 0.0228\n",
      "epoch 2843 loss 0.1292 LR 0.1065 LKL 0.0227\n",
      "epoch 2844 loss 0.0832 LR 0.0604 LKL 0.0228\n",
      "epoch 2845 loss 0.1081 LR 0.0855 LKL 0.0226\n",
      "epoch 2846 loss 0.1018 LR 0.0794 LKL 0.0223\n",
      "epoch 2847 loss 0.1344 LR 0.1120 LKL 0.0224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2848 loss 0.1791 LR 0.1570 LKL 0.0222\n",
      "epoch 2849 loss 0.1076 LR 0.0855 LKL 0.0221\n",
      "epoch 2850 loss 0.1143 LR 0.0921 LKL 0.0222\n",
      "epoch 2851 loss 0.0900 LR 0.0675 LKL 0.0224\n",
      "epoch 2852 loss 0.1053 LR 0.0832 LKL 0.0221\n",
      "epoch 2853 loss 0.1031 LR 0.0808 LKL 0.0223\n",
      "epoch 2854 loss 0.1409 LR 0.1187 LKL 0.0222\n",
      "epoch 2855 loss 0.1327 LR 0.1107 LKL 0.0221\n",
      "epoch 2856 loss 0.1315 LR 0.1093 LKL 0.0222\n",
      "epoch 2857 loss 0.0814 LR 0.0588 LKL 0.0226\n",
      "epoch 2858 loss 0.1186 LR 0.0962 LKL 0.0224\n",
      "epoch 2859 loss 0.1511 LR 0.1286 LKL 0.0226\n",
      "epoch 2860 loss 0.1784 LR 0.1560 LKL 0.0224\n",
      "epoch 2861 loss 0.1542 LR 0.1317 LKL 0.0225\n",
      "epoch 2862 loss 0.1098 LR 0.0871 LKL 0.0227\n",
      "epoch 2863 loss 0.1260 LR 0.1032 LKL 0.0228\n",
      "epoch 2864 loss 0.1476 LR 0.1251 LKL 0.0226\n",
      "epoch 2865 loss 0.0851 LR 0.0625 LKL 0.0226\n",
      "epoch 2866 loss 0.1273 LR 0.1048 LKL 0.0225\n",
      "epoch 2867 loss 0.1101 LR 0.0878 LKL 0.0223\n",
      "epoch 2868 loss 0.1103 LR 0.0879 LKL 0.0224\n",
      "epoch 2869 loss 0.0897 LR 0.0671 LKL 0.0226\n",
      "epoch 2870 loss 0.1598 LR 0.1375 LKL 0.0223\n",
      "epoch 2871 loss 0.1372 LR 0.1148 LKL 0.0223\n",
      "epoch 2872 loss 0.1200 LR 0.0971 LKL 0.0229\n",
      "epoch 2873 loss 0.1187 LR 0.0963 LKL 0.0225\n",
      "epoch 2874 loss 0.1489 LR 0.1264 LKL 0.0225\n",
      "epoch 2875 loss 0.1629 LR 0.1406 LKL 0.0223\n",
      "epoch 2876 loss 0.1128 LR 0.0903 LKL 0.0224\n",
      "epoch 2877 loss 0.1371 LR 0.1147 LKL 0.0224\n",
      "epoch 2878 loss 0.1469 LR 0.1245 LKL 0.0224\n",
      "epoch 2879 loss 0.1216 LR 0.0991 LKL 0.0224\n",
      "epoch 2880 loss 0.1166 LR 0.0943 LKL 0.0223\n",
      "epoch 2881 loss 0.0516 LR 0.0293 LKL 0.0223\n",
      "epoch 2882 loss 0.1519 LR 0.1296 LKL 0.0223\n",
      "epoch 2883 loss 0.1512 LR 0.1293 LKL 0.0219\n",
      "epoch 2884 loss 0.1324 LR 0.1102 LKL 0.0222\n",
      "epoch 2885 loss 0.1227 LR 0.1007 LKL 0.0220\n",
      "epoch 2886 loss 0.0768 LR 0.0547 LKL 0.0221\n",
      "epoch 2887 loss 0.1019 LR 0.0797 LKL 0.0222\n",
      "epoch 2888 loss 0.1043 LR 0.0820 LKL 0.0223\n",
      "epoch 2889 loss 0.0909 LR 0.0683 LKL 0.0226\n",
      "epoch 2890 loss 0.1535 LR 0.1311 LKL 0.0224\n",
      "epoch 2891 loss 0.1309 LR 0.1084 LKL 0.0225\n",
      "epoch 2892 loss 0.0947 LR 0.0719 LKL 0.0228\n",
      "epoch 2893 loss 0.1443 LR 0.1214 LKL 0.0229\n",
      "epoch 2894 loss 0.1319 LR 0.1088 LKL 0.0231\n",
      "epoch 2895 loss 0.1242 LR 0.1009 LKL 0.0233\n",
      "epoch 2896 loss 0.1308 LR 0.1076 LKL 0.0232\n",
      "epoch 2897 loss 0.0934 LR 0.0705 LKL 0.0229\n",
      "epoch 2898 loss 0.0882 LR 0.0652 LKL 0.0231\n",
      "epoch 2899 loss 0.1151 LR 0.0922 LKL 0.0229\n",
      "epoch 2900 loss 0.1585 LR 0.1354 LKL 0.0231\n",
      "53\n",
      "epoch 2901 loss 0.1462 LR 0.1232 LKL 0.0230\n",
      "epoch 2902 loss 0.1307 LR 0.1078 LKL 0.0229\n",
      "epoch 2903 loss 0.1246 LR 0.1018 LKL 0.0228\n",
      "epoch 2904 loss 0.1592 LR 0.1363 LKL 0.0229\n",
      "epoch 2905 loss 0.1437 LR 0.1208 LKL 0.0229\n",
      "epoch 2906 loss 0.1499 LR 0.1274 LKL 0.0225\n",
      "epoch 2907 loss 0.1226 LR 0.0998 LKL 0.0227\n",
      "epoch 2908 loss 0.1038 LR 0.0813 LKL 0.0226\n",
      "epoch 2909 loss 0.0935 LR 0.0709 LKL 0.0226\n",
      "epoch 2910 loss 0.1330 LR 0.1106 LKL 0.0225\n",
      "epoch 2911 loss 0.1442 LR 0.1217 LKL 0.0224\n",
      "epoch 2912 loss 0.1860 LR 0.1638 LKL 0.0222\n",
      "epoch 2913 loss 0.0846 LR 0.0624 LKL 0.0222\n",
      "epoch 2914 loss 0.1313 LR 0.1089 LKL 0.0223\n",
      "epoch 2915 loss 0.1056 LR 0.0832 LKL 0.0224\n",
      "epoch 2916 loss 0.1607 LR 0.1383 LKL 0.0225\n",
      "epoch 2917 loss 0.1422 LR 0.1199 LKL 0.0222\n",
      "epoch 2918 loss 0.1200 LR 0.0976 LKL 0.0224\n",
      "epoch 2919 loss 0.1037 LR 0.0812 LKL 0.0225\n",
      "epoch 2920 loss 0.1259 LR 0.1034 LKL 0.0225\n",
      "epoch 2921 loss 0.0998 LR 0.0771 LKL 0.0227\n",
      "epoch 2922 loss 0.0864 LR 0.0637 LKL 0.0227\n",
      "epoch 2923 loss 0.1473 LR 0.1246 LKL 0.0227\n",
      "epoch 2924 loss 0.1701 LR 0.1477 LKL 0.0224\n",
      "epoch 2925 loss 0.1350 LR 0.1123 LKL 0.0227\n",
      "epoch 2926 loss 0.1163 LR 0.0940 LKL 0.0223\n",
      "epoch 2927 loss 0.1422 LR 0.1195 LKL 0.0227\n",
      "epoch 2928 loss 0.1219 LR 0.0994 LKL 0.0225\n",
      "epoch 2929 loss 0.1138 LR 0.0909 LKL 0.0229\n",
      "epoch 2930 loss 0.0823 LR 0.0597 LKL 0.0227\n",
      "epoch 2931 loss 0.1672 LR 0.1446 LKL 0.0226\n",
      "epoch 2932 loss 0.1198 LR 0.0973 LKL 0.0225\n",
      "epoch 2933 loss 0.0933 LR 0.0708 LKL 0.0226\n",
      "epoch 2934 loss 0.1289 LR 0.1064 LKL 0.0224\n",
      "epoch 2935 loss 0.1471 LR 0.1245 LKL 0.0226\n",
      "epoch 2936 loss 0.0981 LR 0.0755 LKL 0.0226\n",
      "epoch 2937 loss 0.0779 LR 0.0554 LKL 0.0226\n",
      "epoch 2938 loss 0.1298 LR 0.1069 LKL 0.0229\n",
      "epoch 2939 loss 0.1567 LR 0.1341 LKL 0.0226\n",
      "epoch 2940 loss 0.1129 LR 0.0902 LKL 0.0227\n",
      "epoch 2941 loss 0.1137 LR 0.0909 LKL 0.0228\n",
      "epoch 2942 loss 0.1320 LR 0.1093 LKL 0.0227\n",
      "epoch 2943 loss 0.0974 LR 0.0746 LKL 0.0228\n",
      "epoch 2944 loss 0.0799 LR 0.0570 LKL 0.0229\n",
      "epoch 2945 loss 0.1171 LR 0.0942 LKL 0.0229\n",
      "epoch 2946 loss 0.1445 LR 0.1217 LKL 0.0227\n",
      "epoch 2947 loss 0.0676 LR 0.0447 LKL 0.0229\n",
      "epoch 2948 loss 0.1640 LR 0.1413 LKL 0.0227\n",
      "epoch 2949 loss 0.1150 LR 0.0923 LKL 0.0227\n",
      "epoch 2950 loss 0.0989 LR 0.0763 LKL 0.0226\n",
      "epoch 2951 loss 0.1741 LR 0.1517 LKL 0.0225\n",
      "epoch 2952 loss 0.0817 LR 0.0591 LKL 0.0226\n",
      "epoch 2953 loss 0.1407 LR 0.1182 LKL 0.0225\n",
      "epoch 2954 loss 0.0713 LR 0.0486 LKL 0.0227\n",
      "epoch 2955 loss 0.1139 LR 0.0915 LKL 0.0224\n",
      "epoch 2956 loss 0.1015 LR 0.0788 LKL 0.0227\n",
      "epoch 2957 loss 0.1414 LR 0.1190 LKL 0.0224\n",
      "epoch 2958 loss 0.0943 LR 0.0720 LKL 0.0224\n",
      "epoch 2959 loss 0.1085 LR 0.0859 LKL 0.0227\n",
      "epoch 2960 loss 0.0622 LR 0.0395 LKL 0.0227\n",
      "epoch 2961 loss 0.0793 LR 0.0568 LKL 0.0225\n",
      "epoch 2962 loss 0.1449 LR 0.1225 LKL 0.0224\n",
      "epoch 2963 loss 0.1083 LR 0.0859 LKL 0.0225\n",
      "epoch 2964 loss 0.0904 LR 0.0677 LKL 0.0227\n",
      "epoch 2965 loss 0.1683 LR 0.1458 LKL 0.0225\n",
      "epoch 2966 loss 0.0625 LR 0.0397 LKL 0.0228\n",
      "epoch 2967 loss 0.1035 LR 0.0811 LKL 0.0224\n",
      "epoch 2968 loss 0.1252 LR 0.1029 LKL 0.0223\n",
      "epoch 2969 loss 0.0797 LR 0.0573 LKL 0.0224\n",
      "epoch 2970 loss 0.1114 LR 0.0891 LKL 0.0223\n",
      "epoch 2971 loss 0.1722 LR 0.1498 LKL 0.0224\n",
      "epoch 2972 loss 0.1289 LR 0.1065 LKL 0.0223\n",
      "epoch 2973 loss 0.1713 LR 0.1490 LKL 0.0223\n",
      "epoch 2974 loss 0.1393 LR 0.1170 LKL 0.0223\n",
      "epoch 2975 loss 0.1016 LR 0.0794 LKL 0.0222\n",
      "epoch 2976 loss 0.1453 LR 0.1232 LKL 0.0221\n",
      "epoch 2977 loss 0.1309 LR 0.1087 LKL 0.0222\n",
      "epoch 2978 loss 0.1388 LR 0.1168 LKL 0.0220\n",
      "epoch 2979 loss 0.0904 LR 0.0683 LKL 0.0222\n",
      "epoch 2980 loss 0.1000 LR 0.0780 LKL 0.0220\n",
      "epoch 2981 loss 0.1290 LR 0.1069 LKL 0.0221\n",
      "epoch 2982 loss 0.1182 LR 0.0962 LKL 0.0220\n",
      "epoch 2983 loss 0.1179 LR 0.0958 LKL 0.0222\n",
      "epoch 2984 loss 0.1362 LR 0.1138 LKL 0.0224\n",
      "epoch 2985 loss 0.1576 LR 0.1354 LKL 0.0222\n",
      "epoch 2986 loss 0.0988 LR 0.0763 LKL 0.0224\n",
      "epoch 2987 loss 0.1039 LR 0.0817 LKL 0.0222\n",
      "epoch 2988 loss 0.1181 LR 0.0959 LKL 0.0223\n",
      "epoch 2989 loss 0.0450 LR 0.0226 LKL 0.0224\n",
      "epoch 2990 loss 0.0873 LR 0.0650 LKL 0.0223\n",
      "epoch 2991 loss 0.1211 LR 0.0989 LKL 0.0222\n",
      "epoch 2992 loss 0.0890 LR 0.0667 LKL 0.0223\n",
      "epoch 2993 loss 0.1251 LR 0.1027 LKL 0.0224\n",
      "epoch 2994 loss 0.0839 LR 0.0616 LKL 0.0224\n",
      "epoch 2995 loss 0.1493 LR 0.1269 LKL 0.0224\n",
      "epoch 2996 loss 0.1166 LR 0.0941 LKL 0.0225\n",
      "epoch 2997 loss 0.1263 LR 0.1036 LKL 0.0226\n",
      "epoch 2998 loss 0.0568 LR 0.0340 LKL 0.0228\n",
      "epoch 2999 loss 0.1121 LR 0.0893 LKL 0.0228\n",
      "epoch 3000 loss 0.1336 LR 0.1110 LKL 0.0226\n",
      "63\n",
      "epoch 3001 loss 0.1138 LR 0.0908 LKL 0.0230\n",
      "epoch 3002 loss 0.1460 LR 0.1235 LKL 0.0225\n",
      "epoch 3003 loss 0.1014 LR 0.0789 LKL 0.0225\n",
      "epoch 3004 loss 0.1511 LR 0.1287 LKL 0.0224\n",
      "epoch 3005 loss 0.1775 LR 0.1550 LKL 0.0225\n",
      "epoch 3006 loss 0.1046 LR 0.0821 LKL 0.0224\n",
      "epoch 3007 loss 0.1125 LR 0.0902 LKL 0.0222\n",
      "epoch 3008 loss 0.1328 LR 0.1109 LKL 0.0220\n",
      "epoch 3009 loss 0.0771 LR 0.0549 LKL 0.0222\n",
      "epoch 3010 loss 0.1192 LR 0.0971 LKL 0.0221\n",
      "epoch 3011 loss 0.0875 LR 0.0653 LKL 0.0222\n",
      "epoch 3012 loss 0.1164 LR 0.0944 LKL 0.0220\n",
      "epoch 3013 loss 0.1176 LR 0.0953 LKL 0.0223\n",
      "epoch 3014 loss 0.1055 LR 0.0831 LKL 0.0224\n",
      "epoch 3015 loss 0.1330 LR 0.1106 LKL 0.0224\n",
      "epoch 3016 loss 0.1187 LR 0.0963 LKL 0.0224\n",
      "epoch 3017 loss 0.0625 LR 0.0398 LKL 0.0227\n",
      "epoch 3018 loss 0.1093 LR 0.0867 LKL 0.0226\n",
      "epoch 3019 loss 0.1051 LR 0.0825 LKL 0.0225\n",
      "epoch 3020 loss 0.1216 LR 0.0989 LKL 0.0227\n",
      "epoch 3021 loss 0.1086 LR 0.0860 LKL 0.0226\n",
      "epoch 3022 loss 0.1218 LR 0.0993 LKL 0.0225\n",
      "epoch 3023 loss 0.0750 LR 0.0521 LKL 0.0229\n",
      "epoch 3024 loss 0.1163 LR 0.0936 LKL 0.0227\n",
      "epoch 3025 loss 0.1116 LR 0.0889 LKL 0.0226\n",
      "epoch 3026 loss 0.1698 LR 0.1471 LKL 0.0226\n",
      "epoch 3027 loss 0.0882 LR 0.0654 LKL 0.0228\n",
      "epoch 3028 loss 0.1412 LR 0.1184 LKL 0.0228\n",
      "epoch 3029 loss 0.0934 LR 0.0702 LKL 0.0232\n",
      "epoch 3030 loss 0.1012 LR 0.0782 LKL 0.0230\n",
      "epoch 3031 loss 0.1441 LR 0.1215 LKL 0.0226\n",
      "epoch 3032 loss 0.0632 LR 0.0401 LKL 0.0231\n",
      "epoch 3033 loss 0.1987 LR 0.1757 LKL 0.0230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3034 loss 0.1428 LR 0.1200 LKL 0.0228\n",
      "epoch 3035 loss 0.1291 LR 0.1060 LKL 0.0231\n",
      "epoch 3036 loss 0.1065 LR 0.0835 LKL 0.0230\n",
      "epoch 3037 loss 0.0258 LR 0.0026 LKL 0.0232\n",
      "epoch 3038 loss 0.1478 LR 0.1246 LKL 0.0232\n",
      "epoch 3039 loss 0.1039 LR 0.0806 LKL 0.0233\n",
      "epoch 3040 loss 0.1209 LR 0.0983 LKL 0.0227\n",
      "epoch 3041 loss 0.1015 LR 0.0786 LKL 0.0230\n",
      "epoch 3042 loss 0.1353 LR 0.1125 LKL 0.0228\n",
      "epoch 3043 loss 0.1190 LR 0.0961 LKL 0.0230\n",
      "epoch 3044 loss 0.1174 LR 0.0946 LKL 0.0228\n",
      "epoch 3045 loss 0.0792 LR 0.0565 LKL 0.0227\n",
      "epoch 3046 loss 0.1096 LR 0.0868 LKL 0.0228\n",
      "epoch 3047 loss 0.1383 LR 0.1158 LKL 0.0225\n",
      "epoch 3048 loss 0.0984 LR 0.0757 LKL 0.0227\n",
      "epoch 3049 loss 0.1524 LR 0.1296 LKL 0.0228\n",
      "epoch 3050 loss 0.1203 LR 0.0977 LKL 0.0226\n",
      "epoch 3051 loss 0.0906 LR 0.0678 LKL 0.0228\n",
      "epoch 3052 loss 0.1000 LR 0.0777 LKL 0.0223\n",
      "epoch 3053 loss 0.0886 LR 0.0663 LKL 0.0224\n",
      "epoch 3054 loss 0.1520 LR 0.1296 LKL 0.0224\n",
      "epoch 3055 loss 0.1655 LR 0.1434 LKL 0.0220\n",
      "epoch 3056 loss 0.0887 LR 0.0666 LKL 0.0221\n",
      "epoch 3057 loss 0.1098 LR 0.0878 LKL 0.0221\n",
      "epoch 3058 loss 0.0651 LR 0.0427 LKL 0.0225\n",
      "epoch 3059 loss 0.0493 LR 0.0269 LKL 0.0224\n",
      "epoch 3060 loss 0.0732 LR 0.0507 LKL 0.0224\n",
      "epoch 3061 loss 0.0986 LR 0.0763 LKL 0.0223\n",
      "epoch 3062 loss 0.1052 LR 0.0826 LKL 0.0225\n",
      "epoch 3063 loss 0.1130 LR 0.0906 LKL 0.0224\n",
      "epoch 3064 loss 0.0744 LR 0.0518 LKL 0.0226\n",
      "epoch 3065 loss 0.0809 LR 0.0582 LKL 0.0227\n",
      "epoch 3066 loss 0.1105 LR 0.0880 LKL 0.0226\n",
      "epoch 3067 loss 0.0644 LR 0.0415 LKL 0.0230\n",
      "epoch 3068 loss 0.1773 LR 0.1545 LKL 0.0228\n",
      "epoch 3069 loss 0.1456 LR 0.1230 LKL 0.0226\n",
      "epoch 3070 loss 0.0628 LR 0.0399 LKL 0.0228\n",
      "epoch 3071 loss 0.0645 LR 0.0414 LKL 0.0231\n",
      "epoch 3072 loss 0.1477 LR 0.1251 LKL 0.0226\n",
      "epoch 3073 loss 0.0732 LR 0.0503 LKL 0.0228\n",
      "epoch 3074 loss 0.1004 LR 0.0778 LKL 0.0227\n",
      "epoch 3075 loss 0.1221 LR 0.0993 LKL 0.0227\n",
      "epoch 3076 loss 0.1212 LR 0.0987 LKL 0.0226\n",
      "epoch 3077 loss 0.1351 LR 0.1127 LKL 0.0223\n",
      "epoch 3078 loss 0.0798 LR 0.0573 LKL 0.0226\n",
      "epoch 3079 loss 0.1282 LR 0.1057 LKL 0.0225\n",
      "epoch 3080 loss 0.1784 LR 0.1558 LKL 0.0226\n",
      "epoch 3081 loss 0.0796 LR 0.0571 LKL 0.0225\n",
      "epoch 3082 loss 0.0429 LR 0.0200 LKL 0.0230\n",
      "epoch 3083 loss 0.1579 LR 0.1350 LKL 0.0229\n",
      "epoch 3084 loss 0.1157 LR 0.0930 LKL 0.0227\n",
      "epoch 3085 loss 0.1255 LR 0.1028 LKL 0.0227\n",
      "epoch 3086 loss 0.0935 LR 0.0707 LKL 0.0228\n",
      "epoch 3087 loss 0.1085 LR 0.0856 LKL 0.0229\n",
      "epoch 3088 loss 0.1302 LR 0.1075 LKL 0.0227\n",
      "epoch 3089 loss 0.1311 LR 0.1085 LKL 0.0227\n",
      "epoch 3090 loss 0.1572 LR 0.1345 LKL 0.0227\n",
      "epoch 3091 loss 0.0788 LR 0.0560 LKL 0.0228\n",
      "epoch 3092 loss 0.0821 LR 0.0596 LKL 0.0225\n",
      "epoch 3093 loss 0.0963 LR 0.0734 LKL 0.0229\n",
      "epoch 3094 loss 0.1135 LR 0.0907 LKL 0.0228\n",
      "epoch 3095 loss 0.1619 LR 0.1392 LKL 0.0227\n",
      "epoch 3096 loss 0.1318 LR 0.1091 LKL 0.0228\n",
      "epoch 3097 loss 0.0655 LR 0.0426 LKL 0.0228\n",
      "epoch 3098 loss 0.0906 LR 0.0678 LKL 0.0228\n",
      "epoch 3099 loss 0.0790 LR 0.0559 LKL 0.0231\n",
      "epoch 3100 loss 0.1075 LR 0.0847 LKL 0.0228\n",
      "121\n",
      "epoch 3101 loss 0.1065 LR 0.0834 LKL 0.0231\n",
      "epoch 3102 loss 0.1311 LR 0.1079 LKL 0.0232\n",
      "epoch 3103 loss 0.1506 LR 0.1274 LKL 0.0231\n",
      "epoch 3104 loss 0.1423 LR 0.1192 LKL 0.0230\n",
      "epoch 3105 loss 0.1202 LR 0.0975 LKL 0.0227\n",
      "epoch 3106 loss 0.1221 LR 0.0993 LKL 0.0228\n",
      "epoch 3107 loss 0.1343 LR 0.1116 LKL 0.0227\n",
      "epoch 3108 loss 0.0660 LR 0.0434 LKL 0.0225\n",
      "epoch 3109 loss 0.1220 LR 0.0996 LKL 0.0224\n",
      "epoch 3110 loss 0.1234 LR 0.1010 LKL 0.0225\n",
      "epoch 3111 loss 0.0977 LR 0.0755 LKL 0.0222\n",
      "epoch 3112 loss 0.1191 LR 0.0970 LKL 0.0221\n",
      "epoch 3113 loss 0.1114 LR 0.0891 LKL 0.0223\n",
      "epoch 3114 loss 0.1533 LR 0.1313 LKL 0.0220\n",
      "epoch 3115 loss 0.0973 LR 0.0749 LKL 0.0224\n",
      "epoch 3116 loss 0.1563 LR 0.1344 LKL 0.0220\n",
      "epoch 3117 loss 0.1394 LR 0.1173 LKL 0.0222\n",
      "epoch 3118 loss 0.0778 LR 0.0559 LKL 0.0219\n",
      "epoch 3119 loss 0.0535 LR 0.0315 LKL 0.0221\n",
      "epoch 3120 loss 0.0790 LR 0.0569 LKL 0.0221\n",
      "epoch 3121 loss 0.1188 LR 0.0970 LKL 0.0218\n",
      "epoch 3122 loss 0.0670 LR 0.0449 LKL 0.0221\n",
      "epoch 3123 loss 0.1565 LR 0.1348 LKL 0.0217\n",
      "epoch 3124 loss 0.1574 LR 0.1357 LKL 0.0217\n",
      "epoch 3125 loss 0.0797 LR 0.0575 LKL 0.0221\n",
      "epoch 3126 loss 0.1304 LR 0.1084 LKL 0.0219\n",
      "epoch 3127 loss 0.1140 LR 0.0918 LKL 0.0222\n",
      "epoch 3128 loss 0.0834 LR 0.0611 LKL 0.0222\n",
      "epoch 3129 loss 0.1233 LR 0.1010 LKL 0.0223\n",
      "epoch 3130 loss 0.1101 LR 0.0875 LKL 0.0226\n",
      "epoch 3131 loss 0.1630 LR 0.1403 LKL 0.0228\n",
      "epoch 3132 loss 0.0736 LR 0.0506 LKL 0.0230\n",
      "epoch 3133 loss 0.0953 LR 0.0723 LKL 0.0230\n",
      "epoch 3134 loss 0.1574 LR 0.1343 LKL 0.0231\n",
      "epoch 3135 loss 0.0639 LR 0.0406 LKL 0.0233\n",
      "epoch 3136 loss 0.1392 LR 0.1158 LKL 0.0234\n",
      "epoch 3137 loss 0.0790 LR 0.0556 LKL 0.0234\n",
      "epoch 3138 loss 0.1004 LR 0.0771 LKL 0.0233\n",
      "epoch 3139 loss 0.1223 LR 0.0990 LKL 0.0233\n",
      "epoch 3140 loss 0.1564 LR 0.1331 LKL 0.0233\n",
      "epoch 3141 loss 0.0515 LR 0.0283 LKL 0.0232\n",
      "epoch 3142 loss 0.1574 LR 0.1345 LKL 0.0229\n",
      "epoch 3143 loss 0.1273 LR 0.1044 LKL 0.0229\n",
      "epoch 3144 loss 0.0804 LR 0.0578 LKL 0.0226\n",
      "epoch 3145 loss 0.1026 LR 0.0800 LKL 0.0226\n",
      "epoch 3146 loss 0.1273 LR 0.1049 LKL 0.0224\n",
      "epoch 3147 loss 0.0924 LR 0.0698 LKL 0.0225\n",
      "epoch 3148 loss 0.1182 LR 0.0958 LKL 0.0224\n",
      "epoch 3149 loss 0.0877 LR 0.0654 LKL 0.0223\n",
      "epoch 3150 loss 0.0594 LR 0.0371 LKL 0.0223\n",
      "epoch 3151 loss 0.1503 LR 0.1282 LKL 0.0221\n",
      "epoch 3152 loss 0.1261 LR 0.1038 LKL 0.0223\n",
      "epoch 3153 loss 0.0379 LR 0.0156 LKL 0.0223\n",
      "epoch 3154 loss 0.1326 LR 0.1106 LKL 0.0219\n",
      "epoch 3155 loss 0.1361 LR 0.1138 LKL 0.0222\n",
      "epoch 3156 loss 0.1139 LR 0.0919 LKL 0.0220\n",
      "epoch 3157 loss 0.1319 LR 0.1097 LKL 0.0222\n",
      "epoch 3158 loss 0.0679 LR 0.0458 LKL 0.0221\n",
      "epoch 3159 loss 0.1830 LR 0.1608 LKL 0.0222\n",
      "epoch 3160 loss 0.1195 LR 0.0974 LKL 0.0221\n",
      "epoch 3161 loss 0.1385 LR 0.1164 LKL 0.0221\n",
      "epoch 3162 loss 0.1482 LR 0.1259 LKL 0.0223\n",
      "epoch 3163 loss 0.1499 LR 0.1274 LKL 0.0225\n",
      "epoch 3164 loss 0.0955 LR 0.0730 LKL 0.0225\n",
      "epoch 3165 loss 0.1438 LR 0.1213 LKL 0.0225\n",
      "epoch 3166 loss 0.1175 LR 0.0949 LKL 0.0226\n",
      "epoch 3167 loss 0.1231 LR 0.1005 LKL 0.0226\n",
      "epoch 3168 loss 0.0394 LR 0.0168 LKL 0.0226\n",
      "epoch 3169 loss 0.1290 LR 0.1064 LKL 0.0227\n",
      "epoch 3170 loss 0.0955 LR 0.0731 LKL 0.0225\n",
      "epoch 3171 loss 0.1117 LR 0.0892 LKL 0.0225\n",
      "epoch 3172 loss 0.1026 LR 0.0798 LKL 0.0228\n",
      "epoch 3173 loss 0.1133 LR 0.0905 LKL 0.0227\n",
      "epoch 3174 loss 0.0717 LR 0.0490 LKL 0.0228\n",
      "epoch 3175 loss 0.1170 LR 0.0943 LKL 0.0227\n",
      "epoch 3176 loss 0.1132 LR 0.0903 LKL 0.0230\n",
      "epoch 3177 loss 0.1422 LR 0.1194 LKL 0.0229\n",
      "epoch 3178 loss 0.1015 LR 0.0787 LKL 0.0228\n",
      "epoch 3179 loss 0.1333 LR 0.1105 LKL 0.0228\n",
      "epoch 3180 loss 0.0505 LR 0.0275 LKL 0.0230\n",
      "epoch 3181 loss 0.1359 LR 0.1129 LKL 0.0230\n",
      "epoch 3182 loss 0.1290 LR 0.1060 LKL 0.0230\n",
      "epoch 3183 loss 0.0761 LR 0.0531 LKL 0.0230\n",
      "epoch 3184 loss 0.1631 LR 0.1402 LKL 0.0230\n",
      "epoch 3185 loss 0.0893 LR 0.0661 LKL 0.0232\n",
      "epoch 3186 loss 0.0777 LR 0.0546 LKL 0.0231\n",
      "epoch 3187 loss 0.1116 LR 0.0887 LKL 0.0230\n",
      "epoch 3188 loss 0.1629 LR 0.1401 LKL 0.0228\n",
      "epoch 3189 loss 0.0664 LR 0.0435 LKL 0.0229\n",
      "epoch 3190 loss 0.0856 LR 0.0627 LKL 0.0229\n",
      "epoch 3191 loss 0.0997 LR 0.0770 LKL 0.0227\n",
      "epoch 3192 loss 0.1045 LR 0.0819 LKL 0.0226\n",
      "epoch 3193 loss 0.1052 LR 0.0827 LKL 0.0226\n",
      "epoch 3194 loss 0.1042 LR 0.0816 LKL 0.0226\n",
      "epoch 3195 loss 0.1531 LR 0.1302 LKL 0.0229\n",
      "epoch 3196 loss 0.1391 LR 0.1164 LKL 0.0227\n",
      "epoch 3197 loss 0.1643 LR 0.1414 LKL 0.0228\n",
      "epoch 3198 loss 0.0700 LR 0.0471 LKL 0.0229\n",
      "epoch 3199 loss 0.1216 LR 0.0986 LKL 0.0230\n",
      "epoch 3200 loss 0.0882 LR 0.0650 LKL 0.0232\n",
      "64\n",
      "epoch 3201 loss 0.1032 LR 0.0799 LKL 0.0233\n",
      "epoch 3202 loss 0.1434 LR 0.1200 LKL 0.0233\n",
      "epoch 3203 loss 0.1327 LR 0.1096 LKL 0.0231\n",
      "epoch 3204 loss 0.1446 LR 0.1217 LKL 0.0229\n",
      "epoch 3205 loss 0.1039 LR 0.0810 LKL 0.0230\n",
      "epoch 3206 loss 0.0925 LR 0.0696 LKL 0.0229\n",
      "epoch 3207 loss 0.0968 LR 0.0735 LKL 0.0233\n",
      "epoch 3208 loss 0.1173 LR 0.0942 LKL 0.0231\n",
      "epoch 3209 loss 0.1090 LR 0.0857 LKL 0.0233\n",
      "epoch 3210 loss 0.0743 LR 0.0515 LKL 0.0228\n",
      "epoch 3211 loss 0.1118 LR 0.0889 LKL 0.0229\n",
      "epoch 3212 loss 0.1189 LR 0.0959 LKL 0.0230\n",
      "epoch 3213 loss 0.1390 LR 0.1160 LKL 0.0230\n",
      "epoch 3214 loss 0.1216 LR 0.0987 LKL 0.0229\n",
      "epoch 3215 loss 0.1314 LR 0.1089 LKL 0.0225\n",
      "epoch 3216 loss 0.1456 LR 0.1231 LKL 0.0226\n",
      "epoch 3217 loss 0.0763 LR 0.0538 LKL 0.0225\n",
      "epoch 3218 loss 0.0750 LR 0.0527 LKL 0.0223\n",
      "epoch 3219 loss 0.1095 LR 0.0870 LKL 0.0224\n",
      "epoch 3220 loss 0.0844 LR 0.0620 LKL 0.0224\n",
      "epoch 3221 loss 0.0878 LR 0.0654 LKL 0.0224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3222 loss 0.0819 LR 0.0594 LKL 0.0226\n",
      "epoch 3223 loss 0.0651 LR 0.0425 LKL 0.0227\n",
      "epoch 3224 loss 0.1169 LR 0.0944 LKL 0.0226\n",
      "epoch 3225 loss 0.1035 LR 0.0809 LKL 0.0227\n",
      "epoch 3226 loss 0.1730 LR 0.1504 LKL 0.0226\n",
      "epoch 3227 loss 0.1025 LR 0.0799 LKL 0.0226\n",
      "epoch 3228 loss 0.0805 LR 0.0579 LKL 0.0226\n",
      "epoch 3229 loss 0.1375 LR 0.1148 LKL 0.0227\n",
      "epoch 3230 loss 0.1114 LR 0.0886 LKL 0.0228\n",
      "epoch 3231 loss 0.1178 LR 0.0949 LKL 0.0230\n",
      "epoch 3232 loss 0.0737 LR 0.0505 LKL 0.0231\n",
      "epoch 3233 loss 0.0831 LR 0.0600 LKL 0.0231\n",
      "epoch 3234 loss 0.1315 LR 0.1086 LKL 0.0229\n",
      "epoch 3235 loss 0.1208 LR 0.0980 LKL 0.0228\n",
      "epoch 3236 loss 0.1795 LR 0.1568 LKL 0.0227\n",
      "epoch 3237 loss 0.1853 LR 0.1624 LKL 0.0229\n",
      "epoch 3238 loss 0.1204 LR 0.0976 LKL 0.0227\n",
      "epoch 3239 loss 0.1046 LR 0.0817 LKL 0.0228\n",
      "epoch 3240 loss 0.1201 LR 0.0972 LKL 0.0228\n",
      "epoch 3241 loss 0.0924 LR 0.0692 LKL 0.0232\n",
      "epoch 3242 loss 0.1163 LR 0.0936 LKL 0.0227\n",
      "epoch 3243 loss 0.1385 LR 0.1153 LKL 0.0232\n",
      "epoch 3244 loss 0.1270 LR 0.1042 LKL 0.0228\n",
      "epoch 3245 loss 0.0967 LR 0.0741 LKL 0.0226\n",
      "epoch 3246 loss 0.1280 LR 0.1052 LKL 0.0228\n",
      "epoch 3247 loss 0.1258 LR 0.1031 LKL 0.0227\n",
      "epoch 3248 loss 0.1063 LR 0.0836 LKL 0.0227\n",
      "epoch 3249 loss 0.1082 LR 0.0857 LKL 0.0225\n",
      "epoch 3250 loss 0.1163 LR 0.0937 LKL 0.0226\n",
      "epoch 3251 loss 0.1081 LR 0.0855 LKL 0.0226\n",
      "epoch 3252 loss 0.0941 LR 0.0717 LKL 0.0223\n",
      "epoch 3253 loss 0.0857 LR 0.0634 LKL 0.0223\n",
      "epoch 3254 loss 0.1018 LR 0.0793 LKL 0.0225\n",
      "epoch 3255 loss 0.1007 LR 0.0782 LKL 0.0226\n",
      "epoch 3256 loss 0.1049 LR 0.0824 LKL 0.0225\n",
      "epoch 3257 loss 0.1482 LR 0.1257 LKL 0.0225\n",
      "epoch 3258 loss 0.0774 LR 0.0548 LKL 0.0226\n",
      "epoch 3259 loss 0.0579 LR 0.0354 LKL 0.0225\n",
      "epoch 3260 loss 0.0965 LR 0.0740 LKL 0.0225\n",
      "epoch 3261 loss 0.0733 LR 0.0509 LKL 0.0224\n",
      "epoch 3262 loss 0.1529 LR 0.1306 LKL 0.0222\n",
      "epoch 3263 loss 0.1101 LR 0.0875 LKL 0.0226\n",
      "epoch 3264 loss 0.0607 LR 0.0380 LKL 0.0227\n",
      "epoch 3265 loss 0.0498 LR 0.0271 LKL 0.0227\n",
      "epoch 3266 loss 0.0660 LR 0.0429 LKL 0.0231\n",
      "epoch 3267 loss 0.0798 LR 0.0569 LKL 0.0229\n",
      "epoch 3268 loss 0.0968 LR 0.0739 LKL 0.0230\n",
      "epoch 3269 loss 0.0567 LR 0.0339 LKL 0.0228\n",
      "epoch 3270 loss 0.0647 LR 0.0420 LKL 0.0228\n",
      "epoch 3271 loss 0.0684 LR 0.0458 LKL 0.0227\n",
      "epoch 3272 loss 0.1286 LR 0.1060 LKL 0.0226\n",
      "epoch 3273 loss 0.1316 LR 0.1092 LKL 0.0224\n",
      "epoch 3274 loss 0.1093 LR 0.0870 LKL 0.0223\n",
      "epoch 3275 loss 0.1135 LR 0.0911 LKL 0.0224\n",
      "epoch 3276 loss 0.1131 LR 0.0907 LKL 0.0225\n",
      "epoch 3277 loss 0.1458 LR 0.1233 LKL 0.0225\n",
      "epoch 3278 loss 0.1214 LR 0.0988 LKL 0.0226\n",
      "epoch 3279 loss 0.0908 LR 0.0683 LKL 0.0225\n",
      "epoch 3280 loss 0.1108 LR 0.0883 LKL 0.0225\n",
      "epoch 3281 loss 0.1259 LR 0.1034 LKL 0.0225\n",
      "epoch 3282 loss 0.1050 LR 0.0828 LKL 0.0221\n",
      "epoch 3283 loss 0.1264 LR 0.1043 LKL 0.0221\n",
      "epoch 3284 loss 0.0339 LR 0.0112 LKL 0.0227\n",
      "epoch 3285 loss 0.0543 LR 0.0317 LKL 0.0226\n",
      "epoch 3286 loss 0.1058 LR 0.0831 LKL 0.0227\n",
      "epoch 3287 loss 0.1168 LR 0.0942 LKL 0.0227\n",
      "epoch 3288 loss 0.1073 LR 0.0846 LKL 0.0228\n",
      "epoch 3289 loss 0.1427 LR 0.1199 LKL 0.0228\n",
      "epoch 3290 loss 0.0948 LR 0.0719 LKL 0.0229\n",
      "epoch 3291 loss 0.0864 LR 0.0634 LKL 0.0230\n",
      "epoch 3292 loss 0.0776 LR 0.0548 LKL 0.0229\n",
      "epoch 3293 loss 0.1410 LR 0.1182 LKL 0.0228\n",
      "epoch 3294 loss 0.0979 LR 0.0750 LKL 0.0229\n",
      "epoch 3295 loss 0.0454 LR 0.0227 LKL 0.0227\n",
      "epoch 3296 loss 0.1762 LR 0.1532 LKL 0.0230\n",
      "epoch 3297 loss 0.1198 LR 0.0972 LKL 0.0226\n",
      "epoch 3298 loss 0.1637 LR 0.1410 LKL 0.0227\n",
      "epoch 3299 loss 0.1245 LR 0.1020 LKL 0.0225\n",
      "epoch 3300 loss 0.1420 LR 0.1188 LKL 0.0231\n",
      "74\n",
      "epoch 3301 loss 0.0352 LR 0.0123 LKL 0.0229\n",
      "epoch 3302 loss 0.0908 LR 0.0681 LKL 0.0227\n",
      "epoch 3303 loss 0.0883 LR 0.0656 LKL 0.0226\n",
      "epoch 3304 loss 0.1072 LR 0.0844 LKL 0.0227\n",
      "epoch 3305 loss 0.1475 LR 0.1248 LKL 0.0227\n",
      "epoch 3306 loss 0.0852 LR 0.0624 LKL 0.0228\n",
      "epoch 3307 loss 0.0639 LR 0.0409 LKL 0.0230\n",
      "epoch 3308 loss 0.1293 LR 0.1060 LKL 0.0232\n",
      "epoch 3309 loss 0.0670 LR 0.0438 LKL 0.0232\n",
      "epoch 3310 loss 0.0004 LR -0.0228 LKL 0.0233\n",
      "epoch 3311 loss 0.1311 LR 0.1081 LKL 0.0230\n",
      "epoch 3312 loss 0.0625 LR 0.0393 LKL 0.0232\n",
      "epoch 3313 loss 0.0446 LR 0.0215 LKL 0.0231\n",
      "epoch 3314 loss 0.1116 LR 0.0886 LKL 0.0230\n",
      "epoch 3315 loss 0.0519 LR 0.0286 LKL 0.0232\n",
      "epoch 3316 loss 0.0934 LR 0.0705 LKL 0.0229\n",
      "epoch 3317 loss 0.0694 LR 0.0464 LKL 0.0229\n",
      "epoch 3318 loss 0.2210 LR 0.1982 LKL 0.0227\n",
      "epoch 3319 loss 0.1016 LR 0.0788 LKL 0.0228\n",
      "epoch 3320 loss 0.0719 LR 0.0488 LKL 0.0232\n",
      "epoch 3321 loss 0.0620 LR 0.0390 LKL 0.0230\n",
      "epoch 3322 loss 0.1823 LR 0.1595 LKL 0.0227\n",
      "epoch 3323 loss 0.1406 LR 0.1175 LKL 0.0231\n",
      "epoch 3324 loss 0.0699 LR 0.0467 LKL 0.0231\n",
      "epoch 3325 loss 0.1069 LR 0.0841 LKL 0.0228\n",
      "epoch 3326 loss 0.0790 LR 0.0561 LKL 0.0229\n",
      "epoch 3327 loss 0.0892 LR 0.0662 LKL 0.0230\n",
      "epoch 3328 loss 0.1040 LR 0.0809 LKL 0.0231\n",
      "epoch 3329 loss 0.1233 LR 0.1003 LKL 0.0230\n",
      "epoch 3330 loss 0.1066 LR 0.0839 LKL 0.0226\n",
      "epoch 3331 loss 0.0946 LR 0.0715 LKL 0.0230\n",
      "epoch 3332 loss 0.0719 LR 0.0492 LKL 0.0227\n",
      "epoch 3333 loss 0.0686 LR 0.0456 LKL 0.0230\n",
      "epoch 3334 loss 0.0716 LR 0.0489 LKL 0.0227\n",
      "epoch 3335 loss 0.0902 LR 0.0674 LKL 0.0227\n",
      "epoch 3336 loss 0.1205 LR 0.0980 LKL 0.0225\n",
      "epoch 3337 loss 0.1230 LR 0.1003 LKL 0.0227\n",
      "epoch 3338 loss 0.0589 LR 0.0365 LKL 0.0223\n",
      "epoch 3339 loss 0.1177 LR 0.0953 LKL 0.0224\n",
      "epoch 3340 loss 0.1216 LR 0.0992 LKL 0.0224\n",
      "epoch 3341 loss 0.0810 LR 0.0582 LKL 0.0228\n",
      "epoch 3342 loss 0.1524 LR 0.1300 LKL 0.0223\n",
      "epoch 3343 loss 0.1016 LR 0.0791 LKL 0.0225\n",
      "epoch 3344 loss 0.1617 LR 0.1391 LKL 0.0225\n",
      "epoch 3345 loss 0.1137 LR 0.0912 LKL 0.0225\n",
      "epoch 3346 loss 0.1129 LR 0.0904 LKL 0.0225\n",
      "epoch 3347 loss 0.1190 LR 0.0966 LKL 0.0225\n",
      "epoch 3348 loss 0.1243 LR 0.1020 LKL 0.0223\n",
      "epoch 3349 loss 0.1128 LR 0.0905 LKL 0.0224\n",
      "epoch 3350 loss 0.0825 LR 0.0598 LKL 0.0227\n",
      "epoch 3351 loss 0.0911 LR 0.0686 LKL 0.0225\n",
      "epoch 3352 loss 0.0994 LR 0.0770 LKL 0.0224\n",
      "epoch 3353 loss 0.0748 LR 0.0524 LKL 0.0225\n",
      "epoch 3354 loss 0.1243 LR 0.1019 LKL 0.0224\n",
      "epoch 3355 loss 0.0703 LR 0.0477 LKL 0.0226\n",
      "epoch 3356 loss 0.1092 LR 0.0866 LKL 0.0226\n",
      "epoch 3357 loss 0.1132 LR 0.0906 LKL 0.0225\n",
      "epoch 3358 loss 0.0883 LR 0.0658 LKL 0.0224\n",
      "epoch 3359 loss 0.0760 LR 0.0535 LKL 0.0224\n",
      "epoch 3360 loss 0.1211 LR 0.0985 LKL 0.0225\n",
      "epoch 3361 loss 0.1240 LR 0.1014 LKL 0.0226\n",
      "epoch 3362 loss 0.1626 LR 0.1396 LKL 0.0230\n",
      "epoch 3363 loss 0.1046 LR 0.0816 LKL 0.0230\n",
      "epoch 3364 loss 0.1432 LR 0.1202 LKL 0.0230\n",
      "epoch 3365 loss 0.0631 LR 0.0402 LKL 0.0229\n",
      "epoch 3366 loss 0.1208 LR 0.0980 LKL 0.0228\n",
      "epoch 3367 loss 0.1151 LR 0.0922 LKL 0.0229\n",
      "epoch 3368 loss 0.0728 LR 0.0499 LKL 0.0228\n",
      "epoch 3369 loss 0.1128 LR 0.0898 LKL 0.0231\n",
      "epoch 3370 loss 0.1231 LR 0.0999 LKL 0.0232\n",
      "epoch 3371 loss 0.1504 LR 0.1274 LKL 0.0230\n",
      "epoch 3372 loss 0.0861 LR 0.0632 LKL 0.0229\n",
      "epoch 3373 loss 0.1079 LR 0.0851 LKL 0.0228\n",
      "epoch 3374 loss 0.0876 LR 0.0649 LKL 0.0227\n",
      "epoch 3375 loss 0.0588 LR 0.0363 LKL 0.0225\n",
      "epoch 3376 loss 0.0428 LR 0.0204 LKL 0.0224\n",
      "epoch 3377 loss 0.0730 LR 0.0507 LKL 0.0223\n",
      "epoch 3378 loss 0.1272 LR 0.1050 LKL 0.0223\n",
      "epoch 3379 loss 0.0675 LR 0.0451 LKL 0.0225\n",
      "epoch 3380 loss 0.0823 LR 0.0599 LKL 0.0224\n",
      "epoch 3381 loss 0.0686 LR 0.0461 LKL 0.0225\n",
      "epoch 3382 loss 0.0829 LR 0.0604 LKL 0.0226\n",
      "epoch 3383 loss 0.1008 LR 0.0781 LKL 0.0227\n",
      "epoch 3384 loss 0.1429 LR 0.1203 LKL 0.0226\n",
      "epoch 3385 loss 0.0705 LR 0.0477 LKL 0.0228\n",
      "epoch 3386 loss 0.0821 LR 0.0596 LKL 0.0226\n",
      "epoch 3387 loss 0.0799 LR 0.0571 LKL 0.0227\n",
      "epoch 3388 loss 0.0890 LR 0.0661 LKL 0.0229\n",
      "epoch 3389 loss 0.0782 LR 0.0552 LKL 0.0230\n",
      "epoch 3390 loss 0.0922 LR 0.0691 LKL 0.0231\n",
      "epoch 3391 loss 0.1244 LR 0.1012 LKL 0.0232\n",
      "epoch 3392 loss 0.0970 LR 0.0738 LKL 0.0232\n",
      "epoch 3393 loss 0.0350 LR 0.0119 LKL 0.0231\n",
      "epoch 3394 loss 0.1066 LR 0.0834 LKL 0.0232\n",
      "epoch 3395 loss 0.0846 LR 0.0612 LKL 0.0234\n",
      "epoch 3396 loss 0.1118 LR 0.0889 LKL 0.0230\n",
      "epoch 3397 loss 0.0846 LR 0.0614 LKL 0.0232\n",
      "epoch 3398 loss 0.1114 LR 0.0883 LKL 0.0231\n",
      "epoch 3399 loss 0.1160 LR 0.0930 LKL 0.0231\n",
      "epoch 3400 loss 0.0528 LR 0.0297 LKL 0.0231\n",
      "101\n",
      "epoch 3401 loss 0.1225 LR 0.0999 LKL 0.0226\n",
      "epoch 3402 loss 0.1196 LR 0.0968 LKL 0.0228\n",
      "epoch 3403 loss 0.1297 LR 0.1072 LKL 0.0225\n",
      "epoch 3404 loss 0.1686 LR 0.1461 LKL 0.0226\n",
      "epoch 3405 loss 0.0768 LR 0.0540 LKL 0.0229\n",
      "epoch 3406 loss 0.0775 LR 0.0547 LKL 0.0228\n",
      "epoch 3407 loss 0.0433 LR 0.0205 LKL 0.0228\n",
      "epoch 3408 loss 0.0760 LR 0.0532 LKL 0.0228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3409 loss 0.1142 LR 0.0915 LKL 0.0227\n",
      "epoch 3410 loss 0.1024 LR 0.0796 LKL 0.0228\n",
      "epoch 3411 loss 0.1710 LR 0.1479 LKL 0.0231\n",
      "epoch 3412 loss 0.1009 LR 0.0778 LKL 0.0231\n",
      "epoch 3413 loss 0.0954 LR 0.0724 LKL 0.0230\n",
      "epoch 3414 loss 0.1125 LR 0.0895 LKL 0.0230\n",
      "epoch 3415 loss 0.0757 LR 0.0526 LKL 0.0231\n",
      "epoch 3416 loss 0.1104 LR 0.0874 LKL 0.0230\n",
      "epoch 3417 loss 0.1258 LR 0.1024 LKL 0.0234\n",
      "epoch 3418 loss 0.1517 LR 0.1286 LKL 0.0231\n",
      "epoch 3419 loss 0.0619 LR 0.0387 LKL 0.0231\n",
      "epoch 3420 loss 0.1416 LR 0.1188 LKL 0.0228\n",
      "epoch 3421 loss 0.0929 LR 0.0699 LKL 0.0230\n",
      "epoch 3422 loss 0.0531 LR 0.0303 LKL 0.0228\n",
      "epoch 3423 loss 0.1087 LR 0.0857 LKL 0.0230\n",
      "epoch 3424 loss 0.0843 LR 0.0613 LKL 0.0230\n",
      "epoch 3425 loss 0.1114 LR 0.0886 LKL 0.0228\n",
      "epoch 3426 loss 0.0496 LR 0.0265 LKL 0.0230\n",
      "epoch 3427 loss 0.1257 LR 0.1027 LKL 0.0230\n",
      "epoch 3428 loss 0.1041 LR 0.0810 LKL 0.0232\n",
      "epoch 3429 loss 0.0672 LR 0.0441 LKL 0.0232\n",
      "epoch 3430 loss 0.0812 LR 0.0579 LKL 0.0233\n",
      "epoch 3431 loss 0.1361 LR 0.1130 LKL 0.0231\n",
      "epoch 3432 loss 0.0519 LR 0.0285 LKL 0.0234\n",
      "epoch 3433 loss 0.1642 LR 0.1410 LKL 0.0232\n",
      "epoch 3434 loss 0.0882 LR 0.0648 LKL 0.0234\n",
      "epoch 3435 loss 0.0502 LR 0.0271 LKL 0.0232\n",
      "epoch 3436 loss 0.0820 LR 0.0589 LKL 0.0231\n",
      "epoch 3437 loss 0.1036 LR 0.0805 LKL 0.0231\n",
      "epoch 3438 loss 0.1249 LR 0.1017 LKL 0.0232\n",
      "epoch 3439 loss 0.0831 LR 0.0601 LKL 0.0231\n",
      "epoch 3440 loss 0.0523 LR 0.0293 LKL 0.0230\n",
      "epoch 3441 loss 0.0866 LR 0.0638 LKL 0.0229\n",
      "epoch 3442 loss 0.0943 LR 0.0712 LKL 0.0230\n",
      "epoch 3443 loss 0.1254 LR 0.1023 LKL 0.0231\n",
      "epoch 3444 loss 0.0629 LR 0.0396 LKL 0.0233\n",
      "epoch 3445 loss 0.1393 LR 0.1165 LKL 0.0229\n",
      "epoch 3446 loss 0.1248 LR 0.1016 LKL 0.0231\n",
      "epoch 3447 loss 0.0659 LR 0.0429 LKL 0.0230\n",
      "epoch 3448 loss 0.1187 LR 0.0959 LKL 0.0228\n",
      "epoch 3449 loss 0.1074 LR 0.0844 LKL 0.0230\n",
      "epoch 3450 loss 0.1299 LR 0.1071 LKL 0.0227\n",
      "epoch 3451 loss 0.0981 LR 0.0751 LKL 0.0230\n",
      "epoch 3452 loss 0.0821 LR 0.0590 LKL 0.0231\n",
      "epoch 3453 loss 0.0977 LR 0.0751 LKL 0.0226\n",
      "epoch 3454 loss 0.1338 LR 0.1113 LKL 0.0225\n",
      "epoch 3455 loss 0.0695 LR 0.0467 LKL 0.0228\n",
      "epoch 3456 loss 0.1817 LR 0.1591 LKL 0.0226\n",
      "epoch 3457 loss 0.0286 LR 0.0058 LKL 0.0228\n",
      "epoch 3458 loss 0.0934 LR 0.0708 LKL 0.0226\n",
      "epoch 3459 loss 0.1166 LR 0.0939 LKL 0.0227\n",
      "epoch 3460 loss 0.1192 LR 0.0967 LKL 0.0226\n",
      "epoch 3461 loss 0.0574 LR 0.0346 LKL 0.0228\n",
      "epoch 3462 loss 0.1120 LR 0.0894 LKL 0.0226\n",
      "epoch 3463 loss 0.0837 LR 0.0611 LKL 0.0226\n",
      "epoch 3464 loss 0.0871 LR 0.0645 LKL 0.0226\n",
      "epoch 3465 loss 0.1279 LR 0.1053 LKL 0.0226\n",
      "epoch 3466 loss 0.0744 LR 0.0518 LKL 0.0226\n",
      "epoch 3467 loss 0.1400 LR 0.1178 LKL 0.0222\n",
      "epoch 3468 loss 0.0698 LR 0.0472 LKL 0.0226\n",
      "epoch 3469 loss 0.1189 LR 0.0962 LKL 0.0227\n",
      "epoch 3470 loss 0.1609 LR 0.1384 LKL 0.0225\n",
      "epoch 3471 loss 0.1522 LR 0.1295 LKL 0.0227\n",
      "epoch 3472 loss 0.0616 LR 0.0388 LKL 0.0229\n",
      "epoch 3473 loss 0.1073 LR 0.0846 LKL 0.0227\n",
      "epoch 3474 loss 0.0831 LR 0.0605 LKL 0.0226\n",
      "epoch 3475 loss 0.1301 LR 0.1073 LKL 0.0229\n",
      "epoch 3476 loss 0.0952 LR 0.0721 LKL 0.0231\n",
      "epoch 3477 loss 0.1052 LR 0.0823 LKL 0.0229\n",
      "epoch 3478 loss 0.1529 LR 0.1299 LKL 0.0231\n",
      "epoch 3479 loss 0.0752 LR 0.0521 LKL 0.0231\n",
      "epoch 3480 loss 0.1583 LR 0.1354 LKL 0.0229\n",
      "epoch 3481 loss 0.0943 LR 0.0716 LKL 0.0227\n",
      "epoch 3482 loss 0.0812 LR 0.0585 LKL 0.0227\n",
      "epoch 3483 loss 0.0769 LR 0.0542 LKL 0.0227\n",
      "epoch 3484 loss 0.0384 LR 0.0156 LKL 0.0229\n",
      "epoch 3485 loss 0.0951 LR 0.0727 LKL 0.0224\n",
      "epoch 3486 loss 0.0909 LR 0.0682 LKL 0.0227\n",
      "epoch 3487 loss 0.1563 LR 0.1337 LKL 0.0226\n",
      "epoch 3488 loss 0.0552 LR 0.0326 LKL 0.0226\n",
      "epoch 3489 loss 0.1284 LR 0.1058 LKL 0.0226\n",
      "epoch 3490 loss 0.0921 LR 0.0692 LKL 0.0228\n",
      "epoch 3491 loss 0.0919 LR 0.0689 LKL 0.0230\n",
      "epoch 3492 loss 0.0779 LR 0.0550 LKL 0.0229\n",
      "epoch 3493 loss 0.1316 LR 0.1087 LKL 0.0230\n",
      "epoch 3494 loss 0.0557 LR 0.0328 LKL 0.0229\n",
      "epoch 3495 loss 0.0907 LR 0.0676 LKL 0.0231\n",
      "epoch 3496 loss 0.0722 LR 0.0492 LKL 0.0230\n",
      "epoch 3497 loss 0.0499 LR 0.0271 LKL 0.0228\n",
      "epoch 3498 loss 0.0445 LR 0.0216 LKL 0.0229\n",
      "epoch 3499 loss 0.1153 LR 0.0924 LKL 0.0228\n",
      "epoch 3500 loss 0.0918 LR 0.0690 LKL 0.0228\n",
      "60\n",
      "epoch 3501 loss 0.0853 LR 0.0622 LKL 0.0231\n",
      "epoch 3502 loss 0.0930 LR 0.0701 LKL 0.0229\n",
      "epoch 3503 loss 0.1144 LR 0.0916 LKL 0.0229\n",
      "epoch 3504 loss 0.0724 LR 0.0494 LKL 0.0231\n",
      "epoch 3505 loss 0.1087 LR 0.0859 LKL 0.0227\n",
      "epoch 3506 loss 0.0920 LR 0.0693 LKL 0.0227\n",
      "epoch 3507 loss 0.0645 LR 0.0415 LKL 0.0229\n",
      "epoch 3508 loss 0.0361 LR 0.0129 LKL 0.0232\n",
      "epoch 3509 loss 0.0579 LR 0.0349 LKL 0.0230\n",
      "epoch 3510 loss 0.0638 LR 0.0410 LKL 0.0227\n",
      "epoch 3511 loss 0.0930 LR 0.0700 LKL 0.0229\n",
      "epoch 3512 loss 0.1240 LR 0.1014 LKL 0.0226\n",
      "epoch 3513 loss 0.0680 LR 0.0453 LKL 0.0228\n",
      "epoch 3514 loss 0.0899 LR 0.0672 LKL 0.0227\n",
      "epoch 3515 loss 0.0669 LR 0.0444 LKL 0.0225\n",
      "epoch 3516 loss 0.1387 LR 0.1162 LKL 0.0224\n",
      "epoch 3517 loss 0.0285 LR 0.0058 LKL 0.0227\n",
      "epoch 3518 loss 0.1034 LR 0.0809 LKL 0.0226\n",
      "epoch 3519 loss 0.0394 LR 0.0167 LKL 0.0227\n",
      "epoch 3520 loss 0.0830 LR 0.0601 LKL 0.0229\n",
      "epoch 3521 loss 0.0903 LR 0.0679 LKL 0.0224\n",
      "epoch 3522 loss 0.0824 LR 0.0599 LKL 0.0225\n",
      "epoch 3523 loss 0.0880 LR 0.0654 LKL 0.0226\n",
      "epoch 3524 loss 0.0892 LR 0.0666 LKL 0.0226\n",
      "epoch 3525 loss 0.1176 LR 0.0949 LKL 0.0228\n",
      "epoch 3526 loss 0.1092 LR 0.0863 LKL 0.0230\n",
      "epoch 3527 loss 0.1067 LR 0.0840 LKL 0.0227\n",
      "epoch 3528 loss 0.0700 LR 0.0469 LKL 0.0231\n",
      "epoch 3529 loss 0.0873 LR 0.0641 LKL 0.0232\n",
      "epoch 3530 loss 0.1042 LR 0.0813 LKL 0.0229\n",
      "epoch 3531 loss 0.1104 LR 0.0873 LKL 0.0231\n",
      "epoch 3532 loss 0.0708 LR 0.0479 LKL 0.0229\n",
      "epoch 3533 loss 0.0525 LR 0.0298 LKL 0.0226\n",
      "epoch 3534 loss 0.1122 LR 0.0898 LKL 0.0224\n",
      "epoch 3535 loss 0.1203 LR 0.0978 LKL 0.0225\n",
      "epoch 3536 loss 0.0798 LR 0.0571 LKL 0.0227\n",
      "epoch 3537 loss 0.0885 LR 0.0662 LKL 0.0223\n",
      "epoch 3538 loss 0.1377 LR 0.1155 LKL 0.0222\n",
      "epoch 3539 loss 0.1350 LR 0.1132 LKL 0.0219\n",
      "epoch 3540 loss 0.0702 LR 0.0480 LKL 0.0222\n",
      "epoch 3541 loss 0.1155 LR 0.0936 LKL 0.0219\n",
      "epoch 3542 loss 0.1308 LR 0.1091 LKL 0.0217\n",
      "epoch 3543 loss 0.1858 LR 0.1638 LKL 0.0221\n",
      "epoch 3544 loss 0.0944 LR 0.0720 LKL 0.0224\n",
      "epoch 3545 loss 0.1448 LR 0.1226 LKL 0.0221\n",
      "epoch 3546 loss 0.1196 LR 0.0973 LKL 0.0223\n",
      "epoch 3547 loss 0.0954 LR 0.0728 LKL 0.0226\n",
      "epoch 3548 loss 0.0917 LR 0.0690 LKL 0.0227\n",
      "epoch 3549 loss 0.0670 LR 0.0443 LKL 0.0227\n",
      "epoch 3550 loss 0.0501 LR 0.0274 LKL 0.0227\n",
      "epoch 3551 loss 0.0940 LR 0.0710 LKL 0.0231\n",
      "epoch 3552 loss 0.0530 LR 0.0300 LKL 0.0231\n",
      "epoch 3553 loss 0.0900 LR 0.0670 LKL 0.0230\n",
      "epoch 3554 loss 0.0936 LR 0.0705 LKL 0.0231\n",
      "epoch 3555 loss 0.1175 LR 0.0941 LKL 0.0234\n",
      "epoch 3556 loss 0.0720 LR 0.0485 LKL 0.0235\n",
      "epoch 3557 loss 0.0900 LR 0.0670 LKL 0.0230\n",
      "epoch 3558 loss 0.1269 LR 0.1038 LKL 0.0231\n",
      "epoch 3559 loss 0.0989 LR 0.0759 LKL 0.0231\n",
      "epoch 3560 loss 0.0362 LR 0.0133 LKL 0.0229\n",
      "epoch 3561 loss 0.0468 LR 0.0240 LKL 0.0228\n",
      "epoch 3562 loss 0.0449 LR 0.0219 LKL 0.0230\n",
      "epoch 3563 loss 0.0402 LR 0.0172 LKL 0.0230\n",
      "epoch 3564 loss 0.0961 LR 0.0734 LKL 0.0227\n",
      "epoch 3565 loss 0.1375 LR 0.1147 LKL 0.0228\n",
      "epoch 3566 loss 0.0685 LR 0.0460 LKL 0.0225\n",
      "epoch 3567 loss 0.1243 LR 0.1016 LKL 0.0228\n",
      "epoch 3568 loss 0.0767 LR 0.0539 LKL 0.0228\n",
      "epoch 3569 loss 0.0808 LR 0.0581 LKL 0.0227\n",
      "epoch 3570 loss 0.1487 LR 0.1261 LKL 0.0226\n",
      "epoch 3571 loss 0.0911 LR 0.0686 LKL 0.0225\n",
      "epoch 3572 loss 0.1363 LR 0.1139 LKL 0.0224\n",
      "epoch 3573 loss 0.0367 LR 0.0142 LKL 0.0224\n",
      "epoch 3574 loss 0.1145 LR 0.0922 LKL 0.0223\n",
      "epoch 3575 loss 0.1654 LR 0.1433 LKL 0.0220\n",
      "epoch 3576 loss 0.0982 LR 0.0759 LKL 0.0222\n",
      "epoch 3577 loss 0.0908 LR 0.0685 LKL 0.0223\n",
      "epoch 3578 loss 0.1124 LR 0.0902 LKL 0.0222\n",
      "epoch 3579 loss 0.0717 LR 0.0496 LKL 0.0221\n",
      "epoch 3580 loss 0.1243 LR 0.1021 LKL 0.0222\n",
      "epoch 3581 loss 0.0961 LR 0.0740 LKL 0.0221\n",
      "epoch 3582 loss 0.0530 LR 0.0305 LKL 0.0225\n",
      "epoch 3583 loss 0.0461 LR 0.0238 LKL 0.0222\n",
      "epoch 3584 loss 0.1098 LR 0.0874 LKL 0.0224\n",
      "epoch 3585 loss 0.1499 LR 0.1275 LKL 0.0224\n",
      "epoch 3586 loss 0.0454 LR 0.0227 LKL 0.0227\n",
      "epoch 3587 loss 0.0778 LR 0.0550 LKL 0.0227\n",
      "epoch 3588 loss 0.0803 LR 0.0575 LKL 0.0228\n",
      "epoch 3589 loss 0.1518 LR 0.1292 LKL 0.0225\n",
      "epoch 3590 loss 0.1341 LR 0.1117 LKL 0.0224\n",
      "epoch 3591 loss 0.0851 LR 0.0622 LKL 0.0229\n",
      "epoch 3592 loss 0.0966 LR 0.0740 LKL 0.0226\n",
      "epoch 3593 loss 0.1569 LR 0.1340 LKL 0.0229\n",
      "epoch 3594 loss 0.0231 LR -0.0000 LKL 0.0231\n",
      "epoch 3595 loss 0.0980 LR 0.0753 LKL 0.0228\n",
      "epoch 3596 loss 0.1072 LR 0.0849 LKL 0.0224\n",
      "epoch 3597 loss 0.0902 LR 0.0678 LKL 0.0224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3598 loss 0.0856 LR 0.0631 LKL 0.0224\n",
      "epoch 3599 loss 0.0923 LR 0.0699 LKL 0.0224\n",
      "epoch 3600 loss 0.1396 LR 0.1173 LKL 0.0223\n",
      "76\n",
      "epoch 3601 loss 0.0669 LR 0.0445 LKL 0.0224\n",
      "epoch 3602 loss 0.1028 LR 0.0805 LKL 0.0222\n",
      "epoch 3603 loss 0.0111 LR -0.0113 LKL 0.0225\n",
      "epoch 3604 loss 0.0550 LR 0.0328 LKL 0.0222\n",
      "epoch 3605 loss 0.0994 LR 0.0771 LKL 0.0223\n",
      "epoch 3606 loss 0.0361 LR 0.0136 LKL 0.0225\n",
      "epoch 3607 loss 0.0888 LR 0.0662 LKL 0.0226\n",
      "epoch 3608 loss 0.0825 LR 0.0598 LKL 0.0226\n",
      "epoch 3609 loss 0.0581 LR 0.0355 LKL 0.0226\n",
      "epoch 3610 loss 0.0988 LR 0.0760 LKL 0.0228\n",
      "epoch 3611 loss 0.0892 LR 0.0665 LKL 0.0228\n",
      "epoch 3612 loss 0.1314 LR 0.1086 LKL 0.0228\n",
      "epoch 3613 loss 0.1421 LR 0.1196 LKL 0.0226\n",
      "epoch 3614 loss 0.1151 LR 0.0922 LKL 0.0229\n",
      "epoch 3615 loss 0.0776 LR 0.0546 LKL 0.0230\n",
      "epoch 3616 loss 0.0393 LR 0.0163 LKL 0.0230\n",
      "epoch 3617 loss 0.0732 LR 0.0499 LKL 0.0233\n",
      "epoch 3618 loss 0.0959 LR 0.0726 LKL 0.0232\n",
      "epoch 3619 loss 0.0682 LR 0.0451 LKL 0.0231\n",
      "epoch 3620 loss 0.0935 LR 0.0703 LKL 0.0233\n",
      "epoch 3621 loss 0.0770 LR 0.0541 LKL 0.0230\n",
      "epoch 3622 loss 0.1143 LR 0.0912 LKL 0.0231\n",
      "epoch 3623 loss 0.1036 LR 0.0806 LKL 0.0230\n",
      "epoch 3624 loss 0.0626 LR 0.0395 LKL 0.0231\n",
      "epoch 3625 loss 0.0481 LR 0.0253 LKL 0.0228\n",
      "epoch 3626 loss 0.1025 LR 0.0794 LKL 0.0231\n",
      "epoch 3627 loss 0.0925 LR 0.0694 LKL 0.0231\n",
      "epoch 3628 loss 0.0922 LR 0.0691 LKL 0.0230\n",
      "epoch 3629 loss 0.0795 LR 0.0567 LKL 0.0229\n",
      "epoch 3630 loss 0.0620 LR 0.0392 LKL 0.0228\n",
      "epoch 3631 loss 0.1295 LR 0.1068 LKL 0.0227\n",
      "epoch 3632 loss 0.0896 LR 0.0667 LKL 0.0229\n",
      "epoch 3633 loss 0.1194 LR 0.0966 LKL 0.0228\n",
      "epoch 3634 loss 0.0913 LR 0.0684 LKL 0.0228\n",
      "epoch 3635 loss 0.1334 LR 0.1106 LKL 0.0228\n",
      "epoch 3636 loss 0.0504 LR 0.0273 LKL 0.0231\n",
      "epoch 3637 loss 0.0265 LR 0.0034 LKL 0.0231\n",
      "epoch 3638 loss 0.0649 LR 0.0418 LKL 0.0231\n",
      "epoch 3639 loss 0.1022 LR 0.0789 LKL 0.0233\n",
      "epoch 3640 loss 0.0963 LR 0.0731 LKL 0.0232\n",
      "epoch 3641 loss 0.0297 LR 0.0063 LKL 0.0234\n",
      "epoch 3642 loss 0.0681 LR 0.0449 LKL 0.0232\n",
      "epoch 3643 loss 0.1014 LR 0.0782 LKL 0.0233\n",
      "epoch 3644 loss 0.0782 LR 0.0549 LKL 0.0232\n",
      "epoch 3645 loss 0.0814 LR 0.0580 LKL 0.0234\n",
      "epoch 3646 loss 0.1265 LR 0.1036 LKL 0.0230\n",
      "epoch 3647 loss 0.0984 LR 0.0752 LKL 0.0232\n",
      "epoch 3648 loss 0.0837 LR 0.0604 LKL 0.0234\n",
      "epoch 3649 loss 0.0705 LR 0.0472 LKL 0.0233\n",
      "epoch 3650 loss 0.1732 LR 0.1503 LKL 0.0230\n",
      "epoch 3651 loss 0.1128 LR 0.0898 LKL 0.0230\n",
      "epoch 3652 loss 0.1445 LR 0.1215 LKL 0.0230\n",
      "epoch 3653 loss 0.1198 LR 0.0969 LKL 0.0229\n",
      "epoch 3654 loss 0.0990 LR 0.0760 LKL 0.0230\n",
      "epoch 3655 loss 0.0335 LR 0.0104 LKL 0.0231\n",
      "epoch 3656 loss 0.0767 LR 0.0535 LKL 0.0232\n",
      "epoch 3657 loss 0.0880 LR 0.0651 LKL 0.0229\n",
      "epoch 3658 loss 0.0956 LR 0.0727 LKL 0.0230\n",
      "epoch 3659 loss 0.0583 LR 0.0352 LKL 0.0232\n",
      "epoch 3660 loss 0.0837 LR 0.0609 LKL 0.0229\n",
      "epoch 3661 loss 0.1381 LR 0.1153 LKL 0.0227\n",
      "epoch 3662 loss 0.0991 LR 0.0764 LKL 0.0228\n",
      "epoch 3663 loss 0.1066 LR 0.0842 LKL 0.0224\n",
      "epoch 3664 loss 0.1022 LR 0.0796 LKL 0.0226\n",
      "epoch 3665 loss 0.0604 LR 0.0380 LKL 0.0224\n",
      "epoch 3666 loss 0.0469 LR 0.0246 LKL 0.0223\n",
      "epoch 3667 loss 0.0806 LR 0.0580 LKL 0.0226\n",
      "epoch 3668 loss 0.1068 LR 0.0844 LKL 0.0224\n",
      "epoch 3669 loss 0.0914 LR 0.0692 LKL 0.0222\n",
      "epoch 3670 loss 0.0513 LR 0.0289 LKL 0.0224\n",
      "epoch 3671 loss 0.0863 LR 0.0639 LKL 0.0224\n",
      "epoch 3672 loss 0.1209 LR 0.0986 LKL 0.0224\n",
      "epoch 3673 loss 0.0591 LR 0.0366 LKL 0.0225\n",
      "epoch 3674 loss 0.1728 LR 0.1505 LKL 0.0223\n",
      "epoch 3675 loss 0.1029 LR 0.0805 LKL 0.0224\n",
      "epoch 3676 loss 0.0498 LR 0.0272 LKL 0.0226\n",
      "epoch 3677 loss 0.1472 LR 0.1250 LKL 0.0222\n",
      "epoch 3678 loss 0.0749 LR 0.0524 LKL 0.0225\n",
      "epoch 3679 loss 0.0630 LR 0.0407 LKL 0.0223\n",
      "epoch 3680 loss 0.1056 LR 0.0833 LKL 0.0223\n",
      "epoch 3681 loss 0.0748 LR 0.0523 LKL 0.0225\n",
      "epoch 3682 loss 0.1000 LR 0.0775 LKL 0.0226\n",
      "epoch 3683 loss 0.0620 LR 0.0395 LKL 0.0226\n",
      "epoch 3684 loss 0.1030 LR 0.0804 LKL 0.0226\n",
      "epoch 3685 loss 0.0698 LR 0.0474 LKL 0.0224\n",
      "epoch 3686 loss 0.0256 LR 0.0027 LKL 0.0230\n",
      "epoch 3687 loss 0.0520 LR 0.0294 LKL 0.0226\n",
      "epoch 3688 loss 0.1361 LR 0.1130 LKL 0.0231\n",
      "epoch 3689 loss 0.0679 LR 0.0450 LKL 0.0229\n",
      "epoch 3690 loss 0.1007 LR 0.0780 LKL 0.0227\n",
      "epoch 3691 loss 0.0894 LR 0.0665 LKL 0.0228\n",
      "epoch 3692 loss 0.0562 LR 0.0330 LKL 0.0231\n",
      "epoch 3693 loss 0.0861 LR 0.0631 LKL 0.0230\n",
      "epoch 3694 loss 0.0181 LR -0.0053 LKL 0.0234\n",
      "epoch 3695 loss 0.1055 LR 0.0823 LKL 0.0231\n",
      "epoch 3696 loss 0.0715 LR 0.0479 LKL 0.0236\n",
      "epoch 3697 loss 0.0654 LR 0.0419 LKL 0.0235\n",
      "epoch 3698 loss 0.1363 LR 0.1127 LKL 0.0236\n",
      "epoch 3699 loss 0.1013 LR 0.0780 LKL 0.0233\n",
      "epoch 3700 loss 0.0462 LR 0.0227 LKL 0.0234\n",
      "112\n",
      "epoch 3701 loss 0.0622 LR 0.0391 LKL 0.0232\n",
      "epoch 3702 loss 0.0699 LR 0.0465 LKL 0.0234\n",
      "epoch 3703 loss 0.0570 LR 0.0339 LKL 0.0231\n",
      "epoch 3704 loss 0.0836 LR 0.0607 LKL 0.0229\n",
      "epoch 3705 loss 0.0231 LR 0.0002 LKL 0.0229\n",
      "epoch 3706 loss 0.0648 LR 0.0422 LKL 0.0227\n",
      "epoch 3707 loss 0.0892 LR 0.0666 LKL 0.0227\n",
      "epoch 3708 loss 0.0682 LR 0.0457 LKL 0.0224\n",
      "epoch 3709 loss 0.0753 LR 0.0528 LKL 0.0225\n",
      "epoch 3710 loss 0.1215 LR 0.0989 LKL 0.0226\n",
      "epoch 3711 loss 0.0856 LR 0.0627 LKL 0.0229\n",
      "epoch 3712 loss 0.0917 LR 0.0689 LKL 0.0228\n",
      "epoch 3713 loss 0.0524 LR 0.0293 LKL 0.0231\n",
      "epoch 3714 loss 0.1315 LR 0.1083 LKL 0.0232\n",
      "epoch 3715 loss 0.1115 LR 0.0886 LKL 0.0229\n",
      "epoch 3716 loss 0.0551 LR 0.0319 LKL 0.0232\n",
      "epoch 3717 loss 0.0411 LR 0.0180 LKL 0.0231\n",
      "epoch 3718 loss 0.0611 LR 0.0382 LKL 0.0230\n",
      "epoch 3719 loss 0.0524 LR 0.0291 LKL 0.0234\n",
      "epoch 3720 loss 0.1280 LR 0.1049 LKL 0.0231\n",
      "epoch 3721 loss 0.0849 LR 0.0618 LKL 0.0231\n",
      "epoch 3722 loss 0.1016 LR 0.0787 LKL 0.0229\n",
      "epoch 3723 loss 0.0858 LR 0.0628 LKL 0.0230\n",
      "epoch 3724 loss 0.1068 LR 0.0840 LKL 0.0228\n",
      "epoch 3725 loss 0.0323 LR 0.0090 LKL 0.0233\n",
      "epoch 3726 loss 0.0159 LR -0.0074 LKL 0.0232\n",
      "epoch 3727 loss 0.0479 LR 0.0246 LKL 0.0233\n",
      "epoch 3728 loss 0.0985 LR 0.0753 LKL 0.0232\n",
      "epoch 3729 loss 0.0501 LR 0.0267 LKL 0.0233\n",
      "epoch 3730 loss 0.0817 LR 0.0585 LKL 0.0232\n",
      "epoch 3731 loss 0.1146 LR 0.0911 LKL 0.0235\n",
      "epoch 3732 loss 0.0782 LR 0.0550 LKL 0.0232\n",
      "epoch 3733 loss 0.0381 LR 0.0145 LKL 0.0236\n",
      "epoch 3734 loss 0.0440 LR 0.0208 LKL 0.0232\n",
      "epoch 3735 loss 0.0646 LR 0.0415 LKL 0.0232\n",
      "epoch 3736 loss 0.0941 LR 0.0708 LKL 0.0233\n",
      "epoch 3737 loss 0.1274 LR 0.1039 LKL 0.0235\n",
      "epoch 3738 loss 0.0751 LR 0.0517 LKL 0.0234\n",
      "epoch 3739 loss 0.0677 LR 0.0444 LKL 0.0233\n",
      "epoch 3740 loss 0.0490 LR 0.0259 LKL 0.0231\n",
      "epoch 3741 loss 0.1536 LR 0.1307 LKL 0.0229\n",
      "epoch 3742 loss 0.1368 LR 0.1136 LKL 0.0232\n",
      "epoch 3743 loss 0.0836 LR 0.0609 LKL 0.0228\n",
      "epoch 3744 loss 0.0724 LR 0.0495 LKL 0.0229\n",
      "epoch 3745 loss 0.0836 LR 0.0608 LKL 0.0228\n",
      "epoch 3746 loss 0.0458 LR 0.0228 LKL 0.0230\n",
      "epoch 3747 loss 0.1095 LR 0.0864 LKL 0.0231\n",
      "epoch 3748 loss 0.0843 LR 0.0614 LKL 0.0228\n",
      "epoch 3749 loss 0.1519 LR 0.1289 LKL 0.0231\n",
      "epoch 3750 loss 0.1104 LR 0.0876 LKL 0.0227\n",
      "epoch 3751 loss 0.1058 LR 0.0829 LKL 0.0229\n",
      "epoch 3752 loss 0.0297 LR 0.0065 LKL 0.0232\n",
      "epoch 3753 loss 0.1192 LR 0.0961 LKL 0.0231\n",
      "epoch 3754 loss 0.0646 LR 0.0415 LKL 0.0231\n",
      "epoch 3755 loss 0.1169 LR 0.0938 LKL 0.0231\n",
      "epoch 3756 loss 0.0692 LR 0.0460 LKL 0.0232\n",
      "epoch 3757 loss 0.0631 LR 0.0398 LKL 0.0233\n",
      "epoch 3758 loss 0.0974 LR 0.0741 LKL 0.0233\n",
      "epoch 3759 loss 0.1316 LR 0.1086 LKL 0.0230\n",
      "epoch 3760 loss 0.1545 LR 0.1314 LKL 0.0231\n",
      "epoch 3761 loss 0.0513 LR 0.0279 LKL 0.0235\n",
      "epoch 3762 loss 0.0688 LR 0.0459 LKL 0.0229\n",
      "epoch 3763 loss 0.0738 LR 0.0507 LKL 0.0231\n",
      "epoch 3764 loss 0.0937 LR 0.0708 LKL 0.0228\n",
      "epoch 3765 loss 0.1111 LR 0.0881 LKL 0.0230\n",
      "epoch 3766 loss 0.1240 LR 0.1009 LKL 0.0231\n",
      "epoch 3767 loss 0.1017 LR 0.0787 LKL 0.0230\n",
      "epoch 3768 loss 0.1468 LR 0.1240 LKL 0.0228\n",
      "epoch 3769 loss 0.1034 LR 0.0804 LKL 0.0230\n",
      "epoch 3770 loss 0.0619 LR 0.0388 LKL 0.0231\n",
      "epoch 3771 loss 0.1475 LR 0.1246 LKL 0.0229\n",
      "epoch 3772 loss 0.0950 LR 0.0720 LKL 0.0230\n",
      "epoch 3773 loss 0.1064 LR 0.0834 LKL 0.0230\n",
      "epoch 3774 loss 0.1058 LR 0.0827 LKL 0.0231\n",
      "epoch 3775 loss 0.0451 LR 0.0220 LKL 0.0231\n",
      "epoch 3776 loss 0.0538 LR 0.0309 LKL 0.0230\n",
      "epoch 3777 loss 0.0810 LR 0.0578 LKL 0.0231\n",
      "epoch 3778 loss 0.0644 LR 0.0413 LKL 0.0231\n",
      "epoch 3779 loss 0.1230 LR 0.0995 LKL 0.0234\n",
      "epoch 3780 loss 0.1017 LR 0.0787 LKL 0.0230\n",
      "epoch 3781 loss 0.0665 LR 0.0432 LKL 0.0232\n",
      "epoch 3782 loss 0.0497 LR 0.0267 LKL 0.0230\n",
      "epoch 3783 loss 0.1271 LR 0.1043 LKL 0.0229\n",
      "epoch 3784 loss 0.0852 LR 0.0623 LKL 0.0229\n",
      "epoch 3785 loss 0.0301 LR 0.0070 LKL 0.0232\n",
      "epoch 3786 loss 0.1397 LR 0.1167 LKL 0.0230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3787 loss 0.1383 LR 0.1158 LKL 0.0226\n",
      "epoch 3788 loss 0.1455 LR 0.1226 LKL 0.0229\n",
      "epoch 3789 loss 0.0895 LR 0.0665 LKL 0.0230\n",
      "epoch 3790 loss 0.0316 LR 0.0084 LKL 0.0232\n",
      "epoch 3791 loss 0.1146 LR 0.0918 LKL 0.0228\n",
      "epoch 3792 loss 0.0724 LR 0.0495 LKL 0.0230\n",
      "epoch 3793 loss 0.0715 LR 0.0484 LKL 0.0231\n",
      "epoch 3794 loss 0.1111 LR 0.0881 LKL 0.0230\n",
      "epoch 3795 loss 0.1108 LR 0.0878 LKL 0.0229\n",
      "epoch 3796 loss 0.1127 LR 0.0896 LKL 0.0230\n",
      "epoch 3797 loss 0.0481 LR 0.0250 LKL 0.0231\n",
      "epoch 3798 loss 0.0910 LR 0.0678 LKL 0.0233\n",
      "epoch 3799 loss 0.0716 LR 0.0484 LKL 0.0233\n",
      "epoch 3800 loss 0.1061 LR 0.0830 LKL 0.0231\n",
      "94\n",
      "epoch 3801 loss 0.0861 LR 0.0630 LKL 0.0231\n",
      "epoch 3802 loss 0.1315 LR 0.1083 LKL 0.0232\n",
      "epoch 3803 loss 0.0927 LR 0.0696 LKL 0.0231\n",
      "epoch 3804 loss 0.0357 LR 0.0126 LKL 0.0232\n",
      "epoch 3805 loss 0.0847 LR 0.0610 LKL 0.0237\n",
      "epoch 3806 loss 0.0581 LR 0.0347 LKL 0.0234\n",
      "epoch 3807 loss 0.0472 LR 0.0237 LKL 0.0235\n",
      "epoch 3808 loss 0.0367 LR 0.0132 LKL 0.0235\n",
      "epoch 3809 loss 0.1040 LR 0.0805 LKL 0.0235\n",
      "epoch 3810 loss 0.1038 LR 0.0801 LKL 0.0237\n",
      "epoch 3811 loss 0.1015 LR 0.0783 LKL 0.0233\n",
      "epoch 3812 loss 0.0510 LR 0.0274 LKL 0.0236\n",
      "epoch 3813 loss 0.1363 LR 0.1130 LKL 0.0233\n",
      "epoch 3814 loss 0.1206 LR 0.0969 LKL 0.0237\n",
      "epoch 3815 loss 0.1034 LR 0.0799 LKL 0.0234\n",
      "epoch 3816 loss 0.1073 LR 0.0839 LKL 0.0234\n",
      "epoch 3817 loss 0.0749 LR 0.0513 LKL 0.0237\n",
      "epoch 3818 loss 0.0646 LR 0.0412 LKL 0.0234\n",
      "epoch 3819 loss 0.1043 LR 0.0809 LKL 0.0234\n",
      "epoch 3820 loss 0.0607 LR 0.0377 LKL 0.0231\n",
      "epoch 3821 loss 0.0756 LR 0.0526 LKL 0.0230\n",
      "epoch 3822 loss 0.0856 LR 0.0628 LKL 0.0228\n",
      "epoch 3823 loss 0.0396 LR 0.0165 LKL 0.0231\n",
      "epoch 3824 loss 0.0146 LR -0.0081 LKL 0.0227\n",
      "epoch 3825 loss 0.0375 LR 0.0146 LKL 0.0229\n",
      "epoch 3826 loss 0.0722 LR 0.0497 LKL 0.0226\n",
      "epoch 3827 loss 0.1057 LR 0.0830 LKL 0.0227\n",
      "epoch 3828 loss 0.1107 LR 0.0879 LKL 0.0227\n",
      "epoch 3829 loss 0.0765 LR 0.0538 LKL 0.0227\n",
      "epoch 3830 loss 0.1021 LR 0.0795 LKL 0.0226\n",
      "epoch 3831 loss 0.0633 LR 0.0410 LKL 0.0223\n",
      "epoch 3832 loss 0.0973 LR 0.0747 LKL 0.0226\n",
      "epoch 3833 loss 0.1119 LR 0.0895 LKL 0.0223\n",
      "epoch 3834 loss 0.0800 LR 0.0575 LKL 0.0225\n",
      "epoch 3835 loss 0.0642 LR 0.0418 LKL 0.0224\n",
      "epoch 3836 loss 0.1075 LR 0.0852 LKL 0.0224\n",
      "epoch 3837 loss 0.0649 LR 0.0422 LKL 0.0226\n",
      "epoch 3838 loss 0.0671 LR 0.0446 LKL 0.0225\n",
      "epoch 3839 loss 0.0631 LR 0.0405 LKL 0.0226\n",
      "epoch 3840 loss 0.0838 LR 0.0612 LKL 0.0226\n",
      "epoch 3841 loss 0.0773 LR 0.0544 LKL 0.0229\n",
      "epoch 3842 loss 0.1370 LR 0.1140 LKL 0.0230\n",
      "epoch 3843 loss 0.1221 LR 0.0993 LKL 0.0227\n",
      "epoch 3844 loss 0.0993 LR 0.0763 LKL 0.0230\n",
      "epoch 3845 loss 0.1260 LR 0.1029 LKL 0.0231\n",
      "epoch 3846 loss 0.0985 LR 0.0755 LKL 0.0230\n",
      "epoch 3847 loss 0.1347 LR 0.1116 LKL 0.0231\n",
      "epoch 3848 loss 0.0275 LR 0.0043 LKL 0.0232\n",
      "epoch 3849 loss 0.0601 LR 0.0370 LKL 0.0232\n",
      "epoch 3850 loss 0.1226 LR 0.0993 LKL 0.0233\n",
      "epoch 3851 loss 0.0826 LR 0.0597 LKL 0.0229\n",
      "epoch 3852 loss 0.0700 LR 0.0467 LKL 0.0233\n",
      "epoch 3853 loss 0.0660 LR 0.0428 LKL 0.0232\n",
      "epoch 3854 loss 0.0877 LR 0.0646 LKL 0.0231\n",
      "epoch 3855 loss 0.0624 LR 0.0396 LKL 0.0228\n",
      "epoch 3856 loss 0.0575 LR 0.0347 LKL 0.0227\n",
      "epoch 3857 loss 0.0367 LR 0.0140 LKL 0.0227\n",
      "epoch 3858 loss 0.0452 LR 0.0224 LKL 0.0228\n",
      "epoch 3859 loss 0.0642 LR 0.0416 LKL 0.0227\n",
      "epoch 3860 loss 0.0698 LR 0.0471 LKL 0.0227\n",
      "epoch 3861 loss 0.0277 LR 0.0051 LKL 0.0226\n",
      "epoch 3862 loss 0.1390 LR 0.1165 LKL 0.0225\n",
      "epoch 3863 loss 0.1040 LR 0.0814 LKL 0.0226\n",
      "epoch 3864 loss 0.0512 LR 0.0284 LKL 0.0229\n",
      "epoch 3865 loss 0.0528 LR 0.0300 LKL 0.0228\n",
      "epoch 3866 loss 0.1090 LR 0.0863 LKL 0.0227\n",
      "epoch 3867 loss 0.1348 LR 0.1117 LKL 0.0231\n",
      "epoch 3868 loss 0.0889 LR 0.0657 LKL 0.0233\n",
      "epoch 3869 loss 0.0671 LR 0.0439 LKL 0.0232\n",
      "epoch 3870 loss 0.0713 LR 0.0477 LKL 0.0236\n",
      "epoch 3871 loss 0.0793 LR 0.0560 LKL 0.0233\n",
      "epoch 3872 loss 0.0639 LR 0.0401 LKL 0.0238\n",
      "epoch 3873 loss 0.0916 LR 0.0683 LKL 0.0232\n",
      "epoch 3874 loss 0.1043 LR 0.0809 LKL 0.0234\n",
      "epoch 3875 loss 0.0655 LR 0.0418 LKL 0.0237\n",
      "epoch 3876 loss 0.0428 LR 0.0194 LKL 0.0235\n",
      "epoch 3877 loss 0.0410 LR 0.0172 LKL 0.0238\n",
      "epoch 3878 loss 0.0772 LR 0.0538 LKL 0.0234\n",
      "epoch 3879 loss 0.0612 LR 0.0377 LKL 0.0236\n",
      "epoch 3880 loss 0.0979 LR 0.0748 LKL 0.0232\n",
      "epoch 3881 loss 0.0507 LR 0.0274 LKL 0.0234\n",
      "epoch 3882 loss 0.1195 LR 0.0964 LKL 0.0231\n",
      "epoch 3883 loss 0.0551 LR 0.0321 LKL 0.0231\n",
      "epoch 3884 loss 0.0576 LR 0.0345 LKL 0.0232\n",
      "epoch 3885 loss 0.0543 LR 0.0313 LKL 0.0230\n",
      "epoch 3886 loss 0.0257 LR 0.0028 LKL 0.0229\n",
      "epoch 3887 loss 0.0422 LR 0.0194 LKL 0.0228\n",
      "epoch 3888 loss 0.0757 LR 0.0528 LKL 0.0228\n",
      "epoch 3889 loss 0.0921 LR 0.0693 LKL 0.0228\n",
      "epoch 3890 loss 0.0100 LR -0.0127 LKL 0.0227\n",
      "epoch 3891 loss 0.0843 LR 0.0611 LKL 0.0232\n",
      "epoch 3892 loss 0.1093 LR 0.0863 LKL 0.0230\n",
      "epoch 3893 loss 0.0701 LR 0.0471 LKL 0.0230\n",
      "epoch 3894 loss 0.0430 LR 0.0200 LKL 0.0230\n",
      "epoch 3895 loss 0.1537 LR 0.1306 LKL 0.0231\n",
      "epoch 3896 loss 0.0765 LR 0.0534 LKL 0.0231\n",
      "epoch 3897 loss 0.0775 LR 0.0544 LKL 0.0231\n",
      "epoch 3898 loss 0.0975 LR 0.0744 LKL 0.0231\n",
      "epoch 3899 loss 0.0212 LR -0.0020 LKL 0.0232\n",
      "epoch 3900 loss 0.0293 LR 0.0057 LKL 0.0235\n",
      "40\n",
      "epoch 3901 loss 0.1190 LR 0.0958 LKL 0.0232\n",
      "epoch 3902 loss 0.0865 LR 0.0629 LKL 0.0235\n",
      "epoch 3903 loss 0.1767 LR 0.1532 LKL 0.0234\n",
      "epoch 3904 loss 0.1144 LR 0.0910 LKL 0.0234\n",
      "epoch 3905 loss 0.0854 LR 0.0620 LKL 0.0234\n",
      "epoch 3906 loss 0.1182 LR 0.0946 LKL 0.0235\n",
      "epoch 3907 loss 0.0668 LR 0.0432 LKL 0.0236\n",
      "epoch 3908 loss 0.0576 LR 0.0342 LKL 0.0235\n",
      "epoch 3909 loss 0.0303 LR 0.0069 LKL 0.0234\n",
      "epoch 3910 loss 0.0698 LR 0.0465 LKL 0.0234\n",
      "epoch 3911 loss 0.0463 LR 0.0228 LKL 0.0235\n",
      "epoch 3912 loss 0.0809 LR 0.0579 LKL 0.0230\n",
      "epoch 3913 loss 0.0688 LR 0.0457 LKL 0.0231\n",
      "epoch 3914 loss 0.0750 LR 0.0519 LKL 0.0231\n",
      "epoch 3915 loss 0.0815 LR 0.0583 LKL 0.0232\n",
      "epoch 3916 loss 0.1549 LR 0.1321 LKL 0.0228\n",
      "epoch 3917 loss 0.0951 LR 0.0724 LKL 0.0227\n",
      "epoch 3918 loss 0.0947 LR 0.0716 LKL 0.0231\n",
      "epoch 3919 loss 0.1080 LR 0.0853 LKL 0.0228\n",
      "epoch 3920 loss 0.0422 LR 0.0193 LKL 0.0229\n",
      "epoch 3921 loss 0.0944 LR 0.0715 LKL 0.0229\n",
      "epoch 3922 loss 0.0766 LR 0.0535 LKL 0.0231\n",
      "epoch 3923 loss 0.0723 LR 0.0494 LKL 0.0229\n",
      "epoch 3924 loss 0.0475 LR 0.0245 LKL 0.0230\n",
      "epoch 3925 loss 0.0819 LR 0.0589 LKL 0.0230\n",
      "epoch 3926 loss 0.0624 LR 0.0392 LKL 0.0233\n",
      "epoch 3927 loss 0.0627 LR 0.0396 LKL 0.0232\n",
      "epoch 3928 loss 0.0984 LR 0.0751 LKL 0.0232\n",
      "epoch 3929 loss 0.1007 LR 0.0774 LKL 0.0232\n",
      "epoch 3930 loss 0.0464 LR 0.0230 LKL 0.0234\n",
      "epoch 3931 loss 0.0668 LR 0.0432 LKL 0.0236\n",
      "epoch 3932 loss 0.0412 LR 0.0175 LKL 0.0237\n",
      "epoch 3933 loss 0.0886 LR 0.0649 LKL 0.0237\n",
      "epoch 3934 loss 0.0251 LR 0.0012 LKL 0.0238\n",
      "epoch 3935 loss 0.0449 LR 0.0211 LKL 0.0238\n",
      "epoch 3936 loss 0.0802 LR 0.0566 LKL 0.0236\n",
      "epoch 3937 loss 0.0618 LR 0.0383 LKL 0.0236\n",
      "epoch 3938 loss 0.0453 LR 0.0216 LKL 0.0237\n",
      "epoch 3939 loss 0.0559 LR 0.0323 LKL 0.0236\n",
      "epoch 3940 loss 0.0727 LR 0.0491 LKL 0.0236\n",
      "epoch 3941 loss 0.0588 LR 0.0351 LKL 0.0237\n",
      "epoch 3942 loss 0.1147 LR 0.0914 LKL 0.0233\n",
      "epoch 3943 loss 0.0697 LR 0.0464 LKL 0.0233\n",
      "epoch 3944 loss 0.0678 LR 0.0441 LKL 0.0236\n",
      "epoch 3945 loss 0.1073 LR 0.0839 LKL 0.0234\n",
      "epoch 3946 loss 0.0827 LR 0.0593 LKL 0.0234\n",
      "epoch 3947 loss 0.0457 LR 0.0224 LKL 0.0233\n",
      "epoch 3948 loss 0.0618 LR 0.0385 LKL 0.0233\n",
      "epoch 3949 loss 0.0946 LR 0.0709 LKL 0.0237\n",
      "epoch 3950 loss 0.0986 LR 0.0750 LKL 0.0235\n",
      "epoch 3951 loss 0.0579 LR 0.0343 LKL 0.0236\n",
      "epoch 3952 loss 0.1361 LR 0.1126 LKL 0.0235\n",
      "epoch 3953 loss 0.0837 LR 0.0605 LKL 0.0232\n",
      "epoch 3954 loss 0.1099 LR 0.0870 LKL 0.0229\n",
      "epoch 3955 loss 0.0556 LR 0.0327 LKL 0.0228\n",
      "epoch 3956 loss 0.0684 LR 0.0458 LKL 0.0227\n",
      "epoch 3957 loss 0.0536 LR 0.0310 LKL 0.0227\n",
      "epoch 3958 loss 0.1300 LR 0.1074 LKL 0.0226\n",
      "epoch 3959 loss 0.0530 LR 0.0305 LKL 0.0225\n",
      "epoch 3960 loss 0.0772 LR 0.0547 LKL 0.0225\n",
      "epoch 3961 loss 0.1140 LR 0.0915 LKL 0.0226\n",
      "epoch 3962 loss 0.1116 LR 0.0891 LKL 0.0225\n",
      "epoch 3963 loss 0.0355 LR 0.0129 LKL 0.0227\n",
      "epoch 3964 loss 0.1253 LR 0.1025 LKL 0.0228\n",
      "epoch 3965 loss 0.0967 LR 0.0738 LKL 0.0230\n",
      "epoch 3966 loss 0.0504 LR 0.0274 LKL 0.0230\n",
      "epoch 3967 loss 0.1202 LR 0.0973 LKL 0.0230\n",
      "epoch 3968 loss 0.0246 LR 0.0014 LKL 0.0232\n",
      "epoch 3969 loss 0.0540 LR 0.0308 LKL 0.0232\n",
      "epoch 3970 loss 0.1009 LR 0.0778 LKL 0.0231\n",
      "epoch 3971 loss 0.1167 LR 0.0936 LKL 0.0231\n",
      "epoch 3972 loss 0.0673 LR 0.0437 LKL 0.0236\n",
      "epoch 3973 loss 0.0372 LR 0.0136 LKL 0.0236\n",
      "epoch 3974 loss 0.0104 LR -0.0133 LKL 0.0236\n",
      "epoch 3975 loss 0.0960 LR 0.0727 LKL 0.0232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3976 loss 0.0562 LR 0.0328 LKL 0.0234\n",
      "epoch 3977 loss 0.0836 LR 0.0600 LKL 0.0235\n",
      "epoch 3978 loss 0.0546 LR 0.0310 LKL 0.0236\n",
      "epoch 3979 loss 0.0780 LR 0.0544 LKL 0.0236\n",
      "epoch 3980 loss 0.1126 LR 0.0890 LKL 0.0235\n",
      "epoch 3981 loss 0.1051 LR 0.0816 LKL 0.0234\n",
      "epoch 3982 loss 0.0218 LR -0.0017 LKL 0.0235\n",
      "epoch 3983 loss 0.0564 LR 0.0330 LKL 0.0234\n",
      "epoch 3984 loss 0.0500 LR 0.0267 LKL 0.0233\n",
      "epoch 3985 loss 0.1189 LR 0.0957 LKL 0.0231\n",
      "epoch 3986 loss 0.1229 LR 0.0998 LKL 0.0231\n",
      "epoch 3987 loss 0.0525 LR 0.0298 LKL 0.0227\n",
      "epoch 3988 loss 0.0318 LR 0.0087 LKL 0.0232\n",
      "epoch 3989 loss 0.0996 LR 0.0764 LKL 0.0231\n",
      "epoch 3990 loss 0.0577 LR 0.0345 LKL 0.0232\n",
      "epoch 3991 loss 0.0305 LR 0.0071 LKL 0.0233\n",
      "epoch 3992 loss 0.1033 LR 0.0803 LKL 0.0230\n",
      "epoch 3993 loss 0.0265 LR 0.0034 LKL 0.0231\n",
      "epoch 3994 loss 0.0616 LR 0.0386 LKL 0.0230\n",
      "epoch 3995 loss 0.0778 LR 0.0550 LKL 0.0227\n",
      "epoch 3996 loss 0.1358 LR 0.1130 LKL 0.0228\n",
      "epoch 3997 loss 0.0294 LR 0.0063 LKL 0.0231\n",
      "epoch 3998 loss 0.0994 LR 0.0766 LKL 0.0228\n",
      "epoch 3999 loss 0.1355 LR 0.1125 LKL 0.0230\n",
      "epoch 4000 loss 0.0436 LR 0.0208 LKL 0.0228\n",
      "78\n",
      "epoch 4001 loss 0.1081 LR 0.0852 LKL 0.0229\n",
      "epoch 4002 loss 0.0635 LR 0.0405 LKL 0.0230\n",
      "epoch 4003 loss 0.0929 LR 0.0700 LKL 0.0229\n",
      "epoch 4004 loss 0.0834 LR 0.0606 LKL 0.0228\n",
      "epoch 4005 loss 0.0147 LR -0.0084 LKL 0.0231\n",
      "epoch 4006 loss 0.1249 LR 0.1019 LKL 0.0230\n",
      "epoch 4007 loss 0.0977 LR 0.0745 LKL 0.0232\n",
      "epoch 4008 loss 0.0793 LR 0.0559 LKL 0.0234\n",
      "epoch 4009 loss 0.0848 LR 0.0619 LKL 0.0229\n",
      "epoch 4010 loss 0.0865 LR 0.0635 LKL 0.0230\n",
      "epoch 4011 loss 0.0644 LR 0.0413 LKL 0.0231\n",
      "epoch 4012 loss 0.0584 LR 0.0354 LKL 0.0231\n",
      "epoch 4013 loss 0.1068 LR 0.0837 LKL 0.0231\n",
      "epoch 4014 loss 0.0093 LR -0.0137 LKL 0.0231\n",
      "epoch 4015 loss 0.0635 LR 0.0406 LKL 0.0229\n",
      "epoch 4016 loss 0.0411 LR 0.0181 LKL 0.0231\n",
      "epoch 4017 loss 0.0629 LR 0.0400 LKL 0.0230\n",
      "epoch 4018 loss 0.0321 LR 0.0092 LKL 0.0230\n",
      "epoch 4019 loss 0.0608 LR 0.0379 LKL 0.0228\n",
      "epoch 4020 loss 0.1099 LR 0.0872 LKL 0.0227\n",
      "epoch 4021 loss 0.0405 LR 0.0174 LKL 0.0231\n",
      "epoch 4022 loss 0.0484 LR 0.0251 LKL 0.0233\n",
      "epoch 4023 loss 0.0363 LR 0.0131 LKL 0.0232\n",
      "epoch 4024 loss 0.0456 LR 0.0226 LKL 0.0230\n",
      "epoch 4025 loss 0.0378 LR 0.0147 LKL 0.0231\n",
      "epoch 4026 loss 0.0904 LR 0.0672 LKL 0.0231\n",
      "epoch 4027 loss 0.0898 LR 0.0666 LKL 0.0231\n",
      "epoch 4028 loss 0.0697 LR 0.0465 LKL 0.0232\n",
      "epoch 4029 loss 0.0576 LR 0.0343 LKL 0.0233\n",
      "epoch 4030 loss 0.1420 LR 0.1187 LKL 0.0233\n",
      "epoch 4031 loss 0.0846 LR 0.0614 LKL 0.0231\n",
      "epoch 4032 loss 0.0776 LR 0.0542 LKL 0.0234\n",
      "epoch 4033 loss 0.0653 LR 0.0419 LKL 0.0234\n",
      "epoch 4034 loss 0.0801 LR 0.0565 LKL 0.0236\n",
      "epoch 4035 loss 0.0798 LR 0.0565 LKL 0.0233\n",
      "epoch 4036 loss 0.0188 LR -0.0048 LKL 0.0236\n",
      "epoch 4037 loss 0.0502 LR 0.0269 LKL 0.0233\n",
      "epoch 4038 loss 0.0541 LR 0.0307 LKL 0.0234\n",
      "epoch 4039 loss 0.0878 LR 0.0645 LKL 0.0233\n",
      "epoch 4040 loss 0.0804 LR 0.0570 LKL 0.0235\n",
      "epoch 4041 loss 0.0271 LR 0.0036 LKL 0.0235\n",
      "epoch 4042 loss 0.0772 LR 0.0538 LKL 0.0234\n",
      "epoch 4043 loss 0.0811 LR 0.0576 LKL 0.0234\n",
      "epoch 4044 loss 0.0733 LR 0.0499 LKL 0.0234\n",
      "epoch 4045 loss 0.0462 LR 0.0230 LKL 0.0233\n",
      "epoch 4046 loss 0.0948 LR 0.0716 LKL 0.0231\n",
      "epoch 4047 loss 0.0570 LR 0.0340 LKL 0.0231\n",
      "epoch 4048 loss 0.1421 LR 0.1192 LKL 0.0229\n",
      "epoch 4049 loss 0.0677 LR 0.0448 LKL 0.0229\n",
      "epoch 4050 loss 0.0311 LR 0.0077 LKL 0.0234\n",
      "epoch 4051 loss 0.0714 LR 0.0483 LKL 0.0231\n",
      "epoch 4052 loss 0.0569 LR 0.0338 LKL 0.0231\n",
      "epoch 4053 loss 0.0665 LR 0.0434 LKL 0.0231\n",
      "epoch 4054 loss 0.0392 LR 0.0159 LKL 0.0233\n",
      "epoch 4055 loss 0.0984 LR 0.0751 LKL 0.0233\n",
      "epoch 4056 loss 0.0354 LR 0.0122 LKL 0.0232\n",
      "epoch 4057 loss 0.0414 LR 0.0185 LKL 0.0230\n",
      "epoch 4058 loss 0.0497 LR 0.0264 LKL 0.0232\n",
      "epoch 4059 loss 0.1101 LR 0.0870 LKL 0.0231\n",
      "epoch 4060 loss 0.1183 LR 0.0952 LKL 0.0231\n",
      "epoch 4061 loss 0.0631 LR 0.0400 LKL 0.0231\n",
      "epoch 4062 loss 0.1009 LR 0.0775 LKL 0.0234\n",
      "epoch 4063 loss 0.0249 LR 0.0016 LKL 0.0233\n",
      "epoch 4064 loss 0.0626 LR 0.0394 LKL 0.0233\n",
      "epoch 4065 loss 0.0807 LR 0.0575 LKL 0.0232\n",
      "epoch 4066 loss 0.0225 LR -0.0010 LKL 0.0235\n",
      "epoch 4067 loss 0.0684 LR 0.0446 LKL 0.0238\n",
      "epoch 4068 loss 0.0698 LR 0.0459 LKL 0.0239\n",
      "epoch 4069 loss 0.1005 LR 0.0769 LKL 0.0237\n",
      "epoch 4070 loss 0.0182 LR -0.0056 LKL 0.0237\n",
      "epoch 4071 loss 0.0647 LR 0.0409 LKL 0.0238\n",
      "epoch 4072 loss 0.0606 LR 0.0367 LKL 0.0239\n",
      "epoch 4073 loss 0.1112 LR 0.0875 LKL 0.0237\n",
      "epoch 4074 loss 0.0947 LR 0.0706 LKL 0.0241\n",
      "epoch 4075 loss 0.0377 LR 0.0139 LKL 0.0237\n",
      "epoch 4076 loss 0.0684 LR 0.0446 LKL 0.0238\n",
      "epoch 4077 loss 0.0499 LR 0.0267 LKL 0.0232\n",
      "epoch 4078 loss 0.0398 LR 0.0161 LKL 0.0238\n",
      "epoch 4079 loss 0.1204 LR 0.0968 LKL 0.0236\n",
      "epoch 4080 loss 0.0812 LR 0.0575 LKL 0.0237\n",
      "epoch 4081 loss 0.0409 LR 0.0178 LKL 0.0231\n",
      "epoch 4082 loss 0.0814 LR 0.0580 LKL 0.0234\n",
      "epoch 4083 loss 0.1178 LR 0.0944 LKL 0.0234\n",
      "epoch 4084 loss 0.0264 LR 0.0031 LKL 0.0233\n",
      "epoch 4085 loss 0.0733 LR 0.0500 LKL 0.0232\n",
      "epoch 4086 loss 0.0931 LR 0.0701 LKL 0.0230\n",
      "epoch 4087 loss 0.0506 LR 0.0279 LKL 0.0227\n",
      "epoch 4088 loss 0.0485 LR 0.0257 LKL 0.0228\n",
      "epoch 4089 loss 0.1032 LR 0.0805 LKL 0.0227\n",
      "epoch 4090 loss 0.0428 LR 0.0198 LKL 0.0229\n",
      "epoch 4091 loss 0.0485 LR 0.0255 LKL 0.0230\n",
      "epoch 4092 loss 0.0840 LR 0.0612 LKL 0.0228\n",
      "epoch 4093 loss 0.0798 LR 0.0570 LKL 0.0228\n",
      "epoch 4094 loss 0.0418 LR 0.0186 LKL 0.0232\n",
      "epoch 4095 loss 0.0468 LR 0.0234 LKL 0.0234\n",
      "epoch 4096 loss 0.0277 LR 0.0043 LKL 0.0234\n",
      "epoch 4097 loss 0.0683 LR 0.0451 LKL 0.0232\n",
      "epoch 4098 loss 0.0686 LR 0.0450 LKL 0.0236\n",
      "epoch 4099 loss 0.0895 LR 0.0657 LKL 0.0238\n",
      "epoch 4100 loss 0.0755 LR 0.0517 LKL 0.0238\n",
      "42\n",
      "epoch 4101 loss 0.0817 LR 0.0578 LKL 0.0239\n",
      "epoch 4102 loss 0.0838 LR 0.0603 LKL 0.0235\n",
      "epoch 4103 loss 0.0995 LR 0.0758 LKL 0.0237\n",
      "epoch 4104 loss 0.0812 LR 0.0573 LKL 0.0239\n",
      "epoch 4105 loss 0.0360 LR 0.0120 LKL 0.0240\n",
      "epoch 4106 loss 0.1368 LR 0.1133 LKL 0.0235\n",
      "epoch 4107 loss 0.0994 LR 0.0759 LKL 0.0235\n",
      "epoch 4108 loss 0.0498 LR 0.0261 LKL 0.0237\n",
      "epoch 4109 loss 0.0494 LR 0.0258 LKL 0.0237\n",
      "epoch 4110 loss 0.0794 LR 0.0560 LKL 0.0234\n",
      "epoch 4111 loss 0.0737 LR 0.0505 LKL 0.0233\n",
      "epoch 4112 loss 0.0217 LR -0.0013 LKL 0.0230\n",
      "epoch 4113 loss 0.0812 LR 0.0580 LKL 0.0233\n",
      "epoch 4114 loss 0.0665 LR 0.0437 LKL 0.0228\n",
      "epoch 4115 loss 0.0526 LR 0.0297 LKL 0.0229\n",
      "epoch 4116 loss 0.0886 LR 0.0657 LKL 0.0229\n",
      "epoch 4117 loss 0.1006 LR 0.0777 LKL 0.0229\n",
      "epoch 4118 loss 0.0956 LR 0.0727 LKL 0.0229\n",
      "epoch 4119 loss 0.0842 LR 0.0614 LKL 0.0228\n",
      "epoch 4120 loss 0.0132 LR -0.0098 LKL 0.0229\n",
      "epoch 4121 loss 0.0460 LR 0.0232 LKL 0.0228\n",
      "epoch 4122 loss 0.0232 LR 0.0002 LKL 0.0230\n",
      "epoch 4123 loss 0.0842 LR 0.0615 LKL 0.0227\n",
      "epoch 4124 loss -0.0066 LR -0.0294 LKL 0.0228\n",
      "epoch 4125 loss 0.0619 LR 0.0391 LKL 0.0228\n",
      "epoch 4126 loss 0.0766 LR 0.0538 LKL 0.0228\n",
      "epoch 4127 loss 0.0669 LR 0.0442 LKL 0.0227\n",
      "epoch 4128 loss 0.0829 LR 0.0601 LKL 0.0228\n",
      "epoch 4129 loss 0.0774 LR 0.0548 LKL 0.0226\n",
      "epoch 4130 loss 0.1001 LR 0.0772 LKL 0.0229\n",
      "epoch 4131 loss 0.0730 LR 0.0502 LKL 0.0228\n",
      "epoch 4132 loss 0.0657 LR 0.0427 LKL 0.0229\n",
      "epoch 4133 loss 0.0575 LR 0.0348 LKL 0.0227\n",
      "epoch 4134 loss 0.0739 LR 0.0508 LKL 0.0230\n",
      "epoch 4135 loss 0.0798 LR 0.0568 LKL 0.0230\n",
      "epoch 4136 loss 0.1118 LR 0.0889 LKL 0.0230\n",
      "epoch 4137 loss 0.0638 LR 0.0406 LKL 0.0231\n",
      "epoch 4138 loss 0.0785 LR 0.0555 LKL 0.0231\n",
      "epoch 4139 loss 0.0836 LR 0.0606 LKL 0.0230\n",
      "epoch 4140 loss 0.0508 LR 0.0279 LKL 0.0229\n",
      "epoch 4141 loss 0.0459 LR 0.0230 LKL 0.0229\n",
      "epoch 4142 loss 0.0831 LR 0.0604 LKL 0.0228\n",
      "epoch 4143 loss 0.0268 LR 0.0040 LKL 0.0228\n",
      "epoch 4144 loss 0.0788 LR 0.0560 LKL 0.0228\n",
      "epoch 4145 loss 0.0812 LR 0.0585 LKL 0.0227\n",
      "epoch 4146 loss 0.0571 LR 0.0341 LKL 0.0229\n",
      "epoch 4147 loss 0.0873 LR 0.0644 LKL 0.0229\n",
      "epoch 4148 loss 0.0421 LR 0.0190 LKL 0.0231\n",
      "epoch 4149 loss 0.0378 LR 0.0144 LKL 0.0233\n",
      "epoch 4150 loss 0.1030 LR 0.0795 LKL 0.0235\n",
      "epoch 4151 loss 0.0931 LR 0.0696 LKL 0.0235\n",
      "epoch 4152 loss 0.1029 LR 0.0792 LKL 0.0236\n",
      "epoch 4153 loss -0.0101 LR -0.0339 LKL 0.0238\n",
      "epoch 4154 loss 0.0673 LR 0.0437 LKL 0.0236\n",
      "epoch 4155 loss 0.0896 LR 0.0661 LKL 0.0235\n",
      "epoch 4156 loss 0.0550 LR 0.0312 LKL 0.0237\n",
      "epoch 4157 loss 0.0307 LR 0.0069 LKL 0.0237\n",
      "epoch 4158 loss 0.0146 LR -0.0091 LKL 0.0238\n",
      "epoch 4159 loss 0.0754 LR 0.0516 LKL 0.0238\n",
      "epoch 4160 loss 0.0304 LR 0.0068 LKL 0.0236\n",
      "epoch 4161 loss 0.0875 LR 0.0640 LKL 0.0235\n",
      "epoch 4162 loss 0.0920 LR 0.0685 LKL 0.0235\n",
      "epoch 4163 loss 0.0714 LR 0.0481 LKL 0.0234\n",
      "epoch 4164 loss 0.0711 LR 0.0475 LKL 0.0236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4165 loss 0.0862 LR 0.0626 LKL 0.0237\n",
      "epoch 4166 loss 0.0125 LR -0.0110 LKL 0.0235\n",
      "epoch 4167 loss 0.0264 LR 0.0029 LKL 0.0235\n",
      "epoch 4168 loss 0.0814 LR 0.0584 LKL 0.0230\n",
      "epoch 4169 loss 0.0775 LR 0.0546 LKL 0.0228\n",
      "epoch 4170 loss 0.0536 LR 0.0307 LKL 0.0229\n",
      "epoch 4171 loss 0.0823 LR 0.0595 LKL 0.0228\n",
      "epoch 4172 loss 0.0309 LR 0.0079 LKL 0.0230\n",
      "epoch 4173 loss 0.0568 LR 0.0338 LKL 0.0230\n",
      "epoch 4174 loss 0.0695 LR 0.0467 LKL 0.0228\n",
      "epoch 4175 loss 0.0476 LR 0.0245 LKL 0.0231\n",
      "epoch 4176 loss 0.0491 LR 0.0260 LKL 0.0230\n",
      "epoch 4177 loss 0.0731 LR 0.0500 LKL 0.0231\n",
      "epoch 4178 loss 0.0523 LR 0.0293 LKL 0.0230\n",
      "epoch 4179 loss 0.0503 LR 0.0269 LKL 0.0233\n",
      "epoch 4180 loss 0.0438 LR 0.0208 LKL 0.0229\n",
      "epoch 4181 loss 0.0859 LR 0.0627 LKL 0.0233\n",
      "epoch 4182 loss 0.0395 LR 0.0163 LKL 0.0232\n",
      "epoch 4183 loss 0.1066 LR 0.0834 LKL 0.0232\n",
      "epoch 4184 loss 0.0987 LR 0.0757 LKL 0.0230\n",
      "epoch 4185 loss 0.0773 LR 0.0545 LKL 0.0229\n",
      "epoch 4186 loss 0.0429 LR 0.0197 LKL 0.0231\n",
      "epoch 4187 loss 0.0423 LR 0.0191 LKL 0.0232\n",
      "epoch 4188 loss 0.1026 LR 0.0795 LKL 0.0230\n",
      "epoch 4189 loss 0.0642 LR 0.0410 LKL 0.0232\n",
      "epoch 4190 loss 0.0787 LR 0.0556 LKL 0.0231\n",
      "epoch 4191 loss 0.0731 LR 0.0500 LKL 0.0231\n",
      "epoch 4192 loss 0.0416 LR 0.0185 LKL 0.0230\n",
      "epoch 4193 loss 0.0769 LR 0.0538 LKL 0.0231\n",
      "epoch 4194 loss 0.1140 LR 0.0907 LKL 0.0233\n",
      "epoch 4195 loss 0.0606 LR 0.0372 LKL 0.0234\n",
      "epoch 4196 loss 0.0417 LR 0.0181 LKL 0.0236\n",
      "epoch 4197 loss 0.0703 LR 0.0470 LKL 0.0233\n",
      "epoch 4198 loss 0.1085 LR 0.0849 LKL 0.0236\n",
      "epoch 4199 loss 0.0564 LR 0.0329 LKL 0.0235\n",
      "epoch 4200 loss 0.0460 LR 0.0229 LKL 0.0231\n",
      "52\n",
      "epoch 4201 loss 0.0811 LR 0.0579 LKL 0.0233\n",
      "epoch 4202 loss 0.0382 LR 0.0150 LKL 0.0232\n",
      "epoch 4203 loss 0.0703 LR 0.0472 LKL 0.0231\n",
      "epoch 4204 loss 0.1067 LR 0.0834 LKL 0.0233\n",
      "epoch 4205 loss 0.0601 LR 0.0370 LKL 0.0231\n",
      "epoch 4206 loss 0.0878 LR 0.0648 LKL 0.0230\n",
      "epoch 4207 loss 0.0639 LR 0.0411 LKL 0.0228\n",
      "epoch 4208 loss 0.1452 LR 0.1224 LKL 0.0228\n",
      "epoch 4209 loss 0.1012 LR 0.0784 LKL 0.0228\n",
      "epoch 4210 loss 0.0704 LR 0.0474 LKL 0.0230\n",
      "epoch 4211 loss 0.0815 LR 0.0586 LKL 0.0229\n",
      "epoch 4212 loss 0.0490 LR 0.0261 LKL 0.0229\n",
      "epoch 4213 loss 0.0358 LR 0.0129 LKL 0.0229\n",
      "epoch 4214 loss 0.0952 LR 0.0725 LKL 0.0227\n",
      "epoch 4215 loss 0.0089 LR -0.0141 LKL 0.0231\n",
      "epoch 4216 loss 0.0647 LR 0.0417 LKL 0.0230\n",
      "epoch 4217 loss 0.0476 LR 0.0245 LKL 0.0232\n",
      "epoch 4218 loss 0.0351 LR 0.0119 LKL 0.0233\n",
      "epoch 4219 loss 0.0470 LR 0.0239 LKL 0.0231\n",
      "epoch 4220 loss 0.0826 LR 0.0595 LKL 0.0232\n",
      "epoch 4221 loss 0.0614 LR 0.0378 LKL 0.0235\n",
      "epoch 4222 loss 0.0377 LR 0.0143 LKL 0.0235\n",
      "epoch 4223 loss 0.0145 LR -0.0089 LKL 0.0234\n",
      "epoch 4224 loss 0.0366 LR 0.0131 LKL 0.0235\n",
      "epoch 4225 loss 0.0543 LR 0.0306 LKL 0.0236\n",
      "epoch 4226 loss 0.0583 LR 0.0349 LKL 0.0234\n",
      "epoch 4227 loss 0.0103 LR -0.0133 LKL 0.0236\n",
      "epoch 4228 loss 0.0706 LR 0.0471 LKL 0.0235\n",
      "epoch 4229 loss 0.0549 LR 0.0318 LKL 0.0231\n",
      "epoch 4230 loss 0.0531 LR 0.0298 LKL 0.0233\n",
      "epoch 4231 loss 0.0765 LR 0.0533 LKL 0.0232\n",
      "epoch 4232 loss 0.0870 LR 0.0640 LKL 0.0230\n",
      "epoch 4233 loss 0.0149 LR -0.0081 LKL 0.0230\n",
      "epoch 4234 loss 0.0343 LR 0.0113 LKL 0.0231\n",
      "epoch 4235 loss 0.1223 LR 0.0994 LKL 0.0229\n",
      "epoch 4236 loss 0.0956 LR 0.0726 LKL 0.0230\n",
      "epoch 4237 loss 0.1156 LR 0.0925 LKL 0.0231\n",
      "epoch 4238 loss 0.0003 LR -0.0229 LKL 0.0231\n",
      "epoch 4239 loss 0.0456 LR 0.0223 LKL 0.0233\n",
      "epoch 4240 loss 0.0818 LR 0.0585 LKL 0.0234\n",
      "epoch 4241 loss 0.1356 LR 0.1124 LKL 0.0232\n",
      "epoch 4242 loss 0.0854 LR 0.0621 LKL 0.0232\n",
      "epoch 4243 loss 0.1038 LR 0.0806 LKL 0.0232\n",
      "epoch 4244 loss 0.0837 LR 0.0605 LKL 0.0232\n",
      "epoch 4245 loss 0.0671 LR 0.0438 LKL 0.0232\n",
      "epoch 4246 loss 0.1247 LR 0.1014 LKL 0.0233\n",
      "epoch 4247 loss 0.0530 LR 0.0298 LKL 0.0232\n",
      "epoch 4248 loss 0.0563 LR 0.0331 LKL 0.0231\n",
      "epoch 4249 loss 0.1245 LR 0.1011 LKL 0.0234\n",
      "epoch 4250 loss 0.0357 LR 0.0125 LKL 0.0232\n",
      "epoch 4251 loss 0.0755 LR 0.0527 LKL 0.0227\n",
      "epoch 4252 loss 0.1024 LR 0.0792 LKL 0.0232\n",
      "epoch 4253 loss 0.1129 LR 0.0898 LKL 0.0231\n",
      "epoch 4254 loss 0.0135 LR -0.0099 LKL 0.0234\n",
      "epoch 4255 loss 0.0938 LR 0.0706 LKL 0.0233\n",
      "epoch 4256 loss 0.0660 LR 0.0427 LKL 0.0233\n",
      "epoch 4257 loss 0.0815 LR 0.0579 LKL 0.0236\n",
      "epoch 4258 loss 0.0522 LR 0.0287 LKL 0.0236\n",
      "epoch 4259 loss 0.0966 LR 0.0729 LKL 0.0237\n",
      "epoch 4260 loss 0.0317 LR 0.0078 LKL 0.0239\n",
      "epoch 4261 loss 0.0484 LR 0.0246 LKL 0.0238\n",
      "epoch 4262 loss 0.0256 LR 0.0020 LKL 0.0236\n",
      "epoch 4263 loss 0.0423 LR 0.0188 LKL 0.0235\n",
      "epoch 4264 loss 0.0527 LR 0.0293 LKL 0.0234\n",
      "epoch 4265 loss 0.0419 LR 0.0186 LKL 0.0233\n",
      "epoch 4266 loss 0.0515 LR 0.0279 LKL 0.0235\n",
      "epoch 4267 loss 0.0917 LR 0.0681 LKL 0.0236\n",
      "epoch 4268 loss 0.0958 LR 0.0721 LKL 0.0236\n",
      "epoch 4269 loss 0.1014 LR 0.0779 LKL 0.0235\n",
      "epoch 4270 loss 0.0480 LR 0.0243 LKL 0.0237\n",
      "epoch 4271 loss 0.0389 LR 0.0153 LKL 0.0236\n",
      "epoch 4272 loss 0.0247 LR 0.0011 LKL 0.0236\n",
      "epoch 4273 loss 0.0819 LR 0.0585 LKL 0.0234\n",
      "epoch 4274 loss 0.0298 LR 0.0062 LKL 0.0236\n",
      "epoch 4275 loss 0.0472 LR 0.0237 LKL 0.0234\n",
      "epoch 4276 loss 0.0741 LR 0.0510 LKL 0.0232\n",
      "epoch 4277 loss 0.0940 LR 0.0708 LKL 0.0232\n",
      "epoch 4278 loss 0.0152 LR -0.0083 LKL 0.0235\n",
      "epoch 4279 loss 0.0619 LR 0.0386 LKL 0.0233\n",
      "epoch 4280 loss 0.0158 LR -0.0074 LKL 0.0232\n",
      "epoch 4281 loss 0.0456 LR 0.0224 LKL 0.0232\n",
      "epoch 4282 loss -0.0299 LR -0.0533 LKL 0.0234\n",
      "epoch 4283 loss 0.1366 LR 0.1136 LKL 0.0230\n",
      "epoch 4284 loss 0.0469 LR 0.0238 LKL 0.0231\n",
      "epoch 4285 loss 0.0418 LR 0.0188 LKL 0.0230\n",
      "epoch 4286 loss 0.0445 LR 0.0212 LKL 0.0233\n",
      "epoch 4287 loss -0.0017 LR -0.0250 LKL 0.0232\n",
      "epoch 4288 loss 0.0251 LR 0.0019 LKL 0.0232\n",
      "epoch 4289 loss 0.0422 LR 0.0190 LKL 0.0231\n",
      "epoch 4290 loss 0.0734 LR 0.0503 LKL 0.0231\n",
      "epoch 4291 loss 0.0485 LR 0.0251 LKL 0.0234\n",
      "epoch 4292 loss 0.0413 LR 0.0176 LKL 0.0236\n",
      "epoch 4293 loss 0.0910 LR 0.0677 LKL 0.0233\n",
      "epoch 4294 loss -0.0002 LR -0.0237 LKL 0.0235\n",
      "epoch 4295 loss 0.0763 LR 0.0528 LKL 0.0235\n",
      "epoch 4296 loss 0.0704 LR 0.0467 LKL 0.0236\n",
      "epoch 4297 loss 0.0982 LR 0.0747 LKL 0.0235\n",
      "epoch 4298 loss 0.0411 LR 0.0177 LKL 0.0233\n",
      "epoch 4299 loss 0.0557 LR 0.0319 LKL 0.0238\n",
      "epoch 4300 loss 0.0175 LR -0.0059 LKL 0.0234\n",
      "53\n",
      "epoch 4301 loss 0.1107 LR 0.0874 LKL 0.0232\n",
      "epoch 4302 loss 0.0422 LR 0.0189 LKL 0.0233\n",
      "epoch 4303 loss 0.0820 LR 0.0586 LKL 0.0234\n",
      "epoch 4304 loss 0.0827 LR 0.0593 LKL 0.0234\n",
      "epoch 4305 loss 0.0234 LR 0.0000 LKL 0.0234\n",
      "epoch 4306 loss 0.0388 LR 0.0154 LKL 0.0234\n",
      "epoch 4307 loss 0.0169 LR -0.0065 LKL 0.0234\n",
      "epoch 4308 loss 0.0415 LR 0.0179 LKL 0.0236\n",
      "epoch 4309 loss 0.0327 LR 0.0094 LKL 0.0233\n",
      "epoch 4310 loss 0.0973 LR 0.0742 LKL 0.0231\n",
      "epoch 4311 loss 0.1165 LR 0.0930 LKL 0.0235\n",
      "epoch 4312 loss 0.0792 LR 0.0560 LKL 0.0232\n",
      "epoch 4313 loss 0.0868 LR 0.0634 LKL 0.0235\n",
      "epoch 4314 loss 0.0738 LR 0.0504 LKL 0.0234\n",
      "epoch 4315 loss 0.1114 LR 0.0877 LKL 0.0237\n",
      "epoch 4316 loss 0.0387 LR 0.0150 LKL 0.0237\n",
      "epoch 4317 loss 0.1208 LR 0.0972 LKL 0.0235\n",
      "epoch 4318 loss 0.0948 LR 0.0712 LKL 0.0236\n",
      "epoch 4319 loss 0.0727 LR 0.0490 LKL 0.0237\n",
      "epoch 4320 loss 0.0652 LR 0.0419 LKL 0.0234\n",
      "epoch 4321 loss 0.0634 LR 0.0399 LKL 0.0235\n",
      "epoch 4322 loss 0.0319 LR 0.0083 LKL 0.0236\n",
      "epoch 4323 loss 0.0665 LR 0.0432 LKL 0.0233\n",
      "epoch 4324 loss 0.0774 LR 0.0543 LKL 0.0231\n",
      "epoch 4325 loss 0.0679 LR 0.0444 LKL 0.0235\n",
      "epoch 4326 loss 0.0275 LR 0.0040 LKL 0.0234\n",
      "epoch 4327 loss 0.1146 LR 0.0914 LKL 0.0232\n",
      "epoch 4328 loss 0.0329 LR 0.0098 LKL 0.0231\n",
      "epoch 4329 loss 0.0895 LR 0.0665 LKL 0.0230\n",
      "epoch 4330 loss 0.0510 LR 0.0279 LKL 0.0231\n",
      "epoch 4331 loss 0.0394 LR 0.0164 LKL 0.0230\n",
      "epoch 4332 loss 0.0264 LR 0.0031 LKL 0.0233\n",
      "epoch 4333 loss 0.0543 LR 0.0309 LKL 0.0234\n",
      "epoch 4334 loss 0.1215 LR 0.0984 LKL 0.0231\n",
      "epoch 4335 loss -0.0230 LR -0.0467 LKL 0.0236\n",
      "epoch 4336 loss 0.0733 LR 0.0494 LKL 0.0238\n",
      "epoch 4337 loss 0.1195 LR 0.0960 LKL 0.0235\n",
      "epoch 4338 loss 0.0424 LR 0.0188 LKL 0.0236\n",
      "epoch 4339 loss 0.0735 LR 0.0494 LKL 0.0240\n",
      "epoch 4340 loss 0.1299 LR 0.1061 LKL 0.0238\n",
      "epoch 4341 loss 0.0472 LR 0.0232 LKL 0.0240\n",
      "epoch 4342 loss 0.0038 LR -0.0199 LKL 0.0238\n",
      "epoch 4343 loss 0.0480 LR 0.0242 LKL 0.0238\n",
      "epoch 4344 loss 0.0431 LR 0.0195 LKL 0.0236\n",
      "epoch 4345 loss -0.0008 LR -0.0248 LKL 0.0240\n",
      "epoch 4346 loss 0.0160 LR -0.0080 LKL 0.0240\n",
      "epoch 4347 loss 0.1044 LR 0.0810 LKL 0.0234\n",
      "epoch 4348 loss 0.0740 LR 0.0503 LKL 0.0237\n",
      "epoch 4349 loss 0.0443 LR 0.0205 LKL 0.0237\n",
      "epoch 4350 loss 0.0511 LR 0.0275 LKL 0.0236\n",
      "epoch 4351 loss 0.0351 LR 0.0115 LKL 0.0236\n",
      "epoch 4352 loss -0.0096 LR -0.0331 LKL 0.0235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4353 loss 0.0679 LR 0.0446 LKL 0.0233\n",
      "epoch 4354 loss 0.0665 LR 0.0434 LKL 0.0231\n",
      "epoch 4355 loss 0.1316 LR 0.1086 LKL 0.0230\n",
      "epoch 4356 loss 0.0495 LR 0.0261 LKL 0.0234\n",
      "epoch 4357 loss 0.0396 LR 0.0162 LKL 0.0234\n",
      "epoch 4358 loss 0.0638 LR 0.0406 LKL 0.0232\n",
      "epoch 4359 loss 0.0477 LR 0.0242 LKL 0.0235\n",
      "epoch 4360 loss 0.0879 LR 0.0646 LKL 0.0233\n",
      "epoch 4361 loss 0.1046 LR 0.0813 LKL 0.0233\n",
      "epoch 4362 loss 0.0889 LR 0.0655 LKL 0.0235\n",
      "epoch 4363 loss 0.0602 LR 0.0370 LKL 0.0232\n",
      "epoch 4364 loss 0.0606 LR 0.0376 LKL 0.0230\n",
      "epoch 4365 loss 0.0434 LR 0.0202 LKL 0.0232\n",
      "epoch 4366 loss 0.0090 LR -0.0144 LKL 0.0234\n",
      "epoch 4367 loss 0.0295 LR 0.0062 LKL 0.0234\n",
      "epoch 4368 loss 0.0361 LR 0.0126 LKL 0.0234\n",
      "epoch 4369 loss 0.1271 LR 0.1040 LKL 0.0231\n",
      "epoch 4370 loss 0.0327 LR 0.0094 LKL 0.0233\n",
      "epoch 4371 loss 0.0805 LR 0.0575 LKL 0.0230\n",
      "epoch 4372 loss 0.0155 LR -0.0079 LKL 0.0234\n",
      "epoch 4373 loss 0.1126 LR 0.0893 LKL 0.0233\n",
      "epoch 4374 loss 0.0656 LR 0.0423 LKL 0.0233\n",
      "epoch 4375 loss 0.0525 LR 0.0292 LKL 0.0233\n",
      "epoch 4376 loss 0.0687 LR 0.0454 LKL 0.0233\n",
      "epoch 4377 loss 0.0453 LR 0.0216 LKL 0.0236\n",
      "epoch 4378 loss 0.0723 LR 0.0489 LKL 0.0234\n",
      "epoch 4379 loss 0.0460 LR 0.0223 LKL 0.0237\n",
      "epoch 4380 loss 0.0669 LR 0.0436 LKL 0.0233\n",
      "epoch 4381 loss 0.1046 LR 0.0814 LKL 0.0232\n",
      "epoch 4382 loss 0.0599 LR 0.0365 LKL 0.0235\n",
      "epoch 4383 loss 0.0606 LR 0.0372 LKL 0.0235\n",
      "epoch 4384 loss 0.0910 LR 0.0674 LKL 0.0236\n",
      "epoch 4385 loss 0.0249 LR 0.0014 LKL 0.0235\n",
      "epoch 4386 loss 0.0540 LR 0.0303 LKL 0.0237\n",
      "epoch 4387 loss 0.0145 LR -0.0091 LKL 0.0237\n",
      "epoch 4388 loss 0.0269 LR 0.0033 LKL 0.0236\n",
      "epoch 4389 loss 0.0536 LR 0.0300 LKL 0.0236\n",
      "epoch 4390 loss 0.0466 LR 0.0229 LKL 0.0237\n",
      "epoch 4391 loss 0.0475 LR 0.0241 LKL 0.0234\n",
      "epoch 4392 loss 0.0529 LR 0.0294 LKL 0.0235\n",
      "epoch 4393 loss 0.0426 LR 0.0192 LKL 0.0235\n",
      "epoch 4394 loss 0.0637 LR 0.0405 LKL 0.0232\n",
      "epoch 4395 loss 0.0294 LR 0.0060 LKL 0.0234\n",
      "epoch 4396 loss 0.0860 LR 0.0628 LKL 0.0232\n",
      "epoch 4397 loss 0.0799 LR 0.0566 LKL 0.0232\n",
      "epoch 4398 loss 0.0563 LR 0.0331 LKL 0.0233\n",
      "epoch 4399 loss 0.0358 LR 0.0125 LKL 0.0232\n",
      "epoch 4400 loss 0.0954 LR 0.0723 LKL 0.0231\n",
      "106\n",
      "epoch 4401 loss 0.0094 LR -0.0139 LKL 0.0233\n",
      "epoch 4402 loss 0.0053 LR -0.0179 LKL 0.0233\n",
      "epoch 4403 loss 0.0105 LR -0.0129 LKL 0.0234\n",
      "epoch 4404 loss 0.0868 LR 0.0633 LKL 0.0234\n",
      "epoch 4405 loss 0.0218 LR -0.0015 LKL 0.0234\n",
      "epoch 4406 loss 0.0534 LR 0.0302 LKL 0.0233\n",
      "epoch 4407 loss 0.0072 LR -0.0162 LKL 0.0234\n",
      "epoch 4408 loss 0.0452 LR 0.0218 LKL 0.0235\n",
      "epoch 4409 loss 0.0776 LR 0.0543 LKL 0.0234\n",
      "epoch 4410 loss 0.1015 LR 0.0782 LKL 0.0233\n",
      "epoch 4411 loss 0.0683 LR 0.0447 LKL 0.0235\n",
      "epoch 4412 loss 0.0844 LR 0.0609 LKL 0.0235\n",
      "epoch 4413 loss 0.0722 LR 0.0486 LKL 0.0236\n",
      "epoch 4414 loss 0.0736 LR 0.0502 LKL 0.0233\n",
      "epoch 4415 loss 0.0250 LR 0.0016 LKL 0.0233\n",
      "epoch 4416 loss 0.0564 LR 0.0328 LKL 0.0236\n",
      "epoch 4417 loss 0.0587 LR 0.0350 LKL 0.0237\n",
      "epoch 4418 loss 0.0492 LR 0.0258 LKL 0.0234\n",
      "epoch 4419 loss 0.0372 LR 0.0135 LKL 0.0237\n",
      "epoch 4420 loss 0.0837 LR 0.0600 LKL 0.0237\n",
      "epoch 4421 loss 0.0958 LR 0.0721 LKL 0.0237\n",
      "epoch 4422 loss 0.0895 LR 0.0656 LKL 0.0239\n",
      "epoch 4423 loss 0.0498 LR 0.0258 LKL 0.0240\n",
      "epoch 4424 loss 0.0736 LR 0.0496 LKL 0.0240\n",
      "epoch 4425 loss 0.0693 LR 0.0453 LKL 0.0240\n",
      "epoch 4426 loss 0.0517 LR 0.0277 LKL 0.0240\n",
      "epoch 4427 loss 0.0265 LR 0.0024 LKL 0.0241\n",
      "epoch 4428 loss 0.1083 LR 0.0845 LKL 0.0239\n",
      "epoch 4429 loss 0.0770 LR 0.0532 LKL 0.0238\n",
      "epoch 4430 loss 0.0754 LR 0.0512 LKL 0.0241\n",
      "epoch 4431 loss 0.0541 LR 0.0303 LKL 0.0239\n",
      "epoch 4432 loss 0.1240 LR 0.1002 LKL 0.0238\n",
      "epoch 4433 loss 0.0708 LR 0.0468 LKL 0.0239\n",
      "epoch 4434 loss 0.0585 LR 0.0345 LKL 0.0240\n",
      "epoch 4435 loss -0.0090 LR -0.0329 LKL 0.0239\n",
      "epoch 4436 loss 0.0282 LR 0.0046 LKL 0.0236\n",
      "epoch 4437 loss 0.0476 LR 0.0240 LKL 0.0236\n",
      "epoch 4438 loss 0.0118 LR -0.0119 LKL 0.0237\n",
      "epoch 4439 loss 0.0753 LR 0.0517 LKL 0.0236\n",
      "epoch 4440 loss 0.0303 LR 0.0066 LKL 0.0237\n",
      "epoch 4441 loss 0.0453 LR 0.0217 LKL 0.0235\n",
      "epoch 4442 loss 0.0403 LR 0.0170 LKL 0.0234\n",
      "epoch 4443 loss 0.0848 LR 0.0610 LKL 0.0238\n",
      "epoch 4444 loss 0.0195 LR -0.0042 LKL 0.0237\n",
      "epoch 4445 loss 0.0514 LR 0.0276 LKL 0.0238\n",
      "epoch 4446 loss 0.0678 LR 0.0442 LKL 0.0236\n",
      "epoch 4447 loss 0.1007 LR 0.0774 LKL 0.0233\n",
      "epoch 4448 loss 0.0752 LR 0.0518 LKL 0.0234\n",
      "epoch 4449 loss 0.0256 LR 0.0021 LKL 0.0235\n",
      "epoch 4450 loss 0.0705 LR 0.0471 LKL 0.0233\n",
      "epoch 4451 loss 0.0294 LR 0.0063 LKL 0.0232\n",
      "epoch 4452 loss 0.0500 LR 0.0269 LKL 0.0230\n",
      "epoch 4453 loss 0.0690 LR 0.0458 LKL 0.0232\n",
      "epoch 4454 loss 0.0475 LR 0.0243 LKL 0.0233\n",
      "epoch 4455 loss 0.0758 LR 0.0525 LKL 0.0234\n",
      "epoch 4456 loss 0.0415 LR 0.0183 LKL 0.0231\n",
      "epoch 4457 loss 0.0207 LR -0.0027 LKL 0.0234\n",
      "epoch 4458 loss 0.0644 LR 0.0411 LKL 0.0233\n",
      "epoch 4459 loss 0.0499 LR 0.0264 LKL 0.0234\n",
      "epoch 4460 loss 0.0259 LR 0.0021 LKL 0.0239\n",
      "epoch 4461 loss 0.0375 LR 0.0137 LKL 0.0239\n",
      "epoch 4462 loss 0.0698 LR 0.0458 LKL 0.0240\n",
      "epoch 4463 loss 0.0878 LR 0.0639 LKL 0.0239\n",
      "epoch 4464 loss -0.0012 LR -0.0255 LKL 0.0242\n",
      "epoch 4465 loss 0.0553 LR 0.0311 LKL 0.0242\n",
      "epoch 4466 loss 0.0358 LR 0.0116 LKL 0.0242\n",
      "epoch 4467 loss 0.0298 LR 0.0053 LKL 0.0245\n",
      "epoch 4468 loss 0.0649 LR 0.0404 LKL 0.0245\n",
      "epoch 4469 loss 0.0542 LR 0.0299 LKL 0.0243\n",
      "epoch 4470 loss 0.0268 LR 0.0023 LKL 0.0246\n",
      "epoch 4471 loss 0.0405 LR 0.0162 LKL 0.0243\n",
      "epoch 4472 loss 0.0663 LR 0.0418 LKL 0.0245\n",
      "epoch 4473 loss 0.0947 LR 0.0707 LKL 0.0240\n",
      "epoch 4474 loss 0.0427 LR 0.0185 LKL 0.0242\n",
      "epoch 4475 loss 0.0875 LR 0.0633 LKL 0.0242\n",
      "epoch 4476 loss 0.0755 LR 0.0517 LKL 0.0239\n",
      "epoch 4477 loss 0.1133 LR 0.0895 LKL 0.0238\n",
      "epoch 4478 loss -0.0033 LR -0.0271 LKL 0.0238\n",
      "epoch 4479 loss 0.0482 LR 0.0246 LKL 0.0236\n",
      "epoch 4480 loss 0.0527 LR 0.0290 LKL 0.0237\n",
      "epoch 4481 loss 0.0750 LR 0.0517 LKL 0.0233\n",
      "epoch 4482 loss 0.0284 LR 0.0052 LKL 0.0232\n",
      "epoch 4483 loss 0.1009 LR 0.0777 LKL 0.0232\n",
      "epoch 4484 loss 0.0784 LR 0.0553 LKL 0.0231\n",
      "epoch 4485 loss 0.0590 LR 0.0363 LKL 0.0227\n",
      "epoch 4486 loss 0.0252 LR 0.0024 LKL 0.0228\n",
      "epoch 4487 loss 0.0212 LR -0.0012 LKL 0.0225\n",
      "epoch 4488 loss 0.0687 LR 0.0462 LKL 0.0225\n",
      "epoch 4489 loss 0.0715 LR 0.0491 LKL 0.0224\n",
      "epoch 4490 loss 0.0499 LR 0.0271 LKL 0.0228\n",
      "epoch 4491 loss 0.0174 LR -0.0054 LKL 0.0228\n",
      "epoch 4492 loss 0.0159 LR -0.0071 LKL 0.0230\n",
      "epoch 4493 loss 0.0255 LR 0.0027 LKL 0.0229\n",
      "epoch 4494 loss 0.0769 LR 0.0539 LKL 0.0230\n",
      "epoch 4495 loss 0.0514 LR 0.0282 LKL 0.0232\n",
      "epoch 4496 loss 0.0309 LR 0.0073 LKL 0.0236\n",
      "epoch 4497 loss 0.0226 LR -0.0008 LKL 0.0234\n",
      "epoch 4498 loss 0.0272 LR 0.0037 LKL 0.0235\n",
      "epoch 4499 loss 0.0922 LR 0.0683 LKL 0.0240\n",
      "epoch 4500 loss 0.0440 LR 0.0200 LKL 0.0240\n",
      "epoch 4501 loss 0.0702 LR 0.0461 LKL 0.0241\n",
      "epoch 4502 loss 0.0979 LR 0.0739 LKL 0.0240\n",
      "epoch 4503 loss 0.0398 LR 0.0156 LKL 0.0242\n",
      "epoch 4504 loss 0.0976 LR 0.0735 LKL 0.0241\n",
      "epoch 4505 loss 0.0997 LR 0.0759 LKL 0.0238\n",
      "epoch 4506 loss 0.0274 LR 0.0034 LKL 0.0239\n",
      "epoch 4507 loss 0.0472 LR 0.0235 LKL 0.0237\n",
      "epoch 4508 loss 0.0835 LR 0.0598 LKL 0.0237\n",
      "epoch 4509 loss 0.0257 LR 0.0020 LKL 0.0237\n",
      "epoch 4510 loss 0.0276 LR 0.0040 LKL 0.0236\n",
      "epoch 4511 loss 0.0667 LR 0.0432 LKL 0.0235\n",
      "epoch 4512 loss 0.0843 LR 0.0609 LKL 0.0235\n",
      "epoch 4513 loss 0.0887 LR 0.0650 LKL 0.0237\n",
      "epoch 4514 loss 0.0867 LR 0.0631 LKL 0.0236\n",
      "epoch 4515 loss 0.1071 LR 0.0835 LKL 0.0236\n",
      "epoch 4516 loss 0.0611 LR 0.0376 LKL 0.0236\n",
      "epoch 4517 loss 0.0716 LR 0.0479 LKL 0.0237\n",
      "epoch 4518 loss 0.0352 LR 0.0115 LKL 0.0236\n",
      "epoch 4519 loss 0.0588 LR 0.0353 LKL 0.0236\n",
      "epoch 4520 loss 0.0936 LR 0.0700 LKL 0.0236\n",
      "epoch 4521 loss 0.0478 LR 0.0243 LKL 0.0235\n",
      "epoch 4522 loss 0.0459 LR 0.0224 LKL 0.0235\n",
      "epoch 4523 loss 0.0879 LR 0.0643 LKL 0.0235\n",
      "epoch 4524 loss 0.0374 LR 0.0141 LKL 0.0233\n",
      "epoch 4525 loss 0.0392 LR 0.0157 LKL 0.0235\n",
      "epoch 4526 loss 0.0803 LR 0.0569 LKL 0.0234\n",
      "epoch 4527 loss 0.0961 LR 0.0728 LKL 0.0233\n",
      "epoch 4528 loss 0.0912 LR 0.0679 LKL 0.0232\n",
      "epoch 4529 loss 0.0690 LR 0.0458 LKL 0.0232\n",
      "epoch 4530 loss 0.0692 LR 0.0463 LKL 0.0229\n",
      "epoch 4531 loss 0.0634 LR 0.0399 LKL 0.0235\n",
      "epoch 4532 loss 0.0675 LR 0.0446 LKL 0.0229\n",
      "epoch 4533 loss 0.0548 LR 0.0316 LKL 0.0231\n",
      "epoch 4534 loss 0.0162 LR -0.0070 LKL 0.0232\n",
      "epoch 4535 loss 0.0984 LR 0.0752 LKL 0.0232\n",
      "epoch 4536 loss 0.0515 LR 0.0283 LKL 0.0232\n",
      "epoch 4537 loss 0.0418 LR 0.0187 LKL 0.0231\n",
      "epoch 4538 loss 0.0356 LR 0.0124 LKL 0.0231\n",
      "epoch 4539 loss 0.0518 LR 0.0285 LKL 0.0233\n",
      "epoch 4540 loss 0.0365 LR 0.0133 LKL 0.0232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4541 loss -0.0057 LR -0.0292 LKL 0.0235\n",
      "epoch 4542 loss 0.0071 LR -0.0159 LKL 0.0230\n",
      "epoch 4543 loss 0.0649 LR 0.0417 LKL 0.0231\n",
      "epoch 4544 loss 0.0368 LR 0.0137 LKL 0.0232\n",
      "epoch 4545 loss 0.0922 LR 0.0691 LKL 0.0231\n",
      "epoch 4546 loss 0.0448 LR 0.0215 LKL 0.0232\n",
      "epoch 4547 loss 0.0451 LR 0.0222 LKL 0.0229\n",
      "epoch 4548 loss 0.0573 LR 0.0344 LKL 0.0228\n",
      "epoch 4549 loss 0.0335 LR 0.0105 LKL 0.0230\n",
      "epoch 4550 loss 0.0595 LR 0.0364 LKL 0.0230\n",
      "epoch 4551 loss 0.0417 LR 0.0182 LKL 0.0234\n",
      "epoch 4552 loss 0.0391 LR 0.0159 LKL 0.0232\n",
      "epoch 4553 loss 0.0682 LR 0.0445 LKL 0.0238\n",
      "epoch 4554 loss 0.0812 LR 0.0580 LKL 0.0232\n",
      "epoch 4555 loss 0.1045 LR 0.0812 LKL 0.0233\n",
      "epoch 4556 loss 0.0522 LR 0.0288 LKL 0.0234\n",
      "epoch 4557 loss 0.0707 LR 0.0473 LKL 0.0235\n",
      "epoch 4558 loss 0.0075 LR -0.0162 LKL 0.0237\n",
      "epoch 4559 loss 0.1240 LR 0.1002 LKL 0.0238\n",
      "epoch 4560 loss 0.0717 LR 0.0481 LKL 0.0236\n",
      "epoch 4561 loss 0.0317 LR 0.0081 LKL 0.0236\n",
      "epoch 4562 loss 0.0656 LR 0.0420 LKL 0.0236\n",
      "epoch 4563 loss 0.0499 LR 0.0262 LKL 0.0237\n",
      "epoch 4564 loss 0.0133 LR -0.0107 LKL 0.0240\n",
      "epoch 4565 loss 0.0816 LR 0.0576 LKL 0.0240\n",
      "epoch 4566 loss 0.0860 LR 0.0622 LKL 0.0239\n",
      "epoch 4567 loss 0.0759 LR 0.0520 LKL 0.0239\n",
      "epoch 4568 loss 0.0477 LR 0.0240 LKL 0.0237\n",
      "epoch 4569 loss 0.0589 LR 0.0352 LKL 0.0237\n",
      "epoch 4570 loss 0.0538 LR 0.0297 LKL 0.0241\n",
      "epoch 4571 loss 0.0532 LR 0.0294 LKL 0.0238\n",
      "epoch 4572 loss 0.0451 LR 0.0212 LKL 0.0239\n",
      "epoch 4573 loss 0.0436 LR 0.0197 LKL 0.0238\n",
      "epoch 4574 loss 0.0898 LR 0.0661 LKL 0.0237\n",
      "epoch 4575 loss 0.0067 LR -0.0172 LKL 0.0239\n",
      "epoch 4576 loss 0.0422 LR 0.0184 LKL 0.0238\n",
      "epoch 4577 loss 0.0723 LR 0.0486 LKL 0.0237\n",
      "epoch 4578 loss 0.0779 LR 0.0542 LKL 0.0237\n",
      "epoch 4579 loss 0.0888 LR 0.0651 LKL 0.0237\n",
      "epoch 4580 loss 0.0431 LR 0.0192 LKL 0.0239\n",
      "epoch 4581 loss 0.0342 LR 0.0104 LKL 0.0238\n",
      "epoch 4582 loss -0.0037 LR -0.0276 LKL 0.0239\n",
      "epoch 4583 loss 0.0752 LR 0.0514 LKL 0.0238\n",
      "epoch 4584 loss 0.0899 LR 0.0662 LKL 0.0237\n",
      "epoch 4585 loss 0.0798 LR 0.0561 LKL 0.0237\n",
      "epoch 4586 loss 0.0273 LR 0.0034 LKL 0.0239\n",
      "epoch 4587 loss 0.0741 LR 0.0503 LKL 0.0238\n",
      "epoch 4588 loss 0.1233 LR 0.0993 LKL 0.0240\n",
      "epoch 4589 loss 0.0987 LR 0.0747 LKL 0.0240\n",
      "epoch 4590 loss 0.0711 LR 0.0472 LKL 0.0239\n",
      "epoch 4591 loss 0.0818 LR 0.0579 LKL 0.0239\n",
      "epoch 4592 loss 0.0110 LR -0.0131 LKL 0.0242\n",
      "epoch 4593 loss 0.0524 LR 0.0288 LKL 0.0236\n",
      "epoch 4594 loss 0.0276 LR 0.0040 LKL 0.0236\n",
      "epoch 4595 loss 0.0092 LR -0.0145 LKL 0.0238\n",
      "epoch 4596 loss 0.0328 LR 0.0089 LKL 0.0239\n",
      "epoch 4597 loss 0.0569 LR 0.0328 LKL 0.0240\n",
      "epoch 4598 loss 0.0312 LR 0.0073 LKL 0.0239\n",
      "epoch 4599 loss 0.0995 LR 0.0757 LKL 0.0238\n",
      "epoch 4600 loss 0.0313 LR 0.0074 LKL 0.0239\n",
      "74\n",
      "epoch 4601 loss 0.0147 LR -0.0093 LKL 0.0239\n",
      "epoch 4602 loss 0.0237 LR -0.0003 LKL 0.0240\n",
      "epoch 4603 loss 0.0496 LR 0.0258 LKL 0.0238\n",
      "epoch 4604 loss 0.0186 LR -0.0052 LKL 0.0239\n",
      "epoch 4605 loss 0.0436 LR 0.0199 LKL 0.0237\n",
      "epoch 4606 loss 0.0211 LR -0.0026 LKL 0.0237\n",
      "epoch 4607 loss 0.0584 LR 0.0346 LKL 0.0237\n",
      "epoch 4608 loss 0.0502 LR 0.0265 LKL 0.0237\n",
      "epoch 4609 loss 0.0521 LR 0.0284 LKL 0.0237\n",
      "epoch 4610 loss 0.0035 LR -0.0201 LKL 0.0237\n",
      "epoch 4611 loss 0.0537 LR 0.0299 LKL 0.0238\n",
      "epoch 4612 loss 0.0391 LR 0.0155 LKL 0.0236\n",
      "epoch 4613 loss 0.1137 LR 0.0899 LKL 0.0238\n",
      "epoch 4614 loss 0.0924 LR 0.0686 LKL 0.0238\n",
      "epoch 4615 loss 0.0857 LR 0.0621 LKL 0.0236\n",
      "epoch 4616 loss 0.0281 LR 0.0045 LKL 0.0237\n",
      "epoch 4617 loss 0.0056 LR -0.0182 LKL 0.0238\n",
      "epoch 4618 loss 0.0290 LR 0.0051 LKL 0.0239\n",
      "epoch 4619 loss 0.0417 LR 0.0178 LKL 0.0239\n",
      "epoch 4620 loss 0.0714 LR 0.0477 LKL 0.0236\n",
      "epoch 4621 loss 0.0587 LR 0.0351 LKL 0.0237\n",
      "epoch 4622 loss 0.0470 LR 0.0233 LKL 0.0238\n",
      "epoch 4623 loss 0.0424 LR 0.0188 LKL 0.0237\n",
      "epoch 4624 loss 0.0609 LR 0.0372 LKL 0.0237\n",
      "epoch 4625 loss 0.0142 LR -0.0093 LKL 0.0235\n",
      "epoch 4626 loss 0.0792 LR 0.0557 LKL 0.0235\n",
      "epoch 4627 loss 0.0038 LR -0.0195 LKL 0.0234\n",
      "epoch 4628 loss 0.0644 LR 0.0410 LKL 0.0234\n",
      "epoch 4629 loss 0.0335 LR 0.0101 LKL 0.0234\n",
      "epoch 4630 loss 0.0162 LR -0.0074 LKL 0.0236\n",
      "epoch 4631 loss 0.0114 LR -0.0123 LKL 0.0237\n",
      "epoch 4632 loss -0.0050 LR -0.0287 LKL 0.0237\n",
      "epoch 4633 loss 0.0341 LR 0.0105 LKL 0.0236\n",
      "epoch 4634 loss 0.0498 LR 0.0260 LKL 0.0238\n",
      "epoch 4635 loss 0.0383 LR 0.0144 LKL 0.0239\n",
      "epoch 4636 loss 0.0065 LR -0.0173 LKL 0.0238\n",
      "epoch 4637 loss 0.0421 LR 0.0181 LKL 0.0239\n",
      "epoch 4638 loss 0.0084 LR -0.0158 LKL 0.0242\n",
      "epoch 4639 loss 0.0750 LR 0.0512 LKL 0.0238\n",
      "epoch 4640 loss 0.0253 LR 0.0015 LKL 0.0238\n",
      "epoch 4641 loss 0.0053 LR -0.0187 LKL 0.0240\n",
      "epoch 4642 loss 0.0147 LR -0.0093 LKL 0.0240\n",
      "epoch 4643 loss 0.0547 LR 0.0304 LKL 0.0243\n",
      "epoch 4644 loss -0.0477 LR -0.0720 LKL 0.0243\n",
      "epoch 4645 loss 0.0606 LR 0.0364 LKL 0.0242\n",
      "epoch 4646 loss 0.0432 LR 0.0190 LKL 0.0242\n",
      "epoch 4647 loss 0.0726 LR 0.0485 LKL 0.0242\n",
      "epoch 4648 loss 0.0507 LR 0.0266 LKL 0.0241\n",
      "epoch 4649 loss 0.0403 LR 0.0161 LKL 0.0242\n",
      "epoch 4650 loss 0.0493 LR 0.0249 LKL 0.0243\n",
      "epoch 4651 loss 0.0200 LR -0.0038 LKL 0.0239\n",
      "epoch 4652 loss 0.0366 LR 0.0126 LKL 0.0241\n",
      "epoch 4653 loss 0.0791 LR 0.0550 LKL 0.0241\n",
      "epoch 4654 loss 0.0018 LR -0.0224 LKL 0.0242\n",
      "epoch 4655 loss 0.0205 LR -0.0034 LKL 0.0240\n",
      "epoch 4656 loss 0.0279 LR 0.0038 LKL 0.0241\n",
      "epoch 4657 loss 0.0770 LR 0.0533 LKL 0.0238\n",
      "epoch 4658 loss 0.0338 LR 0.0097 LKL 0.0241\n",
      "epoch 4659 loss 0.0619 LR 0.0380 LKL 0.0239\n",
      "epoch 4660 loss 0.0999 LR 0.0760 LKL 0.0240\n",
      "epoch 4661 loss 0.0752 LR 0.0510 LKL 0.0241\n",
      "epoch 4662 loss 0.0868 LR 0.0626 LKL 0.0241\n",
      "epoch 4663 loss 0.0646 LR 0.0406 LKL 0.0240\n",
      "epoch 4664 loss 0.0091 LR -0.0148 LKL 0.0239\n",
      "epoch 4665 loss 0.0421 LR 0.0184 LKL 0.0238\n",
      "epoch 4666 loss 0.0601 LR 0.0363 LKL 0.0239\n",
      "epoch 4667 loss 0.0247 LR 0.0007 LKL 0.0241\n",
      "epoch 4668 loss 0.0054 LR -0.0185 LKL 0.0239\n",
      "epoch 4669 loss 0.0545 LR 0.0307 LKL 0.0238\n",
      "epoch 4670 loss 0.0512 LR 0.0272 LKL 0.0239\n",
      "epoch 4671 loss 0.0157 LR -0.0082 LKL 0.0238\n",
      "epoch 4672 loss 0.0815 LR 0.0578 LKL 0.0237\n",
      "epoch 4673 loss 0.0317 LR 0.0079 LKL 0.0238\n",
      "epoch 4674 loss 0.0176 LR -0.0063 LKL 0.0239\n",
      "epoch 4675 loss 0.0407 LR 0.0169 LKL 0.0238\n",
      "epoch 4676 loss 0.0370 LR 0.0130 LKL 0.0240\n",
      "epoch 4677 loss 0.0811 LR 0.0570 LKL 0.0241\n",
      "epoch 4678 loss 0.0938 LR 0.0701 LKL 0.0237\n",
      "epoch 4679 loss 0.0402 LR 0.0164 LKL 0.0238\n",
      "epoch 4680 loss 0.0471 LR 0.0235 LKL 0.0236\n",
      "epoch 4681 loss 0.0772 LR 0.0534 LKL 0.0238\n",
      "epoch 4682 loss 0.0263 LR 0.0026 LKL 0.0238\n",
      "epoch 4683 loss 0.0520 LR 0.0284 LKL 0.0236\n",
      "epoch 4684 loss 0.0139 LR -0.0097 LKL 0.0236\n",
      "epoch 4685 loss 0.0209 LR -0.0028 LKL 0.0237\n",
      "epoch 4686 loss 0.0379 LR 0.0145 LKL 0.0234\n",
      "epoch 4687 loss 0.0708 LR 0.0475 LKL 0.0233\n",
      "epoch 4688 loss 0.0712 LR 0.0480 LKL 0.0231\n",
      "epoch 4689 loss 0.0493 LR 0.0259 LKL 0.0234\n",
      "epoch 4690 loss 0.0735 LR 0.0503 LKL 0.0232\n",
      "epoch 4691 loss -0.0187 LR -0.0418 LKL 0.0231\n",
      "epoch 4692 loss 0.0905 LR 0.0673 LKL 0.0232\n",
      "epoch 4693 loss 0.0293 LR 0.0060 LKL 0.0233\n",
      "epoch 4694 loss 0.0574 LR 0.0341 LKL 0.0233\n",
      "epoch 4695 loss 0.0068 LR -0.0167 LKL 0.0234\n",
      "epoch 4696 loss 0.0467 LR 0.0233 LKL 0.0234\n",
      "epoch 4697 loss 0.0708 LR 0.0475 LKL 0.0233\n",
      "epoch 4698 loss 0.0838 LR 0.0605 LKL 0.0233\n",
      "epoch 4699 loss -0.0423 LR -0.0659 LKL 0.0236\n",
      "epoch 4700 loss -0.0171 LR -0.0409 LKL 0.0237\n",
      "67\n",
      "epoch 4701 loss 0.0022 LR -0.0217 LKL 0.0239\n",
      "epoch 4702 loss 0.0893 LR 0.0657 LKL 0.0237\n",
      "epoch 4703 loss 0.0600 LR 0.0362 LKL 0.0238\n",
      "epoch 4704 loss 0.0331 LR 0.0095 LKL 0.0236\n",
      "epoch 4705 loss 0.0444 LR 0.0206 LKL 0.0237\n",
      "epoch 4706 loss 0.1199 LR 0.0962 LKL 0.0237\n",
      "epoch 4707 loss 0.0442 LR 0.0203 LKL 0.0239\n",
      "epoch 4708 loss 0.0313 LR 0.0074 LKL 0.0240\n",
      "epoch 4709 loss 0.0398 LR 0.0159 LKL 0.0238\n",
      "epoch 4710 loss 0.0359 LR 0.0123 LKL 0.0237\n",
      "epoch 4711 loss 0.0303 LR 0.0067 LKL 0.0236\n",
      "epoch 4712 loss 0.0577 LR 0.0338 LKL 0.0239\n",
      "epoch 4713 loss 0.0145 LR -0.0095 LKL 0.0240\n",
      "epoch 4714 loss 0.0426 LR 0.0188 LKL 0.0238\n",
      "epoch 4715 loss 0.0543 LR 0.0305 LKL 0.0237\n",
      "epoch 4716 loss 0.0675 LR 0.0440 LKL 0.0235\n",
      "epoch 4717 loss 0.0818 LR 0.0580 LKL 0.0238\n",
      "epoch 4718 loss 0.0822 LR 0.0584 LKL 0.0238\n",
      "epoch 4719 loss 0.0859 LR 0.0622 LKL 0.0237\n",
      "epoch 4720 loss 0.0629 LR 0.0391 LKL 0.0237\n",
      "epoch 4721 loss 0.0811 LR 0.0571 LKL 0.0240\n",
      "epoch 4722 loss 0.0417 LR 0.0181 LKL 0.0236\n",
      "epoch 4723 loss 0.0233 LR -0.0006 LKL 0.0238\n",
      "epoch 4724 loss 0.0908 LR 0.0670 LKL 0.0238\n",
      "epoch 4725 loss 0.0630 LR 0.0392 LKL 0.0238\n",
      "epoch 4726 loss 0.0231 LR -0.0007 LKL 0.0238\n",
      "epoch 4727 loss 0.0386 LR 0.0149 LKL 0.0238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4728 loss 0.0465 LR 0.0230 LKL 0.0235\n",
      "epoch 4729 loss 0.0811 LR 0.0571 LKL 0.0240\n",
      "epoch 4730 loss 0.0954 LR 0.0722 LKL 0.0233\n",
      "epoch 4731 loss 0.0122 LR -0.0114 LKL 0.0237\n",
      "epoch 4732 loss 0.0595 LR 0.0359 LKL 0.0236\n",
      "epoch 4733 loss 0.0897 LR 0.0665 LKL 0.0231\n",
      "epoch 4734 loss 0.0028 LR -0.0206 LKL 0.0234\n",
      "epoch 4735 loss 0.0465 LR 0.0228 LKL 0.0237\n",
      "epoch 4736 loss -0.0251 LR -0.0486 LKL 0.0236\n",
      "epoch 4737 loss 0.0106 LR -0.0130 LKL 0.0236\n",
      "epoch 4738 loss 0.0215 LR -0.0023 LKL 0.0239\n",
      "epoch 4739 loss 0.0387 LR 0.0150 LKL 0.0237\n",
      "epoch 4740 loss 0.0869 LR 0.0631 LKL 0.0238\n",
      "epoch 4741 loss 0.1066 LR 0.0830 LKL 0.0236\n",
      "epoch 4742 loss 0.0789 LR 0.0553 LKL 0.0236\n",
      "epoch 4743 loss 0.0356 LR 0.0120 LKL 0.0236\n",
      "epoch 4744 loss 0.0174 LR -0.0062 LKL 0.0236\n",
      "epoch 4745 loss 0.0426 LR 0.0192 LKL 0.0234\n",
      "epoch 4746 loss 0.0400 LR 0.0168 LKL 0.0233\n",
      "epoch 4747 loss 0.0681 LR 0.0447 LKL 0.0234\n",
      "epoch 4748 loss 0.0506 LR 0.0272 LKL 0.0234\n",
      "epoch 4749 loss 0.0681 LR 0.0449 LKL 0.0232\n",
      "epoch 4750 loss 0.0654 LR 0.0417 LKL 0.0237\n",
      "epoch 4751 loss 0.0437 LR 0.0199 LKL 0.0238\n",
      "epoch 4752 loss 0.0789 LR 0.0555 LKL 0.0234\n",
      "epoch 4753 loss 0.0055 LR -0.0183 LKL 0.0237\n",
      "epoch 4754 loss 0.0595 LR 0.0358 LKL 0.0237\n",
      "epoch 4755 loss 0.0558 LR 0.0321 LKL 0.0237\n",
      "epoch 4756 loss 0.0224 LR -0.0013 LKL 0.0236\n",
      "epoch 4757 loss 0.0279 LR 0.0043 LKL 0.0236\n",
      "epoch 4758 loss 0.0063 LR -0.0178 LKL 0.0241\n",
      "epoch 4759 loss 0.0697 LR 0.0460 LKL 0.0237\n",
      "epoch 4760 loss 0.0681 LR 0.0440 LKL 0.0240\n",
      "epoch 4761 loss -0.0078 LR -0.0318 LKL 0.0240\n",
      "epoch 4762 loss 0.0384 LR 0.0145 LKL 0.0239\n",
      "epoch 4763 loss 0.0323 LR 0.0084 LKL 0.0239\n",
      "epoch 4764 loss 0.0517 LR 0.0277 LKL 0.0240\n",
      "epoch 4765 loss 0.0532 LR 0.0293 LKL 0.0239\n",
      "epoch 4766 loss 0.0620 LR 0.0382 LKL 0.0239\n",
      "epoch 4767 loss 0.0316 LR 0.0075 LKL 0.0241\n",
      "epoch 4768 loss 0.0183 LR -0.0057 LKL 0.0240\n",
      "epoch 4769 loss 0.0879 LR 0.0637 LKL 0.0242\n",
      "epoch 4770 loss 0.0931 LR 0.0691 LKL 0.0240\n",
      "epoch 4771 loss 0.0549 LR 0.0308 LKL 0.0241\n",
      "epoch 4772 loss 0.0415 LR 0.0177 LKL 0.0238\n",
      "epoch 4773 loss 0.0157 LR -0.0080 LKL 0.0237\n",
      "epoch 4774 loss 0.0598 LR 0.0359 LKL 0.0239\n",
      "epoch 4775 loss 0.0354 LR 0.0117 LKL 0.0237\n",
      "epoch 4776 loss 0.0673 LR 0.0436 LKL 0.0237\n",
      "epoch 4777 loss -0.0036 LR -0.0275 LKL 0.0238\n",
      "epoch 4778 loss 0.0312 LR 0.0076 LKL 0.0236\n",
      "epoch 4779 loss 0.0919 LR 0.0681 LKL 0.0238\n",
      "epoch 4780 loss 0.0724 LR 0.0485 LKL 0.0239\n",
      "epoch 4781 loss 0.0509 LR 0.0271 LKL 0.0238\n",
      "epoch 4782 loss 0.0258 LR 0.0022 LKL 0.0236\n",
      "epoch 4783 loss 0.0589 LR 0.0351 LKL 0.0238\n",
      "epoch 4784 loss 0.0188 LR -0.0050 LKL 0.0238\n",
      "epoch 4785 loss 0.0306 LR 0.0067 LKL 0.0239\n",
      "epoch 4786 loss 0.0853 LR 0.0615 LKL 0.0239\n",
      "epoch 4787 loss 0.1000 LR 0.0763 LKL 0.0236\n",
      "epoch 4788 loss 0.0656 LR 0.0417 LKL 0.0239\n",
      "epoch 4789 loss 0.0563 LR 0.0323 LKL 0.0240\n",
      "epoch 4790 loss 0.0517 LR 0.0278 LKL 0.0239\n",
      "epoch 4791 loss 0.1536 LR 0.1300 LKL 0.0236\n",
      "epoch 4792 loss 0.0534 LR 0.0295 LKL 0.0239\n",
      "epoch 4793 loss 0.0090 LR -0.0148 LKL 0.0237\n",
      "epoch 4794 loss 0.0365 LR 0.0126 LKL 0.0239\n",
      "epoch 4795 loss 0.0310 LR 0.0074 LKL 0.0236\n",
      "epoch 4796 loss 0.0260 LR 0.0026 LKL 0.0234\n",
      "epoch 4797 loss 0.0453 LR 0.0219 LKL 0.0234\n",
      "epoch 4798 loss 0.0048 LR -0.0189 LKL 0.0237\n",
      "epoch 4799 loss 0.0484 LR 0.0248 LKL 0.0236\n",
      "epoch 4800 loss 0.0064 LR -0.0173 LKL 0.0238\n",
      "55\n",
      "epoch 4801 loss 0.0137 LR -0.0103 LKL 0.0241\n",
      "epoch 4802 loss 0.0501 LR 0.0261 LKL 0.0240\n",
      "epoch 4803 loss -0.0197 LR -0.0439 LKL 0.0242\n",
      "epoch 4804 loss 0.0398 LR 0.0154 LKL 0.0244\n",
      "epoch 4805 loss 0.0571 LR 0.0329 LKL 0.0242\n",
      "epoch 4806 loss 0.0650 LR 0.0409 LKL 0.0241\n",
      "epoch 4807 loss 0.0441 LR 0.0198 LKL 0.0243\n",
      "epoch 4808 loss -0.0057 LR -0.0301 LKL 0.0244\n",
      "epoch 4809 loss 0.0567 LR 0.0320 LKL 0.0247\n",
      "epoch 4810 loss 0.0134 LR -0.0113 LKL 0.0247\n",
      "epoch 4811 loss 0.0378 LR 0.0133 LKL 0.0245\n",
      "epoch 4812 loss 0.0474 LR 0.0229 LKL 0.0246\n",
      "epoch 4813 loss 0.0326 LR 0.0081 LKL 0.0245\n",
      "epoch 4814 loss 0.0553 LR 0.0311 LKL 0.0242\n",
      "epoch 4815 loss 0.0376 LR 0.0133 LKL 0.0242\n",
      "epoch 4816 loss 0.0367 LR 0.0129 LKL 0.0238\n",
      "epoch 4817 loss 0.0796 LR 0.0555 LKL 0.0241\n",
      "epoch 4818 loss 0.0389 LR 0.0155 LKL 0.0235\n",
      "epoch 4819 loss 0.0287 LR 0.0050 LKL 0.0237\n",
      "epoch 4820 loss 0.0110 LR -0.0128 LKL 0.0238\n",
      "epoch 4821 loss 0.0175 LR -0.0061 LKL 0.0236\n",
      "epoch 4822 loss 0.0785 LR 0.0552 LKL 0.0233\n",
      "epoch 4823 loss 0.0331 LR 0.0097 LKL 0.0234\n",
      "epoch 4824 loss 0.0368 LR 0.0135 LKL 0.0233\n",
      "epoch 4825 loss 0.0158 LR -0.0078 LKL 0.0236\n",
      "epoch 4826 loss 0.0802 LR 0.0566 LKL 0.0236\n",
      "epoch 4827 loss 0.0441 LR 0.0204 LKL 0.0237\n",
      "epoch 4828 loss 0.0677 LR 0.0441 LKL 0.0236\n",
      "epoch 4829 loss 0.0478 LR 0.0243 LKL 0.0235\n",
      "epoch 4830 loss -0.0169 LR -0.0406 LKL 0.0237\n",
      "epoch 4831 loss 0.0412 LR 0.0174 LKL 0.0238\n",
      "epoch 4832 loss 0.0670 LR 0.0435 LKL 0.0235\n",
      "epoch 4833 loss 0.0105 LR -0.0134 LKL 0.0239\n",
      "epoch 4834 loss 0.0388 LR 0.0151 LKL 0.0237\n",
      "epoch 4835 loss 0.0279 LR 0.0046 LKL 0.0232\n",
      "epoch 4836 loss -0.0236 LR -0.0474 LKL 0.0239\n",
      "epoch 4837 loss 0.0242 LR 0.0008 LKL 0.0234\n",
      "epoch 4838 loss 0.0322 LR 0.0084 LKL 0.0238\n",
      "epoch 4839 loss 0.0618 LR 0.0382 LKL 0.0236\n",
      "epoch 4840 loss 0.0654 LR 0.0416 LKL 0.0237\n",
      "epoch 4841 loss 0.0545 LR 0.0307 LKL 0.0238\n",
      "epoch 4842 loss 0.0263 LR 0.0026 LKL 0.0238\n",
      "epoch 4843 loss 0.0263 LR 0.0027 LKL 0.0236\n",
      "epoch 4844 loss 0.0508 LR 0.0271 LKL 0.0237\n",
      "epoch 4845 loss -0.0132 LR -0.0368 LKL 0.0237\n",
      "epoch 4846 loss 0.0677 LR 0.0438 LKL 0.0239\n",
      "epoch 4847 loss 0.0392 LR 0.0155 LKL 0.0238\n",
      "epoch 4848 loss 0.0384 LR 0.0142 LKL 0.0242\n",
      "epoch 4849 loss 0.0562 LR 0.0318 LKL 0.0244\n",
      "epoch 4850 loss 0.0273 LR 0.0030 LKL 0.0242\n",
      "epoch 4851 loss 0.0452 LR 0.0212 LKL 0.0240\n",
      "epoch 4852 loss 0.0270 LR 0.0030 LKL 0.0240\n",
      "epoch 4853 loss 0.0123 LR -0.0121 LKL 0.0243\n",
      "epoch 4854 loss 0.0555 LR 0.0314 LKL 0.0240\n",
      "epoch 4855 loss 0.0278 LR 0.0037 LKL 0.0241\n",
      "epoch 4856 loss 0.0119 LR -0.0120 LKL 0.0239\n",
      "epoch 4857 loss 0.0223 LR -0.0016 LKL 0.0239\n",
      "epoch 4858 loss 0.0370 LR 0.0133 LKL 0.0237\n",
      "epoch 4859 loss 0.0597 LR 0.0361 LKL 0.0236\n",
      "epoch 4860 loss 0.0246 LR 0.0006 LKL 0.0240\n",
      "epoch 4861 loss 0.0594 LR 0.0356 LKL 0.0238\n",
      "epoch 4862 loss 0.0231 LR -0.0009 LKL 0.0240\n",
      "epoch 4863 loss 0.0637 LR 0.0401 LKL 0.0236\n",
      "epoch 4864 loss 0.0463 LR 0.0228 LKL 0.0235\n",
      "epoch 4865 loss 0.0977 LR 0.0740 LKL 0.0237\n",
      "epoch 4866 loss 0.0300 LR 0.0063 LKL 0.0237\n",
      "epoch 4867 loss 0.0678 LR 0.0440 LKL 0.0238\n",
      "epoch 4868 loss -0.0217 LR -0.0456 LKL 0.0239\n",
      "epoch 4869 loss 0.0156 LR -0.0081 LKL 0.0236\n",
      "epoch 4870 loss 0.0567 LR 0.0332 LKL 0.0235\n",
      "epoch 4871 loss 0.0597 LR 0.0360 LKL 0.0237\n",
      "epoch 4872 loss 0.0488 LR 0.0254 LKL 0.0234\n",
      "epoch 4873 loss 0.0332 LR 0.0094 LKL 0.0238\n",
      "epoch 4874 loss 0.0384 LR 0.0144 LKL 0.0240\n",
      "epoch 4875 loss 0.0789 LR 0.0551 LKL 0.0238\n",
      "epoch 4876 loss 0.1002 LR 0.0762 LKL 0.0240\n",
      "epoch 4877 loss 0.0824 LR 0.0583 LKL 0.0241\n",
      "epoch 4878 loss 0.0349 LR 0.0108 LKL 0.0240\n",
      "epoch 4879 loss 0.0600 LR 0.0359 LKL 0.0241\n",
      "epoch 4880 loss 0.0255 LR 0.0014 LKL 0.0241\n",
      "epoch 4881 loss 0.1029 LR 0.0789 LKL 0.0241\n",
      "epoch 4882 loss 0.0444 LR 0.0206 LKL 0.0238\n",
      "epoch 4883 loss 0.0008 LR -0.0230 LKL 0.0239\n",
      "epoch 4884 loss 0.0169 LR -0.0070 LKL 0.0239\n",
      "epoch 4885 loss 0.0323 LR 0.0086 LKL 0.0237\n",
      "epoch 4886 loss 0.1226 LR 0.0989 LKL 0.0237\n",
      "epoch 4887 loss 0.0516 LR 0.0281 LKL 0.0234\n",
      "epoch 4888 loss 0.0432 LR 0.0195 LKL 0.0238\n",
      "epoch 4889 loss 0.0164 LR -0.0073 LKL 0.0237\n",
      "epoch 4890 loss 0.0699 LR 0.0462 LKL 0.0237\n",
      "epoch 4891 loss 0.0019 LR -0.0219 LKL 0.0238\n",
      "epoch 4892 loss 0.0537 LR 0.0297 LKL 0.0240\n",
      "epoch 4893 loss 0.0746 LR 0.0511 LKL 0.0235\n",
      "epoch 4894 loss 0.0485 LR 0.0249 LKL 0.0236\n",
      "epoch 4895 loss 0.0279 LR 0.0041 LKL 0.0238\n",
      "epoch 4896 loss 0.0556 LR 0.0320 LKL 0.0236\n",
      "epoch 4897 loss 0.0587 LR 0.0349 LKL 0.0238\n",
      "epoch 4898 loss 0.0633 LR 0.0398 LKL 0.0235\n",
      "epoch 4899 loss 0.0596 LR 0.0360 LKL 0.0237\n",
      "epoch 4900 loss 0.0090 LR -0.0147 LKL 0.0237\n",
      "62\n",
      "epoch 4901 loss 0.0847 LR 0.0608 LKL 0.0239\n",
      "epoch 4902 loss 0.0177 LR -0.0060 LKL 0.0237\n",
      "epoch 4903 loss 0.0624 LR 0.0386 LKL 0.0238\n",
      "epoch 4904 loss 0.0480 LR 0.0240 LKL 0.0240\n",
      "epoch 4905 loss 0.0826 LR 0.0586 LKL 0.0240\n",
      "epoch 4906 loss 0.0646 LR 0.0406 LKL 0.0240\n",
      "epoch 4907 loss 0.0560 LR 0.0322 LKL 0.0237\n",
      "epoch 4908 loss 0.0445 LR 0.0202 LKL 0.0243\n",
      "epoch 4909 loss 0.0443 LR 0.0204 LKL 0.0239\n",
      "epoch 4910 loss 0.0584 LR 0.0347 LKL 0.0237\n",
      "epoch 4911 loss 0.0699 LR 0.0459 LKL 0.0240\n",
      "epoch 4912 loss 0.0285 LR 0.0051 LKL 0.0234\n",
      "epoch 4913 loss 0.0418 LR 0.0183 LKL 0.0235\n",
      "epoch 4914 loss 0.0749 LR 0.0512 LKL 0.0237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4915 loss 0.1107 LR 0.0873 LKL 0.0234\n",
      "epoch 4916 loss -0.0063 LR -0.0296 LKL 0.0233\n",
      "epoch 4917 loss 0.0408 LR 0.0176 LKL 0.0232\n",
      "epoch 4918 loss 0.0034 LR -0.0202 LKL 0.0236\n",
      "epoch 4919 loss 0.0256 LR 0.0020 LKL 0.0237\n",
      "epoch 4920 loss -0.0048 LR -0.0283 LKL 0.0235\n",
      "epoch 4921 loss 0.0836 LR 0.0602 LKL 0.0234\n",
      "epoch 4922 loss 0.0260 LR 0.0027 LKL 0.0233\n",
      "epoch 4923 loss 0.0537 LR 0.0304 LKL 0.0233\n",
      "epoch 4924 loss 0.1036 LR 0.0804 LKL 0.0232\n",
      "epoch 4925 loss 0.0205 LR -0.0028 LKL 0.0233\n",
      "epoch 4926 loss 0.0265 LR 0.0031 LKL 0.0234\n",
      "epoch 4927 loss 0.0058 LR -0.0175 LKL 0.0233\n",
      "epoch 4928 loss 0.0447 LR 0.0212 LKL 0.0234\n",
      "epoch 4929 loss 0.0662 LR 0.0429 LKL 0.0233\n",
      "epoch 4930 loss 0.0460 LR 0.0227 LKL 0.0233\n",
      "epoch 4931 loss -0.0353 LR -0.0589 LKL 0.0236\n",
      "epoch 4932 loss 0.0246 LR 0.0012 LKL 0.0234\n",
      "epoch 4933 loss 0.0647 LR 0.0412 LKL 0.0235\n",
      "epoch 4934 loss 0.0497 LR 0.0263 LKL 0.0234\n",
      "epoch 4935 loss 0.0767 LR 0.0531 LKL 0.0236\n",
      "epoch 4936 loss 0.0499 LR 0.0259 LKL 0.0240\n",
      "epoch 4937 loss 0.0617 LR 0.0381 LKL 0.0235\n",
      "epoch 4938 loss -0.0109 LR -0.0349 LKL 0.0240\n",
      "epoch 4939 loss 0.0261 LR 0.0024 LKL 0.0237\n",
      "epoch 4940 loss 0.0435 LR 0.0199 LKL 0.0236\n",
      "epoch 4941 loss 0.0575 LR 0.0337 LKL 0.0238\n",
      "epoch 4942 loss 0.0070 LR -0.0169 LKL 0.0239\n",
      "epoch 4943 loss 0.0805 LR 0.0566 LKL 0.0239\n",
      "epoch 4944 loss 0.0017 LR -0.0222 LKL 0.0238\n",
      "epoch 4945 loss 0.0795 LR 0.0556 LKL 0.0239\n",
      "epoch 4946 loss 0.0341 LR 0.0102 LKL 0.0239\n",
      "epoch 4947 loss 0.0619 LR 0.0380 LKL 0.0239\n",
      "epoch 4948 loss 0.0564 LR 0.0324 LKL 0.0240\n",
      "epoch 4949 loss 0.0389 LR 0.0150 LKL 0.0239\n",
      "epoch 4950 loss -0.0160 LR -0.0399 LKL 0.0239\n",
      "epoch 4951 loss 0.0204 LR -0.0034 LKL 0.0238\n",
      "epoch 4952 loss 0.0991 LR 0.0753 LKL 0.0238\n",
      "epoch 4953 loss 0.0051 LR -0.0187 LKL 0.0238\n",
      "epoch 4954 loss 0.0566 LR 0.0328 LKL 0.0238\n",
      "epoch 4955 loss 0.0661 LR 0.0422 LKL 0.0239\n",
      "epoch 4956 loss 0.0273 LR 0.0036 LKL 0.0237\n",
      "epoch 4957 loss -0.0003 LR -0.0242 LKL 0.0239\n",
      "epoch 4958 loss 0.0693 LR 0.0453 LKL 0.0240\n",
      "epoch 4959 loss -0.0168 LR -0.0404 LKL 0.0236\n",
      "epoch 4960 loss -0.0094 LR -0.0332 LKL 0.0238\n",
      "epoch 4961 loss -0.0107 LR -0.0345 LKL 0.0238\n",
      "epoch 4962 loss 0.0680 LR 0.0444 LKL 0.0237\n",
      "epoch 4963 loss 0.0640 LR 0.0401 LKL 0.0239\n",
      "epoch 4964 loss 0.0403 LR 0.0165 LKL 0.0238\n",
      "epoch 4965 loss 0.0217 LR -0.0023 LKL 0.0240\n",
      "epoch 4966 loss 0.0107 LR -0.0131 LKL 0.0238\n",
      "epoch 4967 loss 0.0438 LR 0.0198 LKL 0.0241\n",
      "epoch 4968 loss -0.0191 LR -0.0430 LKL 0.0238\n",
      "epoch 4969 loss 0.0247 LR 0.0009 LKL 0.0239\n",
      "epoch 4970 loss 0.0666 LR 0.0430 LKL 0.0235\n",
      "epoch 4971 loss 0.0233 LR -0.0004 LKL 0.0237\n",
      "epoch 4972 loss -0.0036 LR -0.0276 LKL 0.0240\n",
      "epoch 4973 loss 0.0467 LR 0.0232 LKL 0.0235\n",
      "epoch 4974 loss 0.0111 LR -0.0124 LKL 0.0235\n",
      "epoch 4975 loss 0.0565 LR 0.0332 LKL 0.0233\n",
      "epoch 4976 loss -0.0015 LR -0.0254 LKL 0.0238\n",
      "epoch 4977 loss 0.0490 LR 0.0256 LKL 0.0234\n",
      "epoch 4978 loss 0.0442 LR 0.0207 LKL 0.0234\n",
      "epoch 4979 loss 0.0192 LR -0.0042 LKL 0.0234\n",
      "epoch 4980 loss 0.0455 LR 0.0221 LKL 0.0234\n",
      "epoch 4981 loss 0.0554 LR 0.0321 LKL 0.0232\n",
      "epoch 4982 loss 0.0582 LR 0.0348 LKL 0.0234\n",
      "epoch 4983 loss 0.0173 LR -0.0060 LKL 0.0234\n",
      "epoch 4984 loss 0.0566 LR 0.0334 LKL 0.0232\n",
      "epoch 4985 loss 0.0482 LR 0.0249 LKL 0.0233\n",
      "epoch 4986 loss 0.0488 LR 0.0250 LKL 0.0238\n",
      "epoch 4987 loss 0.0675 LR 0.0438 LKL 0.0236\n",
      "epoch 4988 loss 0.0483 LR 0.0248 LKL 0.0235\n",
      "epoch 4989 loss 0.0247 LR 0.0011 LKL 0.0236\n",
      "epoch 4990 loss 0.1043 LR 0.0808 LKL 0.0235\n",
      "epoch 4991 loss 0.1118 LR 0.0884 LKL 0.0234\n",
      "epoch 4992 loss 0.0351 LR 0.0117 LKL 0.0234\n",
      "epoch 4993 loss 0.0440 LR 0.0203 LKL 0.0237\n",
      "epoch 4994 loss -0.0181 LR -0.0417 LKL 0.0236\n",
      "epoch 4995 loss 0.0782 LR 0.0545 LKL 0.0237\n",
      "epoch 4996 loss 0.0342 LR 0.0106 LKL 0.0236\n",
      "epoch 4997 loss 0.0066 LR -0.0172 LKL 0.0238\n",
      "epoch 4998 loss 0.0289 LR 0.0049 LKL 0.0240\n",
      "epoch 4999 loss 0.0717 LR 0.0480 LKL 0.0238\n",
      "epoch 5000 loss 0.0461 LR 0.0224 LKL 0.0237\n",
      "64\n",
      "epoch 5001 loss 0.0412 LR 0.0175 LKL 0.0238\n",
      "epoch 5002 loss 0.0833 LR 0.0594 LKL 0.0239\n",
      "epoch 5003 loss 0.0703 LR 0.0466 LKL 0.0237\n",
      "epoch 5004 loss 0.0867 LR 0.0629 LKL 0.0239\n",
      "epoch 5005 loss 0.0551 LR 0.0314 LKL 0.0237\n",
      "epoch 5006 loss 0.0012 LR -0.0224 LKL 0.0235\n",
      "epoch 5007 loss 0.0788 LR 0.0552 LKL 0.0236\n",
      "epoch 5008 loss 0.0655 LR 0.0418 LKL 0.0237\n",
      "epoch 5009 loss 0.0089 LR -0.0146 LKL 0.0236\n",
      "epoch 5010 loss 0.0077 LR -0.0159 LKL 0.0236\n",
      "epoch 5011 loss 0.0135 LR -0.0104 LKL 0.0239\n",
      "epoch 5012 loss 0.0462 LR 0.0225 LKL 0.0237\n",
      "epoch 5013 loss 0.0335 LR 0.0098 LKL 0.0237\n",
      "epoch 5014 loss 0.0165 LR -0.0072 LKL 0.0236\n",
      "epoch 5015 loss 0.0696 LR 0.0460 LKL 0.0237\n",
      "epoch 5016 loss 0.0263 LR 0.0026 LKL 0.0238\n",
      "epoch 5017 loss 0.0447 LR 0.0207 LKL 0.0240\n",
      "epoch 5018 loss 0.0579 LR 0.0340 LKL 0.0239\n",
      "epoch 5019 loss 0.0217 LR -0.0023 LKL 0.0240\n",
      "epoch 5020 loss 0.0418 LR 0.0179 LKL 0.0239\n",
      "epoch 5021 loss 0.0086 LR -0.0155 LKL 0.0241\n",
      "epoch 5022 loss 0.1007 LR 0.0770 LKL 0.0237\n",
      "epoch 5023 loss 0.0326 LR 0.0089 LKL 0.0237\n",
      "epoch 5024 loss 0.0839 LR 0.0600 LKL 0.0238\n",
      "epoch 5025 loss 0.0125 LR -0.0115 LKL 0.0240\n",
      "epoch 5026 loss 0.0564 LR 0.0326 LKL 0.0238\n",
      "epoch 5027 loss 0.0289 LR 0.0052 LKL 0.0237\n",
      "epoch 5028 loss 0.0921 LR 0.0687 LKL 0.0234\n",
      "epoch 5029 loss 0.0622 LR 0.0386 LKL 0.0235\n",
      "epoch 5030 loss -0.0107 LR -0.0344 LKL 0.0237\n",
      "epoch 5031 loss 0.0631 LR 0.0397 LKL 0.0234\n",
      "epoch 5032 loss 0.0696 LR 0.0461 LKL 0.0235\n",
      "epoch 5033 loss 0.0506 LR 0.0269 LKL 0.0237\n",
      "epoch 5034 loss 0.0645 LR 0.0411 LKL 0.0233\n",
      "epoch 5035 loss 0.0296 LR 0.0061 LKL 0.0236\n",
      "epoch 5036 loss 0.0322 LR 0.0088 LKL 0.0234\n",
      "epoch 5037 loss 0.0699 LR 0.0463 LKL 0.0236\n",
      "epoch 5038 loss 0.0190 LR -0.0044 LKL 0.0234\n",
      "epoch 5039 loss 0.0902 LR 0.0669 LKL 0.0233\n",
      "epoch 5040 loss 0.0425 LR 0.0188 LKL 0.0237\n",
      "epoch 5041 loss 0.0340 LR 0.0106 LKL 0.0233\n",
      "epoch 5042 loss 0.0654 LR 0.0419 LKL 0.0235\n",
      "epoch 5043 loss 0.0011 LR -0.0226 LKL 0.0237\n",
      "epoch 5044 loss 0.0519 LR 0.0284 LKL 0.0235\n",
      "epoch 5045 loss 0.0516 LR 0.0279 LKL 0.0237\n",
      "epoch 5046 loss 0.0380 LR 0.0141 LKL 0.0240\n",
      "epoch 5047 loss 0.0289 LR 0.0051 LKL 0.0238\n",
      "epoch 5048 loss 0.0311 LR 0.0070 LKL 0.0240\n",
      "epoch 5049 loss 0.0879 LR 0.0641 LKL 0.0237\n",
      "epoch 5050 loss 0.0320 LR 0.0084 LKL 0.0236\n",
      "epoch 5051 loss 0.0091 LR -0.0147 LKL 0.0238\n",
      "epoch 5052 loss 0.0287 LR 0.0050 LKL 0.0238\n",
      "epoch 5053 loss 0.0406 LR 0.0172 LKL 0.0234\n",
      "epoch 5054 loss 0.0064 LR -0.0173 LKL 0.0238\n",
      "epoch 5055 loss 0.0516 LR 0.0279 LKL 0.0237\n",
      "epoch 5056 loss 0.0277 LR 0.0039 LKL 0.0238\n",
      "epoch 5057 loss -0.0290 LR -0.0531 LKL 0.0241\n",
      "epoch 5058 loss 0.0343 LR 0.0101 LKL 0.0242\n",
      "epoch 5059 loss 0.0581 LR 0.0341 LKL 0.0240\n",
      "epoch 5060 loss 0.0150 LR -0.0091 LKL 0.0241\n",
      "epoch 5061 loss 0.0316 LR 0.0076 LKL 0.0240\n",
      "epoch 5062 loss 0.0216 LR -0.0028 LKL 0.0243\n",
      "epoch 5063 loss 0.0235 LR -0.0005 LKL 0.0241\n",
      "epoch 5064 loss 0.0852 LR 0.0608 LKL 0.0243\n",
      "epoch 5065 loss 0.0490 LR 0.0247 LKL 0.0243\n",
      "epoch 5066 loss 0.0753 LR 0.0512 LKL 0.0241\n",
      "epoch 5067 loss 0.0396 LR 0.0156 LKL 0.0240\n",
      "epoch 5068 loss 0.0480 LR 0.0241 LKL 0.0240\n",
      "epoch 5069 loss 0.0431 LR 0.0192 LKL 0.0239\n",
      "epoch 5070 loss -0.0176 LR -0.0414 LKL 0.0238\n",
      "epoch 5071 loss -0.0340 LR -0.0583 LKL 0.0244\n",
      "epoch 5072 loss -0.0278 LR -0.0518 LKL 0.0240\n",
      "epoch 5073 loss 0.0727 LR 0.0492 LKL 0.0235\n",
      "epoch 5074 loss 0.0560 LR 0.0324 LKL 0.0237\n",
      "epoch 5075 loss 0.0280 LR 0.0045 LKL 0.0235\n",
      "epoch 5076 loss -0.0037 LR -0.0276 LKL 0.0239\n",
      "epoch 5077 loss 0.0441 LR 0.0206 LKL 0.0235\n",
      "epoch 5078 loss 0.0886 LR 0.0651 LKL 0.0235\n",
      "epoch 5079 loss 0.0531 LR 0.0301 LKL 0.0230\n",
      "epoch 5080 loss 0.0209 LR -0.0026 LKL 0.0235\n",
      "epoch 5081 loss 0.0563 LR 0.0327 LKL 0.0236\n",
      "epoch 5082 loss 0.0353 LR 0.0118 LKL 0.0235\n",
      "epoch 5083 loss 0.0606 LR 0.0374 LKL 0.0232\n",
      "epoch 5084 loss 0.0467 LR 0.0233 LKL 0.0235\n",
      "epoch 5085 loss 0.0652 LR 0.0422 LKL 0.0230\n",
      "epoch 5086 loss 0.0656 LR 0.0423 LKL 0.0233\n",
      "epoch 5087 loss 0.0327 LR 0.0094 LKL 0.0233\n",
      "epoch 5088 loss 0.0449 LR 0.0218 LKL 0.0231\n",
      "epoch 5089 loss 0.0587 LR 0.0352 LKL 0.0235\n",
      "epoch 5090 loss 0.0602 LR 0.0369 LKL 0.0232\n",
      "epoch 5091 loss 0.0206 LR -0.0032 LKL 0.0237\n",
      "epoch 5092 loss 0.0258 LR 0.0023 LKL 0.0235\n",
      "epoch 5093 loss 0.0320 LR 0.0085 LKL 0.0235\n",
      "epoch 5094 loss 0.0295 LR 0.0060 LKL 0.0236\n",
      "epoch 5095 loss 0.0106 LR -0.0128 LKL 0.0235\n",
      "epoch 5096 loss 0.0433 LR 0.0199 LKL 0.0234\n",
      "epoch 5097 loss 0.0264 LR 0.0028 LKL 0.0236\n",
      "epoch 5098 loss 0.0090 LR -0.0150 LKL 0.0240\n",
      "epoch 5099 loss -0.0084 LR -0.0324 LKL 0.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5100 loss 0.0280 LR 0.0040 LKL 0.0240\n",
      "70\n",
      "epoch 5101 loss -0.0123 LR -0.0365 LKL 0.0242\n",
      "epoch 5102 loss 0.0114 LR -0.0128 LKL 0.0242\n",
      "epoch 5103 loss 0.0279 LR 0.0038 LKL 0.0241\n",
      "epoch 5104 loss 0.0691 LR 0.0450 LKL 0.0241\n",
      "epoch 5105 loss 0.0363 LR 0.0120 LKL 0.0243\n",
      "epoch 5106 loss 0.0671 LR 0.0427 LKL 0.0243\n",
      "epoch 5107 loss -0.0091 LR -0.0332 LKL 0.0241\n",
      "epoch 5108 loss -0.0132 LR -0.0375 LKL 0.0243\n",
      "epoch 5109 loss 0.0301 LR 0.0061 LKL 0.0240\n",
      "epoch 5110 loss 0.0294 LR 0.0053 LKL 0.0240\n",
      "epoch 5111 loss 0.0198 LR -0.0042 LKL 0.0239\n",
      "epoch 5112 loss 0.0795 LR 0.0557 LKL 0.0239\n",
      "epoch 5113 loss 0.0743 LR 0.0508 LKL 0.0235\n",
      "epoch 5114 loss 0.0834 LR 0.0598 LKL 0.0236\n",
      "epoch 5115 loss 0.0373 LR 0.0136 LKL 0.0237\n",
      "epoch 5116 loss 0.0174 LR -0.0065 LKL 0.0239\n",
      "epoch 5117 loss 0.0891 LR 0.0655 LKL 0.0236\n",
      "epoch 5118 loss 0.0338 LR 0.0100 LKL 0.0238\n",
      "epoch 5119 loss 0.0499 LR 0.0259 LKL 0.0240\n",
      "epoch 5120 loss 0.0531 LR 0.0290 LKL 0.0241\n",
      "epoch 5121 loss 0.0573 LR 0.0331 LKL 0.0242\n",
      "epoch 5122 loss 0.0550 LR 0.0309 LKL 0.0241\n",
      "epoch 5123 loss 0.0578 LR 0.0336 LKL 0.0243\n",
      "epoch 5124 loss -0.0046 LR -0.0288 LKL 0.0242\n",
      "epoch 5125 loss 0.0086 LR -0.0152 LKL 0.0239\n",
      "epoch 5126 loss 0.0463 LR 0.0221 LKL 0.0243\n",
      "epoch 5127 loss 0.0273 LR 0.0030 LKL 0.0243\n",
      "epoch 5128 loss 0.0540 LR 0.0299 LKL 0.0240\n",
      "epoch 5129 loss 0.0771 LR 0.0528 LKL 0.0243\n",
      "epoch 5130 loss 0.0380 LR 0.0139 LKL 0.0240\n",
      "epoch 5131 loss 0.0344 LR 0.0109 LKL 0.0235\n",
      "epoch 5132 loss -0.0122 LR -0.0361 LKL 0.0238\n",
      "epoch 5133 loss 0.0205 LR -0.0032 LKL 0.0237\n",
      "epoch 5134 loss 0.0091 LR -0.0143 LKL 0.0234\n",
      "epoch 5135 loss 0.0611 LR 0.0375 LKL 0.0236\n",
      "epoch 5136 loss 0.0639 LR 0.0404 LKL 0.0235\n",
      "epoch 5137 loss 0.0177 LR -0.0058 LKL 0.0235\n",
      "epoch 5138 loss 0.0649 LR 0.0412 LKL 0.0237\n",
      "epoch 5139 loss 0.0199 LR -0.0039 LKL 0.0238\n",
      "epoch 5140 loss 0.0558 LR 0.0322 LKL 0.0237\n",
      "epoch 5141 loss 0.0170 LR -0.0071 LKL 0.0241\n",
      "epoch 5142 loss -0.0009 LR -0.0251 LKL 0.0242\n",
      "epoch 5143 loss 0.0319 LR 0.0078 LKL 0.0241\n",
      "epoch 5144 loss 0.0208 LR -0.0032 LKL 0.0240\n",
      "epoch 5145 loss 0.0113 LR -0.0125 LKL 0.0238\n",
      "epoch 5146 loss 0.0598 LR 0.0363 LKL 0.0236\n",
      "epoch 5147 loss 0.0236 LR -0.0003 LKL 0.0239\n",
      "epoch 5148 loss 0.1062 LR 0.0822 LKL 0.0240\n",
      "epoch 5149 loss 0.0205 LR -0.0034 LKL 0.0238\n",
      "epoch 5150 loss 0.0428 LR 0.0188 LKL 0.0241\n",
      "epoch 5151 loss 0.0342 LR 0.0100 LKL 0.0241\n",
      "epoch 5152 loss 0.0317 LR 0.0074 LKL 0.0243\n",
      "epoch 5153 loss 0.0162 LR -0.0080 LKL 0.0242\n",
      "epoch 5154 loss 0.0419 LR 0.0176 LKL 0.0243\n",
      "epoch 5155 loss 0.0053 LR -0.0189 LKL 0.0242\n",
      "epoch 5156 loss 0.0563 LR 0.0320 LKL 0.0242\n",
      "epoch 5157 loss 0.0559 LR 0.0319 LKL 0.0240\n",
      "epoch 5158 loss 0.0116 LR -0.0125 LKL 0.0241\n",
      "epoch 5159 loss 0.0853 LR 0.0614 LKL 0.0239\n",
      "epoch 5160 loss 0.0381 LR 0.0142 LKL 0.0239\n",
      "epoch 5161 loss -0.0085 LR -0.0325 LKL 0.0240\n",
      "epoch 5162 loss 0.0382 LR 0.0141 LKL 0.0241\n",
      "epoch 5163 loss 0.0337 LR 0.0098 LKL 0.0239\n",
      "epoch 5164 loss 0.0569 LR 0.0330 LKL 0.0240\n",
      "epoch 5165 loss 0.0153 LR -0.0085 LKL 0.0239\n",
      "epoch 5166 loss -0.0015 LR -0.0252 LKL 0.0237\n",
      "epoch 5167 loss 0.0411 LR 0.0175 LKL 0.0236\n",
      "epoch 5168 loss 0.0545 LR 0.0307 LKL 0.0238\n",
      "epoch 5169 loss 0.0260 LR 0.0023 LKL 0.0237\n",
      "epoch 5170 loss 0.0159 LR -0.0075 LKL 0.0235\n",
      "epoch 5171 loss 0.0323 LR 0.0087 LKL 0.0236\n",
      "epoch 5172 loss 0.0008 LR -0.0224 LKL 0.0232\n",
      "epoch 5173 loss 0.0620 LR 0.0388 LKL 0.0232\n",
      "epoch 5174 loss 0.0748 LR 0.0513 LKL 0.0234\n",
      "epoch 5175 loss 0.0348 LR 0.0114 LKL 0.0235\n",
      "epoch 5176 loss 0.0463 LR 0.0228 LKL 0.0235\n",
      "epoch 5177 loss 0.0382 LR 0.0147 LKL 0.0235\n",
      "epoch 5178 loss 0.0046 LR -0.0187 LKL 0.0233\n",
      "epoch 5179 loss 0.0378 LR 0.0145 LKL 0.0233\n",
      "epoch 5180 loss 0.0702 LR 0.0467 LKL 0.0234\n",
      "epoch 5181 loss 0.0280 LR 0.0046 LKL 0.0233\n",
      "epoch 5182 loss 0.0136 LR -0.0101 LKL 0.0237\n",
      "epoch 5183 loss -0.0115 LR -0.0354 LKL 0.0239\n",
      "epoch 5184 loss 0.0724 LR 0.0488 LKL 0.0236\n",
      "epoch 5185 loss 0.0605 LR 0.0365 LKL 0.0240\n",
      "epoch 5186 loss 0.0914 LR 0.0678 LKL 0.0236\n",
      "epoch 5187 loss 0.0405 LR 0.0167 LKL 0.0238\n",
      "epoch 5188 loss 0.0675 LR 0.0437 LKL 0.0238\n",
      "epoch 5189 loss 0.0807 LR 0.0572 LKL 0.0235\n",
      "epoch 5190 loss 0.0302 LR 0.0064 LKL 0.0238\n",
      "epoch 5191 loss 0.0340 LR 0.0100 LKL 0.0240\n",
      "epoch 5192 loss 0.0532 LR 0.0296 LKL 0.0236\n",
      "epoch 5193 loss 0.0142 LR -0.0096 LKL 0.0237\n",
      "epoch 5194 loss 0.0456 LR 0.0215 LKL 0.0240\n",
      "epoch 5195 loss 0.0066 LR -0.0175 LKL 0.0241\n",
      "epoch 5196 loss 0.0403 LR 0.0164 LKL 0.0239\n",
      "epoch 5197 loss 0.0142 LR -0.0099 LKL 0.0241\n",
      "epoch 5198 loss 0.0038 LR -0.0201 LKL 0.0239\n",
      "epoch 5199 loss -0.0052 LR -0.0291 LKL 0.0239\n",
      "epoch 5200 loss 0.0208 LR -0.0033 LKL 0.0241\n",
      "94\n",
      "epoch 5201 loss 0.0545 LR 0.0306 LKL 0.0239\n",
      "epoch 5202 loss -0.0016 LR -0.0256 LKL 0.0240\n",
      "epoch 5203 loss 0.0822 LR 0.0582 LKL 0.0240\n",
      "epoch 5204 loss 0.0418 LR 0.0181 LKL 0.0237\n",
      "epoch 5205 loss 0.0292 LR 0.0053 LKL 0.0238\n",
      "epoch 5206 loss 0.0071 LR -0.0167 LKL 0.0238\n",
      "epoch 5207 loss 0.0321 LR 0.0081 LKL 0.0240\n",
      "epoch 5208 loss -0.0233 LR -0.0473 LKL 0.0240\n",
      "epoch 5209 loss 0.0153 LR -0.0091 LKL 0.0244\n",
      "epoch 5210 loss 0.0894 LR 0.0655 LKL 0.0239\n",
      "epoch 5211 loss -0.0070 LR -0.0311 LKL 0.0241\n",
      "epoch 5212 loss 0.0392 LR 0.0152 LKL 0.0240\n",
      "epoch 5213 loss 0.0772 LR 0.0533 LKL 0.0239\n",
      "epoch 5214 loss 0.0378 LR 0.0139 LKL 0.0239\n",
      "epoch 5215 loss 0.0557 LR 0.0318 LKL 0.0239\n",
      "epoch 5216 loss -0.0230 LR -0.0470 LKL 0.0240\n",
      "epoch 5217 loss -0.0211 LR -0.0451 LKL 0.0240\n",
      "epoch 5218 loss 0.0915 LR 0.0677 LKL 0.0237\n",
      "epoch 5219 loss 0.0204 LR -0.0035 LKL 0.0239\n",
      "epoch 5220 loss -0.0246 LR -0.0486 LKL 0.0239\n",
      "epoch 5221 loss 0.0208 LR -0.0032 LKL 0.0240\n",
      "epoch 5222 loss 0.0060 LR -0.0178 LKL 0.0238\n",
      "epoch 5223 loss 0.0750 LR 0.0512 LKL 0.0238\n",
      "epoch 5224 loss 0.0283 LR 0.0044 LKL 0.0239\n",
      "epoch 5225 loss 0.0380 LR 0.0143 LKL 0.0237\n",
      "epoch 5226 loss 0.0554 LR 0.0313 LKL 0.0241\n",
      "epoch 5227 loss -0.0163 LR -0.0405 LKL 0.0242\n",
      "epoch 5228 loss 0.0002 LR -0.0238 LKL 0.0240\n",
      "epoch 5229 loss 0.0266 LR 0.0027 LKL 0.0238\n",
      "epoch 5230 loss 0.0199 LR -0.0044 LKL 0.0243\n",
      "epoch 5231 loss 0.0428 LR 0.0187 LKL 0.0241\n",
      "epoch 5232 loss 0.0352 LR 0.0112 LKL 0.0239\n",
      "epoch 5233 loss 0.0447 LR 0.0207 LKL 0.0240\n",
      "epoch 5234 loss -0.0049 LR -0.0290 LKL 0.0241\n",
      "epoch 5235 loss 0.0657 LR 0.0423 LKL 0.0234\n",
      "epoch 5236 loss -0.0066 LR -0.0307 LKL 0.0241\n",
      "epoch 5237 loss 0.0004 LR -0.0234 LKL 0.0238\n",
      "epoch 5238 loss 0.0134 LR -0.0104 LKL 0.0238\n",
      "epoch 5239 loss 0.0358 LR 0.0120 LKL 0.0237\n",
      "epoch 5240 loss 0.0383 LR 0.0143 LKL 0.0239\n",
      "epoch 5241 loss 0.0287 LR 0.0047 LKL 0.0240\n",
      "epoch 5242 loss 0.0496 LR 0.0259 LKL 0.0237\n",
      "epoch 5243 loss -0.0051 LR -0.0288 LKL 0.0238\n",
      "epoch 5244 loss 0.0296 LR 0.0058 LKL 0.0238\n",
      "epoch 5245 loss 0.0081 LR -0.0159 LKL 0.0241\n",
      "epoch 5246 loss -0.0037 LR -0.0280 LKL 0.0242\n",
      "epoch 5247 loss 0.0455 LR 0.0215 LKL 0.0240\n",
      "epoch 5248 loss 0.0201 LR -0.0037 LKL 0.0238\n",
      "epoch 5249 loss -0.0472 LR -0.0715 LKL 0.0242\n",
      "epoch 5250 loss -0.0590 LR -0.0830 LKL 0.0241\n",
      "epoch 5251 loss -0.0101 LR -0.0342 LKL 0.0241\n",
      "epoch 5252 loss 0.0399 LR 0.0157 LKL 0.0241\n",
      "epoch 5253 loss 0.0349 LR 0.0110 LKL 0.0239\n",
      "epoch 5254 loss 0.0190 LR -0.0051 LKL 0.0241\n",
      "epoch 5255 loss -0.0003 LR -0.0244 LKL 0.0241\n",
      "epoch 5256 loss 0.0679 LR 0.0441 LKL 0.0239\n",
      "epoch 5257 loss 0.1013 LR 0.0774 LKL 0.0239\n",
      "epoch 5258 loss -0.0279 LR -0.0521 LKL 0.0241\n",
      "epoch 5259 loss -0.0018 LR -0.0255 LKL 0.0237\n",
      "epoch 5260 loss -0.0094 LR -0.0335 LKL 0.0241\n",
      "epoch 5261 loss 0.0331 LR 0.0092 LKL 0.0239\n",
      "epoch 5262 loss 0.0122 LR -0.0118 LKL 0.0240\n",
      "epoch 5263 loss 0.0175 LR -0.0064 LKL 0.0240\n",
      "epoch 5264 loss 0.0812 LR 0.0578 LKL 0.0234\n",
      "epoch 5265 loss 0.0529 LR 0.0290 LKL 0.0238\n",
      "epoch 5266 loss 0.0234 LR -0.0006 LKL 0.0240\n",
      "epoch 5267 loss 0.0212 LR -0.0028 LKL 0.0240\n",
      "epoch 5268 loss 0.0021 LR -0.0215 LKL 0.0237\n",
      "epoch 5269 loss -0.0420 LR -0.0657 LKL 0.0236\n",
      "epoch 5270 loss 0.0761 LR 0.0524 LKL 0.0238\n",
      "epoch 5271 loss 0.0273 LR 0.0034 LKL 0.0239\n",
      "epoch 5272 loss 0.0701 LR 0.0461 LKL 0.0240\n",
      "epoch 5273 loss 0.0292 LR 0.0051 LKL 0.0241\n",
      "epoch 5274 loss 0.0195 LR -0.0044 LKL 0.0239\n",
      "epoch 5275 loss 0.0267 LR 0.0028 LKL 0.0238\n",
      "epoch 5276 loss 0.0668 LR 0.0432 LKL 0.0235\n",
      "epoch 5277 loss 0.0457 LR 0.0220 LKL 0.0237\n",
      "epoch 5278 loss 0.0288 LR 0.0051 LKL 0.0237\n",
      "epoch 5279 loss -0.0064 LR -0.0301 LKL 0.0236\n",
      "epoch 5280 loss 0.0066 LR -0.0172 LKL 0.0237\n",
      "epoch 5281 loss 0.0174 LR -0.0063 LKL 0.0237\n",
      "epoch 5282 loss 0.0249 LR 0.0012 LKL 0.0237\n",
      "epoch 5283 loss 0.0627 LR 0.0392 LKL 0.0235\n",
      "epoch 5284 loss -0.0009 LR -0.0248 LKL 0.0239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5285 loss 0.0253 LR 0.0014 LKL 0.0239\n",
      "epoch 5286 loss 0.0576 LR 0.0337 LKL 0.0239\n",
      "epoch 5287 loss 0.0454 LR 0.0214 LKL 0.0240\n",
      "epoch 5288 loss 0.0211 LR -0.0029 LKL 0.0240\n",
      "epoch 5289 loss 0.0954 LR 0.0715 LKL 0.0240\n",
      "epoch 5290 loss 0.0044 LR -0.0194 LKL 0.0238\n",
      "epoch 5291 loss 0.0817 LR 0.0580 LKL 0.0237\n",
      "epoch 5292 loss 0.0960 LR 0.0722 LKL 0.0238\n",
      "epoch 5293 loss 0.0697 LR 0.0459 LKL 0.0238\n",
      "epoch 5294 loss 0.0117 LR -0.0120 LKL 0.0236\n",
      "epoch 5295 loss 0.0396 LR 0.0156 LKL 0.0241\n",
      "epoch 5296 loss 0.0503 LR 0.0267 LKL 0.0237\n",
      "epoch 5297 loss 0.0312 LR 0.0079 LKL 0.0233\n",
      "epoch 5298 loss 0.0705 LR 0.0466 LKL 0.0239\n",
      "epoch 5299 loss 0.0584 LR 0.0348 LKL 0.0236\n",
      "epoch 5300 loss -0.0118 LR -0.0357 LKL 0.0239\n",
      "77\n",
      "epoch 5301 loss 0.0742 LR 0.0499 LKL 0.0242\n",
      "epoch 5302 loss -0.0062 LR -0.0305 LKL 0.0243\n",
      "epoch 5303 loss -0.0011 LR -0.0251 LKL 0.0240\n",
      "epoch 5304 loss 0.0131 LR -0.0110 LKL 0.0241\n",
      "epoch 5305 loss 0.0602 LR 0.0361 LKL 0.0241\n",
      "epoch 5306 loss -0.0038 LR -0.0280 LKL 0.0242\n",
      "epoch 5307 loss -0.0112 LR -0.0353 LKL 0.0241\n",
      "epoch 5308 loss 0.0192 LR -0.0047 LKL 0.0239\n",
      "epoch 5309 loss 0.0363 LR 0.0124 LKL 0.0239\n",
      "epoch 5310 loss 0.0390 LR 0.0151 LKL 0.0239\n",
      "epoch 5311 loss 0.0311 LR 0.0070 LKL 0.0241\n",
      "epoch 5312 loss -0.0482 LR -0.0723 LKL 0.0241\n",
      "epoch 5313 loss -0.0039 LR -0.0280 LKL 0.0240\n",
      "epoch 5314 loss 0.0441 LR 0.0201 LKL 0.0240\n",
      "epoch 5315 loss -0.0220 LR -0.0462 LKL 0.0242\n",
      "epoch 5316 loss 0.0580 LR 0.0338 LKL 0.0242\n",
      "epoch 5317 loss 0.0356 LR 0.0115 LKL 0.0241\n",
      "epoch 5318 loss 0.0552 LR 0.0311 LKL 0.0241\n",
      "epoch 5319 loss -0.0171 LR -0.0414 LKL 0.0243\n",
      "epoch 5320 loss 0.0638 LR 0.0396 LKL 0.0243\n",
      "epoch 5321 loss 0.0667 LR 0.0425 LKL 0.0242\n",
      "epoch 5322 loss 0.0795 LR 0.0553 LKL 0.0242\n",
      "epoch 5323 loss 0.0285 LR 0.0040 LKL 0.0246\n",
      "epoch 5324 loss 0.0677 LR 0.0434 LKL 0.0243\n",
      "epoch 5325 loss 0.0122 LR -0.0124 LKL 0.0246\n",
      "epoch 5326 loss 0.0425 LR 0.0182 LKL 0.0243\n",
      "epoch 5327 loss 0.0168 LR -0.0075 LKL 0.0244\n",
      "epoch 5328 loss -0.0205 LR -0.0447 LKL 0.0242\n",
      "epoch 5329 loss 0.0290 LR 0.0048 LKL 0.0242\n",
      "epoch 5330 loss 0.0893 LR 0.0648 LKL 0.0245\n",
      "epoch 5331 loss 0.0510 LR 0.0269 LKL 0.0241\n",
      "epoch 5332 loss 0.0134 LR -0.0108 LKL 0.0241\n",
      "epoch 5333 loss 0.0512 LR 0.0273 LKL 0.0239\n",
      "epoch 5334 loss 0.0160 LR -0.0083 LKL 0.0243\n",
      "epoch 5335 loss 0.0228 LR -0.0011 LKL 0.0239\n",
      "epoch 5336 loss 0.0595 LR 0.0358 LKL 0.0237\n",
      "epoch 5337 loss 0.0625 LR 0.0387 LKL 0.0238\n",
      "epoch 5338 loss -0.0208 LR -0.0447 LKL 0.0239\n",
      "epoch 5339 loss 0.0376 LR 0.0139 LKL 0.0237\n",
      "epoch 5340 loss 0.0502 LR 0.0265 LKL 0.0237\n",
      "epoch 5341 loss 0.0564 LR 0.0326 LKL 0.0238\n",
      "epoch 5342 loss 0.0299 LR 0.0061 LKL 0.0238\n",
      "epoch 5343 loss 0.0048 LR -0.0193 LKL 0.0241\n",
      "epoch 5344 loss 0.0016 LR -0.0225 LKL 0.0241\n",
      "epoch 5345 loss 0.0844 LR 0.0606 LKL 0.0238\n",
      "epoch 5346 loss 0.0901 LR 0.0661 LKL 0.0240\n",
      "epoch 5347 loss 0.0050 LR -0.0191 LKL 0.0242\n",
      "epoch 5348 loss -0.0087 LR -0.0328 LKL 0.0240\n",
      "epoch 5349 loss 0.0411 LR 0.0174 LKL 0.0237\n",
      "epoch 5350 loss 0.1178 LR 0.0941 LKL 0.0237\n",
      "epoch 5351 loss 0.0388 LR 0.0147 LKL 0.0241\n",
      "epoch 5352 loss -0.0021 LR -0.0264 LKL 0.0243\n",
      "epoch 5353 loss 0.0381 LR 0.0140 LKL 0.0242\n",
      "epoch 5354 loss 0.0368 LR 0.0125 LKL 0.0243\n",
      "epoch 5355 loss 0.0489 LR 0.0249 LKL 0.0240\n",
      "epoch 5356 loss 0.0621 LR 0.0381 LKL 0.0241\n",
      "epoch 5357 loss 0.0483 LR 0.0242 LKL 0.0241\n",
      "epoch 5358 loss 0.0333 LR 0.0092 LKL 0.0241\n",
      "epoch 5359 loss 0.0250 LR 0.0014 LKL 0.0236\n",
      "epoch 5360 loss -0.0577 LR -0.0820 LKL 0.0243\n",
      "epoch 5361 loss 0.0530 LR 0.0295 LKL 0.0235\n",
      "epoch 5362 loss -0.0554 LR -0.0792 LKL 0.0238\n",
      "epoch 5363 loss 0.0377 LR 0.0140 LKL 0.0236\n",
      "epoch 5364 loss 0.0753 LR 0.0516 LKL 0.0237\n",
      "epoch 5365 loss 0.0350 LR 0.0112 LKL 0.0239\n",
      "epoch 5366 loss 0.0604 LR 0.0368 LKL 0.0236\n",
      "epoch 5367 loss 0.0035 LR -0.0201 LKL 0.0237\n",
      "epoch 5368 loss 0.0309 LR 0.0071 LKL 0.0238\n",
      "epoch 5369 loss 0.0127 LR -0.0113 LKL 0.0240\n",
      "epoch 5370 loss 0.0902 LR 0.0666 LKL 0.0237\n",
      "epoch 5371 loss 0.0358 LR 0.0119 LKL 0.0240\n",
      "epoch 5372 loss 0.0295 LR 0.0056 LKL 0.0240\n",
      "epoch 5373 loss 0.0687 LR 0.0448 LKL 0.0238\n",
      "epoch 5374 loss 0.0200 LR -0.0039 LKL 0.0239\n",
      "epoch 5375 loss 0.0681 LR 0.0442 LKL 0.0239\n",
      "epoch 5376 loss 0.0905 LR 0.0671 LKL 0.0235\n",
      "epoch 5377 loss 0.0154 LR -0.0084 LKL 0.0238\n",
      "epoch 5378 loss 0.0350 LR 0.0114 LKL 0.0235\n",
      "epoch 5379 loss 0.0526 LR 0.0290 LKL 0.0237\n",
      "epoch 5380 loss 0.0363 LR 0.0127 LKL 0.0236\n",
      "epoch 5381 loss 0.0191 LR -0.0045 LKL 0.0235\n",
      "epoch 5382 loss -0.0139 LR -0.0376 LKL 0.0237\n",
      "epoch 5383 loss -0.0232 LR -0.0470 LKL 0.0238\n",
      "epoch 5384 loss -0.0066 LR -0.0301 LKL 0.0235\n",
      "epoch 5385 loss 0.0031 LR -0.0208 LKL 0.0239\n",
      "epoch 5386 loss 0.0318 LR 0.0079 LKL 0.0239\n",
      "epoch 5387 loss 0.0287 LR 0.0051 LKL 0.0236\n",
      "epoch 5388 loss -0.0174 LR -0.0414 LKL 0.0241\n",
      "epoch 5389 loss -0.0013 LR -0.0253 LKL 0.0239\n",
      "epoch 5390 loss 0.0356 LR 0.0115 LKL 0.0241\n",
      "epoch 5391 loss 0.0199 LR -0.0041 LKL 0.0240\n",
      "epoch 5392 loss 0.0161 LR -0.0077 LKL 0.0238\n",
      "epoch 5393 loss 0.0212 LR -0.0024 LKL 0.0236\n",
      "epoch 5394 loss 0.0110 LR -0.0128 LKL 0.0238\n",
      "epoch 5395 loss 0.0207 LR -0.0033 LKL 0.0240\n",
      "epoch 5396 loss 0.0335 LR 0.0094 LKL 0.0240\n",
      "epoch 5397 loss 0.0250 LR 0.0010 LKL 0.0240\n",
      "epoch 5398 loss -0.0200 LR -0.0439 LKL 0.0239\n",
      "epoch 5399 loss 0.0377 LR 0.0142 LKL 0.0235\n",
      "epoch 5400 loss -0.0147 LR -0.0388 LKL 0.0240\n",
      "52\n",
      "epoch 5401 loss 0.0276 LR 0.0036 LKL 0.0240\n",
      "epoch 5402 loss 0.0479 LR 0.0237 LKL 0.0242\n",
      "epoch 5403 loss 0.0176 LR -0.0066 LKL 0.0242\n",
      "epoch 5404 loss -0.0079 LR -0.0322 LKL 0.0243\n",
      "epoch 5405 loss -0.0308 LR -0.0551 LKL 0.0243\n",
      "epoch 5406 loss 0.0358 LR 0.0114 LKL 0.0243\n",
      "epoch 5407 loss 0.0381 LR 0.0138 LKL 0.0243\n",
      "epoch 5408 loss 0.0448 LR 0.0208 LKL 0.0240\n",
      "epoch 5409 loss 0.0610 LR 0.0370 LKL 0.0240\n",
      "epoch 5410 loss 0.0797 LR 0.0557 LKL 0.0240\n",
      "epoch 5411 loss 0.0842 LR 0.0606 LKL 0.0236\n",
      "epoch 5412 loss 0.0333 LR 0.0094 LKL 0.0239\n",
      "epoch 5413 loss -0.0043 LR -0.0284 LKL 0.0240\n",
      "epoch 5414 loss -0.0250 LR -0.0492 LKL 0.0242\n",
      "epoch 5415 loss 0.0423 LR 0.0183 LKL 0.0240\n",
      "epoch 5416 loss 0.0052 LR -0.0189 LKL 0.0241\n",
      "epoch 5417 loss -0.0207 LR -0.0448 LKL 0.0240\n",
      "epoch 5418 loss 0.0191 LR -0.0051 LKL 0.0242\n",
      "epoch 5419 loss 0.0526 LR 0.0288 LKL 0.0238\n",
      "epoch 5420 loss -0.0298 LR -0.0536 LKL 0.0238\n",
      "epoch 5421 loss -0.0149 LR -0.0387 LKL 0.0238\n",
      "epoch 5422 loss 0.0489 LR 0.0250 LKL 0.0239\n",
      "epoch 5423 loss 0.0931 LR 0.0693 LKL 0.0237\n",
      "epoch 5424 loss -0.0393 LR -0.0633 LKL 0.0240\n",
      "epoch 5425 loss 0.0236 LR -0.0004 LKL 0.0240\n",
      "epoch 5426 loss 0.0175 LR -0.0065 LKL 0.0240\n",
      "epoch 5427 loss -0.0106 LR -0.0347 LKL 0.0241\n",
      "epoch 5428 loss 0.0674 LR 0.0432 LKL 0.0242\n",
      "epoch 5429 loss 0.1019 LR 0.0779 LKL 0.0240\n",
      "epoch 5430 loss 0.0239 LR -0.0006 LKL 0.0244\n",
      "epoch 5431 loss -0.0331 LR -0.0573 LKL 0.0243\n",
      "epoch 5432 loss -0.0059 LR -0.0300 LKL 0.0241\n",
      "epoch 5433 loss -0.0026 LR -0.0269 LKL 0.0243\n",
      "epoch 5434 loss 0.0197 LR -0.0046 LKL 0.0243\n",
      "epoch 5435 loss 0.0456 LR 0.0215 LKL 0.0241\n",
      "epoch 5436 loss 0.0246 LR 0.0003 LKL 0.0243\n",
      "epoch 5437 loss 0.0761 LR 0.0518 LKL 0.0244\n",
      "epoch 5438 loss 0.0132 LR -0.0109 LKL 0.0241\n",
      "epoch 5439 loss -0.0294 LR -0.0539 LKL 0.0246\n",
      "epoch 5440 loss 0.0782 LR 0.0539 LKL 0.0242\n",
      "epoch 5441 loss 0.0303 LR 0.0060 LKL 0.0243\n",
      "epoch 5442 loss 0.0024 LR -0.0220 LKL 0.0244\n",
      "epoch 5443 loss 0.0177 LR -0.0065 LKL 0.0243\n",
      "epoch 5444 loss 0.0845 LR 0.0599 LKL 0.0245\n",
      "epoch 5445 loss -0.0101 LR -0.0342 LKL 0.0241\n",
      "epoch 5446 loss 0.0927 LR 0.0687 LKL 0.0240\n",
      "epoch 5447 loss 0.0188 LR -0.0053 LKL 0.0241\n",
      "epoch 5448 loss 0.0307 LR 0.0066 LKL 0.0240\n",
      "epoch 5449 loss 0.0584 LR 0.0342 LKL 0.0242\n",
      "epoch 5450 loss 0.0345 LR 0.0103 LKL 0.0242\n",
      "epoch 5451 loss 0.0581 LR 0.0340 LKL 0.0240\n",
      "epoch 5452 loss 0.0339 LR 0.0100 LKL 0.0240\n",
      "epoch 5453 loss -0.0680 LR -0.0920 LKL 0.0240\n",
      "epoch 5454 loss 0.0265 LR 0.0028 LKL 0.0237\n",
      "epoch 5455 loss -0.0068 LR -0.0306 LKL 0.0239\n",
      "epoch 5456 loss -0.0288 LR -0.0527 LKL 0.0239\n",
      "epoch 5457 loss 0.0177 LR -0.0060 LKL 0.0237\n",
      "epoch 5458 loss 0.0677 LR 0.0438 LKL 0.0238\n",
      "epoch 5459 loss 0.0232 LR -0.0008 LKL 0.0240\n",
      "epoch 5460 loss 0.0284 LR 0.0045 LKL 0.0239\n",
      "epoch 5461 loss -0.0252 LR -0.0491 LKL 0.0239\n",
      "epoch 5462 loss 0.0139 LR -0.0101 LKL 0.0240\n",
      "epoch 5463 loss -0.0009 LR -0.0249 LKL 0.0240\n",
      "epoch 5464 loss 0.0496 LR 0.0258 LKL 0.0238\n",
      "epoch 5465 loss 0.0194 LR -0.0046 LKL 0.0240\n",
      "epoch 5466 loss 0.0646 LR 0.0410 LKL 0.0236\n",
      "epoch 5467 loss 0.0465 LR 0.0224 LKL 0.0241\n",
      "epoch 5468 loss 0.1016 LR 0.0779 LKL 0.0236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5469 loss 0.0397 LR 0.0154 LKL 0.0243\n",
      "epoch 5470 loss 0.0143 LR -0.0102 LKL 0.0244\n",
      "epoch 5471 loss 0.0030 LR -0.0211 LKL 0.0242\n",
      "epoch 5472 loss -0.0018 LR -0.0259 LKL 0.0241\n",
      "epoch 5473 loss 0.0322 LR 0.0084 LKL 0.0238\n",
      "epoch 5474 loss 0.0341 LR 0.0101 LKL 0.0239\n",
      "epoch 5475 loss 0.0676 LR 0.0438 LKL 0.0238\n",
      "epoch 5476 loss 0.0155 LR -0.0084 LKL 0.0240\n",
      "epoch 5477 loss 0.0109 LR -0.0129 LKL 0.0238\n",
      "epoch 5478 loss 0.0550 LR 0.0312 LKL 0.0238\n",
      "epoch 5479 loss -0.0033 LR -0.0274 LKL 0.0241\n",
      "epoch 5480 loss 0.0391 LR 0.0153 LKL 0.0238\n",
      "epoch 5481 loss 0.0263 LR 0.0026 LKL 0.0237\n",
      "epoch 5482 loss 0.0340 LR 0.0102 LKL 0.0239\n",
      "epoch 5483 loss -0.0160 LR -0.0398 LKL 0.0238\n",
      "epoch 5484 loss 0.0315 LR 0.0075 LKL 0.0240\n",
      "epoch 5485 loss -0.0043 LR -0.0280 LKL 0.0237\n",
      "epoch 5486 loss 0.0456 LR 0.0219 LKL 0.0237\n",
      "epoch 5487 loss -0.0014 LR -0.0248 LKL 0.0234\n",
      "epoch 5488 loss 0.0195 LR -0.0043 LKL 0.0238\n",
      "epoch 5489 loss -0.0297 LR -0.0533 LKL 0.0236\n",
      "epoch 5490 loss 0.0111 LR -0.0123 LKL 0.0235\n",
      "epoch 5491 loss 0.0598 LR 0.0361 LKL 0.0237\n",
      "epoch 5492 loss -0.0159 LR -0.0395 LKL 0.0236\n",
      "epoch 5493 loss 0.0809 LR 0.0571 LKL 0.0238\n",
      "epoch 5494 loss -0.0282 LR -0.0520 LKL 0.0238\n",
      "epoch 5495 loss -0.0352 LR -0.0595 LKL 0.0243\n",
      "epoch 5496 loss 0.0465 LR 0.0230 LKL 0.0236\n",
      "epoch 5497 loss 0.0419 LR 0.0181 LKL 0.0238\n",
      "epoch 5498 loss 0.0394 LR 0.0155 LKL 0.0239\n",
      "epoch 5499 loss -0.0079 LR -0.0318 LKL 0.0239\n",
      "epoch 5500 loss 0.0705 LR 0.0465 LKL 0.0240\n",
      "76\n",
      "epoch 5501 loss 0.0170 LR -0.0072 LKL 0.0242\n",
      "epoch 5502 loss 0.0802 LR 0.0562 LKL 0.0241\n",
      "epoch 5503 loss 0.0025 LR -0.0217 LKL 0.0241\n",
      "epoch 5504 loss -0.0034 LR -0.0276 LKL 0.0242\n",
      "epoch 5505 loss 0.0195 LR -0.0046 LKL 0.0241\n",
      "epoch 5506 loss -0.0172 LR -0.0413 LKL 0.0241\n",
      "epoch 5507 loss 0.0008 LR -0.0233 LKL 0.0241\n",
      "epoch 5508 loss 0.0041 LR -0.0202 LKL 0.0243\n",
      "epoch 5509 loss 0.0039 LR -0.0202 LKL 0.0241\n",
      "epoch 5510 loss 0.0345 LR 0.0102 LKL 0.0242\n",
      "epoch 5511 loss 0.0286 LR 0.0045 LKL 0.0241\n",
      "epoch 5512 loss 0.0115 LR -0.0126 LKL 0.0241\n",
      "epoch 5513 loss 0.0299 LR 0.0061 LKL 0.0239\n",
      "epoch 5514 loss 0.0337 LR 0.0096 LKL 0.0241\n",
      "epoch 5515 loss -0.0298 LR -0.0541 LKL 0.0243\n",
      "epoch 5516 loss 0.0753 LR 0.0516 LKL 0.0237\n",
      "epoch 5517 loss 0.0266 LR 0.0028 LKL 0.0239\n",
      "epoch 5518 loss 0.0259 LR 0.0018 LKL 0.0241\n",
      "epoch 5519 loss -0.0111 LR -0.0352 LKL 0.0241\n",
      "epoch 5520 loss -0.0242 LR -0.0485 LKL 0.0243\n",
      "epoch 5521 loss 0.0657 LR 0.0415 LKL 0.0242\n",
      "epoch 5522 loss -0.0355 LR -0.0600 LKL 0.0245\n",
      "epoch 5523 loss -0.0200 LR -0.0445 LKL 0.0245\n",
      "epoch 5524 loss 0.0225 LR -0.0016 LKL 0.0241\n",
      "epoch 5525 loss 0.0564 LR 0.0324 LKL 0.0240\n",
      "epoch 5526 loss -0.0626 LR -0.0870 LKL 0.0244\n",
      "epoch 5527 loss 0.0676 LR 0.0434 LKL 0.0242\n",
      "epoch 5528 loss 0.0439 LR 0.0198 LKL 0.0241\n",
      "epoch 5529 loss 0.0525 LR 0.0287 LKL 0.0238\n",
      "epoch 5530 loss 0.0489 LR 0.0251 LKL 0.0238\n",
      "epoch 5531 loss 0.0010 LR -0.0231 LKL 0.0241\n",
      "epoch 5532 loss 0.0421 LR 0.0181 LKL 0.0240\n",
      "epoch 5533 loss 0.0729 LR 0.0489 LKL 0.0241\n",
      "epoch 5534 loss -0.0137 LR -0.0380 LKL 0.0244\n",
      "epoch 5535 loss 0.0362 LR 0.0118 LKL 0.0244\n",
      "epoch 5536 loss 0.0653 LR 0.0409 LKL 0.0244\n",
      "epoch 5537 loss 0.0089 LR -0.0157 LKL 0.0246\n",
      "epoch 5538 loss -0.0285 LR -0.0532 LKL 0.0246\n",
      "epoch 5539 loss 0.0400 LR 0.0155 LKL 0.0246\n",
      "epoch 5540 loss 0.0199 LR -0.0049 LKL 0.0248\n",
      "epoch 5541 loss 0.0084 LR -0.0160 LKL 0.0245\n",
      "epoch 5542 loss -0.0104 LR -0.0348 LKL 0.0245\n",
      "epoch 5543 loss 0.0037 LR -0.0210 LKL 0.0247\n",
      "epoch 5544 loss -0.0034 LR -0.0279 LKL 0.0245\n",
      "epoch 5545 loss 0.0030 LR -0.0210 LKL 0.0240\n",
      "epoch 5546 loss -0.0154 LR -0.0399 LKL 0.0244\n",
      "epoch 5547 loss -0.0143 LR -0.0386 LKL 0.0243\n",
      "epoch 5548 loss 0.0361 LR 0.0122 LKL 0.0240\n",
      "epoch 5549 loss 0.0669 LR 0.0430 LKL 0.0238\n",
      "epoch 5550 loss -0.0017 LR -0.0256 LKL 0.0238\n",
      "epoch 5551 loss 0.0234 LR -0.0004 LKL 0.0238\n",
      "epoch 5552 loss 0.0042 LR -0.0195 LKL 0.0236\n",
      "epoch 5553 loss -0.0139 LR -0.0375 LKL 0.0236\n",
      "epoch 5554 loss -0.0105 LR -0.0342 LKL 0.0237\n",
      "epoch 5555 loss -0.0240 LR -0.0477 LKL 0.0237\n",
      "epoch 5556 loss 0.0456 LR 0.0220 LKL 0.0236\n",
      "epoch 5557 loss 0.0485 LR 0.0248 LKL 0.0237\n",
      "epoch 5558 loss 0.0176 LR -0.0064 LKL 0.0240\n",
      "epoch 5559 loss 0.0384 LR 0.0145 LKL 0.0238\n",
      "epoch 5560 loss -0.0220 LR -0.0461 LKL 0.0241\n",
      "epoch 5561 loss -0.0293 LR -0.0537 LKL 0.0244\n",
      "epoch 5562 loss 0.0615 LR 0.0376 LKL 0.0239\n",
      "epoch 5563 loss 0.0220 LR -0.0022 LKL 0.0242\n",
      "epoch 5564 loss 0.0124 LR -0.0119 LKL 0.0243\n",
      "epoch 5565 loss 0.0196 LR -0.0044 LKL 0.0240\n",
      "epoch 5566 loss 0.0405 LR 0.0162 LKL 0.0243\n",
      "epoch 5567 loss 0.0644 LR 0.0403 LKL 0.0241\n",
      "epoch 5568 loss 0.0508 LR 0.0271 LKL 0.0238\n",
      "epoch 5569 loss 0.0679 LR 0.0442 LKL 0.0238\n",
      "epoch 5570 loss 0.0581 LR 0.0342 LKL 0.0239\n",
      "epoch 5571 loss 0.0332 LR 0.0092 LKL 0.0240\n",
      "epoch 5572 loss 0.0136 LR -0.0104 LKL 0.0241\n",
      "epoch 5573 loss 0.0601 LR 0.0364 LKL 0.0237\n",
      "epoch 5574 loss 0.0624 LR 0.0386 LKL 0.0237\n",
      "epoch 5575 loss 0.0322 LR 0.0086 LKL 0.0237\n",
      "epoch 5576 loss 0.0618 LR 0.0381 LKL 0.0237\n",
      "epoch 5577 loss 0.0319 LR 0.0080 LKL 0.0239\n",
      "epoch 5578 loss 0.0054 LR -0.0182 LKL 0.0236\n",
      "epoch 5579 loss 0.0286 LR 0.0049 LKL 0.0238\n",
      "epoch 5580 loss 0.0023 LR -0.0214 LKL 0.0238\n",
      "epoch 5581 loss 0.0380 LR 0.0143 LKL 0.0236\n",
      "epoch 5582 loss -0.0272 LR -0.0510 LKL 0.0238\n",
      "epoch 5583 loss 0.0032 LR -0.0206 LKL 0.0237\n",
      "epoch 5584 loss -0.0281 LR -0.0521 LKL 0.0240\n",
      "epoch 5585 loss 0.0026 LR -0.0217 LKL 0.0242\n",
      "epoch 5586 loss -0.0278 LR -0.0521 LKL 0.0242\n",
      "epoch 5587 loss 0.0362 LR 0.0122 LKL 0.0240\n",
      "epoch 5588 loss 0.0608 LR 0.0366 LKL 0.0241\n",
      "epoch 5589 loss 0.0158 LR -0.0081 LKL 0.0240\n",
      "epoch 5590 loss -0.0009 LR -0.0249 LKL 0.0240\n",
      "epoch 5591 loss 0.0233 LR -0.0008 LKL 0.0241\n",
      "epoch 5592 loss 0.0202 LR -0.0035 LKL 0.0237\n",
      "epoch 5593 loss -0.0010 LR -0.0248 LKL 0.0239\n",
      "epoch 5594 loss 0.0326 LR 0.0085 LKL 0.0241\n",
      "epoch 5595 loss 0.0249 LR 0.0008 LKL 0.0241\n",
      "epoch 5596 loss -0.0085 LR -0.0325 LKL 0.0241\n",
      "epoch 5597 loss 0.0360 LR 0.0117 LKL 0.0243\n",
      "epoch 5598 loss -0.0128 LR -0.0370 LKL 0.0242\n",
      "epoch 5599 loss 0.0314 LR 0.0072 LKL 0.0242\n",
      "epoch 5600 loss 0.0130 LR -0.0112 LKL 0.0242\n",
      "110\n",
      "epoch 5601 loss -0.0147 LR -0.0394 LKL 0.0247\n",
      "epoch 5602 loss 0.0604 LR 0.0361 LKL 0.0242\n",
      "epoch 5603 loss 0.0105 LR -0.0140 LKL 0.0245\n",
      "epoch 5604 loss 0.0167 LR -0.0079 LKL 0.0246\n",
      "epoch 5605 loss -0.0014 LR -0.0257 LKL 0.0243\n",
      "epoch 5606 loss -0.0465 LR -0.0710 LKL 0.0245\n",
      "epoch 5607 loss 0.0088 LR -0.0155 LKL 0.0243\n",
      "epoch 5608 loss 0.0000 LR -0.0245 LKL 0.0245\n",
      "epoch 5609 loss 0.0197 LR -0.0046 LKL 0.0243\n",
      "epoch 5610 loss -0.0133 LR -0.0374 LKL 0.0241\n",
      "epoch 5611 loss 0.0182 LR -0.0058 LKL 0.0239\n",
      "epoch 5612 loss 0.0203 LR -0.0040 LKL 0.0243\n",
      "epoch 5613 loss 0.0543 LR 0.0300 LKL 0.0243\n",
      "epoch 5614 loss -0.0346 LR -0.0585 LKL 0.0239\n",
      "epoch 5615 loss 0.0367 LR 0.0128 LKL 0.0239\n",
      "epoch 5616 loss 0.0185 LR -0.0057 LKL 0.0242\n",
      "epoch 5617 loss -0.0180 LR -0.0423 LKL 0.0243\n",
      "epoch 5618 loss -0.0319 LR -0.0562 LKL 0.0242\n",
      "epoch 5619 loss 0.0281 LR 0.0039 LKL 0.0242\n",
      "epoch 5620 loss 0.0196 LR -0.0046 LKL 0.0242\n",
      "epoch 5621 loss 0.0448 LR 0.0207 LKL 0.0241\n",
      "epoch 5622 loss 0.0226 LR -0.0015 LKL 0.0240\n",
      "epoch 5623 loss -0.0321 LR -0.0562 LKL 0.0242\n",
      "epoch 5624 loss -0.0149 LR -0.0392 LKL 0.0243\n",
      "epoch 5625 loss 0.0343 LR 0.0102 LKL 0.0241\n",
      "epoch 5626 loss 0.0140 LR -0.0100 LKL 0.0240\n",
      "epoch 5627 loss 0.0019 LR -0.0220 LKL 0.0239\n",
      "epoch 5628 loss -0.0066 LR -0.0306 LKL 0.0240\n",
      "epoch 5629 loss 0.0667 LR 0.0427 LKL 0.0240\n",
      "epoch 5630 loss -0.0028 LR -0.0267 LKL 0.0238\n",
      "epoch 5631 loss 0.0475 LR 0.0239 LKL 0.0236\n",
      "epoch 5632 loss 0.0576 LR 0.0339 LKL 0.0237\n",
      "epoch 5633 loss 0.0560 LR 0.0323 LKL 0.0237\n",
      "epoch 5634 loss 0.0039 LR -0.0200 LKL 0.0239\n",
      "epoch 5635 loss 0.0120 LR -0.0118 LKL 0.0238\n",
      "epoch 5636 loss 0.0325 LR 0.0088 LKL 0.0237\n",
      "epoch 5637 loss 0.0042 LR -0.0197 LKL 0.0240\n",
      "epoch 5638 loss 0.0364 LR 0.0125 LKL 0.0239\n",
      "epoch 5639 loss 0.0231 LR -0.0010 LKL 0.0241\n",
      "epoch 5640 loss 0.1204 LR 0.0965 LKL 0.0240\n",
      "epoch 5641 loss 0.0151 LR -0.0088 LKL 0.0239\n",
      "epoch 5642 loss -0.0036 LR -0.0276 LKL 0.0240\n",
      "epoch 5643 loss 0.0473 LR 0.0233 LKL 0.0240\n",
      "epoch 5644 loss 0.0228 LR -0.0010 LKL 0.0239\n",
      "epoch 5645 loss 0.0417 LR 0.0177 LKL 0.0240\n",
      "epoch 5646 loss 0.0985 LR 0.0745 LKL 0.0240\n",
      "epoch 5647 loss -0.0029 LR -0.0267 LKL 0.0239\n",
      "epoch 5648 loss -0.0177 LR -0.0419 LKL 0.0242\n",
      "epoch 5649 loss -0.0223 LR -0.0462 LKL 0.0239\n",
      "epoch 5650 loss -0.0408 LR -0.0651 LKL 0.0243\n",
      "epoch 5651 loss 0.0176 LR -0.0065 LKL 0.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5652 loss -0.0094 LR -0.0338 LKL 0.0243\n",
      "epoch 5653 loss 0.0088 LR -0.0154 LKL 0.0242\n",
      "epoch 5654 loss 0.0661 LR 0.0422 LKL 0.0238\n",
      "epoch 5655 loss 0.0053 LR -0.0189 LKL 0.0242\n",
      "epoch 5656 loss 0.0319 LR 0.0077 LKL 0.0241\n",
      "epoch 5657 loss 0.0271 LR 0.0031 LKL 0.0240\n",
      "epoch 5658 loss -0.0369 LR -0.0610 LKL 0.0241\n",
      "epoch 5659 loss 0.0129 LR -0.0113 LKL 0.0242\n",
      "epoch 5660 loss 0.0251 LR 0.0013 LKL 0.0238\n",
      "epoch 5661 loss -0.0042 LR -0.0279 LKL 0.0237\n",
      "epoch 5662 loss 0.0847 LR 0.0610 LKL 0.0236\n",
      "epoch 5663 loss 0.0447 LR 0.0213 LKL 0.0234\n",
      "epoch 5664 loss 0.0319 LR 0.0082 LKL 0.0237\n",
      "epoch 5665 loss -0.0318 LR -0.0558 LKL 0.0240\n",
      "epoch 5666 loss -0.0097 LR -0.0337 LKL 0.0240\n",
      "epoch 5667 loss 0.0078 LR -0.0163 LKL 0.0240\n",
      "epoch 5668 loss 0.0058 LR -0.0181 LKL 0.0239\n",
      "epoch 5669 loss -0.0154 LR -0.0398 LKL 0.0243\n",
      "epoch 5670 loss 0.0233 LR -0.0006 LKL 0.0240\n",
      "epoch 5671 loss 0.0110 LR -0.0128 LKL 0.0238\n",
      "epoch 5672 loss 0.0817 LR 0.0580 LKL 0.0237\n",
      "epoch 5673 loss 0.0378 LR 0.0136 LKL 0.0242\n",
      "epoch 5674 loss 0.0155 LR -0.0088 LKL 0.0243\n",
      "epoch 5675 loss 0.0616 LR 0.0375 LKL 0.0241\n",
      "epoch 5676 loss 0.0004 LR -0.0239 LKL 0.0243\n",
      "epoch 5677 loss 0.0211 LR -0.0031 LKL 0.0242\n",
      "epoch 5678 loss -0.0224 LR -0.0469 LKL 0.0245\n",
      "epoch 5679 loss 0.0040 LR -0.0206 LKL 0.0246\n",
      "epoch 5680 loss 0.0115 LR -0.0129 LKL 0.0244\n",
      "epoch 5681 loss -0.0185 LR -0.0428 LKL 0.0244\n",
      "epoch 5682 loss 0.0416 LR 0.0171 LKL 0.0245\n",
      "epoch 5683 loss 0.0646 LR 0.0403 LKL 0.0243\n",
      "epoch 5684 loss 0.0246 LR 0.0004 LKL 0.0242\n",
      "epoch 5685 loss 0.0014 LR -0.0226 LKL 0.0240\n",
      "epoch 5686 loss -0.0354 LR -0.0597 LKL 0.0243\n",
      "epoch 5687 loss 0.0131 LR -0.0113 LKL 0.0244\n",
      "epoch 5688 loss -0.0092 LR -0.0334 LKL 0.0242\n",
      "epoch 5689 loss 0.0167 LR -0.0079 LKL 0.0246\n",
      "epoch 5690 loss 0.0270 LR 0.0027 LKL 0.0243\n",
      "epoch 5691 loss 0.0692 LR 0.0449 LKL 0.0243\n",
      "epoch 5692 loss -0.0124 LR -0.0366 LKL 0.0242\n",
      "epoch 5693 loss 0.0230 LR -0.0013 LKL 0.0243\n",
      "epoch 5694 loss -0.0495 LR -0.0738 LKL 0.0243\n",
      "epoch 5695 loss 0.0070 LR -0.0175 LKL 0.0245\n",
      "epoch 5696 loss 0.0695 LR 0.0455 LKL 0.0240\n",
      "epoch 5697 loss 0.0093 LR -0.0149 LKL 0.0243\n",
      "epoch 5698 loss 0.0586 LR 0.0345 LKL 0.0241\n",
      "epoch 5699 loss -0.0252 LR -0.0494 LKL 0.0242\n",
      "epoch 5700 loss 0.0260 LR 0.0018 LKL 0.0242\n",
      "67\n",
      "epoch 5701 loss 0.0201 LR -0.0039 LKL 0.0241\n",
      "epoch 5702 loss 0.0333 LR 0.0092 LKL 0.0240\n",
      "epoch 5703 loss -0.0061 LR -0.0302 LKL 0.0242\n",
      "epoch 5704 loss 0.0003 LR -0.0238 LKL 0.0241\n",
      "epoch 5705 loss 0.0306 LR 0.0065 LKL 0.0241\n",
      "epoch 5706 loss -0.0252 LR -0.0492 LKL 0.0240\n",
      "epoch 5707 loss 0.0008 LR -0.0232 LKL 0.0239\n",
      "epoch 5708 loss 0.0534 LR 0.0296 LKL 0.0238\n",
      "epoch 5709 loss -0.0065 LR -0.0305 LKL 0.0240\n",
      "epoch 5710 loss -0.0255 LR -0.0498 LKL 0.0242\n",
      "epoch 5711 loss 0.0206 LR -0.0035 LKL 0.0240\n",
      "epoch 5712 loss 0.0261 LR 0.0020 LKL 0.0242\n",
      "epoch 5713 loss 0.0143 LR -0.0100 LKL 0.0243\n",
      "epoch 5714 loss 0.0044 LR -0.0201 LKL 0.0245\n",
      "epoch 5715 loss 0.0021 LR -0.0221 LKL 0.0243\n",
      "epoch 5716 loss 0.0368 LR 0.0124 LKL 0.0244\n",
      "epoch 5717 loss 0.0134 LR -0.0108 LKL 0.0243\n",
      "epoch 5718 loss 0.0172 LR -0.0071 LKL 0.0243\n",
      "epoch 5719 loss 0.0460 LR 0.0217 LKL 0.0243\n",
      "epoch 5720 loss -0.0218 LR -0.0459 LKL 0.0242\n",
      "epoch 5721 loss 0.0180 LR -0.0065 LKL 0.0245\n",
      "epoch 5722 loss 0.0454 LR 0.0211 LKL 0.0243\n",
      "epoch 5723 loss -0.0136 LR -0.0378 LKL 0.0243\n",
      "epoch 5724 loss 0.0202 LR -0.0042 LKL 0.0244\n",
      "epoch 5725 loss 0.0317 LR 0.0074 LKL 0.0243\n",
      "epoch 5726 loss -0.0268 LR -0.0514 LKL 0.0246\n",
      "epoch 5727 loss 0.0535 LR 0.0291 LKL 0.0244\n",
      "epoch 5728 loss -0.0466 LR -0.0713 LKL 0.0247\n",
      "epoch 5729 loss 0.0097 LR -0.0149 LKL 0.0246\n",
      "epoch 5730 loss 0.0858 LR 0.0613 LKL 0.0245\n",
      "epoch 5731 loss 0.0466 LR 0.0222 LKL 0.0244\n",
      "epoch 5732 loss 0.0776 LR 0.0533 LKL 0.0243\n",
      "epoch 5733 loss -0.0141 LR -0.0387 LKL 0.0246\n",
      "epoch 5734 loss 0.0477 LR 0.0233 LKL 0.0243\n",
      "epoch 5735 loss 0.0164 LR -0.0080 LKL 0.0244\n",
      "epoch 5736 loss 0.0194 LR -0.0048 LKL 0.0242\n",
      "epoch 5737 loss 0.0118 LR -0.0126 LKL 0.0244\n",
      "epoch 5738 loss 0.0283 LR 0.0046 LKL 0.0237\n",
      "epoch 5739 loss 0.0230 LR -0.0008 LKL 0.0238\n",
      "epoch 5740 loss 0.0050 LR -0.0188 LKL 0.0239\n",
      "epoch 5741 loss 0.0512 LR 0.0273 LKL 0.0239\n",
      "epoch 5742 loss 0.0303 LR 0.0066 LKL 0.0236\n",
      "epoch 5743 loss -0.0471 LR -0.0709 LKL 0.0238\n",
      "epoch 5744 loss 0.0349 LR 0.0110 LKL 0.0239\n",
      "epoch 5745 loss 0.0044 LR -0.0192 LKL 0.0236\n",
      "epoch 5746 loss -0.0271 LR -0.0510 LKL 0.0239\n",
      "epoch 5747 loss -0.0392 LR -0.0631 LKL 0.0238\n",
      "epoch 5748 loss 0.0463 LR 0.0225 LKL 0.0238\n",
      "epoch 5749 loss 0.0005 LR -0.0235 LKL 0.0240\n",
      "epoch 5750 loss 0.0493 LR 0.0254 LKL 0.0239\n",
      "epoch 5751 loss 0.0053 LR -0.0184 LKL 0.0237\n",
      "epoch 5752 loss 0.0039 LR -0.0200 LKL 0.0239\n",
      "epoch 5753 loss 0.0468 LR 0.0228 LKL 0.0240\n",
      "epoch 5754 loss -0.0017 LR -0.0255 LKL 0.0238\n",
      "epoch 5755 loss 0.0076 LR -0.0163 LKL 0.0239\n",
      "epoch 5756 loss 0.0345 LR 0.0108 LKL 0.0237\n",
      "epoch 5757 loss 0.0107 LR -0.0131 LKL 0.0237\n",
      "epoch 5758 loss -0.0140 LR -0.0379 LKL 0.0238\n",
      "epoch 5759 loss 0.0432 LR 0.0191 LKL 0.0240\n",
      "epoch 5760 loss 0.0342 LR 0.0102 LKL 0.0240\n",
      "epoch 5761 loss 0.0253 LR 0.0014 LKL 0.0239\n",
      "epoch 5762 loss 0.0238 LR 0.0001 LKL 0.0237\n",
      "epoch 5763 loss 0.0845 LR 0.0607 LKL 0.0238\n",
      "epoch 5764 loss 0.0125 LR -0.0114 LKL 0.0239\n",
      "epoch 5765 loss 0.0093 LR -0.0146 LKL 0.0239\n",
      "epoch 5766 loss 0.0277 LR 0.0037 LKL 0.0239\n",
      "epoch 5767 loss 0.0201 LR -0.0037 LKL 0.0237\n",
      "epoch 5768 loss 0.0344 LR 0.0104 LKL 0.0240\n",
      "epoch 5769 loss 0.0562 LR 0.0322 LKL 0.0240\n",
      "epoch 5770 loss 0.0653 LR 0.0416 LKL 0.0237\n",
      "epoch 5771 loss -0.0525 LR -0.0767 LKL 0.0241\n",
      "epoch 5772 loss 0.0028 LR -0.0214 LKL 0.0242\n",
      "epoch 5773 loss 0.0192 LR -0.0049 LKL 0.0241\n",
      "epoch 5774 loss -0.0082 LR -0.0322 LKL 0.0240\n",
      "epoch 5775 loss 0.0066 LR -0.0176 LKL 0.0242\n",
      "epoch 5776 loss 0.0295 LR 0.0053 LKL 0.0242\n",
      "epoch 5777 loss -0.0284 LR -0.0526 LKL 0.0242\n",
      "epoch 5778 loss -0.0002 LR -0.0244 LKL 0.0242\n",
      "epoch 5779 loss 0.0065 LR -0.0177 LKL 0.0242\n",
      "epoch 5780 loss 0.0208 LR -0.0036 LKL 0.0244\n",
      "epoch 5781 loss 0.0598 LR 0.0356 LKL 0.0242\n",
      "epoch 5782 loss -0.0158 LR -0.0403 LKL 0.0245\n",
      "epoch 5783 loss 0.0798 LR 0.0556 LKL 0.0242\n",
      "epoch 5784 loss 0.0039 LR -0.0205 LKL 0.0244\n",
      "epoch 5785 loss 0.0679 LR 0.0437 LKL 0.0241\n",
      "epoch 5786 loss 0.0669 LR 0.0432 LKL 0.0238\n",
      "epoch 5787 loss -0.0416 LR -0.0654 LKL 0.0238\n",
      "epoch 5788 loss -0.0131 LR -0.0365 LKL 0.0235\n",
      "epoch 5789 loss 0.0500 LR 0.0263 LKL 0.0237\n",
      "epoch 5790 loss 0.0388 LR 0.0154 LKL 0.0234\n",
      "epoch 5791 loss 0.0516 LR 0.0277 LKL 0.0238\n",
      "epoch 5792 loss 0.0419 LR 0.0181 LKL 0.0238\n",
      "epoch 5793 loss 0.0311 LR 0.0073 LKL 0.0238\n",
      "epoch 5794 loss 0.0598 LR 0.0360 LKL 0.0238\n",
      "epoch 5795 loss -0.0014 LR -0.0253 LKL 0.0239\n",
      "epoch 5796 loss 0.0010 LR -0.0230 LKL 0.0240\n",
      "epoch 5797 loss 0.0314 LR 0.0074 LKL 0.0240\n",
      "epoch 5798 loss -0.0063 LR -0.0302 LKL 0.0239\n",
      "epoch 5799 loss -0.0161 LR -0.0401 LKL 0.0240\n",
      "epoch 5800 loss -0.0315 LR -0.0555 LKL 0.0240\n",
      "73\n",
      "epoch 5801 loss -0.0214 LR -0.0453 LKL 0.0238\n",
      "epoch 5802 loss 0.0724 LR 0.0486 LKL 0.0238\n",
      "epoch 5803 loss 0.0419 LR 0.0183 LKL 0.0236\n",
      "epoch 5804 loss -0.0318 LR -0.0557 LKL 0.0240\n",
      "epoch 5805 loss 0.0082 LR -0.0155 LKL 0.0238\n",
      "epoch 5806 loss 0.0490 LR 0.0253 LKL 0.0236\n",
      "epoch 5807 loss 0.0150 LR -0.0089 LKL 0.0239\n",
      "epoch 5808 loss 0.0257 LR 0.0017 LKL 0.0239\n",
      "epoch 5809 loss 0.0093 LR -0.0146 LKL 0.0239\n",
      "epoch 5810 loss 0.0813 LR 0.0576 LKL 0.0237\n",
      "epoch 5811 loss 0.0418 LR 0.0177 LKL 0.0241\n",
      "epoch 5812 loss -0.0144 LR -0.0383 LKL 0.0239\n",
      "epoch 5813 loss 0.0275 LR 0.0035 LKL 0.0240\n",
      "epoch 5814 loss 0.0065 LR -0.0175 LKL 0.0240\n",
      "epoch 5815 loss 0.0211 LR -0.0030 LKL 0.0241\n",
      "epoch 5816 loss 0.0397 LR 0.0158 LKL 0.0239\n",
      "epoch 5817 loss 0.0404 LR 0.0163 LKL 0.0242\n",
      "epoch 5818 loss 0.0780 LR 0.0542 LKL 0.0238\n",
      "epoch 5819 loss 0.0427 LR 0.0187 LKL 0.0240\n",
      "epoch 5820 loss 0.0441 LR 0.0203 LKL 0.0238\n",
      "epoch 5821 loss 0.0623 LR 0.0387 LKL 0.0236\n",
      "epoch 5822 loss 0.0440 LR 0.0202 LKL 0.0238\n",
      "epoch 5823 loss -0.0228 LR -0.0467 LKL 0.0239\n",
      "epoch 5824 loss -0.0086 LR -0.0326 LKL 0.0240\n",
      "epoch 5825 loss 0.0009 LR -0.0231 LKL 0.0239\n",
      "epoch 5826 loss 0.0487 LR 0.0249 LKL 0.0238\n",
      "epoch 5827 loss -0.0346 LR -0.0588 LKL 0.0242\n",
      "epoch 5828 loss -0.0449 LR -0.0687 LKL 0.0238\n",
      "epoch 5829 loss 0.0194 LR -0.0048 LKL 0.0242\n",
      "epoch 5830 loss 0.0200 LR -0.0039 LKL 0.0239\n",
      "epoch 5831 loss -0.0286 LR -0.0528 LKL 0.0241\n",
      "epoch 5832 loss 0.0801 LR 0.0560 LKL 0.0241\n",
      "epoch 5833 loss 0.0260 LR 0.0017 LKL 0.0242\n",
      "epoch 5834 loss 0.0158 LR -0.0086 LKL 0.0244\n",
      "epoch 5835 loss 0.0102 LR -0.0141 LKL 0.0243\n",
      "epoch 5836 loss 0.0411 LR 0.0169 LKL 0.0242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5837 loss 0.0415 LR 0.0174 LKL 0.0242\n",
      "epoch 5838 loss 0.0632 LR 0.0389 LKL 0.0243\n",
      "epoch 5839 loss 0.0680 LR 0.0439 LKL 0.0241\n",
      "epoch 5840 loss 0.0099 LR -0.0144 LKL 0.0243\n",
      "epoch 5841 loss -0.0289 LR -0.0533 LKL 0.0244\n",
      "epoch 5842 loss 0.0559 LR 0.0318 LKL 0.0242\n",
      "epoch 5843 loss 0.0763 LR 0.0524 LKL 0.0239\n",
      "epoch 5844 loss 0.0429 LR 0.0189 LKL 0.0240\n",
      "epoch 5845 loss 0.0096 LR -0.0145 LKL 0.0240\n",
      "epoch 5846 loss 0.0361 LR 0.0124 LKL 0.0238\n",
      "epoch 5847 loss 0.0381 LR 0.0142 LKL 0.0239\n",
      "epoch 5848 loss 0.0838 LR 0.0605 LKL 0.0233\n",
      "epoch 5849 loss 0.0598 LR 0.0362 LKL 0.0235\n",
      "epoch 5850 loss 0.0189 LR -0.0046 LKL 0.0235\n",
      "epoch 5851 loss 0.0230 LR -0.0008 LKL 0.0237\n",
      "epoch 5852 loss 0.0269 LR 0.0031 LKL 0.0237\n",
      "epoch 5853 loss 0.0232 LR -0.0006 LKL 0.0238\n",
      "epoch 5854 loss 0.0298 LR 0.0063 LKL 0.0235\n",
      "epoch 5855 loss 0.0428 LR 0.0189 LKL 0.0239\n",
      "epoch 5856 loss 0.0001 LR -0.0239 LKL 0.0241\n",
      "epoch 5857 loss 0.0242 LR 0.0004 LKL 0.0238\n",
      "epoch 5858 loss 0.0860 LR 0.0619 LKL 0.0241\n",
      "epoch 5859 loss 0.0289 LR 0.0048 LKL 0.0241\n",
      "epoch 5860 loss 0.0519 LR 0.0277 LKL 0.0242\n",
      "epoch 5861 loss -0.0199 LR -0.0440 LKL 0.0242\n",
      "epoch 5862 loss 0.0188 LR -0.0052 LKL 0.0241\n",
      "epoch 5863 loss -0.0289 LR -0.0529 LKL 0.0240\n",
      "epoch 5864 loss 0.0560 LR 0.0320 LKL 0.0241\n",
      "epoch 5865 loss 0.0004 LR -0.0236 LKL 0.0240\n",
      "epoch 5866 loss -0.0008 LR -0.0249 LKL 0.0241\n",
      "epoch 5867 loss -0.0063 LR -0.0304 LKL 0.0241\n",
      "epoch 5868 loss 0.0022 LR -0.0218 LKL 0.0240\n",
      "epoch 5869 loss 0.0327 LR 0.0086 LKL 0.0241\n",
      "epoch 5870 loss 0.0528 LR 0.0291 LKL 0.0237\n",
      "epoch 5871 loss -0.0069 LR -0.0309 LKL 0.0240\n",
      "epoch 5872 loss 0.0486 LR 0.0248 LKL 0.0238\n",
      "epoch 5873 loss 0.0522 LR 0.0280 LKL 0.0241\n",
      "epoch 5874 loss 0.0434 LR 0.0195 LKL 0.0239\n",
      "epoch 5875 loss 0.0158 LR -0.0079 LKL 0.0237\n",
      "epoch 5876 loss 0.0737 LR 0.0498 LKL 0.0239\n",
      "epoch 5877 loss 0.0521 LR 0.0282 LKL 0.0239\n",
      "epoch 5878 loss 0.0207 LR -0.0031 LKL 0.0237\n",
      "epoch 5879 loss -0.0021 LR -0.0261 LKL 0.0240\n",
      "epoch 5880 loss 0.0166 LR -0.0070 LKL 0.0236\n",
      "epoch 5881 loss 0.0307 LR 0.0069 LKL 0.0238\n",
      "epoch 5882 loss 0.0107 LR -0.0136 LKL 0.0242\n",
      "epoch 5883 loss 0.0259 LR 0.0021 LKL 0.0238\n",
      "epoch 5884 loss 0.0327 LR 0.0090 LKL 0.0237\n",
      "epoch 5885 loss 0.0279 LR 0.0040 LKL 0.0239\n",
      "epoch 5886 loss 0.0286 LR 0.0049 LKL 0.0238\n",
      "epoch 5887 loss 0.0780 LR 0.0542 LKL 0.0238\n",
      "epoch 5888 loss 0.0807 LR 0.0568 LKL 0.0239\n",
      "epoch 5889 loss 0.0318 LR 0.0079 LKL 0.0238\n",
      "epoch 5890 loss -0.0057 LR -0.0294 LKL 0.0238\n",
      "epoch 5891 loss -0.0185 LR -0.0423 LKL 0.0238\n",
      "epoch 5892 loss 0.0400 LR 0.0167 LKL 0.0233\n",
      "epoch 5893 loss 0.0545 LR 0.0311 LKL 0.0234\n",
      "epoch 5894 loss -0.0035 LR -0.0268 LKL 0.0233\n",
      "epoch 5895 loss 0.0067 LR -0.0165 LKL 0.0232\n",
      "epoch 5896 loss 0.0328 LR 0.0096 LKL 0.0232\n",
      "epoch 5897 loss 0.0040 LR -0.0194 LKL 0.0235\n",
      "epoch 5898 loss -0.0155 LR -0.0390 LKL 0.0235\n",
      "epoch 5899 loss 0.0684 LR 0.0451 LKL 0.0233\n",
      "epoch 5900 loss 0.0336 LR 0.0101 LKL 0.0235\n",
      "38\n",
      "epoch 5901 loss -0.0152 LR -0.0391 LKL 0.0238\n",
      "epoch 5902 loss 0.0013 LR -0.0225 LKL 0.0237\n",
      "epoch 5903 loss -0.0161 LR -0.0398 LKL 0.0237\n",
      "epoch 5904 loss 0.0105 LR -0.0133 LKL 0.0239\n",
      "epoch 5905 loss 0.0356 LR 0.0114 LKL 0.0242\n",
      "epoch 5906 loss 0.0324 LR 0.0083 LKL 0.0241\n",
      "epoch 5907 loss 0.0154 LR -0.0088 LKL 0.0242\n",
      "epoch 5908 loss 0.0316 LR 0.0074 LKL 0.0242\n",
      "epoch 5909 loss -0.0025 LR -0.0266 LKL 0.0241\n",
      "epoch 5910 loss -0.0184 LR -0.0426 LKL 0.0242\n",
      "epoch 5911 loss 0.0025 LR -0.0218 LKL 0.0243\n",
      "epoch 5912 loss 0.0114 LR -0.0127 LKL 0.0241\n",
      "epoch 5913 loss -0.0028 LR -0.0269 LKL 0.0241\n",
      "epoch 5914 loss 0.0124 LR -0.0117 LKL 0.0241\n",
      "epoch 5915 loss 0.0040 LR -0.0205 LKL 0.0245\n",
      "epoch 5916 loss 0.0469 LR 0.0228 LKL 0.0241\n",
      "epoch 5917 loss 0.0048 LR -0.0191 LKL 0.0239\n",
      "epoch 5918 loss 0.0221 LR -0.0020 LKL 0.0241\n",
      "epoch 5919 loss 0.0063 LR -0.0175 LKL 0.0238\n",
      "epoch 5920 loss 0.0265 LR 0.0030 LKL 0.0236\n",
      "epoch 5921 loss 0.0473 LR 0.0234 LKL 0.0240\n",
      "epoch 5922 loss 0.0181 LR -0.0058 LKL 0.0240\n",
      "epoch 5923 loss 0.0167 LR -0.0073 LKL 0.0240\n",
      "epoch 5924 loss -0.0182 LR -0.0421 LKL 0.0239\n",
      "epoch 5925 loss 0.0161 LR -0.0080 LKL 0.0241\n",
      "epoch 5926 loss -0.0003 LR -0.0246 LKL 0.0243\n",
      "epoch 5927 loss -0.0107 LR -0.0351 LKL 0.0244\n",
      "epoch 5928 loss 0.0023 LR -0.0219 LKL 0.0242\n",
      "epoch 5929 loss 0.0247 LR 0.0008 LKL 0.0239\n",
      "epoch 5930 loss -0.0107 LR -0.0347 LKL 0.0241\n",
      "epoch 5931 loss 0.0128 LR -0.0111 LKL 0.0239\n",
      "epoch 5932 loss -0.0618 LR -0.0860 LKL 0.0242\n",
      "epoch 5933 loss 0.0054 LR -0.0190 LKL 0.0244\n",
      "epoch 5934 loss 0.0505 LR 0.0266 LKL 0.0239\n",
      "epoch 5935 loss 0.0115 LR -0.0125 LKL 0.0240\n",
      "epoch 5936 loss -0.0053 LR -0.0295 LKL 0.0242\n",
      "epoch 5937 loss -0.0172 LR -0.0413 LKL 0.0241\n",
      "epoch 5938 loss -0.0227 LR -0.0466 LKL 0.0239\n",
      "epoch 5939 loss -0.0193 LR -0.0432 LKL 0.0239\n",
      "epoch 5940 loss 0.0209 LR -0.0033 LKL 0.0241\n",
      "epoch 5941 loss 0.0836 LR 0.0593 LKL 0.0243\n",
      "epoch 5942 loss 0.0089 LR -0.0153 LKL 0.0242\n",
      "epoch 5943 loss 0.0271 LR 0.0031 LKL 0.0241\n",
      "epoch 5944 loss -0.0222 LR -0.0462 LKL 0.0240\n",
      "epoch 5945 loss 0.0118 LR -0.0124 LKL 0.0242\n",
      "epoch 5946 loss 0.0231 LR -0.0011 LKL 0.0241\n",
      "epoch 5947 loss -0.0342 LR -0.0581 LKL 0.0239\n",
      "epoch 5948 loss 0.0063 LR -0.0177 LKL 0.0240\n",
      "epoch 5949 loss 0.0126 LR -0.0114 LKL 0.0240\n",
      "epoch 5950 loss -0.0057 LR -0.0297 LKL 0.0239\n",
      "epoch 5951 loss -0.0445 LR -0.0686 LKL 0.0240\n",
      "epoch 5952 loss 0.0609 LR 0.0371 LKL 0.0238\n",
      "epoch 5953 loss -0.0259 LR -0.0498 LKL 0.0239\n",
      "epoch 5954 loss -0.0031 LR -0.0268 LKL 0.0236\n",
      "epoch 5955 loss 0.0448 LR 0.0212 LKL 0.0236\n",
      "epoch 5956 loss 0.0919 LR 0.0683 LKL 0.0236\n",
      "epoch 5957 loss 0.0014 LR -0.0223 LKL 0.0237\n",
      "epoch 5958 loss 0.0269 LR 0.0029 LKL 0.0240\n",
      "epoch 5959 loss 0.0519 LR 0.0280 LKL 0.0239\n",
      "epoch 5960 loss 0.0173 LR -0.0066 LKL 0.0238\n",
      "epoch 5961 loss 0.0589 LR 0.0347 LKL 0.0241\n",
      "epoch 5962 loss 0.0971 LR 0.0731 LKL 0.0240\n",
      "epoch 5963 loss 0.0230 LR -0.0011 LKL 0.0241\n",
      "epoch 5964 loss 0.0265 LR 0.0022 LKL 0.0243\n",
      "epoch 5965 loss 0.0029 LR -0.0214 LKL 0.0243\n",
      "epoch 5966 loss -0.0072 LR -0.0314 LKL 0.0242\n",
      "epoch 5967 loss 0.0385 LR 0.0144 LKL 0.0241\n",
      "epoch 5968 loss 0.0625 LR 0.0384 LKL 0.0241\n",
      "epoch 5969 loss 0.0223 LR -0.0019 LKL 0.0242\n",
      "epoch 5970 loss 0.0050 LR -0.0191 LKL 0.0241\n",
      "epoch 5971 loss 0.0585 LR 0.0344 LKL 0.0241\n",
      "epoch 5972 loss 0.0462 LR 0.0221 LKL 0.0242\n",
      "epoch 5973 loss 0.0019 LR -0.0223 LKL 0.0242\n",
      "epoch 5974 loss 0.0147 LR -0.0094 LKL 0.0241\n",
      "epoch 5975 loss 0.0740 LR 0.0501 LKL 0.0239\n",
      "epoch 5976 loss 0.0524 LR 0.0285 LKL 0.0239\n",
      "epoch 5977 loss 0.0124 LR -0.0113 LKL 0.0238\n",
      "epoch 5978 loss 0.0613 LR 0.0376 LKL 0.0236\n",
      "epoch 5979 loss -0.0254 LR -0.0494 LKL 0.0240\n",
      "epoch 5980 loss 0.0202 LR -0.0035 LKL 0.0236\n",
      "epoch 5981 loss 0.0116 LR -0.0123 LKL 0.0239\n",
      "epoch 5982 loss -0.0171 LR -0.0409 LKL 0.0238\n",
      "epoch 5983 loss 0.0336 LR 0.0095 LKL 0.0241\n",
      "epoch 5984 loss -0.0389 LR -0.0628 LKL 0.0239\n",
      "epoch 5985 loss 0.0193 LR -0.0047 LKL 0.0240\n",
      "epoch 5986 loss 0.0254 LR 0.0011 LKL 0.0243\n",
      "epoch 5987 loss 0.0184 LR -0.0057 LKL 0.0241\n",
      "epoch 5988 loss 0.0333 LR 0.0090 LKL 0.0243\n",
      "epoch 5989 loss 0.0125 LR -0.0117 LKL 0.0242\n",
      "epoch 5990 loss 0.0103 LR -0.0138 LKL 0.0241\n",
      "epoch 5991 loss -0.0362 LR -0.0605 LKL 0.0243\n",
      "epoch 5992 loss 0.0316 LR 0.0072 LKL 0.0244\n",
      "epoch 5993 loss 0.0335 LR 0.0091 LKL 0.0244\n",
      "epoch 5994 loss -0.0306 LR -0.0553 LKL 0.0247\n",
      "epoch 5995 loss 0.0551 LR 0.0307 LKL 0.0243\n",
      "epoch 5996 loss 0.0226 LR -0.0018 LKL 0.0244\n",
      "epoch 5997 loss 0.0139 LR -0.0106 LKL 0.0245\n",
      "epoch 5998 loss 0.0186 LR -0.0058 LKL 0.0244\n",
      "epoch 5999 loss 0.0310 LR 0.0068 LKL 0.0242\n",
      "epoch 6000 loss 0.0099 LR -0.0141 LKL 0.0240\n",
      "122\n",
      "epoch 6001 loss 0.0561 LR 0.0319 LKL 0.0241\n",
      "epoch 6002 loss -0.0054 LR -0.0296 LKL 0.0242\n",
      "epoch 6003 loss 0.0073 LR -0.0166 LKL 0.0239\n",
      "epoch 6004 loss -0.0203 LR -0.0443 LKL 0.0240\n",
      "epoch 6005 loss 0.0577 LR 0.0338 LKL 0.0239\n",
      "epoch 6006 loss 0.0414 LR 0.0176 LKL 0.0238\n",
      "epoch 6007 loss -0.0040 LR -0.0281 LKL 0.0241\n",
      "epoch 6008 loss 0.0014 LR -0.0228 LKL 0.0242\n",
      "epoch 6009 loss -0.0067 LR -0.0308 LKL 0.0241\n",
      "epoch 6010 loss 0.0161 LR -0.0080 LKL 0.0240\n",
      "epoch 6011 loss -0.0052 LR -0.0290 LKL 0.0239\n",
      "epoch 6012 loss 0.0606 LR 0.0368 LKL 0.0238\n",
      "epoch 6013 loss 0.0091 LR -0.0149 LKL 0.0239\n",
      "epoch 6014 loss 0.0618 LR 0.0377 LKL 0.0241\n",
      "epoch 6015 loss -0.0012 LR -0.0253 LKL 0.0241\n",
      "epoch 6016 loss 0.0011 LR -0.0229 LKL 0.0240\n",
      "epoch 6017 loss 0.0310 LR 0.0067 LKL 0.0243\n",
      "epoch 6018 loss -0.0185 LR -0.0427 LKL 0.0242\n",
      "epoch 6019 loss -0.0146 LR -0.0389 LKL 0.0243\n",
      "epoch 6020 loss 0.0300 LR 0.0060 LKL 0.0240\n",
      "epoch 6021 loss -0.0280 LR -0.0522 LKL 0.0242\n",
      "epoch 6022 loss 0.0453 LR 0.0210 LKL 0.0243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6023 loss -0.0228 LR -0.0470 LKL 0.0243\n",
      "epoch 6024 loss 0.0378 LR 0.0140 LKL 0.0238\n",
      "epoch 6025 loss 0.0231 LR -0.0010 LKL 0.0242\n",
      "epoch 6026 loss -0.0392 LR -0.0637 LKL 0.0245\n",
      "epoch 6027 loss 0.0032 LR -0.0212 LKL 0.0244\n",
      "epoch 6028 loss -0.0094 LR -0.0337 LKL 0.0243\n",
      "epoch 6029 loss 0.0229 LR -0.0010 LKL 0.0239\n",
      "epoch 6030 loss 0.0376 LR 0.0132 LKL 0.0244\n",
      "epoch 6031 loss -0.0104 LR -0.0347 LKL 0.0243\n",
      "epoch 6032 loss 0.0308 LR 0.0067 LKL 0.0241\n",
      "epoch 6033 loss 0.0637 LR 0.0396 LKL 0.0240\n",
      "epoch 6034 loss 0.0208 LR -0.0035 LKL 0.0243\n",
      "epoch 6035 loss 0.0436 LR 0.0194 LKL 0.0242\n",
      "epoch 6036 loss 0.0366 LR 0.0122 LKL 0.0244\n",
      "epoch 6037 loss 0.0059 LR -0.0185 LKL 0.0245\n",
      "epoch 6038 loss 0.0411 LR 0.0168 LKL 0.0243\n",
      "epoch 6039 loss -0.0202 LR -0.0444 LKL 0.0242\n",
      "epoch 6040 loss -0.0288 LR -0.0530 LKL 0.0242\n",
      "epoch 6041 loss -0.0074 LR -0.0317 LKL 0.0243\n",
      "epoch 6042 loss -0.0358 LR -0.0601 LKL 0.0243\n",
      "epoch 6043 loss 0.0559 LR 0.0317 LKL 0.0242\n",
      "epoch 6044 loss 0.0443 LR 0.0203 LKL 0.0240\n",
      "epoch 6045 loss 0.0112 LR -0.0129 LKL 0.0241\n",
      "epoch 6046 loss -0.0209 LR -0.0451 LKL 0.0242\n",
      "epoch 6047 loss -0.0118 LR -0.0362 LKL 0.0244\n",
      "epoch 6048 loss 0.0011 LR -0.0232 LKL 0.0242\n",
      "epoch 6049 loss 0.0038 LR -0.0204 LKL 0.0242\n",
      "epoch 6050 loss -0.0130 LR -0.0373 LKL 0.0243\n",
      "epoch 6051 loss 0.0461 LR 0.0221 LKL 0.0240\n",
      "epoch 6052 loss 0.0234 LR -0.0007 LKL 0.0241\n",
      "epoch 6053 loss 0.0895 LR 0.0654 LKL 0.0241\n",
      "epoch 6054 loss 0.0360 LR 0.0118 LKL 0.0242\n",
      "epoch 6055 loss -0.0408 LR -0.0648 LKL 0.0240\n",
      "epoch 6056 loss 0.0313 LR 0.0071 LKL 0.0242\n",
      "epoch 6057 loss 0.0327 LR 0.0085 LKL 0.0242\n",
      "epoch 6058 loss 0.0238 LR -0.0003 LKL 0.0241\n",
      "epoch 6059 loss -0.0424 LR -0.0665 LKL 0.0240\n",
      "epoch 6060 loss -0.0284 LR -0.0526 LKL 0.0241\n",
      "epoch 6061 loss 0.0012 LR -0.0229 LKL 0.0241\n",
      "epoch 6062 loss 0.0207 LR -0.0030 LKL 0.0237\n",
      "epoch 6063 loss -0.0221 LR -0.0464 LKL 0.0242\n",
      "epoch 6064 loss 0.0442 LR 0.0200 LKL 0.0242\n",
      "epoch 6065 loss 0.0306 LR 0.0066 LKL 0.0240\n",
      "epoch 6066 loss 0.0286 LR 0.0043 LKL 0.0244\n",
      "epoch 6067 loss 0.0267 LR 0.0023 LKL 0.0244\n",
      "epoch 6068 loss -0.0286 LR -0.0530 LKL 0.0244\n",
      "epoch 6069 loss 0.0398 LR 0.0157 LKL 0.0242\n",
      "epoch 6070 loss 0.0201 LR -0.0042 LKL 0.0244\n",
      "epoch 6071 loss 0.0066 LR -0.0178 LKL 0.0244\n",
      "epoch 6072 loss 0.0032 LR -0.0211 LKL 0.0243\n",
      "epoch 6073 loss 0.0498 LR 0.0255 LKL 0.0243\n",
      "epoch 6074 loss -0.0435 LR -0.0681 LKL 0.0246\n",
      "epoch 6075 loss 0.0270 LR 0.0027 LKL 0.0244\n",
      "epoch 6076 loss 0.0726 LR 0.0482 LKL 0.0244\n",
      "epoch 6077 loss -0.0486 LR -0.0732 LKL 0.0246\n",
      "epoch 6078 loss -0.0079 LR -0.0324 LKL 0.0245\n",
      "epoch 6079 loss 0.0412 LR 0.0170 LKL 0.0242\n",
      "epoch 6080 loss -0.0347 LR -0.0594 LKL 0.0247\n",
      "epoch 6081 loss 0.0079 LR -0.0166 LKL 0.0245\n",
      "epoch 6082 loss 0.0611 LR 0.0367 LKL 0.0243\n",
      "epoch 6083 loss 0.0129 LR -0.0114 LKL 0.0243\n",
      "epoch 6084 loss -0.0047 LR -0.0293 LKL 0.0246\n",
      "epoch 6085 loss -0.0162 LR -0.0407 LKL 0.0245\n",
      "epoch 6086 loss -0.0125 LR -0.0369 LKL 0.0244\n",
      "epoch 6087 loss 0.0164 LR -0.0077 LKL 0.0241\n",
      "epoch 6088 loss 0.0003 LR -0.0240 LKL 0.0243\n",
      "epoch 6089 loss 0.0292 LR 0.0047 LKL 0.0245\n",
      "epoch 6090 loss 0.0238 LR -0.0007 LKL 0.0245\n",
      "epoch 6091 loss 0.0354 LR 0.0110 LKL 0.0244\n",
      "epoch 6092 loss -0.0530 LR -0.0776 LKL 0.0246\n",
      "epoch 6093 loss 0.0257 LR 0.0010 LKL 0.0247\n",
      "epoch 6094 loss 0.0425 LR 0.0178 LKL 0.0246\n",
      "epoch 6095 loss 0.0311 LR 0.0065 LKL 0.0247\n",
      "epoch 6096 loss 0.0704 LR 0.0463 LKL 0.0242\n",
      "epoch 6097 loss 0.0096 LR -0.0146 LKL 0.0241\n",
      "epoch 6098 loss 0.0735 LR 0.0495 LKL 0.0240\n",
      "epoch 6099 loss 0.0239 LR -0.0000 LKL 0.0239\n",
      "epoch 6100 loss 0.0311 LR 0.0070 LKL 0.0241\n",
      "46\n",
      "epoch 6101 loss 0.0301 LR 0.0062 LKL 0.0239\n",
      "epoch 6102 loss 0.0436 LR 0.0198 LKL 0.0238\n",
      "epoch 6103 loss -0.0151 LR -0.0390 LKL 0.0240\n",
      "epoch 6104 loss -0.0298 LR -0.0538 LKL 0.0240\n",
      "epoch 6105 loss 0.0301 LR 0.0062 LKL 0.0239\n",
      "epoch 6106 loss 0.0781 LR 0.0543 LKL 0.0238\n",
      "epoch 6107 loss 0.0042 LR -0.0200 LKL 0.0242\n",
      "epoch 6108 loss -0.0107 LR -0.0346 LKL 0.0239\n",
      "epoch 6109 loss -0.0491 LR -0.0727 LKL 0.0237\n",
      "epoch 6110 loss -0.0498 LR -0.0739 LKL 0.0241\n",
      "epoch 6111 loss 0.0417 LR 0.0178 LKL 0.0239\n",
      "epoch 6112 loss 0.0112 LR -0.0130 LKL 0.0242\n",
      "epoch 6113 loss 0.0253 LR 0.0016 LKL 0.0238\n",
      "epoch 6114 loss -0.0201 LR -0.0444 LKL 0.0243\n",
      "epoch 6115 loss -0.0009 LR -0.0249 LKL 0.0239\n",
      "epoch 6116 loss -0.0098 LR -0.0334 LKL 0.0236\n",
      "epoch 6117 loss 0.0409 LR 0.0173 LKL 0.0236\n",
      "epoch 6118 loss 0.0389 LR 0.0150 LKL 0.0239\n",
      "epoch 6119 loss 0.0240 LR 0.0003 LKL 0.0238\n",
      "epoch 6120 loss 0.0187 LR -0.0052 LKL 0.0239\n",
      "epoch 6121 loss 0.0068 LR -0.0172 LKL 0.0239\n",
      "epoch 6122 loss -0.0329 LR -0.0569 LKL 0.0240\n",
      "epoch 6123 loss 0.0604 LR 0.0364 LKL 0.0240\n",
      "epoch 6124 loss -0.0459 LR -0.0698 LKL 0.0239\n",
      "epoch 6125 loss 0.0403 LR 0.0163 LKL 0.0240\n",
      "epoch 6126 loss 0.0440 LR 0.0203 LKL 0.0237\n",
      "epoch 6127 loss 0.0268 LR 0.0027 LKL 0.0241\n",
      "epoch 6128 loss -0.0002 LR -0.0243 LKL 0.0241\n",
      "epoch 6129 loss -0.0314 LR -0.0553 LKL 0.0239\n",
      "epoch 6130 loss 0.0505 LR 0.0267 LKL 0.0239\n",
      "epoch 6131 loss 0.0236 LR -0.0006 LKL 0.0242\n",
      "epoch 6132 loss 0.0142 LR -0.0099 LKL 0.0241\n",
      "epoch 6133 loss -0.0051 LR -0.0293 LKL 0.0242\n",
      "epoch 6134 loss 0.0619 LR 0.0378 LKL 0.0241\n",
      "epoch 6135 loss 0.0098 LR -0.0148 LKL 0.0246\n",
      "epoch 6136 loss -0.0155 LR -0.0400 LKL 0.0244\n",
      "epoch 6137 loss 0.0523 LR 0.0278 LKL 0.0246\n",
      "epoch 6138 loss 0.0176 LR -0.0071 LKL 0.0248\n",
      "epoch 6139 loss -0.0178 LR -0.0422 LKL 0.0244\n",
      "epoch 6140 loss 0.0418 LR 0.0173 LKL 0.0245\n",
      "epoch 6141 loss 0.0024 LR -0.0223 LKL 0.0247\n",
      "epoch 6142 loss -0.0211 LR -0.0455 LKL 0.0244\n",
      "epoch 6143 loss -0.0032 LR -0.0275 LKL 0.0243\n",
      "epoch 6144 loss 0.0006 LR -0.0236 LKL 0.0242\n",
      "epoch 6145 loss 0.0577 LR 0.0336 LKL 0.0241\n",
      "epoch 6146 loss 0.0095 LR -0.0148 LKL 0.0243\n",
      "epoch 6147 loss 0.0778 LR 0.0539 LKL 0.0240\n",
      "epoch 6148 loss -0.0457 LR -0.0700 LKL 0.0243\n",
      "epoch 6149 loss 0.0056 LR -0.0189 LKL 0.0245\n",
      "epoch 6150 loss 0.0046 LR -0.0194 LKL 0.0241\n",
      "epoch 6151 loss -0.0369 LR -0.0612 LKL 0.0243\n",
      "epoch 6152 loss -0.0187 LR -0.0432 LKL 0.0244\n",
      "epoch 6153 loss -0.0251 LR -0.0495 LKL 0.0243\n",
      "epoch 6154 loss 0.0035 LR -0.0210 LKL 0.0244\n",
      "epoch 6155 loss -0.0001 LR -0.0244 LKL 0.0242\n",
      "epoch 6156 loss 0.0313 LR 0.0072 LKL 0.0241\n",
      "epoch 6157 loss 0.0332 LR 0.0088 LKL 0.0244\n",
      "epoch 6158 loss 0.0041 LR -0.0201 LKL 0.0242\n",
      "epoch 6159 loss 0.0614 LR 0.0373 LKL 0.0241\n",
      "epoch 6160 loss -0.0517 LR -0.0756 LKL 0.0239\n",
      "epoch 6161 loss 0.0539 LR 0.0297 LKL 0.0242\n",
      "epoch 6162 loss 0.0146 LR -0.0093 LKL 0.0239\n",
      "epoch 6163 loss 0.0687 LR 0.0447 LKL 0.0240\n",
      "epoch 6164 loss 0.0289 LR 0.0047 LKL 0.0242\n",
      "epoch 6165 loss 0.0156 LR -0.0083 LKL 0.0239\n",
      "epoch 6166 loss 0.0522 LR 0.0283 LKL 0.0239\n",
      "epoch 6167 loss 0.0075 LR -0.0164 LKL 0.0240\n",
      "epoch 6168 loss 0.0188 LR -0.0053 LKL 0.0241\n",
      "epoch 6169 loss 0.0505 LR 0.0267 LKL 0.0238\n",
      "epoch 6170 loss -0.0139 LR -0.0379 LKL 0.0240\n",
      "epoch 6171 loss 0.0201 LR -0.0040 LKL 0.0241\n",
      "epoch 6172 loss -0.0324 LR -0.0563 LKL 0.0238\n",
      "epoch 6173 loss -0.0020 LR -0.0259 LKL 0.0240\n",
      "epoch 6174 loss 0.0543 LR 0.0302 LKL 0.0241\n",
      "epoch 6175 loss 0.0266 LR 0.0023 LKL 0.0243\n",
      "epoch 6176 loss -0.0028 LR -0.0268 LKL 0.0240\n",
      "epoch 6177 loss -0.0274 LR -0.0516 LKL 0.0242\n",
      "epoch 6178 loss 0.0569 LR 0.0329 LKL 0.0240\n",
      "epoch 6179 loss 0.0059 LR -0.0183 LKL 0.0243\n",
      "epoch 6180 loss 0.0318 LR 0.0080 LKL 0.0238\n",
      "epoch 6181 loss 0.0174 LR -0.0071 LKL 0.0244\n",
      "epoch 6182 loss 0.0068 LR -0.0174 LKL 0.0242\n",
      "epoch 6183 loss 0.0208 LR -0.0034 LKL 0.0242\n",
      "epoch 6184 loss 0.0226 LR -0.0018 LKL 0.0244\n",
      "epoch 6185 loss -0.0145 LR -0.0388 LKL 0.0243\n",
      "epoch 6186 loss 0.0230 LR -0.0018 LKL 0.0247\n",
      "epoch 6187 loss -0.0833 LR -0.1077 LKL 0.0244\n",
      "epoch 6188 loss -0.0237 LR -0.0482 LKL 0.0245\n",
      "epoch 6189 loss 0.0320 LR 0.0074 LKL 0.0245\n",
      "epoch 6190 loss -0.0128 LR -0.0370 LKL 0.0242\n",
      "epoch 6191 loss -0.0687 LR -0.0929 LKL 0.0242\n",
      "epoch 6192 loss 0.0156 LR -0.0088 LKL 0.0244\n",
      "epoch 6193 loss 0.0441 LR 0.0201 LKL 0.0240\n",
      "epoch 6194 loss 0.0045 LR -0.0197 LKL 0.0242\n",
      "epoch 6195 loss 0.0310 LR 0.0065 LKL 0.0245\n",
      "epoch 6196 loss -0.0329 LR -0.0575 LKL 0.0246\n",
      "epoch 6197 loss 0.0186 LR -0.0060 LKL 0.0246\n",
      "epoch 6198 loss -0.0227 LR -0.0474 LKL 0.0247\n",
      "epoch 6199 loss -0.0153 LR -0.0397 LKL 0.0244\n",
      "epoch 6200 loss 0.0494 LR 0.0251 LKL 0.0243\n",
      "81\n",
      "epoch 6201 loss 0.0328 LR 0.0082 LKL 0.0246\n",
      "epoch 6202 loss 0.0007 LR -0.0239 LKL 0.0246\n",
      "epoch 6203 loss 0.0478 LR 0.0234 LKL 0.0245\n",
      "epoch 6204 loss -0.0015 LR -0.0261 LKL 0.0246\n",
      "epoch 6205 loss -0.0280 LR -0.0524 LKL 0.0244\n",
      "epoch 6206 loss 0.0264 LR 0.0022 LKL 0.0242\n",
      "epoch 6207 loss 0.0143 LR -0.0101 LKL 0.0244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6208 loss 0.0947 LR 0.0704 LKL 0.0243\n",
      "epoch 6209 loss 0.0569 LR 0.0327 LKL 0.0242\n",
      "epoch 6210 loss 0.0317 LR 0.0079 LKL 0.0238\n",
      "epoch 6211 loss -0.0357 LR -0.0600 LKL 0.0243\n",
      "epoch 6212 loss 0.0319 LR 0.0082 LKL 0.0237\n",
      "epoch 6213 loss 0.0140 LR -0.0097 LKL 0.0237\n",
      "epoch 6214 loss 0.0165 LR -0.0074 LKL 0.0239\n",
      "epoch 6215 loss 0.0293 LR 0.0052 LKL 0.0241\n",
      "epoch 6216 loss -0.0066 LR -0.0306 LKL 0.0240\n",
      "epoch 6217 loss 0.0559 LR 0.0320 LKL 0.0239\n",
      "epoch 6218 loss -0.0105 LR -0.0342 LKL 0.0237\n",
      "epoch 6219 loss 0.0114 LR -0.0127 LKL 0.0241\n",
      "epoch 6220 loss -0.0498 LR -0.0742 LKL 0.0243\n",
      "epoch 6221 loss 0.0331 LR 0.0091 LKL 0.0240\n",
      "epoch 6222 loss -0.0098 LR -0.0341 LKL 0.0243\n",
      "epoch 6223 loss 0.0477 LR 0.0232 LKL 0.0246\n",
      "epoch 6224 loss 0.0301 LR 0.0056 LKL 0.0245\n",
      "epoch 6225 loss 0.0103 LR -0.0144 LKL 0.0246\n",
      "epoch 6226 loss 0.0251 LR 0.0008 LKL 0.0242\n",
      "epoch 6227 loss 0.0289 LR 0.0044 LKL 0.0245\n",
      "epoch 6228 loss 0.0221 LR -0.0023 LKL 0.0243\n",
      "epoch 6229 loss 0.0202 LR -0.0045 LKL 0.0247\n",
      "epoch 6230 loss 0.0203 LR -0.0043 LKL 0.0246\n",
      "epoch 6231 loss 0.0190 LR -0.0055 LKL 0.0245\n",
      "epoch 6232 loss -0.0046 LR -0.0293 LKL 0.0247\n",
      "epoch 6233 loss 0.0110 LR -0.0136 LKL 0.0246\n",
      "epoch 6234 loss 0.0098 LR -0.0148 LKL 0.0247\n",
      "epoch 6235 loss -0.0061 LR -0.0306 LKL 0.0246\n",
      "epoch 6236 loss -0.0272 LR -0.0519 LKL 0.0246\n",
      "epoch 6237 loss 0.0430 LR 0.0187 LKL 0.0243\n",
      "epoch 6238 loss -0.0240 LR -0.0483 LKL 0.0243\n",
      "epoch 6239 loss 0.0041 LR -0.0203 LKL 0.0244\n",
      "epoch 6240 loss -0.0097 LR -0.0338 LKL 0.0241\n",
      "epoch 6241 loss 0.0295 LR 0.0050 LKL 0.0244\n",
      "epoch 6242 loss 0.0817 LR 0.0576 LKL 0.0241\n",
      "epoch 6243 loss 0.0421 LR 0.0180 LKL 0.0241\n",
      "epoch 6244 loss -0.0007 LR -0.0250 LKL 0.0243\n",
      "epoch 6245 loss 0.0655 LR 0.0410 LKL 0.0246\n",
      "epoch 6246 loss 0.0197 LR -0.0046 LKL 0.0243\n",
      "epoch 6247 loss 0.0312 LR 0.0070 LKL 0.0242\n",
      "epoch 6248 loss 0.0557 LR 0.0315 LKL 0.0242\n",
      "epoch 6249 loss 0.0191 LR -0.0053 LKL 0.0243\n",
      "epoch 6250 loss -0.0002 LR -0.0243 LKL 0.0241\n",
      "epoch 6251 loss 0.0004 LR -0.0237 LKL 0.0240\n",
      "epoch 6252 loss 0.0147 LR -0.0092 LKL 0.0238\n",
      "epoch 6253 loss -0.0033 LR -0.0275 LKL 0.0242\n",
      "epoch 6254 loss 0.0026 LR -0.0211 LKL 0.0237\n",
      "epoch 6255 loss 0.0088 LR -0.0153 LKL 0.0241\n",
      "epoch 6256 loss 0.0169 LR -0.0071 LKL 0.0240\n",
      "epoch 6257 loss -0.0123 LR -0.0362 LKL 0.0240\n",
      "epoch 6258 loss -0.0096 LR -0.0334 LKL 0.0238\n",
      "epoch 6259 loss -0.0814 LR -0.1055 LKL 0.0241\n",
      "epoch 6260 loss 0.0164 LR -0.0077 LKL 0.0241\n",
      "epoch 6261 loss -0.0362 LR -0.0604 LKL 0.0242\n",
      "epoch 6262 loss -0.0137 LR -0.0380 LKL 0.0243\n",
      "epoch 6263 loss 0.0192 LR -0.0051 LKL 0.0243\n",
      "epoch 6264 loss 0.0189 LR -0.0051 LKL 0.0240\n",
      "epoch 6265 loss -0.0003 LR -0.0245 LKL 0.0242\n",
      "epoch 6266 loss -0.0087 LR -0.0330 LKL 0.0243\n",
      "epoch 6267 loss -0.0241 LR -0.0484 LKL 0.0243\n",
      "epoch 6268 loss -0.0527 LR -0.0774 LKL 0.0247\n",
      "epoch 6269 loss 0.0294 LR 0.0048 LKL 0.0247\n",
      "epoch 6270 loss 0.0033 LR -0.0210 LKL 0.0244\n",
      "epoch 6271 loss 0.0233 LR -0.0012 LKL 0.0244\n",
      "epoch 6272 loss -0.0205 LR -0.0449 LKL 0.0244\n",
      "epoch 6273 loss -0.0044 LR -0.0287 LKL 0.0243\n",
      "epoch 6274 loss 0.0374 LR 0.0131 LKL 0.0243\n",
      "epoch 6275 loss -0.0372 LR -0.0617 LKL 0.0245\n",
      "epoch 6276 loss -0.0057 LR -0.0300 LKL 0.0244\n",
      "epoch 6277 loss -0.0545 LR -0.0788 LKL 0.0243\n",
      "epoch 6278 loss 0.0105 LR -0.0140 LKL 0.0245\n",
      "epoch 6279 loss 0.0023 LR -0.0221 LKL 0.0244\n",
      "epoch 6280 loss 0.0227 LR -0.0019 LKL 0.0246\n",
      "epoch 6281 loss -0.0468 LR -0.0712 LKL 0.0244\n",
      "epoch 6282 loss 0.0366 LR 0.0123 LKL 0.0243\n",
      "epoch 6283 loss 0.0477 LR 0.0233 LKL 0.0244\n",
      "epoch 6284 loss -0.0016 LR -0.0260 LKL 0.0244\n",
      "epoch 6285 loss 0.0770 LR 0.0530 LKL 0.0241\n",
      "epoch 6286 loss -0.0436 LR -0.0684 LKL 0.0247\n",
      "epoch 6287 loss -0.0290 LR -0.0535 LKL 0.0244\n",
      "epoch 6288 loss -0.0056 LR -0.0304 LKL 0.0248\n",
      "epoch 6289 loss -0.0093 LR -0.0338 LKL 0.0246\n",
      "epoch 6290 loss -0.0231 LR -0.0474 LKL 0.0243\n",
      "epoch 6291 loss -0.0181 LR -0.0424 LKL 0.0243\n",
      "epoch 6292 loss 0.0082 LR -0.0164 LKL 0.0246\n",
      "epoch 6293 loss 0.0280 LR 0.0036 LKL 0.0244\n",
      "epoch 6294 loss 0.0218 LR -0.0025 LKL 0.0243\n",
      "epoch 6295 loss 0.0024 LR -0.0222 LKL 0.0246\n",
      "epoch 6296 loss 0.0275 LR 0.0028 LKL 0.0247\n",
      "epoch 6297 loss 0.0273 LR 0.0027 LKL 0.0246\n",
      "epoch 6298 loss -0.0097 LR -0.0343 LKL 0.0246\n",
      "epoch 6299 loss 0.0309 LR 0.0065 LKL 0.0244\n",
      "epoch 6300 loss 0.0272 LR 0.0026 LKL 0.0245\n",
      "45\n",
      "epoch 6301 loss -0.0350 LR -0.0597 LKL 0.0247\n",
      "epoch 6302 loss 0.0166 LR -0.0082 LKL 0.0247\n",
      "epoch 6303 loss -0.0302 LR -0.0551 LKL 0.0249\n",
      "epoch 6304 loss 0.0049 LR -0.0199 LKL 0.0248\n",
      "epoch 6305 loss -0.0183 LR -0.0432 LKL 0.0250\n",
      "epoch 6306 loss 0.0310 LR 0.0063 LKL 0.0248\n",
      "epoch 6307 loss -0.0078 LR -0.0327 LKL 0.0249\n",
      "epoch 6308 loss 0.0998 LR 0.0750 LKL 0.0248\n",
      "epoch 6309 loss -0.0258 LR -0.0504 LKL 0.0246\n",
      "epoch 6310 loss -0.0191 LR -0.0438 LKL 0.0247\n",
      "epoch 6311 loss -0.0617 LR -0.0866 LKL 0.0250\n",
      "epoch 6312 loss 0.0230 LR -0.0015 LKL 0.0245\n",
      "epoch 6313 loss 0.0186 LR -0.0063 LKL 0.0248\n",
      "epoch 6314 loss -0.0436 LR -0.0682 LKL 0.0246\n",
      "epoch 6315 loss 0.0604 LR 0.0356 LKL 0.0248\n",
      "epoch 6316 loss -0.0404 LR -0.0649 LKL 0.0245\n",
      "epoch 6317 loss 0.0230 LR -0.0015 LKL 0.0245\n",
      "epoch 6318 loss -0.0024 LR -0.0270 LKL 0.0246\n",
      "epoch 6319 loss 0.0340 LR 0.0097 LKL 0.0243\n",
      "epoch 6320 loss 0.0638 LR 0.0394 LKL 0.0243\n",
      "epoch 6321 loss 0.0068 LR -0.0177 LKL 0.0245\n",
      "epoch 6322 loss -0.0125 LR -0.0369 LKL 0.0244\n",
      "epoch 6323 loss -0.0594 LR -0.0842 LKL 0.0248\n",
      "epoch 6324 loss 0.0412 LR 0.0167 LKL 0.0245\n",
      "epoch 6325 loss -0.0276 LR -0.0522 LKL 0.0247\n",
      "epoch 6326 loss -0.0251 LR -0.0496 LKL 0.0245\n",
      "epoch 6327 loss 0.0351 LR 0.0104 LKL 0.0247\n",
      "epoch 6328 loss 0.0133 LR -0.0114 LKL 0.0247\n",
      "epoch 6329 loss 0.0224 LR -0.0023 LKL 0.0247\n",
      "epoch 6330 loss -0.0030 LR -0.0277 LKL 0.0247\n",
      "epoch 6331 loss 0.0076 LR -0.0170 LKL 0.0246\n",
      "epoch 6332 loss 0.0197 LR -0.0047 LKL 0.0244\n",
      "epoch 6333 loss 0.0606 LR 0.0363 LKL 0.0243\n",
      "epoch 6334 loss 0.0529 LR 0.0287 LKL 0.0241\n",
      "epoch 6335 loss -0.0511 LR -0.0751 LKL 0.0240\n",
      "epoch 6336 loss 0.0362 LR 0.0120 LKL 0.0242\n",
      "epoch 6337 loss -0.0310 LR -0.0555 LKL 0.0245\n",
      "epoch 6338 loss -0.0080 LR -0.0321 LKL 0.0241\n",
      "epoch 6339 loss 0.0562 LR 0.0319 LKL 0.0243\n",
      "epoch 6340 loss -0.0505 LR -0.0747 LKL 0.0242\n",
      "epoch 6341 loss 0.0149 LR -0.0089 LKL 0.0237\n",
      "epoch 6342 loss -0.0110 LR -0.0351 LKL 0.0241\n",
      "epoch 6343 loss 0.0235 LR -0.0004 LKL 0.0239\n",
      "epoch 6344 loss 0.0422 LR 0.0182 LKL 0.0240\n",
      "epoch 6345 loss 0.0021 LR -0.0221 LKL 0.0241\n",
      "epoch 6346 loss -0.0526 LR -0.0765 LKL 0.0240\n",
      "epoch 6347 loss -0.0254 LR -0.0494 LKL 0.0240\n",
      "epoch 6348 loss 0.0328 LR 0.0086 LKL 0.0242\n",
      "epoch 6349 loss 0.0194 LR -0.0048 LKL 0.0243\n",
      "epoch 6350 loss 0.0411 LR 0.0167 LKL 0.0244\n",
      "epoch 6351 loss -0.0983 LR -0.1228 LKL 0.0245\n",
      "epoch 6352 loss 0.0116 LR -0.0132 LKL 0.0248\n",
      "epoch 6353 loss 0.0220 LR -0.0023 LKL 0.0244\n",
      "epoch 6354 loss -0.0286 LR -0.0535 LKL 0.0250\n",
      "epoch 6355 loss -0.0374 LR -0.0620 LKL 0.0245\n",
      "epoch 6356 loss -0.0571 LR -0.0817 LKL 0.0246\n",
      "epoch 6357 loss -0.0426 LR -0.0672 LKL 0.0246\n",
      "epoch 6358 loss 0.0340 LR 0.0092 LKL 0.0248\n",
      "epoch 6359 loss 0.0094 LR -0.0151 LKL 0.0244\n",
      "epoch 6360 loss -0.0090 LR -0.0335 LKL 0.0245\n",
      "epoch 6361 loss 0.0485 LR 0.0241 LKL 0.0244\n",
      "epoch 6362 loss -0.0062 LR -0.0307 LKL 0.0245\n",
      "epoch 6363 loss 0.0200 LR -0.0044 LKL 0.0244\n",
      "epoch 6364 loss -0.0427 LR -0.0670 LKL 0.0243\n",
      "epoch 6365 loss 0.0022 LR -0.0222 LKL 0.0244\n",
      "epoch 6366 loss -0.0142 LR -0.0384 LKL 0.0242\n",
      "epoch 6367 loss 0.0036 LR -0.0209 LKL 0.0245\n",
      "epoch 6368 loss 0.0232 LR -0.0012 LKL 0.0244\n",
      "epoch 6369 loss -0.0173 LR -0.0417 LKL 0.0244\n",
      "epoch 6370 loss -0.0346 LR -0.0590 LKL 0.0243\n",
      "epoch 6371 loss -0.0150 LR -0.0391 LKL 0.0242\n",
      "epoch 6372 loss -0.0237 LR -0.0479 LKL 0.0242\n",
      "epoch 6373 loss 0.0251 LR 0.0011 LKL 0.0240\n",
      "epoch 6374 loss -0.0370 LR -0.0614 LKL 0.0244\n",
      "epoch 6375 loss 0.0376 LR 0.0135 LKL 0.0241\n",
      "epoch 6376 loss 0.0292 LR 0.0050 LKL 0.0241\n",
      "epoch 6377 loss 0.0725 LR 0.0484 LKL 0.0241\n",
      "epoch 6378 loss 0.0287 LR 0.0042 LKL 0.0244\n",
      "epoch 6379 loss -0.0158 LR -0.0402 LKL 0.0243\n",
      "epoch 6380 loss -0.0005 LR -0.0249 LKL 0.0244\n",
      "epoch 6381 loss 0.0269 LR 0.0025 LKL 0.0243\n",
      "epoch 6382 loss -0.0155 LR -0.0399 LKL 0.0244\n",
      "epoch 6383 loss -0.0130 LR -0.0372 LKL 0.0242\n",
      "epoch 6384 loss -0.0181 LR -0.0425 LKL 0.0244\n",
      "epoch 6385 loss -0.0302 LR -0.0545 LKL 0.0242\n",
      "epoch 6386 loss 0.0458 LR 0.0218 LKL 0.0240\n",
      "epoch 6387 loss 0.0168 LR -0.0073 LKL 0.0241\n",
      "epoch 6388 loss 0.0035 LR -0.0205 LKL 0.0240\n",
      "epoch 6389 loss 0.0328 LR 0.0090 LKL 0.0238\n",
      "epoch 6390 loss 0.0646 LR 0.0406 LKL 0.0241\n",
      "epoch 6391 loss 0.0050 LR -0.0192 LKL 0.0243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6392 loss -0.0254 LR -0.0497 LKL 0.0243\n",
      "epoch 6393 loss -0.0026 LR -0.0270 LKL 0.0244\n",
      "epoch 6394 loss 0.0231 LR -0.0010 LKL 0.0241\n",
      "epoch 6395 loss -0.0520 LR -0.0763 LKL 0.0243\n",
      "epoch 6396 loss 0.0396 LR 0.0154 LKL 0.0242\n",
      "epoch 6397 loss -0.0070 LR -0.0311 LKL 0.0241\n",
      "epoch 6398 loss 0.0584 LR 0.0339 LKL 0.0245\n",
      "epoch 6399 loss 0.0184 LR -0.0060 LKL 0.0244\n",
      "epoch 6400 loss 0.0027 LR -0.0217 LKL 0.0244\n",
      "63\n",
      "epoch 6401 loss -0.0508 LR -0.0751 LKL 0.0243\n",
      "epoch 6402 loss -0.0349 LR -0.0590 LKL 0.0241\n",
      "epoch 6403 loss 0.0055 LR -0.0187 LKL 0.0242\n",
      "epoch 6404 loss -0.0454 LR -0.0697 LKL 0.0242\n",
      "epoch 6405 loss -0.0321 LR -0.0565 LKL 0.0244\n",
      "epoch 6406 loss -0.0007 LR -0.0251 LKL 0.0244\n",
      "epoch 6407 loss 0.0248 LR 0.0009 LKL 0.0240\n",
      "epoch 6408 loss 0.0009 LR -0.0232 LKL 0.0241\n",
      "epoch 6409 loss 0.0521 LR 0.0281 LKL 0.0240\n",
      "epoch 6410 loss -0.0042 LR -0.0282 LKL 0.0239\n",
      "epoch 6411 loss 0.0215 LR -0.0026 LKL 0.0241\n",
      "epoch 6412 loss 0.0175 LR -0.0067 LKL 0.0242\n",
      "epoch 6413 loss -0.0119 LR -0.0363 LKL 0.0244\n",
      "epoch 6414 loss -0.0136 LR -0.0377 LKL 0.0241\n",
      "epoch 6415 loss -0.0120 LR -0.0364 LKL 0.0243\n",
      "epoch 6416 loss -0.0050 LR -0.0295 LKL 0.0246\n",
      "epoch 6417 loss -0.0411 LR -0.0657 LKL 0.0245\n",
      "epoch 6418 loss 0.0513 LR 0.0269 LKL 0.0244\n",
      "epoch 6419 loss 0.0728 LR 0.0486 LKL 0.0241\n",
      "epoch 6420 loss -0.1065 LR -0.1311 LKL 0.0246\n",
      "epoch 6421 loss -0.0368 LR -0.0613 LKL 0.0245\n",
      "epoch 6422 loss 0.0122 LR -0.0121 LKL 0.0243\n",
      "epoch 6423 loss -0.0178 LR -0.0421 LKL 0.0243\n",
      "epoch 6424 loss 0.0215 LR -0.0029 LKL 0.0244\n",
      "epoch 6425 loss 0.0104 LR -0.0140 LKL 0.0243\n",
      "epoch 6426 loss -0.0308 LR -0.0553 LKL 0.0245\n",
      "epoch 6427 loss -0.0498 LR -0.0744 LKL 0.0246\n",
      "epoch 6428 loss -0.0256 LR -0.0504 LKL 0.0248\n",
      "epoch 6429 loss -0.0705 LR -0.0953 LKL 0.0248\n",
      "epoch 6430 loss -0.0457 LR -0.0706 LKL 0.0249\n",
      "epoch 6431 loss -0.0218 LR -0.0467 LKL 0.0249\n",
      "epoch 6432 loss 0.0311 LR 0.0063 LKL 0.0248\n",
      "epoch 6433 loss -0.0468 LR -0.0715 LKL 0.0247\n",
      "epoch 6434 loss -0.0140 LR -0.0389 LKL 0.0249\n",
      "epoch 6435 loss 0.0321 LR 0.0076 LKL 0.0245\n",
      "epoch 6436 loss -0.0322 LR -0.0566 LKL 0.0245\n",
      "epoch 6437 loss 0.0083 LR -0.0160 LKL 0.0242\n",
      "epoch 6438 loss 0.0058 LR -0.0187 LKL 0.0245\n",
      "epoch 6439 loss 0.0026 LR -0.0219 LKL 0.0245\n",
      "epoch 6440 loss 0.0146 LR -0.0099 LKL 0.0245\n",
      "epoch 6441 loss -0.0319 LR -0.0564 LKL 0.0245\n",
      "epoch 6442 loss 0.0021 LR -0.0223 LKL 0.0244\n",
      "epoch 6443 loss -0.0493 LR -0.0738 LKL 0.0246\n",
      "epoch 6444 loss -0.0033 LR -0.0281 LKL 0.0248\n",
      "epoch 6445 loss -0.0487 LR -0.0732 LKL 0.0245\n",
      "epoch 6446 loss 0.0199 LR -0.0047 LKL 0.0246\n",
      "epoch 6447 loss 0.0197 LR -0.0049 LKL 0.0246\n",
      "epoch 6448 loss -0.0396 LR -0.0646 LKL 0.0250\n",
      "epoch 6449 loss -0.0211 LR -0.0460 LKL 0.0249\n",
      "epoch 6450 loss -0.0033 LR -0.0283 LKL 0.0250\n",
      "epoch 6451 loss -0.0402 LR -0.0648 LKL 0.0246\n",
      "epoch 6452 loss -0.0787 LR -0.1037 LKL 0.0250\n",
      "epoch 6453 loss 0.0076 LR -0.0171 LKL 0.0247\n",
      "epoch 6454 loss -0.0269 LR -0.0517 LKL 0.0248\n",
      "epoch 6455 loss 0.0443 LR 0.0198 LKL 0.0245\n",
      "epoch 6456 loss -0.0319 LR -0.0565 LKL 0.0246\n",
      "epoch 6457 loss -0.0149 LR -0.0391 LKL 0.0242\n",
      "epoch 6458 loss -0.0343 LR -0.0590 LKL 0.0247\n",
      "epoch 6459 loss -0.0435 LR -0.0680 LKL 0.0245\n",
      "epoch 6460 loss -0.0342 LR -0.0588 LKL 0.0246\n",
      "epoch 6461 loss -0.0452 LR -0.0697 LKL 0.0245\n",
      "epoch 6462 loss 0.0392 LR 0.0151 LKL 0.0241\n",
      "epoch 6463 loss 0.0139 LR -0.0103 LKL 0.0243\n",
      "epoch 6464 loss -0.0536 LR -0.0777 LKL 0.0241\n",
      "epoch 6465 loss -0.0483 LR -0.0725 LKL 0.0242\n",
      "epoch 6466 loss 0.0212 LR -0.0028 LKL 0.0240\n",
      "epoch 6467 loss 0.0318 LR 0.0074 LKL 0.0244\n",
      "epoch 6468 loss -0.0042 LR -0.0284 LKL 0.0241\n",
      "epoch 6469 loss -0.0298 LR -0.0540 LKL 0.0241\n",
      "epoch 6470 loss 0.0021 LR -0.0220 LKL 0.0241\n",
      "epoch 6471 loss -0.0139 LR -0.0381 LKL 0.0242\n",
      "epoch 6472 loss -0.0251 LR -0.0496 LKL 0.0245\n",
      "epoch 6473 loss -0.0042 LR -0.0288 LKL 0.0246\n",
      "epoch 6474 loss -0.0003 LR -0.0247 LKL 0.0244\n",
      "epoch 6475 loss -0.0304 LR -0.0548 LKL 0.0244\n",
      "epoch 6476 loss -0.0310 LR -0.0555 LKL 0.0244\n",
      "epoch 6477 loss -0.0051 LR -0.0294 LKL 0.0243\n",
      "epoch 6478 loss -0.0508 LR -0.0755 LKL 0.0247\n",
      "epoch 6479 loss -0.0108 LR -0.0353 LKL 0.0245\n",
      "epoch 6480 loss -0.0136 LR -0.0383 LKL 0.0247\n",
      "epoch 6481 loss 0.0070 LR -0.0172 LKL 0.0242\n",
      "epoch 6482 loss -0.0217 LR -0.0459 LKL 0.0242\n",
      "epoch 6483 loss -0.0026 LR -0.0270 LKL 0.0244\n",
      "epoch 6484 loss 0.0352 LR 0.0108 LKL 0.0244\n",
      "epoch 6485 loss 0.0534 LR 0.0289 LKL 0.0245\n",
      "epoch 6486 loss 0.0505 LR 0.0260 LKL 0.0244\n",
      "epoch 6487 loss -0.0120 LR -0.0363 LKL 0.0243\n",
      "epoch 6488 loss 0.0545 LR 0.0304 LKL 0.0241\n",
      "epoch 6489 loss 0.0121 LR -0.0122 LKL 0.0243\n",
      "epoch 6490 loss -0.0646 LR -0.0890 LKL 0.0244\n",
      "epoch 6491 loss 0.0309 LR 0.0067 LKL 0.0242\n",
      "epoch 6492 loss 0.0081 LR -0.0161 LKL 0.0242\n",
      "epoch 6493 loss -0.0339 LR -0.0581 LKL 0.0242\n",
      "epoch 6494 loss 0.0091 LR -0.0149 LKL 0.0240\n",
      "epoch 6495 loss -0.0280 LR -0.0523 LKL 0.0242\n",
      "epoch 6496 loss 0.0260 LR 0.0020 LKL 0.0240\n",
      "epoch 6497 loss -0.0472 LR -0.0712 LKL 0.0240\n",
      "epoch 6498 loss -0.0163 LR -0.0403 LKL 0.0240\n",
      "epoch 6499 loss 0.0113 LR -0.0125 LKL 0.0238\n",
      "epoch 6500 loss -0.0265 LR -0.0506 LKL 0.0241\n",
      "57\n",
      "epoch 6501 loss -0.0085 LR -0.0325 LKL 0.0240\n",
      "epoch 6502 loss 0.0103 LR -0.0141 LKL 0.0244\n",
      "epoch 6503 loss 0.0418 LR 0.0175 LKL 0.0243\n",
      "epoch 6504 loss 0.0377 LR 0.0138 LKL 0.0238\n",
      "epoch 6505 loss -0.0153 LR -0.0393 LKL 0.0241\n",
      "epoch 6506 loss -0.0086 LR -0.0330 LKL 0.0244\n",
      "epoch 6507 loss -0.0457 LR -0.0700 LKL 0.0243\n",
      "epoch 6508 loss 0.0016 LR -0.0224 LKL 0.0241\n",
      "epoch 6509 loss -0.0017 LR -0.0259 LKL 0.0241\n",
      "epoch 6510 loss -0.0189 LR -0.0433 LKL 0.0244\n",
      "epoch 6511 loss -0.0024 LR -0.0271 LKL 0.0247\n",
      "epoch 6512 loss -0.0236 LR -0.0483 LKL 0.0247\n",
      "epoch 6513 loss 0.0540 LR 0.0291 LKL 0.0249\n",
      "epoch 6514 loss 0.0204 LR -0.0048 LKL 0.0252\n",
      "epoch 6515 loss 0.0164 LR -0.0082 LKL 0.0247\n",
      "epoch 6516 loss -0.0069 LR -0.0316 LKL 0.0247\n",
      "epoch 6517 loss 0.0097 LR -0.0150 LKL 0.0247\n",
      "epoch 6518 loss -0.0139 LR -0.0387 LKL 0.0248\n",
      "epoch 6519 loss -0.0503 LR -0.0753 LKL 0.0250\n",
      "epoch 6520 loss 0.0253 LR 0.0010 LKL 0.0244\n",
      "epoch 6521 loss 0.0397 LR 0.0154 LKL 0.0242\n",
      "epoch 6522 loss -0.0311 LR -0.0552 LKL 0.0241\n",
      "epoch 6523 loss -0.0071 LR -0.0313 LKL 0.0242\n",
      "epoch 6524 loss 0.0138 LR -0.0104 LKL 0.0242\n",
      "epoch 6525 loss -0.0232 LR -0.0475 LKL 0.0244\n",
      "epoch 6526 loss -0.0081 LR -0.0321 LKL 0.0241\n",
      "epoch 6527 loss -0.0265 LR -0.0510 LKL 0.0245\n",
      "epoch 6528 loss 0.0002 LR -0.0242 LKL 0.0243\n",
      "epoch 6529 loss -0.0364 LR -0.0607 LKL 0.0243\n",
      "epoch 6530 loss -0.0464 LR -0.0705 LKL 0.0241\n",
      "epoch 6531 loss 0.0530 LR 0.0287 LKL 0.0243\n",
      "epoch 6532 loss 0.0379 LR 0.0137 LKL 0.0242\n",
      "epoch 6533 loss -0.0196 LR -0.0440 LKL 0.0243\n",
      "epoch 6534 loss -0.0059 LR -0.0303 LKL 0.0244\n",
      "epoch 6535 loss 0.0605 LR 0.0362 LKL 0.0243\n",
      "epoch 6536 loss 0.0111 LR -0.0129 LKL 0.0240\n",
      "epoch 6537 loss 0.0735 LR 0.0496 LKL 0.0239\n",
      "epoch 6538 loss -0.0129 LR -0.0369 LKL 0.0240\n",
      "epoch 6539 loss 0.0043 LR -0.0197 LKL 0.0240\n",
      "epoch 6540 loss -0.0194 LR -0.0437 LKL 0.0243\n",
      "epoch 6541 loss -0.0036 LR -0.0280 LKL 0.0245\n",
      "epoch 6542 loss 0.0289 LR 0.0046 LKL 0.0243\n",
      "epoch 6543 loss -0.0424 LR -0.0666 LKL 0.0242\n",
      "epoch 6544 loss -0.0197 LR -0.0440 LKL 0.0243\n",
      "epoch 6545 loss 0.0292 LR 0.0051 LKL 0.0242\n",
      "epoch 6546 loss 0.0550 LR 0.0305 LKL 0.0245\n",
      "epoch 6547 loss 0.0244 LR 0.0000 LKL 0.0244\n",
      "epoch 6548 loss -0.0295 LR -0.0540 LKL 0.0245\n",
      "epoch 6549 loss -0.0397 LR -0.0642 LKL 0.0245\n",
      "epoch 6550 loss 0.0044 LR -0.0204 LKL 0.0247\n",
      "epoch 6551 loss 0.0268 LR 0.0023 LKL 0.0244\n",
      "epoch 6552 loss 0.0124 LR -0.0119 LKL 0.0243\n",
      "epoch 6553 loss 0.0085 LR -0.0158 LKL 0.0242\n",
      "epoch 6554 loss -0.0235 LR -0.0482 LKL 0.0247\n",
      "epoch 6555 loss -0.0136 LR -0.0379 LKL 0.0243\n",
      "epoch 6556 loss -0.0124 LR -0.0367 LKL 0.0244\n",
      "epoch 6557 loss -0.0492 LR -0.0736 LKL 0.0244\n",
      "epoch 6558 loss 0.0422 LR 0.0180 LKL 0.0242\n",
      "epoch 6559 loss 0.0550 LR 0.0310 LKL 0.0240\n",
      "epoch 6560 loss 0.0433 LR 0.0191 LKL 0.0242\n",
      "epoch 6561 loss 0.0159 LR -0.0082 LKL 0.0241\n",
      "epoch 6562 loss -0.0492 LR -0.0732 LKL 0.0239\n",
      "epoch 6563 loss -0.0484 LR -0.0725 LKL 0.0240\n",
      "epoch 6564 loss -0.0067 LR -0.0311 LKL 0.0244\n",
      "epoch 6565 loss 0.0568 LR 0.0326 LKL 0.0242\n",
      "epoch 6566 loss 0.0225 LR -0.0015 LKL 0.0240\n",
      "epoch 6567 loss -0.0351 LR -0.0593 LKL 0.0241\n",
      "epoch 6568 loss 0.0147 LR -0.0093 LKL 0.0240\n",
      "epoch 6569 loss 0.0250 LR 0.0008 LKL 0.0242\n",
      "epoch 6570 loss 0.0475 LR 0.0235 LKL 0.0241\n",
      "epoch 6571 loss -0.0108 LR -0.0352 LKL 0.0244\n",
      "epoch 6572 loss -0.0382 LR -0.0628 LKL 0.0245\n",
      "epoch 6573 loss -0.0471 LR -0.0716 LKL 0.0245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6574 loss -0.0287 LR -0.0532 LKL 0.0245\n",
      "epoch 6575 loss 0.0598 LR 0.0354 LKL 0.0244\n",
      "epoch 6576 loss 0.0302 LR 0.0060 LKL 0.0242\n",
      "epoch 6577 loss -0.0001 LR -0.0245 LKL 0.0244\n",
      "epoch 6578 loss -0.0045 LR -0.0286 LKL 0.0241\n",
      "epoch 6579 loss -0.0190 LR -0.0434 LKL 0.0244\n",
      "epoch 6580 loss -0.0279 LR -0.0522 LKL 0.0244\n",
      "epoch 6581 loss -0.0278 LR -0.0521 LKL 0.0243\n",
      "epoch 6582 loss -0.0434 LR -0.0678 LKL 0.0244\n",
      "epoch 6583 loss 0.0238 LR -0.0006 LKL 0.0244\n",
      "epoch 6584 loss -0.0086 LR -0.0331 LKL 0.0245\n",
      "epoch 6585 loss -0.0252 LR -0.0495 LKL 0.0243\n",
      "epoch 6586 loss 0.0118 LR -0.0126 LKL 0.0244\n",
      "epoch 6587 loss -0.0379 LR -0.0622 LKL 0.0243\n",
      "epoch 6588 loss -0.0137 LR -0.0382 LKL 0.0245\n",
      "epoch 6589 loss -0.0297 LR -0.0545 LKL 0.0248\n",
      "epoch 6590 loss -0.0653 LR -0.0898 LKL 0.0245\n",
      "epoch 6591 loss -0.0133 LR -0.0377 LKL 0.0244\n",
      "epoch 6592 loss -0.0066 LR -0.0310 LKL 0.0244\n",
      "epoch 6593 loss -0.0055 LR -0.0301 LKL 0.0247\n",
      "epoch 6594 loss 0.0066 LR -0.0180 LKL 0.0245\n",
      "epoch 6595 loss 0.0189 LR -0.0057 LKL 0.0246\n",
      "epoch 6596 loss 0.0224 LR -0.0020 LKL 0.0243\n",
      "epoch 6597 loss 0.0261 LR 0.0015 LKL 0.0245\n",
      "epoch 6598 loss 0.0387 LR 0.0144 LKL 0.0243\n",
      "epoch 6599 loss -0.0435 LR -0.0681 LKL 0.0246\n",
      "epoch 6600 loss -0.0121 LR -0.0367 LKL 0.0245\n",
      "52\n",
      "epoch 6601 loss 0.0162 LR -0.0083 LKL 0.0245\n",
      "epoch 6602 loss 0.0170 LR -0.0075 LKL 0.0245\n",
      "epoch 6603 loss 0.0449 LR 0.0206 LKL 0.0243\n",
      "epoch 6604 loss -0.0401 LR -0.0649 LKL 0.0248\n",
      "epoch 6605 loss 0.0169 LR -0.0077 LKL 0.0247\n",
      "epoch 6606 loss -0.0240 LR -0.0485 LKL 0.0245\n",
      "epoch 6607 loss -0.0430 LR -0.0674 LKL 0.0244\n",
      "epoch 6608 loss -0.0294 LR -0.0537 LKL 0.0243\n",
      "epoch 6609 loss 0.0402 LR 0.0159 LKL 0.0243\n",
      "epoch 6610 loss 0.0481 LR 0.0238 LKL 0.0244\n",
      "epoch 6611 loss -0.0005 LR -0.0248 LKL 0.0243\n",
      "epoch 6612 loss 0.0604 LR 0.0360 LKL 0.0243\n",
      "epoch 6613 loss 0.0313 LR 0.0070 LKL 0.0243\n",
      "epoch 6614 loss -0.0450 LR -0.0695 LKL 0.0245\n",
      "epoch 6615 loss -0.0036 LR -0.0280 LKL 0.0244\n",
      "epoch 6616 loss -0.0158 LR -0.0402 LKL 0.0244\n",
      "epoch 6617 loss -0.0091 LR -0.0336 LKL 0.0245\n",
      "epoch 6618 loss -0.0036 LR -0.0275 LKL 0.0240\n",
      "epoch 6619 loss 0.0087 LR -0.0155 LKL 0.0243\n",
      "epoch 6620 loss -0.0119 LR -0.0361 LKL 0.0242\n",
      "epoch 6621 loss 0.0496 LR 0.0253 LKL 0.0243\n",
      "epoch 6622 loss -0.0317 LR -0.0558 LKL 0.0241\n",
      "epoch 6623 loss 0.0415 LR 0.0172 LKL 0.0243\n",
      "epoch 6624 loss -0.0239 LR -0.0484 LKL 0.0245\n",
      "epoch 6625 loss 0.0656 LR 0.0413 LKL 0.0243\n",
      "epoch 6626 loss 0.0259 LR 0.0016 LKL 0.0243\n",
      "epoch 6627 loss 0.0091 LR -0.0152 LKL 0.0243\n",
      "epoch 6628 loss 0.0366 LR 0.0122 LKL 0.0243\n",
      "epoch 6629 loss -0.0065 LR -0.0309 LKL 0.0244\n",
      "epoch 6630 loss 0.0221 LR -0.0021 LKL 0.0243\n",
      "epoch 6631 loss 0.0240 LR -0.0002 LKL 0.0242\n",
      "epoch 6632 loss -0.0231 LR -0.0476 LKL 0.0246\n",
      "epoch 6633 loss 0.0100 LR -0.0145 LKL 0.0245\n",
      "epoch 6634 loss -0.0368 LR -0.0610 LKL 0.0242\n",
      "epoch 6635 loss -0.0718 LR -0.0961 LKL 0.0242\n",
      "epoch 6636 loss -0.0422 LR -0.0664 LKL 0.0242\n",
      "epoch 6637 loss -0.0284 LR -0.0523 LKL 0.0240\n",
      "epoch 6638 loss -0.0237 LR -0.0478 LKL 0.0242\n",
      "epoch 6639 loss -0.0046 LR -0.0287 LKL 0.0241\n",
      "epoch 6640 loss -0.0881 LR -0.1126 LKL 0.0244\n",
      "epoch 6641 loss -0.0361 LR -0.0604 LKL 0.0244\n",
      "epoch 6642 loss 0.0571 LR 0.0333 LKL 0.0238\n",
      "epoch 6643 loss -0.0228 LR -0.0474 LKL 0.0245\n",
      "epoch 6644 loss -0.0247 LR -0.0495 LKL 0.0248\n",
      "epoch 6645 loss -0.0067 LR -0.0312 LKL 0.0244\n",
      "epoch 6646 loss 0.0023 LR -0.0222 LKL 0.0244\n",
      "epoch 6647 loss -0.0150 LR -0.0395 LKL 0.0245\n",
      "epoch 6648 loss -0.0008 LR -0.0256 LKL 0.0248\n",
      "epoch 6649 loss 0.0278 LR 0.0034 LKL 0.0244\n",
      "epoch 6650 loss -0.0479 LR -0.0724 LKL 0.0245\n",
      "epoch 6651 loss -0.0187 LR -0.0430 LKL 0.0244\n",
      "epoch 6652 loss -0.0390 LR -0.0636 LKL 0.0246\n",
      "epoch 6653 loss 0.0073 LR -0.0170 LKL 0.0243\n",
      "epoch 6654 loss 0.0102 LR -0.0144 LKL 0.0246\n",
      "epoch 6655 loss 0.0215 LR -0.0029 LKL 0.0244\n",
      "epoch 6656 loss 0.0200 LR -0.0044 LKL 0.0244\n",
      "epoch 6657 loss -0.0233 LR -0.0481 LKL 0.0247\n",
      "epoch 6658 loss -0.0406 LR -0.0652 LKL 0.0246\n",
      "epoch 6659 loss 0.0304 LR 0.0063 LKL 0.0242\n",
      "epoch 6660 loss 0.0001 LR -0.0243 LKL 0.0244\n",
      "epoch 6661 loss -0.0045 LR -0.0289 LKL 0.0244\n",
      "epoch 6662 loss -0.0117 LR -0.0362 LKL 0.0245\n",
      "epoch 6663 loss -0.0139 LR -0.0384 LKL 0.0244\n",
      "epoch 6664 loss -0.0228 LR -0.0473 LKL 0.0245\n",
      "epoch 6665 loss -0.0541 LR -0.0787 LKL 0.0245\n",
      "epoch 6666 loss 0.0242 LR -0.0001 LKL 0.0244\n",
      "epoch 6667 loss -0.0232 LR -0.0476 LKL 0.0243\n",
      "epoch 6668 loss -0.0676 LR -0.0920 LKL 0.0244\n",
      "epoch 6669 loss 0.0252 LR 0.0006 LKL 0.0246\n",
      "epoch 6670 loss -0.0255 LR -0.0501 LKL 0.0246\n",
      "epoch 6671 loss 0.0099 LR -0.0145 LKL 0.0244\n",
      "epoch 6672 loss -0.0055 LR -0.0298 LKL 0.0243\n",
      "epoch 6673 loss -0.0212 LR -0.0456 LKL 0.0244\n",
      "epoch 6674 loss -0.0251 LR -0.0494 LKL 0.0243\n",
      "epoch 6675 loss 0.0481 LR 0.0239 LKL 0.0242\n",
      "epoch 6676 loss 0.0141 LR -0.0102 LKL 0.0243\n",
      "epoch 6677 loss 0.0209 LR -0.0035 LKL 0.0244\n",
      "epoch 6678 loss 0.0002 LR -0.0242 LKL 0.0244\n",
      "epoch 6679 loss 0.0124 LR -0.0122 LKL 0.0246\n",
      "epoch 6680 loss -0.0144 LR -0.0390 LKL 0.0246\n",
      "epoch 6681 loss 0.0075 LR -0.0169 LKL 0.0244\n",
      "epoch 6682 loss -0.0363 LR -0.0610 LKL 0.0247\n",
      "epoch 6683 loss -0.0422 LR -0.0664 LKL 0.0242\n",
      "epoch 6684 loss -0.0154 LR -0.0398 LKL 0.0244\n",
      "epoch 6685 loss -0.0587 LR -0.0828 LKL 0.0241\n",
      "epoch 6686 loss 0.0193 LR -0.0049 LKL 0.0243\n",
      "epoch 6687 loss 0.0434 LR 0.0192 LKL 0.0242\n",
      "epoch 6688 loss 0.0010 LR -0.0232 LKL 0.0242\n",
      "epoch 6689 loss -0.0218 LR -0.0457 LKL 0.0239\n",
      "epoch 6690 loss -0.0192 LR -0.0435 LKL 0.0243\n",
      "epoch 6691 loss -0.0222 LR -0.0463 LKL 0.0241\n",
      "epoch 6692 loss -0.0500 LR -0.0744 LKL 0.0243\n",
      "epoch 6693 loss -0.0364 LR -0.0604 LKL 0.0240\n",
      "epoch 6694 loss 0.0154 LR -0.0087 LKL 0.0241\n",
      "epoch 6695 loss -0.0301 LR -0.0544 LKL 0.0243\n",
      "epoch 6696 loss -0.0011 LR -0.0252 LKL 0.0241\n",
      "epoch 6697 loss 0.0464 LR 0.0225 LKL 0.0240\n",
      "epoch 6698 loss 0.0049 LR -0.0196 LKL 0.0245\n",
      "epoch 6699 loss -0.0117 LR -0.0363 LKL 0.0246\n",
      "epoch 6700 loss 0.0251 LR 0.0005 LKL 0.0245\n",
      "59\n",
      "epoch 6701 loss -0.0193 LR -0.0440 LKL 0.0247\n",
      "epoch 6702 loss -0.0045 LR -0.0289 LKL 0.0244\n",
      "epoch 6703 loss -0.0281 LR -0.0528 LKL 0.0248\n",
      "epoch 6704 loss -0.0083 LR -0.0331 LKL 0.0248\n",
      "epoch 6705 loss 0.0187 LR -0.0061 LKL 0.0248\n",
      "epoch 6706 loss -0.0044 LR -0.0291 LKL 0.0247\n",
      "epoch 6707 loss 0.0275 LR 0.0028 LKL 0.0247\n",
      "epoch 6708 loss 0.0227 LR -0.0021 LKL 0.0248\n",
      "epoch 6709 loss -0.0908 LR -0.1158 LKL 0.0251\n",
      "epoch 6710 loss -0.0386 LR -0.0637 LKL 0.0251\n",
      "epoch 6711 loss -0.0563 LR -0.0815 LKL 0.0251\n",
      "epoch 6712 loss -0.0091 LR -0.0339 LKL 0.0248\n",
      "epoch 6713 loss -0.0225 LR -0.0475 LKL 0.0251\n",
      "epoch 6714 loss -0.0448 LR -0.0698 LKL 0.0251\n",
      "epoch 6715 loss -0.0419 LR -0.0670 LKL 0.0250\n",
      "epoch 6716 loss 0.0421 LR 0.0170 LKL 0.0250\n",
      "epoch 6717 loss 0.0209 LR -0.0040 LKL 0.0249\n",
      "epoch 6718 loss -0.0178 LR -0.0426 LKL 0.0249\n",
      "epoch 6719 loss -0.0021 LR -0.0270 LKL 0.0249\n",
      "epoch 6720 loss 0.0491 LR 0.0241 LKL 0.0250\n",
      "epoch 6721 loss 0.0092 LR -0.0156 LKL 0.0248\n",
      "epoch 6722 loss 0.0251 LR 0.0002 LKL 0.0249\n",
      "epoch 6723 loss 0.0318 LR 0.0072 LKL 0.0246\n",
      "epoch 6724 loss 0.0054 LR -0.0191 LKL 0.0245\n",
      "epoch 6725 loss -0.0063 LR -0.0308 LKL 0.0245\n",
      "epoch 6726 loss 0.0137 LR -0.0110 LKL 0.0248\n",
      "epoch 6727 loss 0.0138 LR -0.0107 LKL 0.0244\n",
      "epoch 6728 loss 0.0317 LR 0.0075 LKL 0.0243\n",
      "epoch 6729 loss -0.0097 LR -0.0344 LKL 0.0247\n",
      "epoch 6730 loss -0.0078 LR -0.0320 LKL 0.0242\n",
      "epoch 6731 loss 0.0700 LR 0.0461 LKL 0.0239\n",
      "epoch 6732 loss -0.0481 LR -0.0724 LKL 0.0242\n",
      "epoch 6733 loss -0.0306 LR -0.0545 LKL 0.0239\n",
      "epoch 6734 loss 0.0026 LR -0.0215 LKL 0.0241\n",
      "epoch 6735 loss -0.0175 LR -0.0417 LKL 0.0242\n",
      "epoch 6736 loss 0.0557 LR 0.0319 LKL 0.0238\n",
      "epoch 6737 loss 0.0081 LR -0.0157 LKL 0.0238\n",
      "epoch 6738 loss -0.0557 LR -0.0797 LKL 0.0240\n",
      "epoch 6739 loss 0.0318 LR 0.0077 LKL 0.0241\n",
      "epoch 6740 loss -0.0185 LR -0.0426 LKL 0.0241\n",
      "epoch 6741 loss 0.0069 LR -0.0173 LKL 0.0242\n",
      "epoch 6742 loss -0.0326 LR -0.0569 LKL 0.0243\n",
      "epoch 6743 loss -0.0105 LR -0.0348 LKL 0.0243\n",
      "epoch 6744 loss 0.0273 LR 0.0033 LKL 0.0239\n",
      "epoch 6745 loss 0.0078 LR -0.0163 LKL 0.0242\n",
      "epoch 6746 loss -0.0514 LR -0.0758 LKL 0.0244\n",
      "epoch 6747 loss -0.0531 LR -0.0778 LKL 0.0247\n",
      "epoch 6748 loss 0.0012 LR -0.0234 LKL 0.0246\n",
      "epoch 6749 loss 0.0025 LR -0.0221 LKL 0.0247\n",
      "epoch 6750 loss 0.0304 LR 0.0057 LKL 0.0246\n",
      "epoch 6751 loss -0.0418 LR -0.0665 LKL 0.0247\n",
      "epoch 6752 loss 0.0498 LR 0.0253 LKL 0.0246\n",
      "epoch 6753 loss -0.0247 LR -0.0493 LKL 0.0246\n",
      "epoch 6754 loss -0.0237 LR -0.0486 LKL 0.0249\n",
      "epoch 6755 loss 0.0301 LR 0.0052 LKL 0.0249\n",
      "epoch 6756 loss 0.0049 LR -0.0200 LKL 0.0249\n",
      "epoch 6757 loss -0.0304 LR -0.0552 LKL 0.0248\n",
      "epoch 6758 loss 0.0063 LR -0.0188 LKL 0.0251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6759 loss -0.0089 LR -0.0337 LKL 0.0248\n",
      "epoch 6760 loss -0.0328 LR -0.0578 LKL 0.0250\n",
      "epoch 6761 loss -0.0090 LR -0.0339 LKL 0.0249\n",
      "epoch 6762 loss 0.0069 LR -0.0178 LKL 0.0246\n",
      "epoch 6763 loss -0.0333 LR -0.0581 LKL 0.0248\n",
      "epoch 6764 loss 0.0088 LR -0.0160 LKL 0.0248\n",
      "epoch 6765 loss -0.0040 LR -0.0286 LKL 0.0247\n",
      "epoch 6766 loss 0.0694 LR 0.0450 LKL 0.0244\n",
      "epoch 6767 loss -0.0316 LR -0.0564 LKL 0.0249\n",
      "epoch 6768 loss -0.0257 LR -0.0501 LKL 0.0244\n",
      "epoch 6769 loss -0.0037 LR -0.0284 LKL 0.0247\n",
      "epoch 6770 loss -0.0005 LR -0.0251 LKL 0.0245\n",
      "epoch 6771 loss 0.0371 LR 0.0129 LKL 0.0242\n",
      "epoch 6772 loss -0.0294 LR -0.0537 LKL 0.0243\n",
      "epoch 6773 loss 0.0142 LR -0.0100 LKL 0.0242\n",
      "epoch 6774 loss -0.0110 LR -0.0351 LKL 0.0240\n",
      "epoch 6775 loss -0.0367 LR -0.0608 LKL 0.0240\n",
      "epoch 6776 loss 0.0334 LR 0.0093 LKL 0.0241\n",
      "epoch 6777 loss -0.0178 LR -0.0418 LKL 0.0239\n",
      "epoch 6778 loss -0.0230 LR -0.0472 LKL 0.0242\n",
      "epoch 6779 loss -0.0589 LR -0.0832 LKL 0.0243\n",
      "epoch 6780 loss -0.0683 LR -0.0925 LKL 0.0242\n",
      "epoch 6781 loss -0.0209 LR -0.0450 LKL 0.0241\n",
      "epoch 6782 loss -0.0370 LR -0.0613 LKL 0.0243\n",
      "epoch 6783 loss 0.0291 LR 0.0052 LKL 0.0239\n",
      "epoch 6784 loss -0.0142 LR -0.0383 LKL 0.0241\n",
      "epoch 6785 loss 0.0732 LR 0.0494 LKL 0.0238\n",
      "epoch 6786 loss -0.0201 LR -0.0440 LKL 0.0240\n",
      "epoch 6787 loss -0.0568 LR -0.0811 LKL 0.0243\n",
      "epoch 6788 loss 0.0159 LR -0.0082 LKL 0.0241\n",
      "epoch 6789 loss 0.0115 LR -0.0126 LKL 0.0241\n",
      "epoch 6790 loss 0.0255 LR 0.0015 LKL 0.0240\n",
      "epoch 6791 loss 0.0188 LR -0.0058 LKL 0.0245\n",
      "epoch 6792 loss 0.0242 LR 0.0001 LKL 0.0242\n",
      "epoch 6793 loss 0.0102 LR -0.0142 LKL 0.0244\n",
      "epoch 6794 loss 0.0122 LR -0.0124 LKL 0.0247\n",
      "epoch 6795 loss -0.0114 LR -0.0359 LKL 0.0245\n",
      "epoch 6796 loss -0.0104 LR -0.0348 LKL 0.0244\n",
      "epoch 6797 loss 0.0184 LR -0.0062 LKL 0.0246\n",
      "epoch 6798 loss 0.0027 LR -0.0219 LKL 0.0246\n",
      "epoch 6799 loss 0.0222 LR -0.0022 LKL 0.0244\n",
      "epoch 6800 loss 0.0632 LR 0.0384 LKL 0.0248\n",
      "epoch 6801 loss 0.0646 LR 0.0403 LKL 0.0243\n",
      "epoch 6802 loss -0.0587 LR -0.0832 LKL 0.0246\n",
      "epoch 6803 loss 0.0156 LR -0.0088 LKL 0.0244\n",
      "epoch 6804 loss -0.0088 LR -0.0332 LKL 0.0244\n",
      "epoch 6805 loss -0.0253 LR -0.0497 LKL 0.0244\n",
      "epoch 6806 loss -0.0099 LR -0.0347 LKL 0.0248\n",
      "epoch 6807 loss -0.0335 LR -0.0581 LKL 0.0246\n",
      "epoch 6808 loss -0.0354 LR -0.0603 LKL 0.0249\n",
      "epoch 6809 loss -0.0208 LR -0.0456 LKL 0.0248\n",
      "epoch 6810 loss 0.0294 LR 0.0049 LKL 0.0245\n",
      "epoch 6811 loss 0.0094 LR -0.0152 LKL 0.0246\n",
      "epoch 6812 loss -0.0041 LR -0.0292 LKL 0.0251\n",
      "epoch 6813 loss 0.0312 LR 0.0063 LKL 0.0249\n",
      "epoch 6814 loss -0.0069 LR -0.0321 LKL 0.0252\n",
      "epoch 6815 loss -0.0135 LR -0.0383 LKL 0.0248\n",
      "epoch 6816 loss 0.0298 LR 0.0050 LKL 0.0248\n",
      "epoch 6817 loss -0.0201 LR -0.0448 LKL 0.0247\n",
      "epoch 6818 loss -0.0635 LR -0.0888 LKL 0.0252\n",
      "epoch 6819 loss -0.0494 LR -0.0743 LKL 0.0249\n",
      "epoch 6820 loss -0.0518 LR -0.0764 LKL 0.0246\n",
      "epoch 6821 loss 0.0212 LR -0.0033 LKL 0.0245\n",
      "epoch 6822 loss 0.0085 LR -0.0160 LKL 0.0245\n",
      "epoch 6823 loss -0.0111 LR -0.0353 LKL 0.0242\n",
      "epoch 6824 loss 0.0125 LR -0.0121 LKL 0.0246\n",
      "epoch 6825 loss -0.0332 LR -0.0577 LKL 0.0245\n",
      "epoch 6826 loss -0.0055 LR -0.0298 LKL 0.0243\n",
      "epoch 6827 loss 0.0143 LR -0.0103 LKL 0.0246\n",
      "epoch 6828 loss -0.0247 LR -0.0495 LKL 0.0248\n",
      "epoch 6829 loss -0.0214 LR -0.0457 LKL 0.0243\n",
      "epoch 6830 loss 0.0227 LR -0.0018 LKL 0.0246\n",
      "epoch 6831 loss 0.0183 LR -0.0061 LKL 0.0245\n",
      "epoch 6832 loss -0.0514 LR -0.0761 LKL 0.0247\n",
      "epoch 6833 loss 0.0419 LR 0.0171 LKL 0.0248\n",
      "epoch 6834 loss -0.0156 LR -0.0404 LKL 0.0249\n",
      "epoch 6835 loss 0.0163 LR -0.0082 LKL 0.0245\n",
      "epoch 6836 loss 0.0100 LR -0.0147 LKL 0.0247\n",
      "epoch 6837 loss -0.0185 LR -0.0434 LKL 0.0249\n",
      "epoch 6838 loss -0.0282 LR -0.0530 LKL 0.0248\n",
      "epoch 6839 loss -0.0405 LR -0.0655 LKL 0.0250\n",
      "epoch 6840 loss 0.0327 LR 0.0081 LKL 0.0246\n",
      "epoch 6841 loss -0.0202 LR -0.0451 LKL 0.0249\n",
      "epoch 6842 loss -0.0126 LR -0.0373 LKL 0.0247\n",
      "epoch 6843 loss 0.0294 LR 0.0046 LKL 0.0248\n",
      "epoch 6844 loss -0.0346 LR -0.0596 LKL 0.0250\n",
      "epoch 6845 loss 0.0164 LR -0.0084 LKL 0.0248\n",
      "epoch 6846 loss 0.0013 LR -0.0236 LKL 0.0249\n",
      "epoch 6847 loss 0.0232 LR -0.0016 LKL 0.0248\n",
      "epoch 6848 loss -0.0920 LR -0.1168 LKL 0.0249\n",
      "epoch 6849 loss 0.0829 LR 0.0578 LKL 0.0251\n",
      "epoch 6850 loss -0.0449 LR -0.0700 LKL 0.0250\n",
      "epoch 6851 loss -0.0364 LR -0.0612 LKL 0.0248\n",
      "epoch 6852 loss 0.0022 LR -0.0225 LKL 0.0247\n",
      "epoch 6853 loss 0.0045 LR -0.0201 LKL 0.0246\n",
      "epoch 6854 loss -0.0055 LR -0.0300 LKL 0.0245\n",
      "epoch 6855 loss 0.0253 LR 0.0008 LKL 0.0245\n",
      "epoch 6856 loss 0.0027 LR -0.0219 LKL 0.0246\n",
      "epoch 6857 loss 0.0145 LR -0.0098 LKL 0.0243\n",
      "epoch 6858 loss -0.0147 LR -0.0394 LKL 0.0248\n",
      "epoch 6859 loss 0.0166 LR -0.0078 LKL 0.0245\n",
      "epoch 6860 loss 0.0256 LR 0.0009 LKL 0.0247\n",
      "epoch 6861 loss -0.0025 LR -0.0274 LKL 0.0249\n",
      "epoch 6862 loss -0.0185 LR -0.0431 LKL 0.0247\n",
      "epoch 6863 loss -0.0152 LR -0.0399 LKL 0.0247\n",
      "epoch 6864 loss -0.0343 LR -0.0590 LKL 0.0247\n",
      "epoch 6865 loss 0.0468 LR 0.0220 LKL 0.0248\n",
      "epoch 6866 loss -0.0119 LR -0.0370 LKL 0.0250\n",
      "epoch 6867 loss -0.0008 LR -0.0256 LKL 0.0247\n",
      "epoch 6868 loss 0.0139 LR -0.0110 LKL 0.0249\n",
      "epoch 6869 loss -0.0084 LR -0.0331 LKL 0.0247\n",
      "epoch 6870 loss 0.0352 LR 0.0104 LKL 0.0249\n",
      "epoch 6871 loss -0.0621 LR -0.0872 LKL 0.0251\n",
      "epoch 6872 loss 0.0115 LR -0.0134 LKL 0.0249\n",
      "epoch 6873 loss -0.0000 LR -0.0248 LKL 0.0248\n",
      "epoch 6874 loss -0.0080 LR -0.0326 LKL 0.0247\n",
      "epoch 6875 loss -0.0697 LR -0.0941 LKL 0.0244\n",
      "epoch 6876 loss 0.0461 LR 0.0214 LKL 0.0246\n",
      "epoch 6877 loss -0.0158 LR -0.0405 LKL 0.0246\n",
      "epoch 6878 loss 0.0275 LR 0.0032 LKL 0.0243\n",
      "epoch 6879 loss -0.0116 LR -0.0360 LKL 0.0244\n",
      "epoch 6880 loss 0.0283 LR 0.0040 LKL 0.0243\n",
      "epoch 6881 loss -0.0210 LR -0.0452 LKL 0.0242\n",
      "epoch 6882 loss -0.0052 LR -0.0296 LKL 0.0245\n",
      "epoch 6883 loss -0.0435 LR -0.0684 LKL 0.0248\n",
      "epoch 6884 loss -0.0303 LR -0.0548 LKL 0.0245\n",
      "epoch 6885 loss 0.0053 LR -0.0190 LKL 0.0243\n",
      "epoch 6886 loss -0.0215 LR -0.0457 LKL 0.0242\n",
      "epoch 6887 loss 0.0149 LR -0.0096 LKL 0.0245\n",
      "epoch 6888 loss 0.0002 LR -0.0245 LKL 0.0247\n",
      "epoch 6889 loss -0.0224 LR -0.0470 LKL 0.0246\n",
      "epoch 6890 loss -0.0233 LR -0.0479 LKL 0.0246\n",
      "epoch 6891 loss -0.0601 LR -0.0850 LKL 0.0250\n",
      "epoch 6892 loss -0.0097 LR -0.0343 LKL 0.0245\n",
      "epoch 6893 loss 0.0165 LR -0.0084 LKL 0.0249\n",
      "epoch 6894 loss 0.0198 LR -0.0048 LKL 0.0246\n",
      "epoch 6895 loss -0.0344 LR -0.0591 LKL 0.0248\n",
      "epoch 6896 loss -0.0030 LR -0.0276 LKL 0.0246\n",
      "epoch 6897 loss -0.0149 LR -0.0398 LKL 0.0250\n",
      "epoch 6898 loss 0.0040 LR -0.0208 LKL 0.0248\n",
      "epoch 6899 loss 0.0325 LR 0.0079 LKL 0.0246\n",
      "epoch 6900 loss -0.0363 LR -0.0612 LKL 0.0249\n",
      "62\n",
      "epoch 6901 loss -0.0460 LR -0.0710 LKL 0.0251\n",
      "epoch 6902 loss -0.0017 LR -0.0264 LKL 0.0246\n",
      "epoch 6903 loss 0.0196 LR -0.0051 LKL 0.0247\n",
      "epoch 6904 loss 0.0193 LR -0.0056 LKL 0.0248\n",
      "epoch 6905 loss -0.0076 LR -0.0325 LKL 0.0249\n",
      "epoch 6906 loss -0.0034 LR -0.0281 LKL 0.0247\n",
      "epoch 6907 loss -0.0074 LR -0.0317 LKL 0.0244\n",
      "epoch 6908 loss -0.0202 LR -0.0450 LKL 0.0248\n",
      "epoch 6909 loss 0.0194 LR -0.0053 LKL 0.0247\n",
      "epoch 6910 loss -0.0057 LR -0.0304 LKL 0.0247\n",
      "epoch 6911 loss 0.0080 LR -0.0169 LKL 0.0249\n",
      "epoch 6912 loss 0.0496 LR 0.0248 LKL 0.0248\n",
      "epoch 6913 loss -0.0464 LR -0.0712 LKL 0.0248\n",
      "epoch 6914 loss 0.0017 LR -0.0230 LKL 0.0246\n",
      "epoch 6915 loss -0.0345 LR -0.0591 LKL 0.0246\n",
      "epoch 6916 loss -0.0247 LR -0.0495 LKL 0.0248\n",
      "epoch 6917 loss -0.0056 LR -0.0302 LKL 0.0246\n",
      "epoch 6918 loss -0.0264 LR -0.0511 LKL 0.0246\n",
      "epoch 6919 loss -0.0188 LR -0.0433 LKL 0.0245\n",
      "epoch 6920 loss -0.0148 LR -0.0394 LKL 0.0246\n",
      "epoch 6921 loss 0.0251 LR 0.0006 LKL 0.0246\n",
      "epoch 6922 loss 0.0210 LR -0.0035 LKL 0.0245\n",
      "epoch 6923 loss -0.0259 LR -0.0503 LKL 0.0244\n",
      "epoch 6924 loss -0.0450 LR -0.0700 LKL 0.0250\n",
      "epoch 6925 loss 0.0217 LR -0.0029 LKL 0.0246\n",
      "epoch 6926 loss -0.0283 LR -0.0532 LKL 0.0249\n",
      "epoch 6927 loss -0.0064 LR -0.0308 LKL 0.0244\n",
      "epoch 6928 loss 0.0444 LR 0.0199 LKL 0.0245\n",
      "epoch 6929 loss -0.0113 LR -0.0360 LKL 0.0247\n",
      "epoch 6930 loss 0.0445 LR 0.0200 LKL 0.0244\n",
      "epoch 6931 loss -0.0516 LR -0.0767 LKL 0.0251\n",
      "epoch 6932 loss -0.0386 LR -0.0636 LKL 0.0250\n",
      "epoch 6933 loss 0.0031 LR -0.0219 LKL 0.0249\n",
      "epoch 6934 loss 0.0349 LR 0.0102 LKL 0.0247\n",
      "epoch 6935 loss 0.0007 LR -0.0242 LKL 0.0249\n",
      "epoch 6936 loss 0.0056 LR -0.0192 LKL 0.0248\n",
      "epoch 6937 loss -0.0305 LR -0.0556 LKL 0.0251\n",
      "epoch 6938 loss -0.0337 LR -0.0588 LKL 0.0251\n",
      "epoch 6939 loss -0.0265 LR -0.0515 LKL 0.0250\n",
      "epoch 6940 loss 0.0289 LR 0.0039 LKL 0.0250\n",
      "epoch 6941 loss -0.0433 LR -0.0683 LKL 0.0251\n",
      "epoch 6942 loss -0.0320 LR -0.0568 LKL 0.0248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6943 loss -0.0352 LR -0.0599 LKL 0.0247\n",
      "epoch 6944 loss 0.0214 LR -0.0032 LKL 0.0246\n",
      "epoch 6945 loss -0.0596 LR -0.0844 LKL 0.0247\n",
      "epoch 6946 loss 0.0110 LR -0.0137 LKL 0.0247\n",
      "epoch 6947 loss 0.0052 LR -0.0197 LKL 0.0248\n",
      "epoch 6948 loss 0.0298 LR 0.0052 LKL 0.0246\n",
      "epoch 6949 loss -0.0069 LR -0.0318 LKL 0.0249\n",
      "epoch 6950 loss -0.0149 LR -0.0396 LKL 0.0248\n",
      "epoch 6951 loss -0.0635 LR -0.0886 LKL 0.0251\n",
      "epoch 6952 loss -0.0217 LR -0.0466 LKL 0.0249\n",
      "epoch 6953 loss 0.0134 LR -0.0114 LKL 0.0248\n",
      "epoch 6954 loss -0.0563 LR -0.0813 LKL 0.0249\n",
      "epoch 6955 loss -0.0388 LR -0.0636 LKL 0.0248\n",
      "epoch 6956 loss 0.0132 LR -0.0116 LKL 0.0248\n",
      "epoch 6957 loss 0.0128 LR -0.0120 LKL 0.0249\n",
      "epoch 6958 loss 0.0008 LR -0.0240 LKL 0.0248\n",
      "epoch 6959 loss -0.0599 LR -0.0848 LKL 0.0249\n",
      "epoch 6960 loss 0.0163 LR -0.0087 LKL 0.0249\n",
      "epoch 6961 loss 0.0419 LR 0.0173 LKL 0.0245\n",
      "epoch 6962 loss -0.0220 LR -0.0467 LKL 0.0246\n",
      "epoch 6963 loss -0.0052 LR -0.0301 LKL 0.0249\n",
      "epoch 6964 loss 0.0685 LR 0.0438 LKL 0.0246\n",
      "epoch 6965 loss 0.0363 LR 0.0117 LKL 0.0246\n",
      "epoch 6966 loss 0.0212 LR -0.0034 LKL 0.0246\n",
      "epoch 6967 loss -0.0199 LR -0.0443 LKL 0.0243\n",
      "epoch 6968 loss 0.0085 LR -0.0159 LKL 0.0244\n",
      "epoch 6969 loss -0.0011 LR -0.0256 LKL 0.0245\n",
      "epoch 6970 loss -0.0343 LR -0.0589 LKL 0.0246\n",
      "epoch 6971 loss -0.0290 LR -0.0533 LKL 0.0243\n",
      "epoch 6972 loss 0.0088 LR -0.0155 LKL 0.0243\n",
      "epoch 6973 loss 0.0415 LR 0.0170 LKL 0.0246\n",
      "epoch 6974 loss 0.0032 LR -0.0214 LKL 0.0246\n",
      "epoch 6975 loss -0.0332 LR -0.0578 LKL 0.0246\n",
      "epoch 6976 loss 0.0318 LR 0.0073 LKL 0.0245\n",
      "epoch 6977 loss -0.0660 LR -0.0905 LKL 0.0245\n",
      "epoch 6978 loss -0.0797 LR -0.1045 LKL 0.0248\n",
      "epoch 6979 loss 0.0045 LR -0.0202 LKL 0.0247\n",
      "epoch 6980 loss -0.0088 LR -0.0335 LKL 0.0247\n",
      "epoch 6981 loss -0.0014 LR -0.0259 LKL 0.0245\n",
      "epoch 6982 loss 0.0045 LR -0.0205 LKL 0.0249\n",
      "epoch 6983 loss -0.0195 LR -0.0444 LKL 0.0249\n",
      "epoch 6984 loss 0.0129 LR -0.0119 LKL 0.0248\n",
      "epoch 6985 loss -0.0341 LR -0.0589 LKL 0.0248\n",
      "epoch 6986 loss 0.0175 LR -0.0074 LKL 0.0249\n",
      "epoch 6987 loss 0.0284 LR 0.0037 LKL 0.0247\n",
      "epoch 6988 loss 0.0139 LR -0.0108 LKL 0.0247\n",
      "epoch 6989 loss -0.0131 LR -0.0381 LKL 0.0250\n",
      "epoch 6990 loss -0.0206 LR -0.0453 LKL 0.0247\n",
      "epoch 6991 loss -0.0027 LR -0.0276 LKL 0.0249\n",
      "epoch 6992 loss 0.0478 LR 0.0229 LKL 0.0249\n",
      "epoch 6993 loss 0.0278 LR 0.0032 LKL 0.0247\n",
      "epoch 6994 loss 0.0352 LR 0.0107 LKL 0.0245\n",
      "epoch 6995 loss -0.0184 LR -0.0431 LKL 0.0247\n",
      "epoch 6996 loss -0.0152 LR -0.0397 LKL 0.0245\n",
      "epoch 6997 loss 0.0117 LR -0.0129 LKL 0.0246\n",
      "epoch 6998 loss 0.0192 LR -0.0054 LKL 0.0246\n",
      "epoch 6999 loss 0.0445 LR 0.0200 LKL 0.0245\n",
      "epoch 7000 loss 0.0151 LR -0.0096 LKL 0.0247\n",
      "60\n",
      "epoch 7001 loss 0.0404 LR 0.0158 LKL 0.0246\n",
      "epoch 7002 loss -0.0250 LR -0.0495 LKL 0.0245\n",
      "epoch 7003 loss 0.0031 LR -0.0218 LKL 0.0249\n",
      "epoch 7004 loss -0.0151 LR -0.0396 LKL 0.0244\n",
      "epoch 7005 loss 0.0296 LR 0.0050 LKL 0.0246\n",
      "epoch 7006 loss 0.0259 LR 0.0013 LKL 0.0246\n",
      "epoch 7007 loss -0.0830 LR -0.1081 LKL 0.0250\n",
      "epoch 7008 loss -0.0110 LR -0.0357 LKL 0.0247\n",
      "epoch 7009 loss 0.0265 LR 0.0022 LKL 0.0243\n",
      "epoch 7010 loss -0.0037 LR -0.0283 LKL 0.0246\n",
      "epoch 7011 loss 0.0082 LR -0.0164 LKL 0.0246\n",
      "epoch 7012 loss -0.0412 LR -0.0659 LKL 0.0246\n",
      "epoch 7013 loss -0.0295 LR -0.0540 LKL 0.0245\n",
      "epoch 7014 loss 0.0281 LR 0.0037 LKL 0.0244\n",
      "epoch 7015 loss -0.0376 LR -0.0620 LKL 0.0244\n",
      "epoch 7016 loss 0.0255 LR 0.0013 LKL 0.0243\n",
      "epoch 7017 loss -0.0280 LR -0.0523 LKL 0.0244\n",
      "epoch 7018 loss -0.0255 LR -0.0498 LKL 0.0243\n",
      "epoch 7019 loss -0.0044 LR -0.0289 LKL 0.0245\n",
      "epoch 7020 loss -0.0014 LR -0.0256 LKL 0.0241\n",
      "epoch 7021 loss 0.0386 LR 0.0141 LKL 0.0245\n",
      "epoch 7022 loss 0.0010 LR -0.0237 LKL 0.0247\n",
      "epoch 7023 loss -0.0069 LR -0.0313 LKL 0.0243\n",
      "epoch 7024 loss -0.0606 LR -0.0853 LKL 0.0247\n",
      "epoch 7025 loss -0.0117 LR -0.0362 LKL 0.0245\n",
      "epoch 7026 loss -0.0021 LR -0.0266 LKL 0.0245\n",
      "epoch 7027 loss -0.0306 LR -0.0555 LKL 0.0248\n",
      "epoch 7028 loss -0.0355 LR -0.0603 LKL 0.0248\n",
      "epoch 7029 loss -0.0110 LR -0.0356 LKL 0.0246\n",
      "epoch 7030 loss 0.0100 LR -0.0149 LKL 0.0249\n",
      "epoch 7031 loss -0.0668 LR -0.0916 LKL 0.0248\n",
      "epoch 7032 loss -0.0420 LR -0.0667 LKL 0.0247\n",
      "epoch 7033 loss -0.0487 LR -0.0733 LKL 0.0246\n",
      "epoch 7034 loss -0.0414 LR -0.0661 LKL 0.0247\n",
      "epoch 7035 loss -0.0663 LR -0.0911 LKL 0.0248\n",
      "epoch 7036 loss -0.0111 LR -0.0353 LKL 0.0242\n",
      "epoch 7037 loss 0.0327 LR 0.0083 LKL 0.0244\n",
      "epoch 7038 loss -0.0205 LR -0.0449 LKL 0.0244\n",
      "epoch 7039 loss -0.0364 LR -0.0611 LKL 0.0247\n",
      "epoch 7040 loss 0.0122 LR -0.0123 LKL 0.0246\n",
      "epoch 7041 loss -0.0679 LR -0.0928 LKL 0.0249\n",
      "epoch 7042 loss 0.0431 LR 0.0185 LKL 0.0246\n",
      "epoch 7043 loss -0.0190 LR -0.0435 LKL 0.0245\n",
      "epoch 7044 loss -0.0693 LR -0.0941 LKL 0.0247\n",
      "epoch 7045 loss -0.0217 LR -0.0463 LKL 0.0246\n",
      "epoch 7046 loss -0.0237 LR -0.0479 LKL 0.0243\n",
      "epoch 7047 loss -0.0334 LR -0.0580 LKL 0.0246\n",
      "epoch 7048 loss 0.0195 LR -0.0052 LKL 0.0246\n",
      "epoch 7049 loss -0.0433 LR -0.0681 LKL 0.0248\n",
      "epoch 7050 loss -0.0617 LR -0.0862 LKL 0.0245\n",
      "epoch 7051 loss 0.0111 LR -0.0134 LKL 0.0246\n",
      "epoch 7052 loss 0.0373 LR 0.0127 LKL 0.0246\n",
      "epoch 7053 loss -0.0081 LR -0.0329 LKL 0.0248\n",
      "epoch 7054 loss 0.0320 LR 0.0074 LKL 0.0246\n",
      "epoch 7055 loss -0.0202 LR -0.0449 LKL 0.0246\n",
      "epoch 7056 loss -0.0041 LR -0.0289 LKL 0.0248\n",
      "epoch 7057 loss 0.0136 LR -0.0110 LKL 0.0245\n",
      "epoch 7058 loss -0.0259 LR -0.0506 LKL 0.0247\n",
      "epoch 7059 loss -0.0646 LR -0.0892 LKL 0.0246\n",
      "epoch 7060 loss -0.0546 LR -0.0793 LKL 0.0248\n",
      "epoch 7061 loss 0.0459 LR 0.0213 LKL 0.0246\n",
      "epoch 7062 loss -0.0624 LR -0.0876 LKL 0.0252\n",
      "epoch 7063 loss 0.0212 LR -0.0034 LKL 0.0246\n",
      "epoch 7064 loss 0.0082 LR -0.0168 LKL 0.0250\n",
      "epoch 7065 loss -0.0458 LR -0.0706 LKL 0.0249\n",
      "epoch 7066 loss -0.0422 LR -0.0671 LKL 0.0249\n",
      "epoch 7067 loss 0.0635 LR 0.0389 LKL 0.0246\n",
      "epoch 7068 loss 0.0607 LR 0.0359 LKL 0.0248\n",
      "epoch 7069 loss 0.0152 LR -0.0097 LKL 0.0249\n",
      "epoch 7070 loss -0.0105 LR -0.0354 LKL 0.0248\n",
      "epoch 7071 loss -0.0410 LR -0.0658 LKL 0.0248\n",
      "epoch 7072 loss -0.0547 LR -0.0795 LKL 0.0248\n",
      "epoch 7073 loss -0.0193 LR -0.0440 LKL 0.0248\n",
      "epoch 7074 loss -0.0141 LR -0.0389 LKL 0.0248\n",
      "epoch 7075 loss -0.0725 LR -0.0973 LKL 0.0248\n",
      "epoch 7076 loss -0.0122 LR -0.0369 LKL 0.0246\n",
      "epoch 7077 loss -0.0372 LR -0.0618 LKL 0.0246\n",
      "epoch 7078 loss -0.0170 LR -0.0419 LKL 0.0248\n",
      "epoch 7079 loss -0.0856 LR -0.1105 LKL 0.0248\n",
      "epoch 7080 loss -0.0034 LR -0.0279 LKL 0.0245\n",
      "epoch 7081 loss -0.0322 LR -0.0571 LKL 0.0249\n",
      "epoch 7082 loss 0.0253 LR 0.0007 LKL 0.0246\n",
      "epoch 7083 loss -0.0104 LR -0.0349 LKL 0.0245\n",
      "epoch 7084 loss -0.0390 LR -0.0635 LKL 0.0246\n",
      "epoch 7085 loss -0.0541 LR -0.0786 LKL 0.0245\n",
      "epoch 7086 loss 0.0162 LR -0.0084 LKL 0.0246\n",
      "epoch 7087 loss -0.0196 LR -0.0439 LKL 0.0243\n",
      "epoch 7088 loss -0.0241 LR -0.0488 LKL 0.0247\n",
      "epoch 7089 loss -0.0723 LR -0.0969 LKL 0.0246\n",
      "epoch 7090 loss -0.0200 LR -0.0446 LKL 0.0246\n",
      "epoch 7091 loss -0.0081 LR -0.0328 LKL 0.0247\n",
      "epoch 7092 loss 0.0635 LR 0.0388 LKL 0.0247\n",
      "epoch 7093 loss -0.0930 LR -0.1177 LKL 0.0247\n",
      "epoch 7094 loss 0.0287 LR 0.0039 LKL 0.0248\n",
      "epoch 7095 loss -0.0409 LR -0.0659 LKL 0.0250\n",
      "epoch 7096 loss 0.0478 LR 0.0231 LKL 0.0247\n",
      "epoch 7097 loss -0.0846 LR -0.1097 LKL 0.0251\n",
      "epoch 7098 loss -0.0759 LR -0.1010 LKL 0.0251\n",
      "epoch 7099 loss 0.0219 LR -0.0031 LKL 0.0250\n",
      "epoch 7100 loss -0.0272 LR -0.0522 LKL 0.0249\n",
      "89\n",
      "epoch 7101 loss 0.0436 LR 0.0188 LKL 0.0247\n",
      "epoch 7102 loss -0.0365 LR -0.0614 LKL 0.0249\n",
      "epoch 7103 loss 0.0658 LR 0.0411 LKL 0.0247\n",
      "epoch 7104 loss -0.0121 LR -0.0367 LKL 0.0246\n",
      "epoch 7105 loss -0.0331 LR -0.0579 LKL 0.0248\n",
      "epoch 7106 loss -0.0223 LR -0.0470 LKL 0.0247\n",
      "epoch 7107 loss -0.0172 LR -0.0418 LKL 0.0247\n",
      "epoch 7108 loss -0.0175 LR -0.0422 LKL 0.0247\n",
      "epoch 7109 loss 0.0118 LR -0.0131 LKL 0.0249\n",
      "epoch 7110 loss -0.0449 LR -0.0697 LKL 0.0248\n",
      "epoch 7111 loss -0.0330 LR -0.0580 LKL 0.0250\n",
      "epoch 7112 loss -0.0177 LR -0.0425 LKL 0.0248\n",
      "epoch 7113 loss -0.0404 LR -0.0651 LKL 0.0246\n",
      "epoch 7114 loss -0.0271 LR -0.0517 LKL 0.0246\n",
      "epoch 7115 loss -0.0169 LR -0.0418 LKL 0.0249\n",
      "epoch 7116 loss -0.0193 LR -0.0442 LKL 0.0248\n",
      "epoch 7117 loss -0.0242 LR -0.0491 LKL 0.0249\n",
      "epoch 7118 loss -0.0344 LR -0.0590 LKL 0.0246\n",
      "epoch 7119 loss -0.0272 LR -0.0518 LKL 0.0247\n",
      "epoch 7120 loss -0.0000 LR -0.0246 LKL 0.0246\n",
      "epoch 7121 loss -0.0224 LR -0.0472 LKL 0.0247\n",
      "epoch 7122 loss 0.0082 LR -0.0166 LKL 0.0248\n",
      "epoch 7123 loss -0.0074 LR -0.0319 LKL 0.0245\n",
      "epoch 7124 loss 0.0380 LR 0.0134 LKL 0.0246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7125 loss 0.0013 LR -0.0237 LKL 0.0250\n",
      "epoch 7126 loss -0.0285 LR -0.0533 LKL 0.0248\n",
      "epoch 7127 loss 0.0120 LR -0.0129 LKL 0.0248\n",
      "epoch 7128 loss -0.0290 LR -0.0539 LKL 0.0249\n",
      "epoch 7129 loss 0.0386 LR 0.0139 LKL 0.0246\n",
      "epoch 7130 loss -0.0106 LR -0.0352 LKL 0.0246\n",
      "epoch 7131 loss -0.0256 LR -0.0504 LKL 0.0248\n",
      "epoch 7132 loss -0.0069 LR -0.0317 LKL 0.0248\n",
      "epoch 7133 loss 0.0322 LR 0.0073 LKL 0.0249\n",
      "epoch 7134 loss -0.0288 LR -0.0537 LKL 0.0249\n",
      "epoch 7135 loss -0.0356 LR -0.0606 LKL 0.0250\n",
      "epoch 7136 loss -0.0505 LR -0.0756 LKL 0.0252\n",
      "epoch 7137 loss -0.0043 LR -0.0292 LKL 0.0249\n",
      "epoch 7138 loss -0.0126 LR -0.0379 LKL 0.0253\n",
      "epoch 7139 loss -0.0139 LR -0.0389 LKL 0.0250\n",
      "epoch 7140 loss -0.0380 LR -0.0631 LKL 0.0251\n",
      "epoch 7141 loss 0.0356 LR 0.0107 LKL 0.0249\n",
      "epoch 7142 loss -0.0437 LR -0.0690 LKL 0.0253\n",
      "epoch 7143 loss 0.0377 LR 0.0128 LKL 0.0249\n",
      "epoch 7144 loss -0.0581 LR -0.0832 LKL 0.0251\n",
      "epoch 7145 loss -0.0488 LR -0.0740 LKL 0.0252\n",
      "epoch 7146 loss -0.0598 LR -0.0851 LKL 0.0253\n",
      "epoch 7147 loss -0.0173 LR -0.0426 LKL 0.0252\n",
      "epoch 7148 loss 0.0029 LR -0.0220 LKL 0.0249\n",
      "epoch 7149 loss -0.0043 LR -0.0295 LKL 0.0251\n",
      "epoch 7150 loss -0.0425 LR -0.0673 LKL 0.0248\n",
      "epoch 7151 loss -0.0355 LR -0.0604 LKL 0.0249\n",
      "epoch 7152 loss -0.0069 LR -0.0318 LKL 0.0249\n",
      "epoch 7153 loss 0.0081 LR -0.0166 LKL 0.0247\n",
      "epoch 7154 loss 0.0105 LR -0.0141 LKL 0.0246\n",
      "epoch 7155 loss -0.0586 LR -0.0833 LKL 0.0247\n",
      "epoch 7156 loss 0.0524 LR 0.0278 LKL 0.0246\n",
      "epoch 7157 loss 0.0245 LR 0.0000 LKL 0.0244\n",
      "epoch 7158 loss -0.0390 LR -0.0637 LKL 0.0248\n",
      "epoch 7159 loss 0.0108 LR -0.0137 LKL 0.0245\n",
      "epoch 7160 loss -0.0308 LR -0.0553 LKL 0.0246\n",
      "epoch 7161 loss -0.0014 LR -0.0259 LKL 0.0245\n",
      "epoch 7162 loss -0.0063 LR -0.0307 LKL 0.0245\n",
      "epoch 7163 loss 0.0129 LR -0.0115 LKL 0.0244\n",
      "epoch 7164 loss -0.0434 LR -0.0679 LKL 0.0244\n",
      "epoch 7165 loss -0.0133 LR -0.0380 LKL 0.0246\n",
      "epoch 7166 loss -0.0233 LR -0.0477 LKL 0.0243\n",
      "epoch 7167 loss -0.0139 LR -0.0382 LKL 0.0242\n",
      "epoch 7168 loss 0.0336 LR 0.0091 LKL 0.0245\n",
      "epoch 7169 loss -0.0129 LR -0.0374 LKL 0.0245\n",
      "epoch 7170 loss -0.0804 LR -0.1050 LKL 0.0247\n",
      "epoch 7171 loss 0.0108 LR -0.0138 LKL 0.0246\n",
      "epoch 7172 loss -0.0085 LR -0.0328 LKL 0.0244\n",
      "epoch 7173 loss 0.0365 LR 0.0120 LKL 0.0245\n",
      "epoch 7174 loss 0.0078 LR -0.0167 LKL 0.0245\n",
      "epoch 7175 loss 0.0191 LR -0.0052 LKL 0.0243\n",
      "epoch 7176 loss -0.0626 LR -0.0872 LKL 0.0246\n",
      "epoch 7177 loss -0.0410 LR -0.0658 LKL 0.0248\n",
      "epoch 7178 loss 0.0126 LR -0.0117 LKL 0.0243\n",
      "epoch 7179 loss 0.0106 LR -0.0138 LKL 0.0244\n",
      "epoch 7180 loss -0.0278 LR -0.0522 LKL 0.0244\n",
      "epoch 7181 loss 0.0241 LR -0.0005 LKL 0.0246\n",
      "epoch 7182 loss 0.0233 LR -0.0014 LKL 0.0246\n",
      "epoch 7183 loss -0.0094 LR -0.0340 LKL 0.0246\n",
      "epoch 7184 loss 0.0135 LR -0.0107 LKL 0.0242\n",
      "epoch 7185 loss -0.0155 LR -0.0402 LKL 0.0247\n",
      "epoch 7186 loss -0.0176 LR -0.0422 LKL 0.0246\n",
      "epoch 7187 loss -0.0283 LR -0.0530 LKL 0.0246\n",
      "epoch 7188 loss -0.0653 LR -0.0897 LKL 0.0244\n",
      "epoch 7189 loss -0.0861 LR -0.1110 LKL 0.0249\n",
      "epoch 7190 loss -0.0704 LR -0.0950 LKL 0.0246\n",
      "epoch 7191 loss -0.0294 LR -0.0539 LKL 0.0245\n",
      "epoch 7192 loss -0.0338 LR -0.0582 LKL 0.0244\n",
      "epoch 7193 loss -0.0149 LR -0.0391 LKL 0.0242\n",
      "epoch 7194 loss -0.0094 LR -0.0338 LKL 0.0244\n",
      "epoch 7195 loss -0.0142 LR -0.0385 LKL 0.0244\n",
      "epoch 7196 loss -0.0453 LR -0.0700 LKL 0.0247\n",
      "epoch 7197 loss 0.0000 LR -0.0245 LKL 0.0245\n",
      "epoch 7198 loss -0.0355 LR -0.0602 LKL 0.0247\n",
      "epoch 7199 loss -0.0256 LR -0.0502 LKL 0.0246\n",
      "epoch 7200 loss -0.0309 LR -0.0554 LKL 0.0246\n",
      "epoch 7201 loss -0.0167 LR -0.0414 LKL 0.0246\n",
      "epoch 7202 loss -0.0274 LR -0.0523 LKL 0.0249\n",
      "epoch 7203 loss -0.1013 LR -0.1262 LKL 0.0249\n",
      "epoch 7204 loss -0.0408 LR -0.0658 LKL 0.0250\n",
      "epoch 7205 loss 0.0203 LR -0.0041 LKL 0.0245\n",
      "epoch 7206 loss -0.0219 LR -0.0468 LKL 0.0249\n",
      "epoch 7207 loss -0.0108 LR -0.0356 LKL 0.0248\n",
      "epoch 7208 loss -0.0081 LR -0.0331 LKL 0.0250\n",
      "epoch 7209 loss 0.0025 LR -0.0225 LKL 0.0249\n",
      "epoch 7210 loss -0.0749 LR -0.0999 LKL 0.0250\n",
      "epoch 7211 loss -0.0190 LR -0.0436 LKL 0.0246\n",
      "epoch 7212 loss 0.0424 LR 0.0175 LKL 0.0249\n",
      "epoch 7213 loss -0.0035 LR -0.0284 LKL 0.0249\n",
      "epoch 7214 loss -0.0058 LR -0.0307 LKL 0.0248\n",
      "epoch 7215 loss -0.0179 LR -0.0427 LKL 0.0248\n",
      "epoch 7216 loss 0.0016 LR -0.0232 LKL 0.0248\n",
      "epoch 7217 loss -0.0471 LR -0.0721 LKL 0.0249\n",
      "epoch 7218 loss -0.0036 LR -0.0282 LKL 0.0246\n",
      "epoch 7219 loss 0.0250 LR 0.0004 LKL 0.0246\n",
      "epoch 7220 loss -0.0311 LR -0.0560 LKL 0.0249\n",
      "epoch 7221 loss 0.0494 LR 0.0247 LKL 0.0248\n",
      "epoch 7222 loss -0.0255 LR -0.0502 LKL 0.0248\n",
      "epoch 7223 loss 0.0065 LR -0.0183 LKL 0.0248\n",
      "epoch 7224 loss -0.0353 LR -0.0600 LKL 0.0247\n",
      "epoch 7225 loss -0.0030 LR -0.0277 LKL 0.0247\n",
      "epoch 7226 loss -0.0079 LR -0.0324 LKL 0.0245\n",
      "epoch 7227 loss -0.0065 LR -0.0315 LKL 0.0249\n",
      "epoch 7228 loss -0.0233 LR -0.0481 LKL 0.0248\n",
      "epoch 7229 loss -0.0815 LR -0.1065 LKL 0.0249\n",
      "epoch 7230 loss -0.0562 LR -0.0811 LKL 0.0249\n",
      "epoch 7231 loss -0.0013 LR -0.0262 LKL 0.0249\n",
      "epoch 7232 loss 0.0197 LR -0.0051 LKL 0.0249\n",
      "epoch 7233 loss -0.0218 LR -0.0463 LKL 0.0246\n",
      "epoch 7234 loss -0.0478 LR -0.0726 LKL 0.0248\n",
      "epoch 7235 loss -0.0044 LR -0.0293 LKL 0.0249\n",
      "epoch 7236 loss 0.0088 LR -0.0160 LKL 0.0248\n",
      "epoch 7237 loss -0.0226 LR -0.0475 LKL 0.0248\n",
      "epoch 7238 loss -0.0210 LR -0.0459 LKL 0.0250\n",
      "epoch 7239 loss -0.0346 LR -0.0593 LKL 0.0247\n",
      "epoch 7240 loss -0.0118 LR -0.0364 LKL 0.0246\n",
      "epoch 7241 loss 0.0252 LR 0.0004 LKL 0.0248\n",
      "epoch 7242 loss -0.0247 LR -0.0497 LKL 0.0250\n",
      "epoch 7243 loss 0.0600 LR 0.0349 LKL 0.0251\n",
      "epoch 7244 loss -0.0548 LR -0.0801 LKL 0.0253\n",
      "epoch 7245 loss 0.0063 LR -0.0187 LKL 0.0249\n",
      "epoch 7246 loss -0.0302 LR -0.0553 LKL 0.0251\n",
      "epoch 7247 loss -0.0317 LR -0.0566 LKL 0.0249\n",
      "epoch 7248 loss -0.0645 LR -0.0897 LKL 0.0252\n",
      "epoch 7249 loss -0.0457 LR -0.0708 LKL 0.0252\n",
      "epoch 7250 loss 0.0076 LR -0.0173 LKL 0.0249\n",
      "epoch 7251 loss -0.0376 LR -0.0624 LKL 0.0248\n",
      "epoch 7252 loss -0.0461 LR -0.0709 LKL 0.0247\n",
      "epoch 7253 loss -0.0747 LR -0.0996 LKL 0.0250\n",
      "epoch 7254 loss -0.0237 LR -0.0485 LKL 0.0248\n",
      "epoch 7255 loss -0.0600 LR -0.0849 LKL 0.0250\n",
      "epoch 7256 loss 0.0087 LR -0.0160 LKL 0.0247\n",
      "epoch 7257 loss -0.0447 LR -0.0695 LKL 0.0247\n",
      "epoch 7258 loss -0.0599 LR -0.0847 LKL 0.0249\n",
      "epoch 7259 loss -0.0654 LR -0.0902 LKL 0.0248\n",
      "epoch 7260 loss 0.0221 LR -0.0023 LKL 0.0244\n",
      "epoch 7261 loss -0.0112 LR -0.0358 LKL 0.0246\n",
      "epoch 7262 loss -0.0562 LR -0.0809 LKL 0.0247\n",
      "epoch 7263 loss -0.0255 LR -0.0500 LKL 0.0245\n",
      "epoch 7264 loss -0.0285 LR -0.0532 LKL 0.0247\n",
      "epoch 7265 loss 0.0100 LR -0.0146 LKL 0.0246\n",
      "epoch 7266 loss -0.0417 LR -0.0665 LKL 0.0248\n",
      "epoch 7267 loss 0.0031 LR -0.0216 LKL 0.0247\n",
      "epoch 7268 loss 0.0761 LR 0.0514 LKL 0.0247\n",
      "epoch 7269 loss -0.1165 LR -0.1415 LKL 0.0250\n",
      "epoch 7270 loss 0.0051 LR -0.0197 LKL 0.0247\n",
      "epoch 7271 loss -0.0966 LR -0.1215 LKL 0.0248\n",
      "epoch 7272 loss -0.0159 LR -0.0409 LKL 0.0250\n",
      "epoch 7273 loss -0.0336 LR -0.0584 LKL 0.0248\n",
      "epoch 7274 loss -0.0158 LR -0.0405 LKL 0.0247\n",
      "epoch 7275 loss -0.0209 LR -0.0461 LKL 0.0252\n",
      "epoch 7276 loss -0.0098 LR -0.0345 LKL 0.0247\n",
      "epoch 7277 loss 0.0034 LR -0.0218 LKL 0.0251\n",
      "epoch 7278 loss 0.0382 LR 0.0132 LKL 0.0249\n",
      "epoch 7279 loss -0.0590 LR -0.0840 LKL 0.0250\n",
      "epoch 7280 loss -0.0086 LR -0.0335 LKL 0.0249\n",
      "epoch 7281 loss 0.0036 LR -0.0214 LKL 0.0250\n",
      "epoch 7282 loss 0.0239 LR -0.0010 LKL 0.0249\n",
      "epoch 7283 loss -0.0343 LR -0.0590 LKL 0.0247\n",
      "epoch 7284 loss 0.0346 LR 0.0098 LKL 0.0248\n",
      "epoch 7285 loss 0.0088 LR -0.0161 LKL 0.0249\n",
      "epoch 7286 loss -0.0204 LR -0.0449 LKL 0.0245\n",
      "epoch 7287 loss 0.0214 LR -0.0035 LKL 0.0249\n",
      "epoch 7288 loss -0.0322 LR -0.0571 LKL 0.0249\n",
      "epoch 7289 loss -0.0236 LR -0.0487 LKL 0.0251\n",
      "epoch 7290 loss -0.0320 LR -0.0570 LKL 0.0250\n",
      "epoch 7291 loss -0.0159 LR -0.0407 LKL 0.0248\n",
      "epoch 7292 loss -0.0430 LR -0.0679 LKL 0.0250\n",
      "epoch 7293 loss 0.0526 LR 0.0276 LKL 0.0249\n",
      "epoch 7294 loss -0.0573 LR -0.0824 LKL 0.0251\n",
      "epoch 7295 loss -0.0051 LR -0.0302 LKL 0.0251\n",
      "epoch 7296 loss 0.0159 LR -0.0088 LKL 0.0247\n",
      "epoch 7297 loss 0.0095 LR -0.0153 LKL 0.0249\n",
      "epoch 7298 loss -0.0100 LR -0.0348 LKL 0.0249\n",
      "epoch 7299 loss 0.0331 LR 0.0084 LKL 0.0247\n",
      "epoch 7300 loss -0.0050 LR -0.0295 LKL 0.0244\n",
      "48\n",
      "epoch 7301 loss 0.0535 LR 0.0291 LKL 0.0244\n",
      "epoch 7302 loss 0.0165 LR -0.0081 LKL 0.0247\n",
      "epoch 7303 loss 0.0056 LR -0.0191 LKL 0.0247\n",
      "epoch 7304 loss -0.0560 LR -0.0805 LKL 0.0244\n",
      "epoch 7305 loss -0.0056 LR -0.0301 LKL 0.0246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7306 loss -0.0227 LR -0.0475 LKL 0.0248\n",
      "epoch 7307 loss 0.0128 LR -0.0118 LKL 0.0246\n",
      "epoch 7308 loss -0.0477 LR -0.0727 LKL 0.0250\n",
      "epoch 7309 loss -0.0559 LR -0.0805 LKL 0.0246\n",
      "epoch 7310 loss 0.0607 LR 0.0363 LKL 0.0244\n",
      "epoch 7311 loss 0.0265 LR 0.0021 LKL 0.0244\n",
      "epoch 7312 loss -0.0233 LR -0.0478 LKL 0.0245\n",
      "epoch 7313 loss -0.0196 LR -0.0442 LKL 0.0245\n",
      "epoch 7314 loss -0.0295 LR -0.0541 LKL 0.0247\n",
      "epoch 7315 loss -0.0624 LR -0.0871 LKL 0.0246\n",
      "epoch 7316 loss 0.0003 LR -0.0240 LKL 0.0244\n",
      "epoch 7317 loss -0.0736 LR -0.0981 LKL 0.0245\n",
      "epoch 7318 loss -0.0495 LR -0.0741 LKL 0.0247\n",
      "epoch 7319 loss -0.0688 LR -0.0934 LKL 0.0246\n",
      "epoch 7320 loss -0.0281 LR -0.0528 LKL 0.0247\n",
      "epoch 7321 loss -0.0415 LR -0.0664 LKL 0.0249\n",
      "epoch 7322 loss 0.0186 LR -0.0061 LKL 0.0247\n",
      "epoch 7323 loss -0.0164 LR -0.0411 LKL 0.0247\n",
      "epoch 7324 loss -0.0753 LR -0.0999 LKL 0.0246\n",
      "epoch 7325 loss -0.0686 LR -0.0934 LKL 0.0249\n",
      "epoch 7326 loss 0.0172 LR -0.0071 LKL 0.0244\n",
      "epoch 7327 loss -0.0567 LR -0.0813 LKL 0.0246\n",
      "epoch 7328 loss -0.0531 LR -0.0776 LKL 0.0245\n",
      "epoch 7329 loss -0.0353 LR -0.0599 LKL 0.0246\n",
      "epoch 7330 loss -0.0330 LR -0.0577 LKL 0.0248\n",
      "epoch 7331 loss -0.0698 LR -0.0944 LKL 0.0247\n",
      "epoch 7332 loss -0.0330 LR -0.0576 LKL 0.0246\n",
      "epoch 7333 loss -0.0181 LR -0.0429 LKL 0.0248\n",
      "epoch 7334 loss 0.0083 LR -0.0161 LKL 0.0244\n",
      "epoch 7335 loss -0.0340 LR -0.0586 LKL 0.0245\n",
      "epoch 7336 loss -0.0250 LR -0.0499 LKL 0.0249\n",
      "epoch 7337 loss 0.0300 LR 0.0053 LKL 0.0247\n",
      "epoch 7338 loss -0.0322 LR -0.0568 LKL 0.0246\n",
      "epoch 7339 loss -0.0536 LR -0.0785 LKL 0.0249\n",
      "epoch 7340 loss -0.0175 LR -0.0425 LKL 0.0250\n",
      "epoch 7341 loss -0.0607 LR -0.0856 LKL 0.0249\n",
      "epoch 7342 loss -0.0445 LR -0.0696 LKL 0.0251\n",
      "epoch 7343 loss -0.0315 LR -0.0565 LKL 0.0249\n",
      "epoch 7344 loss -0.0359 LR -0.0610 LKL 0.0251\n",
      "epoch 7345 loss -0.0733 LR -0.0985 LKL 0.0252\n",
      "epoch 7346 loss -0.0529 LR -0.0780 LKL 0.0252\n",
      "epoch 7347 loss 0.0577 LR 0.0327 LKL 0.0249\n",
      "epoch 7348 loss 0.0101 LR -0.0153 LKL 0.0254\n",
      "epoch 7349 loss -0.0359 LR -0.0608 LKL 0.0250\n",
      "epoch 7350 loss -0.0246 LR -0.0495 LKL 0.0248\n",
      "epoch 7351 loss 0.0209 LR -0.0039 LKL 0.0248\n",
      "epoch 7352 loss 0.0465 LR 0.0215 LKL 0.0250\n",
      "epoch 7353 loss -0.0525 LR -0.0777 LKL 0.0252\n",
      "epoch 7354 loss -0.0055 LR -0.0307 LKL 0.0252\n",
      "epoch 7355 loss -0.0584 LR -0.0835 LKL 0.0251\n",
      "epoch 7356 loss -0.0346 LR -0.0595 LKL 0.0248\n",
      "epoch 7357 loss -0.0032 LR -0.0283 LKL 0.0251\n",
      "epoch 7358 loss -0.0619 LR -0.0870 LKL 0.0251\n",
      "epoch 7359 loss -0.0332 LR -0.0582 LKL 0.0250\n",
      "epoch 7360 loss -0.0118 LR -0.0366 LKL 0.0247\n",
      "epoch 7361 loss -0.0038 LR -0.0288 LKL 0.0251\n",
      "epoch 7362 loss -0.0048 LR -0.0297 LKL 0.0249\n",
      "epoch 7363 loss -0.0159 LR -0.0405 LKL 0.0246\n",
      "epoch 7364 loss -0.0352 LR -0.0596 LKL 0.0245\n",
      "epoch 7365 loss -0.0014 LR -0.0263 LKL 0.0249\n",
      "epoch 7366 loss -0.0580 LR -0.0826 LKL 0.0246\n",
      "epoch 7367 loss -0.0313 LR -0.0561 LKL 0.0248\n",
      "epoch 7368 loss -0.0501 LR -0.0750 LKL 0.0248\n",
      "epoch 7369 loss 0.0313 LR 0.0068 LKL 0.0246\n",
      "epoch 7370 loss -0.0777 LR -0.1025 LKL 0.0249\n",
      "epoch 7371 loss -0.0005 LR -0.0254 LKL 0.0249\n",
      "epoch 7372 loss -0.0201 LR -0.0450 LKL 0.0249\n",
      "epoch 7373 loss 0.0226 LR -0.0023 LKL 0.0249\n",
      "epoch 7374 loss -0.0658 LR -0.0907 LKL 0.0250\n",
      "epoch 7375 loss 0.0204 LR -0.0044 LKL 0.0248\n",
      "epoch 7376 loss 0.0040 LR -0.0208 LKL 0.0248\n",
      "epoch 7377 loss -0.0761 LR -0.1007 LKL 0.0246\n",
      "epoch 7378 loss -0.0297 LR -0.0544 LKL 0.0247\n",
      "epoch 7379 loss -0.0141 LR -0.0388 LKL 0.0247\n",
      "epoch 7380 loss -0.0045 LR -0.0292 LKL 0.0247\n",
      "epoch 7381 loss 0.0346 LR 0.0100 LKL 0.0247\n",
      "epoch 7382 loss -0.0266 LR -0.0512 LKL 0.0246\n",
      "epoch 7383 loss -0.0808 LR -0.1055 LKL 0.0247\n",
      "epoch 7384 loss 0.0145 LR -0.0102 LKL 0.0247\n",
      "epoch 7385 loss -0.0033 LR -0.0284 LKL 0.0251\n",
      "epoch 7386 loss -0.0352 LR -0.0601 LKL 0.0248\n",
      "epoch 7387 loss -0.0226 LR -0.0474 LKL 0.0248\n",
      "epoch 7388 loss -0.0681 LR -0.0929 LKL 0.0248\n",
      "epoch 7389 loss 0.0592 LR 0.0345 LKL 0.0247\n",
      "epoch 7390 loss -0.0386 LR -0.0633 LKL 0.0247\n",
      "epoch 7391 loss -0.0170 LR -0.0416 LKL 0.0246\n",
      "epoch 7392 loss -0.0479 LR -0.0729 LKL 0.0251\n",
      "epoch 7393 loss -0.0620 LR -0.0868 LKL 0.0248\n",
      "epoch 7394 loss 0.0364 LR 0.0115 LKL 0.0250\n",
      "epoch 7395 loss 0.0184 LR -0.0064 LKL 0.0248\n",
      "epoch 7396 loss 0.0141 LR -0.0103 LKL 0.0245\n",
      "epoch 7397 loss -0.0021 LR -0.0269 LKL 0.0248\n",
      "epoch 7398 loss -0.0251 LR -0.0502 LKL 0.0250\n",
      "epoch 7399 loss 0.0165 LR -0.0082 LKL 0.0247\n",
      "epoch 7400 loss 0.0033 LR -0.0215 LKL 0.0248\n",
      "69\n",
      "epoch 7401 loss -0.0513 LR -0.0762 LKL 0.0249\n",
      "epoch 7402 loss -0.0390 LR -0.0637 LKL 0.0248\n",
      "epoch 7403 loss -0.0339 LR -0.0587 LKL 0.0248\n",
      "epoch 7404 loss 0.0175 LR -0.0071 LKL 0.0246\n",
      "epoch 7405 loss 0.0022 LR -0.0224 LKL 0.0247\n",
      "epoch 7406 loss 0.0088 LR -0.0157 LKL 0.0244\n",
      "epoch 7407 loss -0.0296 LR -0.0542 LKL 0.0246\n",
      "epoch 7408 loss -0.0111 LR -0.0358 LKL 0.0247\n",
      "epoch 7409 loss -0.0223 LR -0.0470 LKL 0.0246\n",
      "epoch 7410 loss 0.0100 LR -0.0146 LKL 0.0246\n",
      "epoch 7411 loss -0.0480 LR -0.0726 LKL 0.0245\n",
      "epoch 7412 loss -0.0230 LR -0.0476 LKL 0.0246\n",
      "epoch 7413 loss -0.0382 LR -0.0629 LKL 0.0247\n",
      "epoch 7414 loss -0.0021 LR -0.0268 LKL 0.0247\n",
      "epoch 7415 loss -0.0072 LR -0.0319 LKL 0.0247\n",
      "epoch 7416 loss -0.0472 LR -0.0718 LKL 0.0246\n",
      "epoch 7417 loss -0.0423 LR -0.0669 LKL 0.0247\n",
      "epoch 7418 loss -0.0403 LR -0.0651 LKL 0.0248\n",
      "epoch 7419 loss -0.0188 LR -0.0436 LKL 0.0248\n",
      "epoch 7420 loss -0.0310 LR -0.0558 LKL 0.0248\n",
      "epoch 7421 loss 0.0164 LR -0.0082 LKL 0.0246\n",
      "epoch 7422 loss -0.0033 LR -0.0278 LKL 0.0245\n",
      "epoch 7423 loss -0.0163 LR -0.0411 LKL 0.0247\n",
      "epoch 7424 loss -0.0406 LR -0.0648 LKL 0.0242\n",
      "epoch 7425 loss -0.0438 LR -0.0686 LKL 0.0248\n",
      "epoch 7426 loss -0.0633 LR -0.0881 LKL 0.0248\n",
      "epoch 7427 loss -0.0090 LR -0.0334 LKL 0.0244\n",
      "epoch 7428 loss -0.0192 LR -0.0438 LKL 0.0246\n",
      "epoch 7429 loss -0.0092 LR -0.0337 LKL 0.0245\n",
      "epoch 7430 loss 0.0184 LR -0.0062 LKL 0.0246\n",
      "epoch 7431 loss -0.0009 LR -0.0252 LKL 0.0243\n",
      "epoch 7432 loss -0.0739 LR -0.0984 LKL 0.0245\n",
      "epoch 7433 loss -0.0598 LR -0.0846 LKL 0.0248\n",
      "epoch 7434 loss -0.0205 LR -0.0452 LKL 0.0247\n",
      "epoch 7435 loss -0.0189 LR -0.0434 LKL 0.0246\n",
      "epoch 7436 loss 0.0527 LR 0.0279 LKL 0.0249\n",
      "epoch 7437 loss -0.0746 LR -0.0995 LKL 0.0249\n",
      "epoch 7438 loss 0.0262 LR 0.0015 LKL 0.0247\n",
      "epoch 7439 loss -0.0444 LR -0.0691 LKL 0.0247\n",
      "epoch 7440 loss 0.0307 LR 0.0062 LKL 0.0245\n",
      "epoch 7441 loss -0.0372 LR -0.0619 LKL 0.0247\n",
      "epoch 7442 loss -0.0478 LR -0.0726 LKL 0.0249\n",
      "epoch 7443 loss -0.0688 LR -0.0935 LKL 0.0247\n",
      "epoch 7444 loss 0.0110 LR -0.0141 LKL 0.0251\n",
      "epoch 7445 loss 0.0006 LR -0.0242 LKL 0.0248\n",
      "epoch 7446 loss -0.0037 LR -0.0283 LKL 0.0246\n",
      "epoch 7447 loss 0.0099 LR -0.0151 LKL 0.0250\n",
      "epoch 7448 loss -0.0166 LR -0.0419 LKL 0.0253\n",
      "epoch 7449 loss -0.0288 LR -0.0539 LKL 0.0251\n",
      "epoch 7450 loss -0.0218 LR -0.0471 LKL 0.0253\n",
      "epoch 7451 loss 0.0356 LR 0.0107 LKL 0.0249\n",
      "epoch 7452 loss -0.0319 LR -0.0572 LKL 0.0252\n",
      "epoch 7453 loss -0.0323 LR -0.0573 LKL 0.0250\n",
      "epoch 7454 loss -0.0123 LR -0.0375 LKL 0.0252\n",
      "epoch 7455 loss -0.0565 LR -0.0818 LKL 0.0253\n",
      "epoch 7456 loss -0.0606 LR -0.0856 LKL 0.0250\n",
      "epoch 7457 loss -0.0242 LR -0.0493 LKL 0.0252\n",
      "epoch 7458 loss -0.1077 LR -0.1333 LKL 0.0256\n",
      "epoch 7459 loss -0.0790 LR -0.1041 LKL 0.0251\n",
      "epoch 7460 loss 0.0266 LR 0.0014 LKL 0.0252\n",
      "epoch 7461 loss 0.0073 LR -0.0178 LKL 0.0251\n",
      "epoch 7462 loss -0.0880 LR -0.1132 LKL 0.0252\n",
      "epoch 7463 loss 0.0031 LR -0.0222 LKL 0.0253\n",
      "epoch 7464 loss 0.0400 LR 0.0147 LKL 0.0254\n",
      "epoch 7465 loss -0.0725 LR -0.0981 LKL 0.0256\n",
      "epoch 7466 loss -0.0414 LR -0.0666 LKL 0.0252\n",
      "epoch 7467 loss -0.0906 LR -0.1161 LKL 0.0255\n",
      "epoch 7468 loss -0.0541 LR -0.0796 LKL 0.0255\n",
      "epoch 7469 loss -0.0343 LR -0.0593 LKL 0.0250\n",
      "epoch 7470 loss -0.0654 LR -0.0906 LKL 0.0252\n",
      "epoch 7471 loss 0.0143 LR -0.0108 LKL 0.0252\n",
      "epoch 7472 loss 0.0032 LR -0.0222 LKL 0.0254\n",
      "epoch 7473 loss 0.0045 LR -0.0208 LKL 0.0253\n",
      "epoch 7474 loss 0.0152 LR -0.0099 LKL 0.0251\n",
      "epoch 7475 loss 0.0338 LR 0.0086 LKL 0.0251\n",
      "epoch 7476 loss -0.0242 LR -0.0495 LKL 0.0253\n",
      "epoch 7477 loss -0.0576 LR -0.0827 LKL 0.0251\n",
      "epoch 7478 loss -0.0512 LR -0.0763 LKL 0.0251\n",
      "epoch 7479 loss -0.0624 LR -0.0874 LKL 0.0250\n",
      "epoch 7480 loss -0.0201 LR -0.0453 LKL 0.0252\n",
      "epoch 7481 loss -0.0459 LR -0.0708 LKL 0.0249\n",
      "epoch 7482 loss -0.0129 LR -0.0378 LKL 0.0249\n",
      "epoch 7483 loss -0.0307 LR -0.0557 LKL 0.0250\n",
      "epoch 7484 loss -0.0355 LR -0.0606 LKL 0.0251\n",
      "epoch 7485 loss 0.0081 LR -0.0167 LKL 0.0248\n",
      "epoch 7486 loss -0.0865 LR -0.1118 LKL 0.0253\n",
      "epoch 7487 loss -0.0304 LR -0.0555 LKL 0.0251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7488 loss 0.0286 LR 0.0035 LKL 0.0251\n",
      "epoch 7489 loss 0.0218 LR -0.0029 LKL 0.0248\n",
      "epoch 7490 loss -0.0542 LR -0.0795 LKL 0.0253\n",
      "epoch 7491 loss -0.0520 LR -0.0770 LKL 0.0249\n",
      "epoch 7492 loss -0.0438 LR -0.0688 LKL 0.0250\n",
      "epoch 7493 loss -0.0365 LR -0.0616 LKL 0.0251\n",
      "epoch 7494 loss -0.0588 LR -0.0840 LKL 0.0253\n",
      "epoch 7495 loss -0.0628 LR -0.0880 LKL 0.0252\n",
      "epoch 7496 loss -0.0947 LR -0.1199 LKL 0.0252\n",
      "epoch 7497 loss 0.0052 LR -0.0198 LKL 0.0250\n",
      "epoch 7498 loss -0.0178 LR -0.0431 LKL 0.0254\n",
      "epoch 7499 loss -0.0520 LR -0.0771 LKL 0.0251\n",
      "epoch 7500 loss -0.0095 LR -0.0348 LKL 0.0253\n",
      "54\n",
      "epoch 7501 loss -0.0076 LR -0.0328 LKL 0.0252\n",
      "epoch 7502 loss -0.0407 LR -0.0659 LKL 0.0253\n",
      "epoch 7503 loss -0.0163 LR -0.0417 LKL 0.0254\n",
      "epoch 7504 loss -0.0175 LR -0.0424 LKL 0.0249\n",
      "epoch 7505 loss -0.0259 LR -0.0508 LKL 0.0248\n",
      "epoch 7506 loss -0.0355 LR -0.0607 LKL 0.0252\n",
      "epoch 7507 loss -0.0499 LR -0.0747 LKL 0.0248\n",
      "epoch 7508 loss -0.0458 LR -0.0710 LKL 0.0252\n",
      "epoch 7509 loss -0.0242 LR -0.0493 LKL 0.0251\n",
      "epoch 7510 loss -0.0566 LR -0.0819 LKL 0.0253\n",
      "epoch 7511 loss -0.0510 LR -0.0759 LKL 0.0249\n",
      "epoch 7512 loss -0.0377 LR -0.0629 LKL 0.0252\n",
      "epoch 7513 loss -0.0412 LR -0.0662 LKL 0.0250\n",
      "epoch 7514 loss -0.0260 LR -0.0509 LKL 0.0249\n",
      "epoch 7515 loss -0.0699 LR -0.0947 LKL 0.0248\n",
      "epoch 7516 loss 0.0230 LR -0.0017 LKL 0.0247\n",
      "epoch 7517 loss -0.0337 LR -0.0585 LKL 0.0248\n",
      "epoch 7518 loss -0.0354 LR -0.0601 LKL 0.0247\n",
      "epoch 7519 loss -0.0506 LR -0.0757 LKL 0.0251\n",
      "epoch 7520 loss -0.0680 LR -0.0931 LKL 0.0251\n",
      "epoch 7521 loss -0.0513 LR -0.0763 LKL 0.0250\n",
      "epoch 7522 loss -0.0351 LR -0.0604 LKL 0.0252\n",
      "epoch 7523 loss -0.0112 LR -0.0362 LKL 0.0250\n",
      "epoch 7524 loss 0.0033 LR -0.0215 LKL 0.0247\n",
      "epoch 7525 loss -0.0325 LR -0.0575 LKL 0.0250\n",
      "epoch 7526 loss -0.0551 LR -0.0800 LKL 0.0248\n",
      "epoch 7527 loss -0.0162 LR -0.0411 LKL 0.0249\n",
      "epoch 7528 loss 0.0065 LR -0.0185 LKL 0.0250\n",
      "epoch 7529 loss -0.0651 LR -0.0902 LKL 0.0251\n",
      "epoch 7530 loss -0.0087 LR -0.0337 LKL 0.0250\n",
      "epoch 7531 loss 0.0314 LR 0.0063 LKL 0.0251\n",
      "epoch 7532 loss 0.0013 LR -0.0236 LKL 0.0250\n",
      "epoch 7533 loss -0.0120 LR -0.0369 LKL 0.0249\n",
      "epoch 7534 loss -0.0237 LR -0.0488 LKL 0.0250\n",
      "epoch 7535 loss 0.0001 LR -0.0253 LKL 0.0254\n",
      "epoch 7536 loss -0.0310 LR -0.0562 LKL 0.0251\n",
      "epoch 7537 loss -0.0182 LR -0.0433 LKL 0.0251\n",
      "epoch 7538 loss 0.0101 LR -0.0147 LKL 0.0248\n",
      "epoch 7539 loss -0.0401 LR -0.0651 LKL 0.0250\n",
      "epoch 7540 loss -0.0225 LR -0.0476 LKL 0.0251\n",
      "epoch 7541 loss -0.0737 LR -0.0985 LKL 0.0249\n",
      "epoch 7542 loss -0.0229 LR -0.0479 LKL 0.0251\n",
      "epoch 7543 loss 0.0177 LR -0.0074 LKL 0.0251\n",
      "epoch 7544 loss -0.0567 LR -0.0819 LKL 0.0252\n",
      "epoch 7545 loss -0.0684 LR -0.0936 LKL 0.0252\n",
      "epoch 7546 loss -0.0696 LR -0.0948 LKL 0.0251\n",
      "epoch 7547 loss -0.0470 LR -0.0722 LKL 0.0252\n",
      "epoch 7548 loss -0.0006 LR -0.0258 LKL 0.0252\n",
      "epoch 7549 loss -0.0867 LR -0.1120 LKL 0.0252\n",
      "epoch 7550 loss -0.0032 LR -0.0282 LKL 0.0249\n",
      "epoch 7551 loss -0.0386 LR -0.0638 LKL 0.0253\n",
      "epoch 7552 loss -0.0204 LR -0.0456 LKL 0.0252\n",
      "epoch 7553 loss -0.0056 LR -0.0307 LKL 0.0251\n",
      "epoch 7554 loss -0.0122 LR -0.0373 LKL 0.0251\n",
      "epoch 7555 loss 0.0138 LR -0.0115 LKL 0.0253\n",
      "epoch 7556 loss -0.0733 LR -0.0986 LKL 0.0253\n",
      "epoch 7557 loss -0.0347 LR -0.0598 LKL 0.0251\n",
      "epoch 7558 loss 0.0077 LR -0.0170 LKL 0.0247\n",
      "epoch 7559 loss -0.0514 LR -0.0766 LKL 0.0251\n",
      "epoch 7560 loss 0.0255 LR 0.0004 LKL 0.0251\n",
      "epoch 7561 loss -0.0433 LR -0.0684 LKL 0.0252\n",
      "epoch 7562 loss -0.0978 LR -0.1229 LKL 0.0251\n",
      "epoch 7563 loss 0.0124 LR -0.0125 LKL 0.0249\n",
      "epoch 7564 loss 0.0227 LR -0.0025 LKL 0.0252\n",
      "epoch 7565 loss -0.0254 LR -0.0505 LKL 0.0251\n",
      "epoch 7566 loss -0.0868 LR -0.1118 LKL 0.0250\n",
      "epoch 7567 loss -0.0675 LR -0.0927 LKL 0.0252\n",
      "epoch 7568 loss -0.0634 LR -0.0883 LKL 0.0249\n",
      "epoch 7569 loss -0.0428 LR -0.0676 LKL 0.0248\n",
      "epoch 7570 loss 0.0017 LR -0.0232 LKL 0.0249\n",
      "epoch 7571 loss 0.0001 LR -0.0248 LKL 0.0249\n",
      "epoch 7572 loss -0.0718 LR -0.0969 LKL 0.0251\n",
      "epoch 7573 loss -0.0420 LR -0.0668 LKL 0.0248\n",
      "epoch 7574 loss -0.0767 LR -0.1017 LKL 0.0250\n",
      "epoch 7575 loss 0.0200 LR -0.0048 LKL 0.0248\n",
      "epoch 7576 loss -0.0141 LR -0.0391 LKL 0.0250\n",
      "epoch 7577 loss 0.0039 LR -0.0211 LKL 0.0250\n",
      "epoch 7578 loss 0.0420 LR 0.0172 LKL 0.0248\n",
      "epoch 7579 loss -0.0627 LR -0.0876 LKL 0.0248\n",
      "epoch 7580 loss -0.0687 LR -0.0938 LKL 0.0251\n",
      "epoch 7581 loss 0.0037 LR -0.0211 LKL 0.0248\n",
      "epoch 7582 loss -0.0237 LR -0.0487 LKL 0.0250\n",
      "epoch 7583 loss -0.0509 LR -0.0759 LKL 0.0250\n",
      "epoch 7584 loss -0.0315 LR -0.0562 LKL 0.0247\n",
      "epoch 7585 loss -0.0411 LR -0.0664 LKL 0.0253\n",
      "epoch 7586 loss -0.0418 LR -0.0667 LKL 0.0249\n",
      "epoch 7587 loss -0.0135 LR -0.0384 LKL 0.0249\n",
      "epoch 7588 loss -0.0207 LR -0.0453 LKL 0.0247\n",
      "epoch 7589 loss -0.0002 LR -0.0252 LKL 0.0250\n",
      "epoch 7590 loss -0.0891 LR -0.1138 LKL 0.0247\n",
      "epoch 7591 loss -0.0060 LR -0.0310 LKL 0.0250\n",
      "epoch 7592 loss -0.0113 LR -0.0359 LKL 0.0246\n",
      "epoch 7593 loss -0.0601 LR -0.0850 LKL 0.0249\n",
      "epoch 7594 loss 0.0087 LR -0.0161 LKL 0.0248\n",
      "epoch 7595 loss -0.0117 LR -0.0366 LKL 0.0249\n",
      "epoch 7596 loss 0.0112 LR -0.0137 LKL 0.0250\n",
      "epoch 7597 loss -0.0508 LR -0.0760 LKL 0.0252\n",
      "epoch 7598 loss -0.0661 LR -0.0909 LKL 0.0248\n",
      "epoch 7599 loss -0.0069 LR -0.0318 LKL 0.0248\n",
      "epoch 7600 loss -0.0533 LR -0.0782 LKL 0.0250\n",
      "60\n",
      "epoch 7601 loss -0.0430 LR -0.0679 LKL 0.0250\n",
      "epoch 7602 loss -0.0190 LR -0.0438 LKL 0.0248\n",
      "epoch 7603 loss -0.0283 LR -0.0532 LKL 0.0248\n",
      "epoch 7604 loss -0.0255 LR -0.0504 LKL 0.0249\n",
      "epoch 7605 loss -0.0636 LR -0.0886 LKL 0.0249\n",
      "epoch 7606 loss -0.0789 LR -0.1037 LKL 0.0249\n",
      "epoch 7607 loss -0.0237 LR -0.0485 LKL 0.0248\n",
      "epoch 7608 loss -0.0359 LR -0.0609 LKL 0.0250\n",
      "epoch 7609 loss -0.0074 LR -0.0320 LKL 0.0246\n",
      "epoch 7610 loss -0.0244 LR -0.0492 LKL 0.0248\n",
      "epoch 7611 loss -0.0340 LR -0.0588 LKL 0.0248\n",
      "epoch 7612 loss -0.0424 LR -0.0669 LKL 0.0245\n",
      "epoch 7613 loss -0.0264 LR -0.0513 LKL 0.0248\n",
      "epoch 7614 loss -0.0417 LR -0.0661 LKL 0.0244\n",
      "epoch 7615 loss -0.0138 LR -0.0384 LKL 0.0247\n",
      "epoch 7616 loss 0.0221 LR -0.0028 LKL 0.0248\n",
      "epoch 7617 loss -0.0455 LR -0.0702 LKL 0.0247\n",
      "epoch 7618 loss 0.0044 LR -0.0202 LKL 0.0246\n",
      "epoch 7619 loss -0.0603 LR -0.0847 LKL 0.0244\n",
      "epoch 7620 loss -0.0222 LR -0.0467 LKL 0.0245\n",
      "epoch 7621 loss -0.0357 LR -0.0604 LKL 0.0247\n",
      "epoch 7622 loss 0.0265 LR 0.0019 LKL 0.0246\n",
      "epoch 7623 loss -0.0582 LR -0.0831 LKL 0.0249\n",
      "epoch 7624 loss -0.0542 LR -0.0792 LKL 0.0250\n",
      "epoch 7625 loss 0.0062 LR -0.0187 LKL 0.0249\n",
      "epoch 7626 loss -0.0526 LR -0.0775 LKL 0.0249\n",
      "epoch 7627 loss -0.0479 LR -0.0726 LKL 0.0247\n",
      "epoch 7628 loss -0.0370 LR -0.0619 LKL 0.0249\n",
      "epoch 7629 loss 0.0275 LR 0.0027 LKL 0.0249\n",
      "epoch 7630 loss 0.0662 LR 0.0415 LKL 0.0247\n",
      "epoch 7631 loss 0.0017 LR -0.0232 LKL 0.0249\n",
      "epoch 7632 loss -0.0529 LR -0.0780 LKL 0.0251\n",
      "epoch 7633 loss -0.0255 LR -0.0506 LKL 0.0251\n",
      "epoch 7634 loss -0.0081 LR -0.0331 LKL 0.0250\n",
      "epoch 7635 loss -0.0365 LR -0.0614 LKL 0.0248\n",
      "epoch 7636 loss -0.0062 LR -0.0310 LKL 0.0247\n",
      "epoch 7637 loss -0.0712 LR -0.0961 LKL 0.0249\n",
      "epoch 7638 loss 0.0135 LR -0.0113 LKL 0.0248\n",
      "epoch 7639 loss -0.0442 LR -0.0688 LKL 0.0246\n",
      "epoch 7640 loss -0.0370 LR -0.0619 LKL 0.0249\n",
      "epoch 7641 loss -0.0002 LR -0.0252 LKL 0.0250\n",
      "epoch 7642 loss -0.0349 LR -0.0596 LKL 0.0247\n",
      "epoch 7643 loss -0.0235 LR -0.0482 LKL 0.0247\n",
      "epoch 7644 loss -0.0265 LR -0.0515 LKL 0.0250\n",
      "epoch 7645 loss -0.0287 LR -0.0537 LKL 0.0250\n",
      "epoch 7646 loss 0.0100 LR -0.0149 LKL 0.0248\n",
      "epoch 7647 loss -0.0229 LR -0.0482 LKL 0.0253\n",
      "epoch 7648 loss -0.0849 LR -0.1100 LKL 0.0250\n",
      "epoch 7649 loss -0.0386 LR -0.0636 LKL 0.0250\n",
      "epoch 7650 loss -0.0318 LR -0.0568 LKL 0.0250\n",
      "epoch 7651 loss -0.0243 LR -0.0492 LKL 0.0249\n",
      "epoch 7652 loss -0.0594 LR -0.0847 LKL 0.0253\n",
      "epoch 7653 loss -0.0064 LR -0.0315 LKL 0.0251\n",
      "epoch 7654 loss -0.0056 LR -0.0306 LKL 0.0250\n",
      "epoch 7655 loss 0.0343 LR 0.0096 LKL 0.0247\n",
      "epoch 7656 loss 0.0071 LR -0.0178 LKL 0.0248\n",
      "epoch 7657 loss 0.0071 LR -0.0180 LKL 0.0251\n",
      "epoch 7658 loss -0.0402 LR -0.0649 LKL 0.0248\n",
      "epoch 7659 loss -0.0249 LR -0.0496 LKL 0.0247\n",
      "epoch 7660 loss 0.0064 LR -0.0183 LKL 0.0247\n",
      "epoch 7661 loss -0.0092 LR -0.0341 LKL 0.0248\n",
      "epoch 7662 loss -0.0290 LR -0.0540 LKL 0.0250\n",
      "epoch 7663 loss -0.0311 LR -0.0562 LKL 0.0251\n",
      "epoch 7664 loss -0.0052 LR -0.0302 LKL 0.0250\n",
      "epoch 7665 loss -0.0700 LR -0.0951 LKL 0.0251\n",
      "epoch 7666 loss -0.0340 LR -0.0589 LKL 0.0249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7667 loss -0.0567 LR -0.0815 LKL 0.0248\n",
      "epoch 7668 loss -0.0577 LR -0.0827 LKL 0.0250\n",
      "epoch 7669 loss -0.0397 LR -0.0646 LKL 0.0248\n",
      "epoch 7670 loss -0.0154 LR -0.0403 LKL 0.0249\n",
      "epoch 7671 loss -0.0442 LR -0.0689 LKL 0.0248\n",
      "epoch 7672 loss -0.0107 LR -0.0355 LKL 0.0249\n",
      "epoch 7673 loss -0.0362 LR -0.0612 LKL 0.0250\n",
      "epoch 7674 loss -0.0569 LR -0.0821 LKL 0.0251\n",
      "epoch 7675 loss -0.0902 LR -0.1156 LKL 0.0254\n",
      "epoch 7676 loss -0.0944 LR -0.1192 LKL 0.0249\n",
      "epoch 7677 loss 0.0098 LR -0.0151 LKL 0.0249\n",
      "epoch 7678 loss 0.0329 LR 0.0078 LKL 0.0251\n",
      "epoch 7679 loss -0.0390 LR -0.0640 LKL 0.0250\n",
      "epoch 7680 loss -0.0485 LR -0.0736 LKL 0.0250\n",
      "epoch 7681 loss -0.0929 LR -0.1182 LKL 0.0253\n",
      "epoch 7682 loss -0.0443 LR -0.0692 LKL 0.0249\n",
      "epoch 7683 loss -0.0752 LR -0.1002 LKL 0.0250\n",
      "epoch 7684 loss -0.1310 LR -0.1562 LKL 0.0252\n",
      "epoch 7685 loss -0.0611 LR -0.0867 LKL 0.0255\n",
      "epoch 7686 loss -0.0676 LR -0.0927 LKL 0.0251\n",
      "epoch 7687 loss -0.0373 LR -0.0624 LKL 0.0251\n",
      "epoch 7688 loss -0.0210 LR -0.0461 LKL 0.0251\n",
      "epoch 7689 loss 0.0125 LR -0.0126 LKL 0.0252\n",
      "epoch 7690 loss -0.0008 LR -0.0260 LKL 0.0252\n",
      "epoch 7691 loss 0.0097 LR -0.0153 LKL 0.0250\n",
      "epoch 7692 loss -0.0198 LR -0.0450 LKL 0.0252\n",
      "epoch 7693 loss -0.0639 LR -0.0888 LKL 0.0250\n",
      "epoch 7694 loss -0.0796 LR -0.1049 LKL 0.0254\n",
      "epoch 7695 loss 0.0188 LR -0.0063 LKL 0.0251\n",
      "epoch 7696 loss -0.1229 LR -0.1486 LKL 0.0256\n",
      "epoch 7697 loss -0.0207 LR -0.0460 LKL 0.0253\n",
      "epoch 7698 loss -0.0416 LR -0.0668 LKL 0.0252\n",
      "epoch 7699 loss 0.0181 LR -0.0072 LKL 0.0253\n",
      "epoch 7700 loss -0.0075 LR -0.0327 LKL 0.0252\n",
      "epoch 7701 loss -0.0207 LR -0.0458 LKL 0.0251\n",
      "epoch 7702 loss -0.0769 LR -0.1022 LKL 0.0253\n",
      "epoch 7703 loss 0.0232 LR -0.0017 LKL 0.0249\n",
      "epoch 7704 loss -0.0442 LR -0.0696 LKL 0.0254\n",
      "epoch 7705 loss -0.0432 LR -0.0681 LKL 0.0249\n",
      "epoch 7706 loss -0.0472 LR -0.0724 LKL 0.0252\n",
      "epoch 7707 loss 0.0078 LR -0.0174 LKL 0.0251\n",
      "epoch 7708 loss -0.0437 LR -0.0689 LKL 0.0252\n",
      "epoch 7709 loss 0.0364 LR 0.0116 LKL 0.0248\n",
      "epoch 7710 loss 0.0035 LR -0.0217 LKL 0.0252\n",
      "epoch 7711 loss -0.0837 LR -0.1091 LKL 0.0253\n",
      "epoch 7712 loss 0.0106 LR -0.0144 LKL 0.0250\n",
      "epoch 7713 loss -0.0420 LR -0.0669 LKL 0.0250\n",
      "epoch 7714 loss -0.0159 LR -0.0410 LKL 0.0251\n",
      "epoch 7715 loss -0.0738 LR -0.0988 LKL 0.0250\n",
      "epoch 7716 loss -0.0617 LR -0.0864 LKL 0.0247\n",
      "epoch 7717 loss -0.0530 LR -0.0780 LKL 0.0250\n",
      "epoch 7718 loss -0.0519 LR -0.0768 LKL 0.0250\n",
      "epoch 7719 loss -0.0221 LR -0.0467 LKL 0.0247\n",
      "epoch 7720 loss -0.0336 LR -0.0588 LKL 0.0251\n",
      "epoch 7721 loss -0.0457 LR -0.0707 LKL 0.0249\n",
      "epoch 7722 loss -0.0691 LR -0.0940 LKL 0.0249\n",
      "epoch 7723 loss -0.0533 LR -0.0783 LKL 0.0250\n",
      "epoch 7724 loss 0.0020 LR -0.0227 LKL 0.0246\n",
      "epoch 7725 loss -0.0281 LR -0.0531 LKL 0.0250\n",
      "epoch 7726 loss -0.0454 LR -0.0705 LKL 0.0251\n",
      "epoch 7727 loss -0.0582 LR -0.0831 LKL 0.0249\n",
      "epoch 7728 loss -0.0615 LR -0.0866 LKL 0.0251\n",
      "epoch 7729 loss -0.0616 LR -0.0868 LKL 0.0252\n",
      "epoch 7730 loss -0.0458 LR -0.0709 LKL 0.0252\n",
      "epoch 7731 loss 0.0214 LR -0.0036 LKL 0.0250\n",
      "epoch 7732 loss -0.0378 LR -0.0631 LKL 0.0253\n",
      "epoch 7733 loss -0.0248 LR -0.0496 LKL 0.0248\n",
      "epoch 7734 loss -0.0463 LR -0.0715 LKL 0.0252\n",
      "epoch 7735 loss -0.0567 LR -0.0820 LKL 0.0253\n",
      "epoch 7736 loss -0.0551 LR -0.0802 LKL 0.0251\n",
      "epoch 7737 loss 0.0138 LR -0.0115 LKL 0.0253\n",
      "epoch 7738 loss -0.0098 LR -0.0352 LKL 0.0255\n",
      "epoch 7739 loss -0.0136 LR -0.0385 LKL 0.0249\n",
      "epoch 7740 loss -0.0016 LR -0.0269 LKL 0.0253\n",
      "epoch 7741 loss -0.0175 LR -0.0427 LKL 0.0252\n",
      "epoch 7742 loss 0.0016 LR -0.0234 LKL 0.0250\n",
      "epoch 7743 loss -0.0341 LR -0.0591 LKL 0.0250\n",
      "epoch 7744 loss -0.0426 LR -0.0676 LKL 0.0250\n",
      "epoch 7745 loss -0.0501 LR -0.0754 LKL 0.0253\n",
      "epoch 7746 loss -0.0602 LR -0.0854 LKL 0.0253\n",
      "epoch 7747 loss -0.0101 LR -0.0353 LKL 0.0252\n",
      "epoch 7748 loss -0.0541 LR -0.0795 LKL 0.0253\n",
      "epoch 7749 loss -0.0984 LR -0.1235 LKL 0.0251\n",
      "epoch 7750 loss -0.0065 LR -0.0317 LKL 0.0252\n",
      "epoch 7751 loss -0.0672 LR -0.0926 LKL 0.0253\n",
      "epoch 7752 loss -0.0217 LR -0.0468 LKL 0.0251\n",
      "epoch 7753 loss -0.0360 LR -0.0614 LKL 0.0254\n",
      "epoch 7754 loss -0.0111 LR -0.0361 LKL 0.0250\n",
      "epoch 7755 loss -0.0376 LR -0.0627 LKL 0.0250\n",
      "epoch 7756 loss -0.0342 LR -0.0591 LKL 0.0249\n",
      "epoch 7757 loss -0.0306 LR -0.0555 LKL 0.0249\n",
      "epoch 7758 loss -0.0104 LR -0.0356 LKL 0.0251\n",
      "epoch 7759 loss -0.0411 LR -0.0664 LKL 0.0252\n",
      "epoch 7760 loss -0.0336 LR -0.0589 LKL 0.0254\n",
      "epoch 7761 loss -0.0809 LR -0.1060 LKL 0.0251\n",
      "epoch 7762 loss -0.0133 LR -0.0385 LKL 0.0252\n",
      "epoch 7763 loss -0.0222 LR -0.0471 LKL 0.0249\n",
      "epoch 7764 loss -0.0093 LR -0.0346 LKL 0.0253\n",
      "epoch 7765 loss -0.0218 LR -0.0470 LKL 0.0251\n",
      "epoch 7766 loss -0.0175 LR -0.0429 LKL 0.0254\n",
      "epoch 7767 loss -0.0236 LR -0.0486 LKL 0.0250\n",
      "epoch 7768 loss -0.0354 LR -0.0607 LKL 0.0253\n",
      "epoch 7769 loss -0.0561 LR -0.0815 LKL 0.0253\n",
      "epoch 7770 loss -0.0550 LR -0.0801 LKL 0.0251\n",
      "epoch 7771 loss 0.0184 LR -0.0066 LKL 0.0251\n",
      "epoch 7772 loss -0.0369 LR -0.0618 LKL 0.0249\n",
      "epoch 7773 loss -0.0481 LR -0.0732 LKL 0.0251\n",
      "epoch 7774 loss -0.0399 LR -0.0649 LKL 0.0249\n",
      "epoch 7775 loss -0.0101 LR -0.0349 LKL 0.0248\n",
      "epoch 7776 loss -0.0088 LR -0.0335 LKL 0.0247\n",
      "epoch 7777 loss -0.0055 LR -0.0305 LKL 0.0250\n",
      "epoch 7778 loss -0.0875 LR -0.1129 LKL 0.0254\n",
      "epoch 7779 loss -0.0439 LR -0.0691 LKL 0.0252\n",
      "epoch 7780 loss 0.0070 LR -0.0180 LKL 0.0250\n",
      "epoch 7781 loss -0.0201 LR -0.0449 LKL 0.0249\n",
      "epoch 7782 loss -0.0227 LR -0.0479 LKL 0.0252\n",
      "epoch 7783 loss -0.0397 LR -0.0648 LKL 0.0251\n",
      "epoch 7784 loss -0.0525 LR -0.0777 LKL 0.0253\n",
      "epoch 7785 loss -0.0575 LR -0.0828 LKL 0.0253\n",
      "epoch 7786 loss 0.0132 LR -0.0117 LKL 0.0249\n",
      "epoch 7787 loss -0.0612 LR -0.0862 LKL 0.0250\n",
      "epoch 7788 loss -0.0327 LR -0.0579 LKL 0.0252\n",
      "epoch 7789 loss -0.0503 LR -0.0754 LKL 0.0252\n",
      "epoch 7790 loss -0.0092 LR -0.0342 LKL 0.0250\n",
      "epoch 7791 loss 0.0196 LR -0.0057 LKL 0.0253\n",
      "epoch 7792 loss 0.0141 LR -0.0111 LKL 0.0252\n",
      "epoch 7793 loss 0.0126 LR -0.0127 LKL 0.0253\n",
      "epoch 7794 loss 0.0104 LR -0.0147 LKL 0.0251\n",
      "epoch 7795 loss -0.0205 LR -0.0454 LKL 0.0249\n",
      "epoch 7796 loss -0.0061 LR -0.0311 LKL 0.0250\n",
      "epoch 7797 loss -0.0086 LR -0.0334 LKL 0.0249\n",
      "epoch 7798 loss -0.0211 LR -0.0460 LKL 0.0249\n",
      "epoch 7799 loss -0.0311 LR -0.0562 LKL 0.0251\n",
      "epoch 7800 loss -0.1021 LR -0.1270 LKL 0.0249\n",
      "50\n",
      "epoch 7801 loss -0.0726 LR -0.0975 LKL 0.0250\n",
      "epoch 7802 loss -0.0410 LR -0.0657 LKL 0.0247\n",
      "epoch 7803 loss -0.0652 LR -0.0903 LKL 0.0252\n",
      "epoch 7804 loss -0.1201 LR -0.1452 LKL 0.0251\n",
      "epoch 7805 loss -0.0430 LR -0.0680 LKL 0.0250\n",
      "epoch 7806 loss -0.0077 LR -0.0329 LKL 0.0252\n",
      "epoch 7807 loss 0.0298 LR 0.0048 LKL 0.0250\n",
      "epoch 7808 loss -0.0312 LR -0.0561 LKL 0.0249\n",
      "epoch 7809 loss -0.0117 LR -0.0367 LKL 0.0250\n",
      "epoch 7810 loss 0.0145 LR -0.0103 LKL 0.0247\n",
      "epoch 7811 loss -0.0606 LR -0.0853 LKL 0.0247\n",
      "epoch 7812 loss 0.0335 LR 0.0087 LKL 0.0248\n",
      "epoch 7813 loss -0.0628 LR -0.0879 LKL 0.0251\n",
      "epoch 7814 loss -0.0588 LR -0.0835 LKL 0.0247\n",
      "epoch 7815 loss -0.0106 LR -0.0354 LKL 0.0249\n",
      "epoch 7816 loss -0.0149 LR -0.0396 LKL 0.0248\n",
      "epoch 7817 loss -0.0538 LR -0.0787 LKL 0.0249\n",
      "epoch 7818 loss -0.0228 LR -0.0475 LKL 0.0246\n",
      "epoch 7819 loss 0.0180 LR -0.0068 LKL 0.0248\n",
      "epoch 7820 loss -0.0245 LR -0.0492 LKL 0.0247\n",
      "epoch 7821 loss -0.0806 LR -0.1058 LKL 0.0251\n",
      "epoch 7822 loss -0.0592 LR -0.0844 LKL 0.0252\n",
      "epoch 7823 loss -0.0177 LR -0.0426 LKL 0.0249\n",
      "epoch 7824 loss -0.0218 LR -0.0468 LKL 0.0250\n",
      "epoch 7825 loss -0.0521 LR -0.0770 LKL 0.0249\n",
      "epoch 7826 loss -0.0507 LR -0.0757 LKL 0.0250\n",
      "epoch 7827 loss 0.0095 LR -0.0152 LKL 0.0248\n",
      "epoch 7828 loss -0.0736 LR -0.0981 LKL 0.0246\n",
      "epoch 7829 loss -0.0638 LR -0.0886 LKL 0.0248\n",
      "epoch 7830 loss -0.0325 LR -0.0571 LKL 0.0247\n",
      "epoch 7831 loss 0.0098 LR -0.0148 LKL 0.0246\n",
      "epoch 7832 loss 0.0028 LR -0.0220 LKL 0.0248\n",
      "epoch 7833 loss -0.0019 LR -0.0265 LKL 0.0246\n",
      "epoch 7834 loss -0.0169 LR -0.0416 LKL 0.0247\n",
      "epoch 7835 loss -0.0520 LR -0.0765 LKL 0.0244\n",
      "epoch 7836 loss -0.0535 LR -0.0781 LKL 0.0245\n",
      "epoch 7837 loss -0.0344 LR -0.0590 LKL 0.0245\n",
      "epoch 7838 loss -0.0684 LR -0.0933 LKL 0.0249\n",
      "epoch 7839 loss -0.0468 LR -0.0714 LKL 0.0246\n",
      "epoch 7840 loss -0.0244 LR -0.0492 LKL 0.0247\n",
      "epoch 7841 loss -0.0093 LR -0.0341 LKL 0.0247\n",
      "epoch 7842 loss -0.0287 LR -0.0535 LKL 0.0248\n",
      "epoch 7843 loss -0.0420 LR -0.0668 LKL 0.0248\n",
      "epoch 7844 loss 0.0167 LR -0.0077 LKL 0.0244\n",
      "epoch 7845 loss 0.0118 LR -0.0131 LKL 0.0249\n",
      "epoch 7846 loss -0.0375 LR -0.0624 LKL 0.0249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7847 loss -0.0744 LR -0.0995 LKL 0.0251\n",
      "epoch 7848 loss -0.0526 LR -0.0775 LKL 0.0249\n",
      "epoch 7849 loss -0.0413 LR -0.0663 LKL 0.0250\n",
      "epoch 7850 loss -0.0081 LR -0.0331 LKL 0.0250\n",
      "epoch 7851 loss -0.1024 LR -0.1273 LKL 0.0248\n",
      "epoch 7852 loss -0.0446 LR -0.0700 LKL 0.0254\n",
      "epoch 7853 loss -0.0122 LR -0.0369 LKL 0.0248\n",
      "epoch 7854 loss -0.0311 LR -0.0560 LKL 0.0249\n",
      "epoch 7855 loss -0.0686 LR -0.0937 LKL 0.0251\n",
      "epoch 7856 loss -0.0328 LR -0.0580 LKL 0.0253\n",
      "epoch 7857 loss -0.0369 LR -0.0619 LKL 0.0251\n",
      "epoch 7858 loss -0.0323 LR -0.0572 LKL 0.0250\n",
      "epoch 7859 loss -0.0253 LR -0.0504 LKL 0.0251\n",
      "epoch 7860 loss 0.0104 LR -0.0144 LKL 0.0248\n",
      "epoch 7861 loss 0.0010 LR -0.0243 LKL 0.0253\n",
      "epoch 7862 loss 0.0075 LR -0.0172 LKL 0.0247\n",
      "epoch 7863 loss -0.0630 LR -0.0881 LKL 0.0251\n",
      "epoch 7864 loss -0.0502 LR -0.0755 LKL 0.0253\n",
      "epoch 7865 loss -0.0459 LR -0.0710 LKL 0.0251\n",
      "epoch 7866 loss -0.0333 LR -0.0585 LKL 0.0252\n",
      "epoch 7867 loss 0.0138 LR -0.0111 LKL 0.0249\n",
      "epoch 7868 loss -0.0700 LR -0.0950 LKL 0.0250\n",
      "epoch 7869 loss -0.0746 LR -0.0996 LKL 0.0250\n",
      "epoch 7870 loss 0.0324 LR 0.0075 LKL 0.0249\n",
      "epoch 7871 loss -0.0862 LR -0.1113 LKL 0.0251\n",
      "epoch 7872 loss -0.0810 LR -0.1062 LKL 0.0252\n",
      "epoch 7873 loss 0.0246 LR -0.0003 LKL 0.0250\n",
      "epoch 7874 loss -0.0635 LR -0.0887 LKL 0.0253\n",
      "epoch 7875 loss -0.0443 LR -0.0696 LKL 0.0253\n",
      "epoch 7876 loss 0.0098 LR -0.0152 LKL 0.0250\n",
      "epoch 7877 loss -0.0644 LR -0.0900 LKL 0.0255\n",
      "epoch 7878 loss -0.0338 LR -0.0589 LKL 0.0251\n",
      "epoch 7879 loss -0.0513 LR -0.0763 LKL 0.0250\n",
      "epoch 7880 loss -0.0470 LR -0.0720 LKL 0.0251\n",
      "epoch 7881 loss -0.0577 LR -0.0829 LKL 0.0252\n",
      "epoch 7882 loss -0.0706 LR -0.0958 LKL 0.0253\n",
      "epoch 7883 loss -0.0413 LR -0.0664 LKL 0.0250\n",
      "epoch 7884 loss -0.0425 LR -0.0675 LKL 0.0250\n",
      "epoch 7885 loss -0.0047 LR -0.0298 LKL 0.0252\n",
      "epoch 7886 loss -0.0857 LR -0.1111 LKL 0.0254\n",
      "epoch 7887 loss -0.0186 LR -0.0437 LKL 0.0251\n",
      "epoch 7888 loss 0.0111 LR -0.0141 LKL 0.0252\n",
      "epoch 7889 loss -0.0376 LR -0.0627 LKL 0.0251\n",
      "epoch 7890 loss -0.0551 LR -0.0804 LKL 0.0253\n",
      "epoch 7891 loss -0.0158 LR -0.0411 LKL 0.0253\n",
      "epoch 7892 loss 0.0028 LR -0.0222 LKL 0.0250\n",
      "epoch 7893 loss -0.0259 LR -0.0511 LKL 0.0252\n",
      "epoch 7894 loss -0.0616 LR -0.0869 LKL 0.0253\n",
      "epoch 7895 loss 0.0200 LR -0.0051 LKL 0.0251\n",
      "epoch 7896 loss -0.0353 LR -0.0606 LKL 0.0252\n",
      "epoch 7897 loss -0.0268 LR -0.0521 LKL 0.0253\n",
      "epoch 7898 loss -0.0325 LR -0.0577 LKL 0.0252\n",
      "epoch 7899 loss -0.0405 LR -0.0657 LKL 0.0252\n",
      "epoch 7900 loss -0.0538 LR -0.0793 LKL 0.0256\n",
      "53\n",
      "epoch 7901 loss -0.0350 LR -0.0604 LKL 0.0254\n",
      "epoch 7902 loss -0.0314 LR -0.0568 LKL 0.0254\n",
      "epoch 7903 loss -0.0494 LR -0.0746 LKL 0.0252\n",
      "epoch 7904 loss -0.0182 LR -0.0433 LKL 0.0251\n",
      "epoch 7905 loss -0.0672 LR -0.0922 LKL 0.0251\n",
      "epoch 7906 loss -0.0928 LR -0.1180 LKL 0.0253\n",
      "epoch 7907 loss -0.0237 LR -0.0491 LKL 0.0254\n",
      "epoch 7908 loss -0.0391 LR -0.0644 LKL 0.0252\n",
      "epoch 7909 loss -0.0426 LR -0.0680 LKL 0.0254\n",
      "epoch 7910 loss -0.0022 LR -0.0273 LKL 0.0251\n",
      "epoch 7911 loss 0.0023 LR -0.0227 LKL 0.0250\n",
      "epoch 7912 loss -0.0337 LR -0.0587 LKL 0.0250\n",
      "epoch 7913 loss -0.0556 LR -0.0806 LKL 0.0250\n",
      "epoch 7914 loss -0.0030 LR -0.0283 LKL 0.0252\n",
      "epoch 7915 loss -0.0208 LR -0.0460 LKL 0.0251\n",
      "epoch 7916 loss -0.0275 LR -0.0527 LKL 0.0251\n",
      "epoch 7917 loss -0.0048 LR -0.0298 LKL 0.0250\n",
      "epoch 7918 loss -0.0193 LR -0.0442 LKL 0.0250\n",
      "epoch 7919 loss -0.0088 LR -0.0338 LKL 0.0250\n",
      "epoch 7920 loss 0.0465 LR 0.0216 LKL 0.0250\n",
      "epoch 7921 loss 0.0112 LR -0.0139 LKL 0.0251\n",
      "epoch 7922 loss -0.0257 LR -0.0510 LKL 0.0253\n",
      "epoch 7923 loss 0.0040 LR -0.0210 LKL 0.0250\n",
      "epoch 7924 loss -0.0534 LR -0.0789 LKL 0.0254\n",
      "epoch 7925 loss 0.0260 LR 0.0015 LKL 0.0245\n",
      "epoch 7926 loss -0.0525 LR -0.0776 LKL 0.0251\n",
      "epoch 7927 loss -0.0376 LR -0.0626 LKL 0.0250\n",
      "epoch 7928 loss -0.0523 LR -0.0771 LKL 0.0248\n",
      "epoch 7929 loss -0.0227 LR -0.0476 LKL 0.0249\n",
      "epoch 7930 loss -0.0034 LR -0.0283 LKL 0.0249\n",
      "epoch 7931 loss -0.0406 LR -0.0655 LKL 0.0249\n",
      "epoch 7932 loss -0.0392 LR -0.0640 LKL 0.0248\n",
      "epoch 7933 loss 0.0128 LR -0.0121 LKL 0.0249\n",
      "epoch 7934 loss -0.0562 LR -0.0812 LKL 0.0251\n",
      "epoch 7935 loss 0.0034 LR -0.0216 LKL 0.0250\n",
      "epoch 7936 loss -0.0263 LR -0.0513 LKL 0.0249\n",
      "epoch 7937 loss -0.0681 LR -0.0930 LKL 0.0249\n",
      "epoch 7938 loss -0.0379 LR -0.0629 LKL 0.0250\n",
      "epoch 7939 loss -0.0261 LR -0.0511 LKL 0.0250\n",
      "epoch 7940 loss -0.0285 LR -0.0533 LKL 0.0249\n",
      "epoch 7941 loss -0.0820 LR -0.1071 LKL 0.0252\n",
      "epoch 7942 loss -0.0862 LR -0.1112 LKL 0.0250\n",
      "epoch 7943 loss -0.0503 LR -0.0753 LKL 0.0250\n",
      "epoch 7944 loss -0.0387 LR -0.0640 LKL 0.0253\n",
      "epoch 7945 loss -0.0375 LR -0.0623 LKL 0.0249\n",
      "epoch 7946 loss -0.0703 LR -0.0954 LKL 0.0251\n",
      "epoch 7947 loss -0.0171 LR -0.0422 LKL 0.0251\n",
      "epoch 7948 loss -0.0138 LR -0.0389 LKL 0.0250\n",
      "epoch 7949 loss -0.0105 LR -0.0355 LKL 0.0250\n",
      "epoch 7950 loss -0.0490 LR -0.0740 LKL 0.0250\n",
      "epoch 7951 loss -0.0563 LR -0.0814 LKL 0.0251\n",
      "epoch 7952 loss -0.0243 LR -0.0495 LKL 0.0252\n",
      "epoch 7953 loss -0.0465 LR -0.0715 LKL 0.0250\n",
      "epoch 7954 loss -0.0902 LR -0.1155 LKL 0.0253\n",
      "epoch 7955 loss -0.0857 LR -0.1113 LKL 0.0256\n",
      "epoch 7956 loss -0.0845 LR -0.1097 LKL 0.0252\n",
      "epoch 7957 loss -0.0542 LR -0.0793 LKL 0.0251\n",
      "epoch 7958 loss -0.0621 LR -0.0875 LKL 0.0253\n",
      "epoch 7959 loss -0.0712 LR -0.0964 LKL 0.0252\n",
      "epoch 7960 loss 0.0115 LR -0.0138 LKL 0.0253\n",
      "epoch 7961 loss -0.0331 LR -0.0584 LKL 0.0253\n",
      "epoch 7962 loss -0.0225 LR -0.0475 LKL 0.0250\n",
      "epoch 7963 loss -0.0084 LR -0.0338 LKL 0.0254\n",
      "epoch 7964 loss -0.0207 LR -0.0461 LKL 0.0254\n",
      "epoch 7965 loss -0.0502 LR -0.0754 LKL 0.0252\n",
      "epoch 7966 loss -0.0412 LR -0.0668 LKL 0.0255\n",
      "epoch 7967 loss -0.0053 LR -0.0308 LKL 0.0255\n",
      "epoch 7968 loss -0.0010 LR -0.0265 LKL 0.0255\n",
      "epoch 7969 loss -0.0057 LR -0.0310 LKL 0.0253\n",
      "epoch 7970 loss -0.0680 LR -0.0934 LKL 0.0254\n",
      "epoch 7971 loss -0.0880 LR -0.1134 LKL 0.0253\n",
      "epoch 7972 loss -0.0907 LR -0.1161 LKL 0.0254\n",
      "epoch 7973 loss -0.0426 LR -0.0683 LKL 0.0257\n",
      "epoch 7974 loss -0.0287 LR -0.0540 LKL 0.0254\n",
      "epoch 7975 loss 0.0357 LR 0.0104 LKL 0.0253\n",
      "epoch 7976 loss -0.0269 LR -0.0524 LKL 0.0254\n",
      "epoch 7977 loss 0.0132 LR -0.0120 LKL 0.0252\n",
      "epoch 7978 loss -0.0807 LR -0.1063 LKL 0.0256\n",
      "epoch 7979 loss -0.0378 LR -0.0631 LKL 0.0253\n",
      "epoch 7980 loss -0.0416 LR -0.0670 LKL 0.0254\n",
      "epoch 7981 loss -0.0263 LR -0.0518 LKL 0.0255\n",
      "epoch 7982 loss -0.0280 LR -0.0534 LKL 0.0254\n",
      "epoch 7983 loss -0.0154 LR -0.0406 LKL 0.0252\n",
      "epoch 7984 loss -0.1071 LR -0.1328 LKL 0.0257\n",
      "epoch 7985 loss -0.0617 LR -0.0871 LKL 0.0254\n",
      "epoch 7986 loss -0.0529 LR -0.0779 LKL 0.0250\n",
      "epoch 7987 loss -0.0640 LR -0.0892 LKL 0.0251\n",
      "epoch 7988 loss -0.0575 LR -0.0827 LKL 0.0253\n",
      "epoch 7989 loss -0.0075 LR -0.0328 LKL 0.0253\n",
      "epoch 7990 loss -0.0704 LR -0.0957 LKL 0.0253\n",
      "epoch 7991 loss -0.0872 LR -0.1128 LKL 0.0255\n",
      "epoch 7992 loss 0.0154 LR -0.0100 LKL 0.0254\n",
      "epoch 7993 loss -0.0449 LR -0.0702 LKL 0.0253\n",
      "epoch 7994 loss -0.0008 LR -0.0257 LKL 0.0250\n",
      "epoch 7995 loss -0.0055 LR -0.0308 LKL 0.0253\n",
      "epoch 7996 loss -0.0587 LR -0.0840 LKL 0.0253\n",
      "epoch 7997 loss -0.0260 LR -0.0514 LKL 0.0254\n",
      "epoch 7998 loss -0.0497 LR -0.0752 LKL 0.0255\n",
      "epoch 7999 loss -0.0337 LR -0.0588 LKL 0.0251\n",
      "epoch 8000 loss -0.0466 LR -0.0721 LKL 0.0255\n",
      "47\n",
      "epoch 8001 loss -0.0633 LR -0.0888 LKL 0.0254\n",
      "epoch 8002 loss -0.0541 LR -0.0794 LKL 0.0253\n",
      "epoch 8003 loss 0.0483 LR 0.0230 LKL 0.0252\n",
      "epoch 8004 loss -0.0573 LR -0.0826 LKL 0.0252\n",
      "epoch 8005 loss -0.0271 LR -0.0522 LKL 0.0251\n",
      "epoch 8006 loss -0.0473 LR -0.0725 LKL 0.0252\n",
      "epoch 8007 loss -0.0510 LR -0.0762 LKL 0.0253\n",
      "epoch 8008 loss -0.0455 LR -0.0711 LKL 0.0256\n",
      "epoch 8009 loss -0.0407 LR -0.0659 LKL 0.0252\n",
      "epoch 8010 loss -0.0409 LR -0.0662 LKL 0.0253\n",
      "epoch 8011 loss -0.0118 LR -0.0369 LKL 0.0251\n",
      "epoch 8012 loss -0.0410 LR -0.0663 LKL 0.0254\n",
      "epoch 8013 loss -0.0609 LR -0.0864 LKL 0.0255\n",
      "epoch 8014 loss -0.0301 LR -0.0552 LKL 0.0252\n",
      "epoch 8015 loss 0.0247 LR -0.0003 LKL 0.0250\n",
      "epoch 8016 loss 0.0249 LR -0.0005 LKL 0.0254\n",
      "epoch 8017 loss -0.0308 LR -0.0559 LKL 0.0251\n",
      "epoch 8018 loss -0.0285 LR -0.0537 LKL 0.0251\n",
      "epoch 8019 loss -0.0019 LR -0.0271 LKL 0.0252\n",
      "epoch 8020 loss -0.0433 LR -0.0686 LKL 0.0253\n",
      "epoch 8021 loss -0.0403 LR -0.0653 LKL 0.0250\n",
      "epoch 8022 loss -0.0612 LR -0.0864 LKL 0.0252\n",
      "epoch 8023 loss -0.0555 LR -0.0804 LKL 0.0249\n",
      "epoch 8024 loss -0.0435 LR -0.0687 LKL 0.0252\n",
      "epoch 8025 loss 0.0109 LR -0.0140 LKL 0.0250\n",
      "epoch 8026 loss -0.0126 LR -0.0373 LKL 0.0247\n",
      "epoch 8027 loss -0.0218 LR -0.0466 LKL 0.0248\n",
      "epoch 8028 loss -0.0051 LR -0.0301 LKL 0.0250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8029 loss -0.0537 LR -0.0789 LKL 0.0252\n",
      "epoch 8030 loss 0.0357 LR 0.0105 LKL 0.0251\n",
      "epoch 8031 loss -0.0426 LR -0.0677 LKL 0.0251\n",
      "epoch 8032 loss -0.0295 LR -0.0544 LKL 0.0249\n",
      "epoch 8033 loss -0.0422 LR -0.0670 LKL 0.0249\n",
      "epoch 8034 loss -0.0397 LR -0.0647 LKL 0.0250\n",
      "epoch 8035 loss -0.0619 LR -0.0867 LKL 0.0248\n",
      "epoch 8036 loss -0.0704 LR -0.0953 LKL 0.0249\n",
      "epoch 8037 loss 0.0217 LR -0.0033 LKL 0.0250\n",
      "epoch 8038 loss -0.0613 LR -0.0861 LKL 0.0248\n",
      "epoch 8039 loss -0.0828 LR -0.1079 LKL 0.0251\n",
      "epoch 8040 loss -0.0779 LR -0.1029 LKL 0.0249\n",
      "epoch 8041 loss -0.0372 LR -0.0621 LKL 0.0249\n",
      "epoch 8042 loss -0.0575 LR -0.0825 LKL 0.0250\n",
      "epoch 8043 loss -0.0234 LR -0.0480 LKL 0.0246\n",
      "epoch 8044 loss -0.0241 LR -0.0488 LKL 0.0247\n",
      "epoch 8045 loss -0.0526 LR -0.0775 LKL 0.0249\n",
      "epoch 8046 loss -0.0606 LR -0.0857 LKL 0.0251\n",
      "epoch 8047 loss -0.0417 LR -0.0667 LKL 0.0250\n",
      "epoch 8048 loss -0.0607 LR -0.0857 LKL 0.0250\n",
      "epoch 8049 loss -0.0753 LR -0.1006 LKL 0.0253\n",
      "epoch 8050 loss -0.0070 LR -0.0319 LKL 0.0249\n",
      "epoch 8051 loss -0.0572 LR -0.0821 LKL 0.0248\n",
      "epoch 8052 loss -0.0470 LR -0.0719 LKL 0.0249\n",
      "epoch 8053 loss -0.0355 LR -0.0605 LKL 0.0250\n",
      "epoch 8054 loss -0.0186 LR -0.0437 LKL 0.0250\n",
      "epoch 8055 loss -0.0530 LR -0.0780 LKL 0.0250\n",
      "epoch 8056 loss -0.0750 LR -0.0999 LKL 0.0249\n",
      "epoch 8057 loss -0.0045 LR -0.0295 LKL 0.0250\n",
      "epoch 8058 loss -0.0340 LR -0.0593 LKL 0.0253\n",
      "epoch 8059 loss 0.0322 LR 0.0072 LKL 0.0251\n",
      "epoch 8060 loss -0.0599 LR -0.0848 LKL 0.0250\n",
      "epoch 8061 loss 0.0107 LR -0.0144 LKL 0.0251\n",
      "epoch 8062 loss -0.0512 LR -0.0764 LKL 0.0251\n",
      "epoch 8063 loss -0.0459 LR -0.0713 LKL 0.0254\n",
      "epoch 8064 loss -0.0278 LR -0.0529 LKL 0.0251\n",
      "epoch 8065 loss -0.0667 LR -0.0919 LKL 0.0251\n",
      "epoch 8066 loss -0.0844 LR -0.1100 LKL 0.0256\n",
      "epoch 8067 loss -0.0387 LR -0.0637 LKL 0.0250\n",
      "epoch 8068 loss -0.0331 LR -0.0582 LKL 0.0252\n",
      "epoch 8069 loss -0.0669 LR -0.0924 LKL 0.0255\n",
      "epoch 8070 loss 0.0284 LR 0.0031 LKL 0.0253\n",
      "epoch 8071 loss -0.0952 LR -0.1204 LKL 0.0252\n",
      "epoch 8072 loss -0.0019 LR -0.0270 LKL 0.0251\n",
      "epoch 8073 loss -0.0168 LR -0.0419 LKL 0.0251\n",
      "epoch 8074 loss -0.0315 LR -0.0567 LKL 0.0252\n",
      "epoch 8075 loss -0.0106 LR -0.0357 LKL 0.0251\n",
      "epoch 8076 loss 0.0040 LR -0.0213 LKL 0.0254\n",
      "epoch 8077 loss -0.0018 LR -0.0269 LKL 0.0251\n",
      "epoch 8078 loss -0.0438 LR -0.0690 LKL 0.0252\n",
      "epoch 8079 loss -0.0688 LR -0.0945 LKL 0.0256\n",
      "epoch 8080 loss -0.0595 LR -0.0849 LKL 0.0254\n",
      "epoch 8081 loss -0.0185 LR -0.0436 LKL 0.0251\n",
      "epoch 8082 loss -0.0390 LR -0.0644 LKL 0.0253\n",
      "epoch 8083 loss -0.0090 LR -0.0343 LKL 0.0253\n",
      "epoch 8084 loss -0.0440 LR -0.0696 LKL 0.0257\n",
      "epoch 8085 loss 0.0132 LR -0.0122 LKL 0.0253\n",
      "epoch 8086 loss -0.0535 LR -0.0789 LKL 0.0254\n",
      "epoch 8087 loss -0.0178 LR -0.0432 LKL 0.0254\n",
      "epoch 8088 loss -0.0479 LR -0.0732 LKL 0.0253\n",
      "epoch 8089 loss -0.0637 LR -0.0891 LKL 0.0254\n",
      "epoch 8090 loss -0.0001 LR -0.0254 LKL 0.0253\n",
      "epoch 8091 loss -0.0141 LR -0.0393 LKL 0.0252\n",
      "epoch 8092 loss -0.0314 LR -0.0568 LKL 0.0254\n",
      "epoch 8093 loss 0.0293 LR 0.0041 LKL 0.0252\n",
      "epoch 8094 loss -0.0409 LR -0.0662 LKL 0.0253\n",
      "epoch 8095 loss -0.0430 LR -0.0684 LKL 0.0254\n",
      "epoch 8096 loss -0.0225 LR -0.0477 LKL 0.0252\n",
      "epoch 8097 loss -0.0245 LR -0.0497 LKL 0.0252\n",
      "epoch 8098 loss -0.0486 LR -0.0738 LKL 0.0253\n",
      "epoch 8099 loss -0.0525 LR -0.0776 LKL 0.0252\n",
      "epoch 8100 loss -0.0148 LR -0.0400 LKL 0.0252\n",
      "61\n",
      "epoch 8101 loss -0.0083 LR -0.0335 LKL 0.0252\n",
      "epoch 8102 loss -0.0222 LR -0.0475 LKL 0.0253\n",
      "epoch 8103 loss -0.0073 LR -0.0326 LKL 0.0253\n",
      "epoch 8104 loss 0.0037 LR -0.0214 LKL 0.0251\n",
      "epoch 8105 loss -0.0087 LR -0.0339 LKL 0.0252\n",
      "epoch 8106 loss -0.0065 LR -0.0315 LKL 0.0251\n",
      "epoch 8107 loss -0.0440 LR -0.0691 LKL 0.0252\n",
      "epoch 8108 loss -0.0648 LR -0.0901 LKL 0.0253\n",
      "epoch 8109 loss -0.0670 LR -0.0923 LKL 0.0253\n",
      "epoch 8110 loss -0.0850 LR -0.1105 LKL 0.0255\n",
      "epoch 8111 loss -0.0305 LR -0.0557 LKL 0.0252\n",
      "epoch 8112 loss -0.1043 LR -0.1296 LKL 0.0253\n",
      "epoch 8113 loss -0.0667 LR -0.0920 LKL 0.0252\n",
      "epoch 8114 loss -0.0028 LR -0.0281 LKL 0.0253\n",
      "epoch 8115 loss -0.0836 LR -0.1090 LKL 0.0254\n",
      "epoch 8116 loss -0.0790 LR -0.1044 LKL 0.0254\n",
      "epoch 8117 loss 0.0065 LR -0.0188 LKL 0.0253\n",
      "epoch 8118 loss -0.0746 LR -0.1001 LKL 0.0255\n",
      "epoch 8119 loss -0.0007 LR -0.0258 LKL 0.0251\n",
      "epoch 8120 loss -0.0580 LR -0.0833 LKL 0.0253\n",
      "epoch 8121 loss -0.0692 LR -0.0945 LKL 0.0253\n",
      "epoch 8122 loss -0.0323 LR -0.0577 LKL 0.0254\n",
      "epoch 8123 loss -0.0165 LR -0.0419 LKL 0.0254\n",
      "epoch 8124 loss -0.0562 LR -0.0816 LKL 0.0253\n",
      "epoch 8125 loss -0.0747 LR -0.1002 LKL 0.0255\n",
      "epoch 8126 loss -0.0115 LR -0.0370 LKL 0.0255\n",
      "epoch 8127 loss -0.0100 LR -0.0352 LKL 0.0252\n",
      "epoch 8128 loss -0.0508 LR -0.0764 LKL 0.0256\n",
      "epoch 8129 loss -0.0708 LR -0.0963 LKL 0.0255\n",
      "epoch 8130 loss -0.0707 LR -0.0961 LKL 0.0255\n",
      "epoch 8131 loss -0.0275 LR -0.0529 LKL 0.0254\n",
      "epoch 8132 loss -0.0621 LR -0.0875 LKL 0.0254\n",
      "epoch 8133 loss -0.0226 LR -0.0479 LKL 0.0254\n",
      "epoch 8134 loss -0.1061 LR -0.1317 LKL 0.0256\n",
      "epoch 8135 loss -0.0226 LR -0.0479 LKL 0.0253\n",
      "epoch 8136 loss -0.0468 LR -0.0722 LKL 0.0254\n",
      "epoch 8137 loss -0.0865 LR -0.1120 LKL 0.0255\n",
      "epoch 8138 loss -0.0821 LR -0.1076 LKL 0.0254\n",
      "epoch 8139 loss -0.0711 LR -0.0960 LKL 0.0249\n",
      "epoch 8140 loss -0.0348 LR -0.0600 LKL 0.0252\n",
      "epoch 8141 loss -0.0824 LR -0.1075 LKL 0.0251\n",
      "epoch 8142 loss -0.0677 LR -0.0928 LKL 0.0252\n",
      "epoch 8143 loss -0.0302 LR -0.0555 LKL 0.0253\n",
      "epoch 8144 loss -0.0551 LR -0.0803 LKL 0.0252\n",
      "epoch 8145 loss -0.0843 LR -0.1095 LKL 0.0251\n",
      "epoch 8146 loss -0.0381 LR -0.0635 LKL 0.0254\n",
      "epoch 8147 loss 0.0239 LR -0.0011 LKL 0.0251\n",
      "epoch 8148 loss -0.0779 LR -0.1028 LKL 0.0249\n",
      "epoch 8149 loss -0.1202 LR -0.1453 LKL 0.0251\n",
      "epoch 8150 loss -0.0482 LR -0.0733 LKL 0.0251\n",
      "epoch 8151 loss -0.0186 LR -0.0434 LKL 0.0248\n",
      "epoch 8152 loss -0.0796 LR -0.1049 LKL 0.0253\n",
      "epoch 8153 loss -0.0153 LR -0.0405 LKL 0.0252\n",
      "epoch 8154 loss -0.0613 LR -0.0865 LKL 0.0252\n",
      "epoch 8155 loss -0.0503 LR -0.0753 LKL 0.0250\n",
      "epoch 8156 loss -0.1135 LR -0.1387 LKL 0.0252\n",
      "epoch 8157 loss -0.0863 LR -0.1113 LKL 0.0250\n",
      "epoch 8158 loss -0.0099 LR -0.0350 LKL 0.0251\n",
      "epoch 8159 loss -0.0212 LR -0.0463 LKL 0.0251\n",
      "epoch 8160 loss -0.0244 LR -0.0496 LKL 0.0252\n",
      "epoch 8161 loss -0.0216 LR -0.0463 LKL 0.0247\n",
      "epoch 8162 loss -0.0821 LR -0.1076 LKL 0.0255\n",
      "epoch 8163 loss -0.0639 LR -0.0892 LKL 0.0253\n",
      "epoch 8164 loss -0.0448 LR -0.0699 LKL 0.0251\n",
      "epoch 8165 loss -0.1066 LR -0.1319 LKL 0.0253\n",
      "epoch 8166 loss -0.0413 LR -0.0668 LKL 0.0255\n",
      "epoch 8167 loss -0.0257 LR -0.0511 LKL 0.0253\n",
      "epoch 8168 loss -0.0534 LR -0.0787 LKL 0.0252\n",
      "epoch 8169 loss -0.1002 LR -0.1255 LKL 0.0253\n",
      "epoch 8170 loss -0.0111 LR -0.0359 LKL 0.0247\n",
      "epoch 8171 loss -0.0674 LR -0.0926 LKL 0.0252\n",
      "epoch 8172 loss 0.0158 LR -0.0096 LKL 0.0254\n",
      "epoch 8173 loss -0.0244 LR -0.0498 LKL 0.0254\n",
      "epoch 8174 loss -0.0358 LR -0.0610 LKL 0.0252\n",
      "epoch 8175 loss -0.0003 LR -0.0256 LKL 0.0252\n",
      "epoch 8176 loss -0.0354 LR -0.0606 LKL 0.0253\n",
      "epoch 8177 loss -0.0465 LR -0.0717 LKL 0.0252\n",
      "epoch 8178 loss 0.0319 LR 0.0068 LKL 0.0252\n",
      "epoch 8179 loss 0.0115 LR -0.0136 LKL 0.0251\n",
      "epoch 8180 loss -0.0374 LR -0.0628 LKL 0.0254\n",
      "epoch 8181 loss -0.0280 LR -0.0533 LKL 0.0253\n",
      "epoch 8182 loss -0.0558 LR -0.0810 LKL 0.0252\n",
      "epoch 8183 loss -0.0304 LR -0.0559 LKL 0.0255\n",
      "epoch 8184 loss -0.0307 LR -0.0561 LKL 0.0254\n",
      "epoch 8185 loss -0.0821 LR -0.1076 LKL 0.0255\n",
      "epoch 8186 loss -0.0197 LR -0.0449 LKL 0.0252\n",
      "epoch 8187 loss -0.0298 LR -0.0549 LKL 0.0251\n",
      "epoch 8188 loss -0.0290 LR -0.0546 LKL 0.0256\n",
      "epoch 8189 loss -0.0674 LR -0.0929 LKL 0.0255\n",
      "epoch 8190 loss -0.0421 LR -0.0675 LKL 0.0253\n",
      "epoch 8191 loss -0.0469 LR -0.0722 LKL 0.0253\n",
      "epoch 8192 loss -0.0167 LR -0.0419 LKL 0.0252\n",
      "epoch 8193 loss -0.0606 LR -0.0858 LKL 0.0251\n",
      "epoch 8194 loss -0.0264 LR -0.0517 LKL 0.0253\n",
      "epoch 8195 loss -0.0763 LR -0.1016 LKL 0.0253\n",
      "epoch 8196 loss -0.0590 LR -0.0843 LKL 0.0254\n",
      "epoch 8197 loss -0.0177 LR -0.0429 LKL 0.0252\n",
      "epoch 8198 loss 0.0048 LR -0.0203 LKL 0.0252\n",
      "epoch 8199 loss -0.1191 LR -0.1445 LKL 0.0254\n",
      "epoch 8200 loss -0.0050 LR -0.0302 LKL 0.0252\n",
      "46\n",
      "epoch 8201 loss -0.0327 LR -0.0582 LKL 0.0255\n",
      "epoch 8202 loss -0.0450 LR -0.0701 LKL 0.0251\n",
      "epoch 8203 loss -0.0280 LR -0.0531 LKL 0.0251\n",
      "epoch 8204 loss -0.0624 LR -0.0878 LKL 0.0254\n",
      "epoch 8205 loss -0.0541 LR -0.0791 LKL 0.0250\n",
      "epoch 8206 loss -0.0442 LR -0.0695 LKL 0.0253\n",
      "epoch 8207 loss 0.0359 LR 0.0108 LKL 0.0252\n",
      "epoch 8208 loss -0.0423 LR -0.0677 LKL 0.0254\n",
      "epoch 8209 loss 0.0219 LR -0.0030 LKL 0.0249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8210 loss -0.0651 LR -0.0907 LKL 0.0256\n",
      "epoch 8211 loss -0.0776 LR -0.1033 LKL 0.0257\n",
      "epoch 8212 loss 0.0245 LR -0.0007 LKL 0.0252\n",
      "epoch 8213 loss 0.0043 LR -0.0210 LKL 0.0253\n",
      "epoch 8214 loss -0.0893 LR -0.1144 LKL 0.0252\n",
      "epoch 8215 loss -0.0061 LR -0.0316 LKL 0.0255\n",
      "epoch 8216 loss -0.0834 LR -0.1089 LKL 0.0255\n",
      "epoch 8217 loss -0.0276 LR -0.0528 LKL 0.0253\n",
      "epoch 8218 loss -0.0416 LR -0.0669 LKL 0.0253\n",
      "epoch 8219 loss -0.0355 LR -0.0610 LKL 0.0255\n",
      "epoch 8220 loss -0.0842 LR -0.1098 LKL 0.0256\n",
      "epoch 8221 loss -0.1024 LR -0.1279 LKL 0.0255\n",
      "epoch 8222 loss -0.0445 LR -0.0699 LKL 0.0254\n",
      "epoch 8223 loss -0.0700 LR -0.0954 LKL 0.0253\n",
      "epoch 8224 loss -0.0706 LR -0.0959 LKL 0.0254\n",
      "epoch 8225 loss -0.0582 LR -0.0834 LKL 0.0252\n",
      "epoch 8226 loss -0.0800 LR -0.1054 LKL 0.0254\n",
      "epoch 8227 loss -0.0624 LR -0.0879 LKL 0.0255\n",
      "epoch 8228 loss -0.0760 LR -0.1014 LKL 0.0254\n",
      "epoch 8229 loss -0.0666 LR -0.0919 LKL 0.0253\n",
      "epoch 8230 loss -0.0265 LR -0.0520 LKL 0.0255\n",
      "epoch 8231 loss -0.0330 LR -0.0582 LKL 0.0253\n",
      "epoch 8232 loss -0.0312 LR -0.0564 LKL 0.0251\n",
      "epoch 8233 loss -0.0717 LR -0.0972 LKL 0.0255\n",
      "epoch 8234 loss -0.0633 LR -0.0889 LKL 0.0256\n",
      "epoch 8235 loss -0.0236 LR -0.0487 LKL 0.0251\n",
      "epoch 8236 loss -0.1167 LR -0.1421 LKL 0.0253\n",
      "epoch 8237 loss -0.0589 LR -0.0843 LKL 0.0254\n",
      "epoch 8238 loss -0.0570 LR -0.0822 LKL 0.0253\n",
      "epoch 8239 loss -0.0125 LR -0.0378 LKL 0.0253\n",
      "epoch 8240 loss -0.0479 LR -0.0733 LKL 0.0254\n",
      "epoch 8241 loss -0.0108 LR -0.0362 LKL 0.0253\n",
      "epoch 8242 loss -0.0528 LR -0.0782 LKL 0.0254\n",
      "epoch 8243 loss 0.0242 LR -0.0011 LKL 0.0253\n",
      "epoch 8244 loss -0.0504 LR -0.0756 LKL 0.0252\n",
      "epoch 8245 loss -0.0338 LR -0.0591 LKL 0.0253\n",
      "epoch 8246 loss -0.0587 LR -0.0842 LKL 0.0255\n",
      "epoch 8247 loss -0.0586 LR -0.0840 LKL 0.0255\n",
      "epoch 8248 loss -0.0464 LR -0.0716 LKL 0.0253\n",
      "epoch 8249 loss -0.0150 LR -0.0406 LKL 0.0256\n",
      "epoch 8250 loss -0.0382 LR -0.0634 LKL 0.0252\n",
      "epoch 8251 loss -0.0259 LR -0.0512 LKL 0.0254\n",
      "epoch 8252 loss -0.0197 LR -0.0451 LKL 0.0253\n",
      "epoch 8253 loss -0.0499 LR -0.0755 LKL 0.0256\n",
      "epoch 8254 loss -0.0705 LR -0.0960 LKL 0.0255\n",
      "epoch 8255 loss -0.0717 LR -0.0972 LKL 0.0255\n",
      "epoch 8256 loss -0.0311 LR -0.0565 LKL 0.0254\n",
      "epoch 8257 loss -0.0009 LR -0.0264 LKL 0.0255\n",
      "epoch 8258 loss -0.0692 LR -0.0944 LKL 0.0252\n",
      "epoch 8259 loss -0.0130 LR -0.0387 LKL 0.0257\n",
      "epoch 8260 loss -0.0575 LR -0.0828 LKL 0.0253\n",
      "epoch 8261 loss -0.0967 LR -0.1223 LKL 0.0256\n",
      "epoch 8262 loss -0.0610 LR -0.0864 LKL 0.0254\n",
      "epoch 8263 loss -0.0508 LR -0.0761 LKL 0.0253\n",
      "epoch 8264 loss -0.0377 LR -0.0632 LKL 0.0255\n",
      "epoch 8265 loss -0.0165 LR -0.0418 LKL 0.0253\n",
      "epoch 8266 loss -0.0340 LR -0.0594 LKL 0.0254\n",
      "epoch 8267 loss -0.0618 LR -0.0873 LKL 0.0255\n",
      "epoch 8268 loss -0.0227 LR -0.0481 LKL 0.0255\n",
      "epoch 8269 loss -0.0341 LR -0.0596 LKL 0.0255\n",
      "epoch 8270 loss -0.0378 LR -0.0633 LKL 0.0255\n",
      "epoch 8271 loss 0.0004 LR -0.0246 LKL 0.0250\n",
      "epoch 8272 loss 0.0115 LR -0.0139 LKL 0.0253\n",
      "epoch 8273 loss -0.0420 LR -0.0671 LKL 0.0251\n",
      "epoch 8274 loss -0.0237 LR -0.0490 LKL 0.0253\n",
      "epoch 8275 loss -0.0404 LR -0.0655 LKL 0.0252\n",
      "epoch 8276 loss -0.0249 LR -0.0502 LKL 0.0253\n",
      "epoch 8277 loss 0.0348 LR 0.0094 LKL 0.0254\n",
      "epoch 8278 loss -0.0195 LR -0.0450 LKL 0.0255\n",
      "epoch 8279 loss -0.0680 LR -0.0931 LKL 0.0251\n",
      "epoch 8280 loss 0.0266 LR 0.0013 LKL 0.0253\n",
      "epoch 8281 loss -0.0279 LR -0.0533 LKL 0.0254\n",
      "epoch 8282 loss -0.0645 LR -0.0898 LKL 0.0253\n",
      "epoch 8283 loss -0.0872 LR -0.1128 LKL 0.0256\n",
      "epoch 8284 loss 0.0111 LR -0.0143 LKL 0.0254\n",
      "epoch 8285 loss -0.0414 LR -0.0668 LKL 0.0254\n",
      "epoch 8286 loss -0.0543 LR -0.0798 LKL 0.0255\n",
      "epoch 8287 loss -0.0556 LR -0.0808 LKL 0.0252\n",
      "epoch 8288 loss -0.0100 LR -0.0351 LKL 0.0252\n",
      "epoch 8289 loss -0.0336 LR -0.0591 LKL 0.0255\n",
      "epoch 8290 loss -0.0118 LR -0.0369 LKL 0.0251\n",
      "epoch 8291 loss -0.0537 LR -0.0791 LKL 0.0254\n",
      "epoch 8292 loss -0.0701 LR -0.0953 LKL 0.0253\n",
      "epoch 8293 loss 0.0134 LR -0.0120 LKL 0.0254\n",
      "epoch 8294 loss -0.0712 LR -0.0966 LKL 0.0254\n",
      "epoch 8295 loss 0.0212 LR -0.0040 LKL 0.0252\n",
      "epoch 8296 loss -0.0099 LR -0.0356 LKL 0.0256\n",
      "epoch 8297 loss -0.1112 LR -0.1367 LKL 0.0255\n",
      "epoch 8298 loss -0.0805 LR -0.1062 LKL 0.0257\n",
      "epoch 8299 loss -0.0096 LR -0.0348 LKL 0.0252\n",
      "epoch 8300 loss -0.0221 LR -0.0475 LKL 0.0254\n",
      "60\n",
      "epoch 8301 loss -0.0486 LR -0.0740 LKL 0.0254\n",
      "epoch 8302 loss -0.0279 LR -0.0531 LKL 0.0251\n",
      "epoch 8303 loss -0.0145 LR -0.0399 LKL 0.0254\n",
      "epoch 8304 loss -0.0071 LR -0.0324 LKL 0.0254\n",
      "epoch 8305 loss -0.0261 LR -0.0511 LKL 0.0250\n",
      "epoch 8306 loss -0.0167 LR -0.0420 LKL 0.0253\n",
      "epoch 8307 loss -0.1013 LR -0.1265 LKL 0.0252\n",
      "epoch 8308 loss -0.0644 LR -0.0898 LKL 0.0255\n",
      "epoch 8309 loss -0.0747 LR -0.1001 LKL 0.0254\n",
      "epoch 8310 loss -0.0499 LR -0.0750 LKL 0.0251\n",
      "epoch 8311 loss -0.0387 LR -0.0638 LKL 0.0251\n",
      "epoch 8312 loss -0.1039 LR -0.1291 LKL 0.0252\n",
      "epoch 8313 loss -0.0812 LR -0.1064 LKL 0.0252\n",
      "epoch 8314 loss -0.0228 LR -0.0476 LKL 0.0249\n",
      "epoch 8315 loss -0.0568 LR -0.0819 LKL 0.0251\n",
      "epoch 8316 loss -0.0688 LR -0.0939 LKL 0.0251\n",
      "epoch 8317 loss -0.0441 LR -0.0692 LKL 0.0251\n",
      "epoch 8318 loss -0.0301 LR -0.0551 LKL 0.0250\n",
      "epoch 8319 loss -0.0262 LR -0.0516 LKL 0.0254\n",
      "epoch 8320 loss 0.0086 LR -0.0165 LKL 0.0251\n",
      "epoch 8321 loss 0.0247 LR -0.0003 LKL 0.0250\n",
      "epoch 8322 loss -0.0749 LR -0.0999 LKL 0.0250\n",
      "epoch 8323 loss -0.0253 LR -0.0505 LKL 0.0252\n",
      "epoch 8324 loss -0.0384 LR -0.0632 LKL 0.0248\n",
      "epoch 8325 loss -0.0745 LR -0.0996 LKL 0.0251\n",
      "epoch 8326 loss -0.0797 LR -0.1047 LKL 0.0250\n",
      "epoch 8327 loss -0.0999 LR -0.1253 LKL 0.0254\n",
      "epoch 8328 loss -0.0230 LR -0.0479 LKL 0.0249\n",
      "epoch 8329 loss -0.0296 LR -0.0544 LKL 0.0249\n",
      "epoch 8330 loss -0.0321 LR -0.0574 LKL 0.0252\n",
      "epoch 8331 loss -0.0472 LR -0.0725 LKL 0.0253\n",
      "epoch 8332 loss -0.0236 LR -0.0485 LKL 0.0249\n",
      "epoch 8333 loss -0.0415 LR -0.0665 LKL 0.0249\n",
      "epoch 8334 loss -0.0587 LR -0.0839 LKL 0.0252\n",
      "epoch 8335 loss -0.0402 LR -0.0653 LKL 0.0251\n",
      "epoch 8336 loss -0.0963 LR -0.1213 LKL 0.0249\n",
      "epoch 8337 loss -0.0992 LR -0.1245 LKL 0.0254\n",
      "epoch 8338 loss 0.0365 LR 0.0114 LKL 0.0251\n",
      "epoch 8339 loss -0.0460 LR -0.0714 LKL 0.0254\n",
      "epoch 8340 loss -0.0469 LR -0.0717 LKL 0.0247\n",
      "epoch 8341 loss -0.0322 LR -0.0572 LKL 0.0251\n",
      "epoch 8342 loss -0.0658 LR -0.0909 LKL 0.0250\n",
      "epoch 8343 loss -0.0001 LR -0.0252 LKL 0.0251\n",
      "epoch 8344 loss -0.0551 LR -0.0805 LKL 0.0253\n",
      "epoch 8345 loss -0.0691 LR -0.0943 LKL 0.0251\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16684/4012017532.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msketchRNN_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     '''\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16684/2731887533.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# encode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# create start of sequence（sos）:拓展一维(1,100,5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16684/146493954.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, batch_size)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mcell_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc_hidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#bi-SLTM单元状态\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mh_cell_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh_0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcell_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_cell_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mh_forward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_backward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#h_forward,h_backward[2,batchsize,hiddensize]->h[batchsize,2*hidden_size]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mh_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh_forward\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_backward\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    767\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[0;32m    770\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    771\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    model = sketchRNN_model()\n",
    "    for epoch in range(50001):\n",
    "        model.train(epoch)\n",
    "\n",
    "    '''\n",
    "    model.load('encoder.pth','decoder.pth')\n",
    "    model.conditional_generation(0)\n",
    "    #'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b742ceeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
